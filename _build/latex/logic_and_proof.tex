%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}


\usepackage{unixode}
\usepackage{bussproofs}
\usepackage{mylogic}
\usepackage{amsmath}
\definecolor{VerbatimBorderColor}{rgb}{0.7,0.7,0.7}


\title{Logic and Proof}
\date{Sep 04, 2024}
\release{3.18.4}
\author{Jeremy Avigad, Joseph Hua, Robert Y. Lewis, and Floris van Doorn}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction:id1}}\label{\detokenize{introduction::doc}}

\section{Mathematical Proof}
\label{\detokenize{introduction:mathematical-proof}}
\sphinxAtStartPar
Although there is written evidence of mathematical activity in Egypt as early as 3000 BC, many scholars locate the birth of mathematics proper in ancient Greece around the sixth century BC, when deductive proof was first introduced. Aristotle credited Thales of Miletus with recognizing the importance of not just what we know but how we know it, and finding grounds for knowledge in the deductive method. Around 300 BC, Euclid codified a deductive approach to geometry in his treatise, the \sphinxstyleemphasis{Elements}. Through the centuries, Euclid’s axiomatic style was held as a paradigm of rigorous argumentation, not just in mathematics, but in philosophy and the sciences as well.

\sphinxAtStartPar
Here is an example of an ordinary proof, in contemporary mathematical language. It establishes a fact that was known to the Pythagoreans.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} \(\sqrt 2\) is irrational, which is to say, it cannot be expressed as a fraction \(a / b\), where \(a\) and \(b\) are integers.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(\sqrt 2 = a / b\) for some pair of integers \(a\) and \(b\). By removing any common factors, we can assume \(a / b\) is in lowest terms, so that \(a\) and \(b\) have no factor in common. Then we have \(a = \sqrt 2 b\), and squaring both sides, we have \(a^2 = 2 b^2\).

\sphinxAtStartPar
The last equation implies that \(a^2\) is even, and since the square of an odd number is odd, \(a\) itself must be even as well. We therefore have \(a = 2c\) for some integer \(c\). Substituting this into the equation \(a^2 = 2 b^2\), we have \(4 c^2 = 2 b^2\), and hence \(2 c^2 = b^2\). This means that \(b^2\) is even, and so \(b\) is even as well.

\sphinxAtStartPar
The fact that \(a\) and \(b\) are both even contradicts the fact that \(a\) and \(b\) have no common factor. So the original assumption that \(\sqrt 2 = a / b\) is false.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In the next example, we focus on the natural numbers,
\begin{equation*}
\begin{split}\mathbb{N} = \{ 0, 1, 2, \ldots \}.\end{split}
\end{equation*}
\sphinxAtStartPar
A natural number \(n\) greater than or equal to 2 is said to be \sphinxstyleemphasis{composite} if it can be written as a product \(n = m \cdot k\) where neither \(m\) nor \(k\) is equal to \(1\), and \sphinxstyleemphasis{prime} otherwise. Notice that if \(n = m \cdot k\) witnesses the fact that \(n\) is composite, then \(m\) and \(k\) are both smaller than \(n\). Notice also that, by convention, 0 and 1 are considered neither prime nor composite.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every natural number greater than or equal to 2 can be written as a product of primes.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We proceed by induction on \(n\). Let \(n\) be any natural number greater than 2. If \(n\) is prime, we are done; we can consider \(n\) itself as a product with one term. Otherwise, \(n\) is composite, and we can write \(n = m \cdot k\) where \(m\) and \(k\) are smaller than \(n\) and greater than 1. By the inductive hypothesis, each of \(m\) and \(k\) can be written as a product of primes, say
\(m = p_1 \cdot p_2 \cdot \ldots \cdot p_u\) and \(k = q_1 \cdot q_2 \cdot \ldots \cdot q_v\). But then we have
\begin{equation*}
\begin{split}n = m \cdot k = p_1 \cdot p_2 \cdot \ldots \cdot p_u \cdot q_1 \cdot
q_2 \cdot \ldots \cdot q_v,\end{split}
\end{equation*}
\sphinxAtStartPar
a product of primes, as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Later, we will see that more is true: every natural number greater than 2 can be written as a product of primes in a unique way, a fact known as the \sphinxstyleemphasis{fundamental theorem of arithmetic}.

\sphinxAtStartPar
The first goal of this course is to teach you to write clear, readable mathematical proofs. We will do this by considering a number of examples, but also by taking a reflective point of view: we will carefully study the components of mathematical language and the structure of mathematical proofs, in order to gain a better understanding of how they work.


\section{Symbolic Logic}
\label{\detokenize{introduction:symbolic-logic}}
\sphinxAtStartPar
Toward understanding how proofs work, it will be helpful to study a subject known as “symbolic logic,” which provides an idealized model of mathematical language and proof. In the \sphinxstyleemphasis{Prior Analytics}, the ancient Greek philosopher set out to analyze patterns of reasoning, and developed the theory of the \sphinxstyleemphasis{syllogism}. Here is one instance of a syllogism:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Every man is an animal.

\sphinxAtStartPar
Every animal is mortal.

\sphinxAtStartPar
Therefore every man is mortal.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Aristotle observed that the correctness of this inference has nothing to do with the truth or falsity of the individual statements, but, rather, the general pattern:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Every A is B.

\sphinxAtStartPar
Every B is C.

\sphinxAtStartPar
Therefore every A is C.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can substitute various properties for A, B, and C; try substituting the properties of being a fish, being a unicorn, being a swimming creature, being a mythical creature, etc. The various statements that result may come out true or false, but all the instantiations will have the following crucial feature: if the two hypotheses come out true, then the conclusion comes out true as well. We express this by saying that the inference is \sphinxstyleemphasis{valid}.

\sphinxAtStartPar
Although the patterns of language addressed by Aristotle’s theory of reasoning are limited, we have him to thank for a crucial insight: we can classify valid patterns of inference by their logical form, while abstracting away specific content. It is this fundamental observation that underlies the entire field of symbolic logic.

\sphinxAtStartPar
In the seventeenth century, Leibniz proposed the design of a \sphinxstyleemphasis{characteristica universalis}, a universal symbolic language in which one would express any assertion in a precise way, and a \sphinxstyleemphasis{calculus ratiocinatur}, a “calculus of thought” which would express the precise rules of reasoning. Leibniz himself took some steps to develop such a language and calculus, but much greater strides were made in the nineteenth century, through the work of Boole, Frege, Peirce, Schroeder, and others. Early in the twentieth century, these efforts blossomed into the field of mathematical logic.

\sphinxAtStartPar
If you consider the examples of proofs in the last section, you will notice that some terms and rules of inference are specific to the subject matter at hand, having to do with numbers and the properties of being prime, composite, even, odd, and so on. But there are other terms and rules of inference that are not domain specific, such as those related to the words “every,” “some,” “and,” and “if … then.” The goal of symbolic logic is to identify these core elements of reasoning and argumentation and explain how they work, as well as to explain how more domain\sphinxhyphen{}specific notions are introduced and used.

\sphinxAtStartPar
To that end, we will introduce symbols for key logical notions, including the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \to B\), “\(\mbox{if $A$ then $B$}\)”

\item {} 
\sphinxAtStartPar
\(A \wedge B\), “\(\mbox{$A$ and $B$}\)”

\item {} 
\sphinxAtStartPar
\(A \vee B\), “\(\mbox{$A$ or $B$}\)”

\item {} 
\sphinxAtStartPar
\(\neg A\), “\(\mbox{not $A$}\)”

\item {} 
\sphinxAtStartPar
\(\forall x \; A\), “\(\mbox{for every $x$, $A$}\)”

\item {} 
\sphinxAtStartPar
\(\exists x \; A\), “\(\mbox{for some $x$, $A$}\)”

\end{itemize}

\sphinxAtStartPar
We will then provide a formal proof system that will let us establish, deductively, that certain entailments between such statements are valid.

\sphinxAtStartPar
The proof system we will use is a version of \sphinxstyleemphasis{natural deduction}, a type of proof system introduced by Gerhard Gentzen in the 1930s to model informal styles of argument. In this system, the fundamental unit of judgment is the assertion that a statement, \(A\), follows from a finite set of hypotheses, \(\Gamma\). This is written as \(\Gamma \vdash A\). If \(\Gamma\) and \(\Delta\) are two finite sets of hypotheses, we will write \(\Gamma, \Delta\) for the \sphinxstyleemphasis{union} of these two sets, that is, the set consisting of all the hypotheses in each. With these conventions, the rule for the conjunction
symbol can be expressed as follows:



\begin{prooftree}
\def\fCenter{\ \vdash\ }
\Axiom$\Gamma \fCenter A$
\Axiom$\Delta \fCenter B$
\BinaryInf$\Gamma, \Delta \fCenter A \wedge B$
\end{prooftree}

\sphinxAtStartPar
This should be interpreted as saying: assuming \(A\) follows from the hypotheses \(\Gamma\), and \(B\) follows from the hypotheses \(\Delta\), \(A \wedge B\) follows from the hypotheses in both \(\Gamma\) and \(\Delta\).

\sphinxAtStartPar
We will see that one can write such proofs more compactly leaving the hypotheses implicit, so that the rule above is expressed as follows:



\begin{prooftree}
\AxiomC{$A$}
\AxiomC{$B$}
\BinaryInfC{$A \wedge B$}
\end{prooftree}

\sphinxAtStartPar
In this format, a snippet of the first proof in the previous section might be rendered as follows:



\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\neg \mathit{even}(b)$}
\AxiomC{$\forall x \; (\neg \mathit{even}(x) \to \neg \mathit{even}(x^2))$}
\UnaryInfC{$\neg \mathit{even}(b) \to \neg \mathit{even}(b^2)$}
\BinaryInfC{$\neg \mathit{even}(b^2)$}
\AxiomC{$\mathit{even}(b^2)$}
\BinaryInfC{$\bot$}
\UnaryInfC{$\mathit{even}(b)$}
\end{prooftree}

\sphinxAtStartPar
The complexity of such proofs can quickly grow out of hand, and complete proofs of even elementary mathematical facts can become quite long. Such systems are not designed for writing serious mathematics. Rather, they provide idealized models of mathematical inference, and insofar as they capture something of the structure of an informal proof, they enable us to study the properties of mathematical reasoning.

\sphinxAtStartPar
The second goal of this course is to help you understand natural deduction, as an example of a formal deductive system.


\section{Interactive Theorem Proving}
\label{\detokenize{introduction:interactive-theorem-proving}}
\sphinxAtStartPar
Early work in mathematical logic aimed to show that ordinary mathematical arguments could be modeled in symbolic calculi, at least in principle. As noted above, complexity issues limit the range of what can be accomplished in practice; even elementary mathematical arguments require long derivations that are hard to write and hard to read, and do little to promote understanding of the underlying mathematics.

\sphinxAtStartPar
Since the end of the twentieth century, however, the advent of computational proof assistants has begun to make complete formalization feasible. Working interactively with theorem proving software, users can construct formal derivations of complex theorems that can be stored and checked by computer. Automated methods can be used to fill in small gaps by hand, verify long calculations axiomatically, or fill in long chains of inferences deterministically. The reach of automation is currently fairly limited, however. The strategy used in interactive theorem proving is to ask users to provide just enough information for the system to be able to construct and check a formal derivation. This typically involves writing proofs in a sort of “programming language” that is designed with that purpose in mind. For example, here is a short proof in the \sphinxstyleemphasis{Lean} theorem prover:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{n}{Q} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{theorem} \PYG{n}{my\PYGZus{}theorem} \PYG{o}{:} \PYG{n}{P} \PYG{n+nb+bp}{∧} \PYG{n}{Q} \PYG{n+nb+bp}{→} \PYG{n}{Q} \PYG{n+nb+bp}{∧} \PYG{n}{P} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rintro} \PYG{n}{h} \PYG{o}{:} \PYG{n}{P} \PYG{n+nb+bp}{∧} \PYG{n}{Q}
  \PYG{n}{apply} \PYG{n}{And.intro}
  \PYG{n+nb+bp}{.} \PYG{n}{apply} \PYG{n}{And.right} \PYG{n}{h}
  \PYG{n+nb+bp}{.} \PYG{n}{apply} \PYG{n}{And.left} \PYG{n}{h}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you are reading the present text in online form, you will find a button above the formal “proof script” that says “try it!” Pressing the button opens the proof in an editor window and runs a version of Lean inside your browser to process the proof, turn it into an axiomatic derivation, and verify its correctness. You can experiment by varying the text in the editor; any errors will be noted in the window to the right.

\sphinxAtStartPar
Proofs in Lean can access a library of prior mathematical results, all verified down to axiomatic foundations. A goal of the field of interactive theorem proving is to reach the point where any contemporary theorem can be verified in this way. For example, here is a formal proof that the square root of two is irrational, following the model of the informal proof presented above:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Prime}
\PYG{k+kn}{open} \PYG{n}{Nat}
\PYG{k+kn}{open} \PYG{n}{Prime}

\PYG{k+kn}{section}

\PYG{k+kd}{theorem} \PYG{n}{sqrt\PYGZus{}two\PYGZus{}irrational} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{co} \PYG{o}{:} \PYG{n}{gcd} \PYG{n}{a} \PYG{n}{b} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{o}{:}
    \PYG{n}{a}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{n+nb+bp}{≠} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{b}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rintro} \PYG{n}{h} \PYG{o}{:} \PYG{n}{a}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{b}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{a}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{simp} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{a} \PYG{o}{:=}
  \PYG{n}{dvd\PYGZus{}of\PYGZus{}dvd\PYGZus{}pow} \PYG{n}{prime\PYGZus{}two} \PYG{n}{this}
  \PYG{n}{apply} \PYG{n}{Exists.elim} \PYG{n}{this}
  \PYG{n}{rintro} \PYG{n}{c} \PYG{n}{aeq}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{c}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{b}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{simp} \PYG{o}{[}\PYG{n}{Eq.symm} \PYG{n}{h}\PYG{o}{,} \PYG{n}{aeq}\PYG{o}{]}\PYG{n+nb+bp}{;}
    \PYG{n}{simp} \PYG{o}{[}\PYG{n}{pow\PYGZus{}succ\PYGZsq{}} \PYG{n}{\PYGZus{}}\PYG{o}{,} \PYG{n}{mul\PYGZus{}comm}\PYG{o}{,} \PYG{n}{mul\PYGZus{}assoc}\PYG{o}{,} \PYG{n}{mul\PYGZus{}left\PYGZus{}comm}\PYG{o}{]}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{c}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{n+nb+bp}{=} \PYG{n}{b}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{apply} \PYG{n}{mul\PYGZus{}left\PYGZus{}cancel₀} \PYG{n}{\PYGZus{}} \PYG{n}{this}
    \PYG{n}{decide}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{b}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{simp} \PYG{o}{[}\PYG{n}{Eq.symm} \PYG{n}{this}\PYG{o}{]}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{b} \PYG{o}{:=} \PYG{k+kd}{by}
        \PYG{n}{apply} \PYG{n}{dvd\PYGZus{}of\PYGZus{}dvd\PYGZus{}pow} \PYG{n}{prime\PYGZus{}two} \PYG{n}{this}
  \PYG{k}{have} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{gcd} \PYG{n}{a} \PYG{n}{b} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{apply} \PYG{n}{dvd\PYGZus{}gcd}
    \PYG{n+nb+bp}{.} \PYG{n}{assumption}
    \PYG{n+nb+bp}{.} \PYG{n}{assumption}
  \PYG{k}{have} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{o}{(}\PYG{l+m+mi}{1} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{simp} \PYG{o}{[}\PYG{n}{co}\PYG{o}{]} \PYG{n}{at} \PYG{n+nb+bp}{*}
  \PYG{n}{contradiction}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The third goal of this course is to teach you to write elementary proofs in Lean. The facts that we will ask you to prove in Lean will be more elementary than the informal proofs we will ask you to write, but our intent is that formal proofs will model and clarify the informal proof strategies we will teach you.


\section{The Semantic Point of View}
\label{\detokenize{introduction:the-semantic-point-of-view}}
\sphinxAtStartPar
As we have presented the subject here, the goal of symbolic logic is to specify a language and rules of inference that enable us to get at the truth in a reliable way. The idea is that the symbols we choose denote objects and concepts that have a fixed meaning, and the rules of inference we adopt enable us to draw true conclusions from true hypotheses.

\sphinxAtStartPar
One can adopt another view of logic, however, as a system where some symbols have a fixed meaning, such as the symbols for “and,” “or,” and “not,” and others have a meaning that is taken to vary. For example, the expression \(P \wedge (Q \vee R)\), read “\(P\) and either \(Q\) or \(R\),” may be true or false \sphinxstyleemphasis{depending on the basic assertions that} \(P\), \(Q\), \sphinxstyleemphasis{and} \(R\) \sphinxstyleemphasis{stand for}. More precisely, the truth of the compound expression depends only on whether the component symbols denote expressions that are true or false. For example, if \(P\), \(Q\), and \(R\) stand for “seven is prime,” “seven is even,” and “seven is odd,” respectively, then the expression is true. If we replace “seven” by “six,” the statement is false. More generally, the expression comes out true whenever \(P\) is true and at least one of \(Q\) and \(R\) is true, and false otherwise.

\sphinxAtStartPar
From this perspective, logic is not so much a language for asserting truth, but a language for describing possible states of affairs. In other words, logic provides a specification language, with expressions that can be true or false depending on how we interpret the symbols that are allowed to vary. For example, if we fix the meaning of the basic predicates, the statement “there is a red block between two blue blocks” may be true or false of a given “world” of blocks, and we can take the expression to describe the set of worlds in which it is true. Such a view of logic is important in computer science, where we use logical expressions to select entries from a database matching certain criteria, to specify properties of hardware and software systems, or to assert constraints that we would like a constraint solver to satisfy.

\sphinxAtStartPar
There are important connections between the syntactic / deductive point of view on the one hand, and the semantic / model\sphinxhyphen{}theoretic point of view on the other. We will explore some of these along the way. For example, we will see that it is possible to view the “valid” assertions as those that are true under all possible interpretations of the non\sphinxhyphen{}fixed symbols, and the “valid” inferences as those that maintain truth in all possible states and affairs. From this point of view, a deductive system should only allow us to derive valid assertions and entailments, a property known as \sphinxstyleemphasis{soundness}. If a deductive system is strong enough to allow us to verify \sphinxstyleemphasis{all} valid assertions and entailments, it is said to be \sphinxstyleemphasis{complete}.

\sphinxAtStartPar
The fourth goal of this course is to convey the semantic view of logic, and to lead you to understand how logical expressions can be used to specify states of affairs.


\section{Goals Summarized}
\label{\detokenize{introduction:goals-summarized}}
\sphinxAtStartPar
To summarize, these are the goals of this course:
\begin{itemize}
\item {} 
\sphinxAtStartPar
You should learn to write clear, “literate,” mathematical proofs.

\item {} 
\sphinxAtStartPar
You should become comfortable with symbolic logic and the formal modeling of deductive proof.

\item {} 
\sphinxAtStartPar
You should learn how to use an interactive proof assistant.

\item {} 
\sphinxAtStartPar
You should understand how to use logic as a precise language for making claims about systems of objects and the relationships between them, and specifying certain states of affairs.

\end{itemize}

\sphinxAtStartPar
Let us take a moment to consider the relationship between some of these goals. It is important not to confuse the first three. We are dealing with three kinds of mathematical language: ordinary mathematical language, the symbolic representations of mathematical logic, and computational implementations in interactive proof assistants. These are very different things!

\sphinxAtStartPar
Symbolic logic is not meant to replace ordinary mathematical language, and you should not use symbols like \(\wedge\) and \(\vee\) in ordinary mathematical proofs any more than you would use them in place of the words “and” and “or” in letters home to your parents. Natural languages provide nuances of expression that can convey levels of meaning and understanding that go beyond pattern matching to verify correctness. At the same time, modeling mathematical language with symbolic expressions provides a level of precision that makes it possible to turn mathematical language itself into an object of study. Each has its place, and we hope to get you to appreciate the value of each without confusing the two.

\sphinxAtStartPar
The proof languages used by interactive theorem provers lie somewhere between the two extremes. On the one hand, they have to be specified with enough precision for a computer to process them and act appropriately; on the other hand, they aim to capture some of the higher\sphinxhyphen{}level nuances and features of informal language in a way that enables us to write more complex arguments and proofs. Rooted in symbolic logic and designed with ordinary mathematical language in mind, they aim to bridge the gap between the two.

\sphinxAtStartPar
This book also aims to show you how mathematics is built up from fundamental concepts. Logic provides the rules of the game, and then we work our way up from properties of sets, relations, functions, and the natural numbers to elementary number theory, combinatorics, and properties of the real numbers. The last chapter rounds out the story with a discussion of axiomatic foundations.


\section{About this Textbook}
\label{\detokenize{introduction:about-this-textbook}}
\sphinxAtStartPar
Both this online textbook and the \sphinxstyleemphasis{Lean} theorem prover are ongoing projects.
The original \sphinxcode{\sphinxupquote{lean3}} version of this textbook
is available \sphinxhref{https://leanprover.github.io/logic\_and\_proof\_lean3/index.html}{here}.
This version introduces \sphinxcode{\sphinxupquote{lean4}} instead.

\sphinxAtStartPar
You can learn more about Lean from its \sphinxhref{http://leanlang.org}{project page},
the Lean \sphinxhref{http://leanprover-community.github.io/}{community pages}, and the online textbook,
\sphinxhref{http://leanprover.github.io/theorem\_proving\_in\_lean4/}{Theorem Proving in Lean}.

\sphinxAtStartPar
The original textbook was written by Jeremy Avigad, Robert Y. Lewis, and Floris van Doorn.
This was adapted to \sphinxcode{\sphinxupquote{lean4}} by Joseph Hua.
We are grateful for feedback and corrections from a number of people,
including Bruno Cuconato, William DeMeo, Tobias Grosser, Lyle Kopnicky,
Alexandre Rademaker, Matt Rice, and Jason Siefken.


\chapter{Propositional Logic}
\label{\detokenize{propositional_logic:propositional-logic}}\label{\detokenize{propositional_logic:id1}}\label{\detokenize{propositional_logic::doc}}

\section{A Puzzle}
\label{\detokenize{propositional_logic:a-puzzle}}
\sphinxAtStartPar
The following puzzle, titled “Malice and Alice,” is from George J. Summers’ \sphinxstyleemphasis{Logical Deduction Puzzles}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice, Alice’s husband, their son, their daughter, and Alice’s brother were involved in a murder. One of the five killed one of the other four. The following facts refer to the five people mentioned:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
A man and a woman were together in a bar at the time of the murder.

\item {} 
\sphinxAtStartPar
The victim and the killer were together on a beach at the time of the murder.

\item {} 
\sphinxAtStartPar
One of Alice’s two children was alone at the time of the murder.

\item {} 
\sphinxAtStartPar
Alice and her husband were not together at the time of the murder.

\item {} 
\sphinxAtStartPar
The victim’s twin was not the killer.

\item {} 
\sphinxAtStartPar
The killer was younger than the victim.

\end{enumerate}

\sphinxAtStartPar
Which one of the five was the victim?


\bigskip\hrule\bigskip


\sphinxAtStartPar
Take some time to try to work out a solution. (You should assume that the victim’s twin is one of the five people mentioned.) Summers’ book offers the following hint: “First find the locations of two pairs of people at the time of the murder, and then determine who the killer and the victim were so that no condition is contradicted.”


\section{A Solution}
\label{\detokenize{propositional_logic:a-solution}}
\sphinxAtStartPar
If you have worked on the puzzle, you may have noticed a few things. First, it is helpful to draw a diagram, and to be systematic about searching for an answer. The number of characters, locations, and attributes is finite, so that there are only finitely many possible “states of affairs” that need to be considered. The numbers are also small enough so that systematic search through all the possibilities, though tedious, will eventually get you to the right answer. This is a special feature of logic puzzles like this; you would not expect to show, for example, that every even number greater than two can be written as a sum of primes by running through all the possibilities.

\sphinxAtStartPar
Another thing that you may have noticed is that the question seems to presuppose that there is a unique answer to the question, which is to say, over all the states of affairs that meet the list of conditions, there is only one person who can possibly be the killer. \sphinxstyleemphasis{A priori}, without that assumption, there is a difference between finding \sphinxstyleemphasis{some} person who could have been the victim and showing that that person \sphinxstyleemphasis{had} to be the victim. In other words, there is a difference between exhibiting some state of affairs that meets the criteria and demonstrating conclusively that no other solution is possible.

\sphinxAtStartPar
The published solution in the book not only produces a state of affairs that meets the criterion, but at the same time proves that this is the only one that does so. It is quoted below, in full.


\bigskip\hrule\bigskip


\sphinxAtStartPar
From (1), (2), and (3), the roles of the five people were as follows: Man and Woman in the bar, Killer and Victim on the beach, and Child alone.

\sphinxAtStartPar
Then, from (4), either Alice’s husband was in the bar and Alice was on the beach, or Alice was in the bar and Alice’s husband was on the beach.

\sphinxAtStartPar
If Alice’s husband was in the bar, the woman he was with was his daughter, the child who was alone was his son, and Alice and her brother were on the beach. Then either Alice or her brother was the victim; so the other was the killer. But, from (5), the victim had a twin, and this twin was innocent. Since Alice and her brother could only be twins to each other, this situation is impossible. Therefore Alice’s husband was not in the bar.

\sphinxAtStartPar
So Alice was in the bar. If Alice was in the bar, she was with her brother or her son.

\sphinxAtStartPar
If Alice was with her brother, her husband was on the beach with one of the two children. From (5), the victim could not be her husband, because none of the others could be his twin; so the killer was her husband and the victim was the child he was with. But this situation is impossible, because it contradicts (6). Therefore, Alice was not with her brother in the bar.

\sphinxAtStartPar
So Alice was with her son in the bar. Then the child who was alone was her daughter. Therefore, Alice’s husband was with Alice’s brother on the beach. From previous reasoning, the victim could not be Alice’s husband. But the victim could be Alice’s brother because Alice could be his twin.

\sphinxAtStartPar
So \sphinxstyleemphasis{Alice’s brother was the victim} and Alice’s husband was the killer.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This argument relies on some “extralogical” elements, for example, that a father cannot be younger than his child, and that a parent and his or her child cannot be twins. But the argument also involves a number of common logical terms and associated patterns of inference. In the next section, we will focus on some of the key logical terms occurring in the argument above, words like “and,” “or,” “not,” and “if … then.”

\sphinxAtStartPar
Our goal is to give an account of the patterns of inference that govern the use of those terms. To that end, using the methods of symbolic logic, we will introduce variables \(A\), \(B\), \(C\), … to stand for fundamental statements, or \sphinxstyleemphasis{propositions}, and symbols \(\wedge\), \(\vee\), \(\neg\), and \(\to\) to stand for “and,” “or,” “not,” and “if … then … ,” respectively. Doing so will let us focus on the way that compound statements are built up from basic ones using the logical terms, while abstracting away from the specific content. We will also adopt a stylized notation for representing inferences as \sphinxstyleemphasis{rules}: the inscription



\begin{center}
\AXM{A}
\AXM{B}
\BIM{C}
\DP
\end{center}

\sphinxAtStartPar
indicates that statement \(C\) is a \sphinxstyleemphasis{logical consequence} of \(A\) and \(B\).


\section{Rules of Inference}
\label{\detokenize{propositional_logic:rules-of-inference}}

\subsection{Implication}
\label{\detokenize{propositional_logic:implication}}
\sphinxAtStartPar
The first pattern of inference we will discuss, involving the “if … then …” construct, can be hard to discern. Its use is largely implicit in the solution above. The inference in the fourth paragraph, spelled out in greater detail, runs as follows:


\bigskip\hrule\bigskip


\sphinxAtStartPar
If Alice was in the bar, Alice was with her brother or her son.

\sphinxAtStartPar
Alice was in the bar.

\sphinxAtStartPar
Alice was with her brother or son.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This rule is sometimes known as \sphinxstyleemphasis{modus ponens}, or “implication elimination,” since it tells us how to use an implication in an argument. As a rule, it is expressed as follows:



\begin{center}
\AXM{A \to B}
\AXM{A}
\RLM{\mathord{\to}\mathrm{E}}
\BIM{B}
\DP
\end{center}

\sphinxAtStartPar
Read this as saying that if you have a proof of \(A \to B\), possibly from some hypotheses, and a proof of \(A\), possibly from hypotheses, then combining these yields a proof of \(B\), from the hypotheses in both subproofs.

\sphinxAtStartPar
The rule for deriving an “if … then” statement is more subtle. Consider the beginning of the third paragraph, which argues that if Alice’s husband was in the bar, then Alice or her brother was the victim. Abstracting away some of the details, the argument has the following form:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose Alice’s husband was in the bar.

\sphinxAtStartPar
Then …

\sphinxAtStartPar
Then …

\sphinxAtStartPar
Then Alice or her brother was the victim.

\sphinxAtStartPar
Thus, if Alice’s husband was in the bar, then Alice or her brother was the victim.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This is a form of \sphinxstyleemphasis{hypothetical reasoning}. On the supposition that \(A\) holds, we argue that \(B\) holds as well. If we are successful, we have shown that \(A\) implies \(B\), without supposing \(A\). In other words, the temporary assumption that \(A\) holds is “canceled” by making it explicit in the conclusion.



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1 \; \; \mathord{\to}\mathrm{I}}
\UIM{A \to B}
\DP
\end{center}

\sphinxAtStartPar
The hypothesis is given the label \(1\); when the introduction rule is applied, the label \(1\) indicates the relevant hypothesis. The line over the hypothesis indicates that the assumption has been “canceled” by the introduction rule.


\subsection{Conjunction}
\label{\detokenize{propositional_logic:conjunction}}
\sphinxAtStartPar
As was the case for implication, other logical connectives are generally characterized by their \sphinxstyleemphasis{introduction} and \sphinxstyleemphasis{elimination} rules. An introduction rule shows how to establish a claim involving the connective, while an elimination rule shows how to use such a statement that contains the connective to derive others.

\sphinxAtStartPar
Let us consider, for example, the case of conjunction, that is, the word “and.” Informally, we establish a conjunction by establishing each conjunct. For example, informally we might argue:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice’s brother was the victim.

\sphinxAtStartPar
Alice’s husband was the killer.

\sphinxAtStartPar
Therefore Alice’s brother was the victim and Alice’s husband was the killer.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The inference seems almost too obvious to state explicitly, since the word “and” simply combines the two assertions into one. Informal proofs often downplay the distinction. In symbolic logic, the rule reads as follows:



\begin{center}
\AXM{A}
\AXM{B}
\RLM{\mathord{\wedge}\mathrm{I}}
\BIM{A \wedge B}
\DP
\end{center}

\sphinxAtStartPar
The two elimination rules allow us to extract the two components:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice’s husband was in the bar and Alice was on the beach.

\sphinxAtStartPar
So Alice’s husband was in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Or:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice’s husband was in the bar and Alice was on the beach.

\sphinxAtStartPar
So Alice was on the beach.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In symbols, these patterns are rendered as follows:



\begin{center}
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_l}}
\UIM{A}
\DP
\quad
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_r}}
\UIM{B}
\DP
\end{center}

\sphinxAtStartPar
Here the \(l\) and \(r\) stand for “left” and “right”.


\subsection{Negation and Falsity}
\label{\detokenize{propositional_logic:negation-and-falsity}}
\sphinxAtStartPar
In logical terms, showing “not A” amounts to showing that A leads to a contradiction. For example:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose Alice’s husband was in the bar.

\sphinxAtStartPar
…

\sphinxAtStartPar
This situation is impossible.

\sphinxAtStartPar
Therefore Alice’s husband was not in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This is another form of hypothetical reasoning, similar to that used in establishing an “if … then” statement: we temporarily assume A, show that leads to a contradiction, and conclude that “not A” holds. In symbols, the rule reads as follows:



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1 \; \; \neg \mathrm{I}}
\UIM{\neg A}
\DP
\end{center}

\sphinxAtStartPar
The elimination rule is dual to these. It expresses that if we have both “A” and “not A,” then we have a contradiction. This pattern is illustrated in the informal argument below, which is implicit in the fourth paragraph of the solution to “Malice and Alice.”


\bigskip\hrule\bigskip


\sphinxAtStartPar
The killer was Alice’s husband and the victim was the child he was with.

\sphinxAtStartPar
So the killer was not younger than his victim.

\sphinxAtStartPar
But according to (6), the killer was younger than his victim.

\sphinxAtStartPar
This situation is impossible.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In symbolic logic, the rule of inference is expressed as follows:



\begin{center}
\AXM{\neg A}
\AXM{A}
\RLM{\neg \mathrm{E}}
\BIM{\bot}
\DP
\end{center}

\sphinxAtStartPar
Notice also that in the symbolic framework, we have introduced a new symbol, \(\bot\). It corresponds to natural language phrases like “this is a contradiction” or “this is impossible.”

\sphinxAtStartPar
What are the rules governing \(\bot\)? In the proof system we will introduce in the next chapter, there is no introduction rule; “false” is false, and there should be no way to prove it, other than extract it from contradictory hypotheses. On the other hand, the system provides a rule that allows us to conclude anything from a contradiction:



\begin{center}
\AXM{\bot}
\RLM{\bot \mathrm{E}}
\UIM{A}
\DP
\end{center}

\sphinxAtStartPar
The elimination rule also has the fancy Latin name, \sphinxstyleemphasis{ex falso sequitur quodlibet}, which means “anything you want follows from falsity.”

\sphinxAtStartPar
This elimination rule is harder to motivate from a natural language perspective, but, nonetheless, it is needed to capture common patterns of inference. One way to understand it is this. Consider the following statement:


\bigskip\hrule\bigskip


\sphinxAtStartPar
For every natural number \(n\), if \(n\) is prime and greater than 2, then \(n\) is odd.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We would like to say that this is a true statement. But if it is true, then it is true of any particular number \(n\). Taking \(n = 2\), we have the statement:


\bigskip\hrule\bigskip


\sphinxAtStartPar
If 2 is prime and greater than 2, then 2 is odd.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In this conditional statement, both the antecedent and consequent are false. The fact that we are committed to saying that this statement is true shows that we should be able to prove, one way or another, that the statement 2 is odd follows from the false statement that 2 is prime and greater than 2. The \sphinxstyleemphasis{ex falso} neatly encapsulates this sort of
inference.

\sphinxAtStartPar
Notice that if we define \(\neg A\) to be \(A \to \bot\), then the rules for negation introduction and elimination are nothing more than implication introduction and elimination, respectively. We can think of \(\neg A\) expressed colorfully by saying “if \(A\) is true, then pigs have wings,” where “pigs have wings” stands for \(\bot\).

\sphinxAtStartPar
Having introduced a symbol for “false,” it is only fair to introduce a symbol for “true.” In contrast to “false,” “true” has no elimination rule, only an introduction rule:



\begin{prooftree}
\AXM{}
\UIM{\top}
\end{prooftree}

\sphinxAtStartPar
Put simply, “true” is true.


\subsection{Disjunction}
\label{\detokenize{propositional_logic:disjunction}}
\sphinxAtStartPar
The introduction rules for disjunction, otherwise known as “or,” are straightforward. For example, the claim that condition (3) is met in the proposed solution can be justified as follows:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice’s daughter was alone at the time of the murder.

\sphinxAtStartPar
Therefore, either Alice’s daughter was alone at the time of the murder, or Alice’s son was alone at the time of the murder.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In symbolic terms, the two introduction rules are as follows:



\begin{center}
\AXM{A}
\RLM{\mathord{\vee}\mathrm{I_l}}
\UIM{A \vee B}
\DP
\quad
\AXM{B}
\RLM{\mathord{\vee}\mathrm{I_r}}
\UIM{A \vee B}
\DP
\end{center}

\sphinxAtStartPar
Here, again, the \(l\) and \(r\) stand for “left” and “right”.

\sphinxAtStartPar
The disjunction elimination rule is trickier, but it represents a natural form of case\sphinxhyphen{}based hypothetical reasoning. The instances that occur in the solution to “Malice and Alice” are all special cases of this rule, so it will be helpful to make up a new example to illustrate the general phenomenon. Suppose, in the argument above, we had established that either Alice’s brother or her son was in the bar, and we wanted to argue for the conclusion that her husband was on the beach. One option is to argue by cases: first, consider the case that her brother was in the bar, and argue for the conclusion on the basis of that assumption; then consider the case that her son was in the bar, and argue for the same conclusion, this time on the basis of the second assumption. Since the two cases are exhaustive, if we know that the conclusion holds in each case, we know that it holds outright. The pattern looks something like this:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Either Alice’s brother was in the bar, or Alice’s son was in the bar.

\sphinxAtStartPar
Suppose, in the first case, that her brother was in the bar. Then … Therefore, her husband was on the beach.

\sphinxAtStartPar
On the other hand, suppose her son was in the bar. In that case, … Therefore, in this case also, her husband was on the beach.

\sphinxAtStartPar
Either way, we have established that her husband was on the beach.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In symbols, this pattern is expressed as follows:



\begin{center}
\AXM{A \vee B}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\RLM{1 \; \; \mathord{\vee}\mathrm{E}}
\TIM{C}
\DP
\end{center}

\sphinxAtStartPar
What makes this pattern confusing is that it requires two instances of nested hypothetical reasoning: in the first block of parentheses, we temporarily assume \(A\), and in the second block, we temporarily assume \(B\). When the dust settles, we have established \(C\) outright.

\sphinxAtStartPar
There is another pattern of reasoning that is commonly used with “or,”
as in the following example:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Either Alice’s husband was in the bar, or Alice was in the bar.

\sphinxAtStartPar
Alice’s husband was not in the bar.

\sphinxAtStartPar
So Alice was in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In symbols, we would render this rule as follows:



\begin{center}
\AXM{A \vee B}
\AXM{\neg A}
\BIM{B}
\DP
\end{center}

\sphinxAtStartPar
We will see in the next chapter that it is possible to \sphinxstyleemphasis{derive} this rule from the others. As a result, we will \sphinxstyleemphasis{not} take this to be a fundamental rule of inference in our system.


\subsection{If and only if}
\label{\detokenize{propositional_logic:if-and-only-if}}
\sphinxAtStartPar
In mathematical arguments, it is common to say of two statements, \(A\) and \(B\), that “\(A\) holds if and only if \(B\) holds.” This assertion is sometimes abbreviated “\(A\) iff \(B\),” and means simply that \(A\) implies \(B\) and \(B\) implies \(A\). It is not essential that we introduce a new symbol into our logical language to model this connective, since the statement can be expressed, as we just did, in terms of “implies” and “and.” But notice that the length of the expression doubles because \(A\) and \(B\) are each repeated. The logical abbreviation is therefore convenient, as well as natural.

\sphinxAtStartPar
The conditions of “Malice and Alice” imply that Alice is in the bar if and only if Alice’s husband is on the beach. Such a statement is established by arguing for each implication in turn:


\bigskip\hrule\bigskip


\sphinxAtStartPar
I claim that Alice is in the bar if and only if Alice’s husband is on the beach.

\sphinxAtStartPar
To see this, first suppose that Alice is in the bar.

\sphinxAtStartPar
Then …

\sphinxAtStartPar
Hence Alice’s husband is on the beach.

\sphinxAtStartPar
Conversely, suppose Alice’s husband is on the beach.

\sphinxAtStartPar
Then …

\sphinxAtStartPar
Hence Alice is in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that with this example, we have varied the form of presentation, stating the conclusion first, rather than at the end of the argument. This kind of “signposting” is common in informal arguments, in that is helps guide the reader’s expectations and foreshadow where the argument is going. The fact that formal systems of deduction do not generally model such nuances marks a difference between formal and informal arguments, a topic we will return to below.

\sphinxAtStartPar
The introduction is modeled in natural deduction as follows:



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{A}
\RLM{1 \; \; \liff \mathrm{I}}
\BIM{A \liff B}
\DP
\end{center}

\sphinxAtStartPar
The elimination rules for iff are unexciting. In informal language, here is the “left” rule:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice is in the bar if and only if Alice’s husband is on the beach.

\sphinxAtStartPar
Alice is in the bar.

\sphinxAtStartPar
Hence, Alice’s husband is on the beach.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The “right” rule simply runs in the opposite direction.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Alice is in the bar if and only if Alice’s husband is on the beach.

\sphinxAtStartPar
Alice’s husband is on the beach.

\sphinxAtStartPar
Hence, Alice is in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Rendered in natural deduction, the rules are as follows:



\begin{center}
\AXM{A \liff B}
\AXM{A}
\RLM{\liff \mathrm{E}_l}
\BIM{B}
\DP
\quad
\AXM{A \liff B}
\AXM{B}
\RLM{\liff \mathrm{E}_r}
\BIM{A}
\DP
\end{center}


\subsection{Proof by Contradiction}
\label{\detokenize{propositional_logic:proof-by-contradiction}}
\sphinxAtStartPar
We saw an example of an informal argument that implicitly uses the introduction rule for negation:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose Alice’s husband was in the bar.

\sphinxAtStartPar
…

\sphinxAtStartPar
This situation is impossible.

\sphinxAtStartPar
Therefore Alice’s husband was not in the bar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Consider the following argument:


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose Alice’s husband was not on the beach.

\sphinxAtStartPar
…

\sphinxAtStartPar
This situation is impossible.

\sphinxAtStartPar
Therefore Alice’s husband was on the beach.


\bigskip\hrule\bigskip


\sphinxAtStartPar
At first glance, you might think this argument follows the same pattern as the one before. But a closer look should reveal a difference: in the first argument, a negation is \sphinxstyleemphasis{introduced} into the conclusion, whereas in the second, it is \sphinxstyleemphasis{eliminated} from the hypothesis. Using negation introduction to close the second argument would yield the conclusion “It is not the case that Alice’s husband was not on the beach.” The rule of inference that replaces the conclusion with the positive statement that Alice’s husband \sphinxstyleemphasis{was} on the beach is called a \sphinxstyleemphasis{proof by contradiction}. (It also has a fancy name, \sphinxstyleemphasis{reductio ad absurdum}, “reduction to an absurdity.”)

\sphinxAtStartPar
It may be hard to see the difference between the two rules, because we commonly take the statement “Alice’s husband was not not on the beach” to be a roundabout and borderline ungrammatical way of saying that Alice’s husband was on the beach. Indeed, the rule is equivalent to adding an axiom that says that for every statement A, “not not A” is equivalent to A.

\sphinxAtStartPar
There is a style of doing mathematics known as “constructive mathematics” that denies the equivalence of “not not A” and A. Constructive arguments tend to have much better computational interpretations; a proof that something is true should provide explicit evidence that the statement is true, rather than evidence that it can’t possibly be false. We will discuss constructive reasoning in a later chapter. Nonetheless, proof by contradiction is used extensively in contemporary mathematics, and so, in the meanwhile, we will use proof by contradiction freely as one of our basic rules.

\sphinxAtStartPar
In natural deduction, proof by contradiction is expressed by the following pattern:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\neg A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{\mathrm{RAA}, 1}
\UIM{A}
\end{prooftree}

\sphinxAtStartPar
The assumption \(\neg A\) is canceled at the final inference.


\section{The Language of Propositional Logic}
\label{\detokenize{propositional_logic:the-language-of-propositional-logic}}
\sphinxAtStartPar
The language of propositional logic starts with symbols \(A\), \(B\), \(C\), … which are intended to range over basic assertions, or propositions, which can be true or false. Compound expressions are built up using parentheses and the logical symbols introduced in the last section. For example,
\begin{equation*}
\begin{split}((A \wedge (\neg B)) \to \neg (C \vee D))\end{split}
\end{equation*}
\sphinxAtStartPar
is an example of a propositional formula.

\sphinxAtStartPar
When writing expressions in symbolic logic, we will adopt an order of operations which allows us to drop superfluous parentheses. When parsing an expression:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Negation binds most tightly.

\item {} 
\sphinxAtStartPar
Then, conjunctions and disjunctions bind from right to left.

\item {} 
\sphinxAtStartPar
Finally, implications and bi\sphinxhyphen{}implications bind from right to left.

\end{itemize}

\sphinxAtStartPar
So, for example, the expression \(\neg A \vee B \to C \wedge D\) is understood as \(((\neg A) \vee B) \to (C \wedge D)\).

\sphinxAtStartPar
For example, suppose we assign the following variables:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A\): Alice’s husband was in the bar

\item {} 
\sphinxAtStartPar
\(B\): Alice was on the beach

\item {} 
\sphinxAtStartPar
\(C\): Alice was in the bar

\item {} 
\sphinxAtStartPar
\(D\): Alice’s husband was on the beach

\end{itemize}

\sphinxAtStartPar
Then the statement “either Alice’s husband was in the bar and Alice was on the beach, or Alice was in the bar and Alice’s husband was on the beach” would be rendered as
\begin{equation*}
\begin{split}(A \wedge B) \vee (C \wedge D).\end{split}
\end{equation*}
\sphinxAtStartPar
Sometimes the appropriate translation is not so straightforward, however. Because natural language is more flexible and nuanced, a degree of abstraction and regimentation is needed to carry out the translation. Sometimes different translations are arguably reasonable. In happy situations, alternative translations will be logically equivalent, in the sense that one can derive each from the other using purely logical rules. In less happy situations, the translations will not be equivalent, in which case the original statement is simply ambiguous, from a logical point of view. In cases like that, choosing a symbolic representation helps clarify the intended meaning.

\sphinxAtStartPar
Consider, for example, a statement like “Alice was with her son on the beach, but her husband was alone.” We might choose variables as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A\): Alice was on the beach

\item {} 
\sphinxAtStartPar
\(B\): Alice’s son was on the beach

\item {} 
\sphinxAtStartPar
\(C\): Alice’s husband was alone

\end{itemize}

\sphinxAtStartPar
In that case, we might represent the statement in symbols as \(A \wedge B \wedge C\). Using the word “with” may seem to connote more than the fact that Alice and her son were both on the beach; for example, it seems to connote that they aware of each others’ presence, interacting, etc. Similarly, although we have translated the word “but” and “and,” the word “but” also convey information; in this case, it seems to emphasize a contrast, while in other situations, it can be used to assert a fact that is contrary to expectations. In both cases, then, the logical rendering models certain features of the original sentence while abstracting others.


\section{Exercises}
\label{\detokenize{propositional_logic:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Here is another (gruesome) logic puzzle by George J. Summers, called “Murder in the Family.”
\begin{quote}

\sphinxAtStartPar
Murder occurred one evening in the home of a father and mother and their son and daughter. One member of the family murdered another member, the third member witnessed the crime, and the fourth member was an accessory after the fact.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
The accessory and the witness were of opposite sex.

\item {} 
\sphinxAtStartPar
The oldest member and the witness were of opposite sex.

\item {} 
\sphinxAtStartPar
The youngest member and the victim were of opposite sex.

\item {} 
\sphinxAtStartPar
The accessory was older than the victim.

\item {} 
\sphinxAtStartPar
The father was the oldest member.

\item {} 
\sphinxAtStartPar
The murderer was not the youngest member.

\end{enumerate}

\sphinxAtStartPar
Which of the four—father, mother, son, or daughter—was the murderer?
\end{quote}

\sphinxAtStartPar
Solve this puzzle, and \sphinxstyleemphasis{write a clear argument} to establish that your answer is correct.

\item {} 
\sphinxAtStartPar
Using the mnemonic \(F\) (Father), \(M\) (Mother), \(D\) (Daughter), \(S\) (Son), \(\mathord{Mu}\) (Murderer), \(V\) (Victim), \(W\) (Witness), \(A\) (Accessory), \(O\) (Oldest), \(Y\) (Youngest), we can define propositional variables like \(FM\) (Father is the Murderer), \(DV\) (Daughter is the Victim), \(FO\) (Father is Oldest), \(VY\) (Victim is Youngest), etc. Notice that only the son or daughter can be the youngest, and only the mother or father can be the oldest.

\sphinxAtStartPar
With these conventions, the first clue can be represented as
\begin{equation*}
\begin{split}((FA \vee SA) \to (MW \vee DW)) \wedge ((MA \vee DA) \to (FW \vee SW)),\end{split}
\end{equation*}
\sphinxAtStartPar
in other words, if the father or son was the accessory, then the mother or daughter was the witness, and vice\sphinxhyphen{}versa. Represent the other five clues in a similar manner.

\sphinxAtStartPar
Representing the fourth clue is tricky. Try to write down a formula that describes all the possibilities that are not ruled out by the information.

\item {} 
\sphinxAtStartPar
Consider the following three hypotheses:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Alan likes kangaroos, and either Betty likes frogs or Carl likes hamsters.

\item {} 
\sphinxAtStartPar
If Betty likes frogs, then Alan doesn’t like kangaroos.

\item {} 
\sphinxAtStartPar
If Carl likes hamsters, then Betty likes frogs.

\end{itemize}

\sphinxAtStartPar
Write a clear argument to show that these three hypotheses are contradictory.

\end{enumerate}


\chapter{Natural Deduction for Propositional Logic}
\label{\detokenize{natural_deduction_for_propositional_logic:natural-deduction-for-propositional-logic}}\label{\detokenize{natural_deduction_for_propositional_logic::doc}}
\sphinxAtStartPar
Reflecting on the arguments in the previous chapter, we see that, intuitively speaking, some inferences are \sphinxstyleemphasis{valid} and some are not. For example, if, in a chain of reasoning, we had established “\(A\) and \(B\),” it would seem perfectly reasonable to conclude \(B\). If we had established \(A\), \(B\), and “If \(A\) and \(B\) then \(C\),” it would be reasonable to conclude \(C\). On the other hand, if we had established “\(A\) or \(B\),” we would not be justified in concluding \(B\) without further information.

\sphinxAtStartPar
The task of symbolic logic is to develop a precise mathematical theory that explains which inferences are valid and why. There are two general approaches to spelling out the notion of validity. In this chapter, we will consider the \sphinxstyleemphasis{deductive} approach: an inference is valid if it can be justified by fundamental rules of reasoning that reflect the meaning of the logical terms involved. In \hyperref[\detokenize{semantics_of_propositional_logic:semantics-of-propositional-logic}]{Chapter \ref{\detokenize{semantics_of_propositional_logic:semantics-of-propositional-logic}}} we will consider the “semantic” approach: an inference is valid if it is an instance of a pattern that always yields a true conclusion from true hypotheses.


\section{Derivations in Natural Deduction}
\label{\detokenize{natural_deduction_for_propositional_logic:derivations-in-natural-deduction}}\label{\detokenize{natural_deduction_for_propositional_logic:id1}}
\sphinxAtStartPar
We have seen that the language of propositional logic allows us to build up expressions from propositional variables \(A, B, C, \ldots\) using propositional connectives like \(\to\), \(\wedge\), \(\vee\), and \(\neg\). We will now consider a formal deductive system that we can use to \sphinxstyleemphasis{prove} propositional formulas. There are a number of such systems on offer; the one will use is called \sphinxstyleemphasis{natural deduction}, designed by Gerhard Gentzen in the 1930s.

\sphinxAtStartPar
In natural deduction, every proof is a proof from \sphinxstyleemphasis{hypotheses}. In other words, in any proof, there is a finite set of hypotheses \(\{ B, C, \ldots \}\) and a conclusion \(A\), and what the proof shows is that \(A\) follows from \(B, C, \ldots\).

\sphinxAtStartPar
Like formulas, proofs are built by putting together smaller proofs, according to the rules. For instance, the way to read the and\sphinxhyphen{}introduction rule



\begin{center}
\AXM{A}
\AXM{B}
\BIM{A \wedge B}
\DP
\end{center}

\sphinxAtStartPar
is as follows: if you have a proof \(P_1\) of \(A\) from some hypotheses, and you have a proof \(P_2\) of \(B\) from some hypotheses, then you can put them together using this rule to obtain a proof of \(A \wedge B\), which uses all the hypotheses in \(P_1\) together with all the hypotheses in \(P_2\). For example, this is a proof of \((A \wedge B) \wedge (A \wedge C)\) from three hypotheses, \(A\), \(B\), and \(C\):



\begin{center}
\AXM{A}
\AXM{B}
\BIM{A \wedge B}
\AXM{A}
\AXM{C}
\BIM{A \wedge C}
\BIM{(A \wedge B) \wedge (A \wedge C)}
\DP
\end{center}

\sphinxAtStartPar
In some presentations of natural deduction, a proof is written as a sequence of lines in which each line can refer to any previous lines for justification. But here we will adopt a rigid two\sphinxhyphen{}dimensional diagrammatic format in which the premises of each inference appear immediately above the conclusion. This makes it easy to look over a proof and check that it is correct: each inference should be the result of instantiating the letters in one of the rules with particular formulas.

\sphinxAtStartPar
One thing that makes natural deduction confusing is that when you put together proofs in this way, hypotheses can be eliminated, or, as we will say, \sphinxstyleemphasis{canceled}. For example, we can apply the implies\sphinxhyphen{}introduction rule to the last proof, and obtain the following proof of \(B \to (A \wedge B) \wedge (A \wedge C)\) from only \sphinxstyleemphasis{two} hypotheses, \(A\) and \(C\):



\begin{center}
\AXM{A}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{A \wedge B}
\AXM{A}
\AXM{C}
\BIM{A \wedge C}
\BIM{(A \wedge B) \wedge (A \wedge C)}
\RLM{1}
\UIM{B \to (A \wedge B) \wedge (A \wedge C)}
\DP
\end{center}

\sphinxAtStartPar
Here, we have used the label 1 to indicate the place where the hypothesis \(B\) was canceled. Any label will do, though we will tend to use numbers for that purpose.

\sphinxAtStartPar
We can continue to cancel the hypothesis \(A\):



\begin{center}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{A \wedge B}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{C}
\BIM{A \wedge C}
\BIM{(A \wedge B) \wedge (A \wedge C)}
\RLM{1}
\UIM{B \to (A \wedge B) \wedge (A \wedge C)}
\RLM{2}
\UIM{A \to (B \to (A \wedge B) \wedge (A \wedge C))}
\DP
\end{center}

\sphinxAtStartPar
The result is a proof using only the hypothesis \(C\). We can continue to cancel that hypothesis as well:



\begin{center}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{A \wedge B}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{}
\RLM{3}
\UIM{C}
\BIM{A \wedge C}
\BIM{(A \wedge B) \wedge (A \wedge C)}
\RLM{1}
\UIM{B \to (A \wedge B) \wedge (A \wedge C)}
\RLM{2}
\UIM{A \to (B \to (A \wedge B) \wedge (A \wedge C))}
\RLM{3}
\UIM{C \to (A \to (B \to (A \wedge B) \wedge (A \wedge C)))}
\DP
\end{center}

\sphinxAtStartPar
The resulting proof uses no hypothesis at all. In other words, it establishes the conclusion outright.

\sphinxAtStartPar
Notice that in the second step, we canceled two “copies” of the hypothesis \(A\). In natural deduction, we can choose which hypotheses to cancel; we could have canceled either one, and left the other hypothesis \sphinxstyleemphasis{open}. In fact, we can also carry out the implication\sphinxhyphen{}introduction rule and cancel \sphinxstyleemphasis{zero} hypotheses. For example, the following is a short proof of \(A \to B\) from the hypothesis \(B\):



\begin{center}
\AXM{B}
\UIM{A \to B}
\DP
\end{center}

\sphinxAtStartPar
In this proof, zero copies of \(A\) are canceled.

\sphinxAtStartPar
Also notice that although we are using letters like \(A\), \(B\), and \(C\) as propositional variables, in the proofs above we can replace them by any propositional formula. For example, we can replace \(A\) by the formula \((D \vee E)\) everywhere, and still have correct proofs. In some presentations of logic, different letters are used for propositional variables and arbitrary propositional formulas, but we will continue to blur the distinction. You can think of \(A\), \(B\), and \(C\) as standing for propositional variables or formulas, as you prefer. If you think of them as propositional variables, just keep in mind that in any rule or proof, you can replace every variable by a different formula, and still have a valid rule or proof.

\sphinxAtStartPar
Finally, notice also that in these examples, we have assumed a special rule as the starting point for building proofs. It is called the assumption rule, and it looks like this:



\begin{center}
\AXM{A}
\DP
\end{center}

\sphinxAtStartPar
What it means is that at any point we are free to simply assume a formula, \(A\). The single formula \(A\) constitutes a one\sphinxhyphen{}line proof, and the way to read this proof is as follows: assuming \(A\), we have proved \(A\).

\sphinxAtStartPar
The remaining rules of inference were given in the last chapter, and we summarize them here.

\sphinxAtStartPar
\sphinxstyleemphasis{Implication:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1 \;\; \mathord{\to}\mathrm{I}}
\UIM{A \to B}
\DP
\quad\quad
\AXM{A \to B}
\AXM{A}
\RLM{\mathord{\to}\mathrm{E}}
\BIM{B}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Conjunction:}



\begin{quote}
\AXM{A}
\AXM{B}
\RLM{\mathord{\wedge}\mathrm{I}}
\BIM{A \wedge B}
\DP
\quad\quad
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_l}}
\UIM{A}
\DP
\quad\quad
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_r}}
\UIM{B}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Negation:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1 \;\; \neg \mathrm{I}}
\UIM{\neg A}
\DP
\quad\quad
\AXM{\neg A}
\AXM{A}
\RLM{\neg \mathrm{E}}
\BIM{\bot}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Disjunction:}



\begin{quote}
\AXM{A}
\RLM{\mathord{\vee}\mathrm{I_l}}
\UIM{A \vee B}
\DP
\quad\quad
\AXM{B}
\RLM{\mathord{\vee}\mathrm{I_r}}
\UIM{A \vee B}
\DP
\quad\quad
\AXM{A \vee B}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\RLM{1 \;\; \mathord{\vee}\mathrm{E}}
\TIM{C}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Truth and falsity:}



\begin{quote}
\AXM{\bot}
\RLM{\bot \mathrm{E}}
\UIM{A}
\DP
\quad\quad
\AXM{}
\RLM{\top \mathrm{I}}
\UIM{\top}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Bi\sphinxhyphen{}implication:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{A}
\RLM{1 \;\; \mathord{\leftrightarrow}\mathrm{I}}
\BIM{A \leftrightarrow B}
\DP
\AXM{A \leftrightarrow B}
\AXM{A}
\RLM{\mathord{\leftrightarrow}\mathrm{E}_l}
\BIM{B}
\DP
\quad\quad
\AXM{A \leftrightarrow B}
\AXM{B}
\RLM{\mathord{\leftrightarrow}\mathrm{E}_r}
\BIM{A}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Reductio ad absurdum (proof by contradiction):}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{\neg A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1 \;\; \mathrm{RAA}}
\UIM{A}
\DP
\end{quote}


\section{Examples}
\label{\detokenize{natural_deduction_for_propositional_logic:examples}}
\sphinxAtStartPar
Let us consider some more examples of natural deduction proofs. In each case, you should think about what the formulas say and which rule of inference is invoked at each step. Also pay close attention to which hypotheses are canceled at each stage. If you look at any node of the tree, what has been established at that point is that the claim follows from all the hypotheses above it that haven’t been canceled yet.

\sphinxAtStartPar
The following is a proof of \(A \to C\) from \(A \to B\) and \(B \to C\):



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\AXM{A \to B}
\BIM{B}
\AXM{B \to C}
\BIM{C}
\RLM{1}
\UIM{A \to C}
\DP
\end{center}

\sphinxAtStartPar
Intuitively, the formula
\begin{equation*}
\begin{split}(A \to B) \wedge (B \to C) \to (A \to C)\end{split}
\end{equation*}
\sphinxAtStartPar
“internalizes” the conclusion of the previous proof. The \(\wedge\) symbol is used to combine hypotheses, and the \(\to\) symbol is used to express that the right\sphinxhyphen{}hand side is a consequence of the left. Here is a proof of that formula:



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\AXM{}
\RLM{2}
\UIM{(A \to B) \wedge (B \to C)}
\UIM{A \to B}
\BIM{B}
\AXM{}
\RLM{2}
\UIM{(A \to B) \wedge (B \to C)}
\UIM{B \to C}
\BIM{C}
\RLM{1}
\UIM{A \to C}
\RLM{2}
\UIM{(A \to B) \wedge (B \to C) \to (A \to C)}
\DP
\end{center}

\sphinxAtStartPar
The next proof shows that if a conclusion, \(C\), follows from \(A\) and \(B\), then it follows from their conjunction.



\begin{center}
\AXM{}
\RLM{2}
\UIM{A \to (B \to C)}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{A}
\BIM{B \to C}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{B}
\BIM{C}
\RLM{1}
\UIM{A \wedge B \to C}
\RLM{2}
\UIM{(A \to (B \to C)) \to
(A \wedge B \to C)}
\DP
\end{center}

\sphinxAtStartPar
The conclusion of the next proof can be interpreted as saying that if it is not the case that one of \(A\) or \(B\) is true, then they are both false. It illustrates the use of the rules for negation.



\begin{center}
\AXM{}
\RLM{3}
\UIM{\neg (A \vee B)}
\AXM{}
\RLM{1}
\UIM{A}
\UIM{A \vee B}
\BIM{\bot}
\RLM{1}
\UIM{\neg A}
\AXM{}
\RLM{3}
\UIM{\neg (A \vee B)}
\AXM{}
\RLM{2}
\UIM{B}
\UIM{A \vee B}
\BIM{\bot}
\RLM{2}
\UIM{\neg B}
\BIM{\neg A \wedge \neg B}
\RLM{3}
\UIM{\neg (A \vee B) \to \neg A \wedge \neg B}
\DP
\end{center}

\sphinxAtStartPar
Finally, the next two examples illustrate the use of the \sphinxstyleemphasis{ex falso} rule. The first is a derivation of an arbitrary formula \(B\) from \(\neg A\) and \(A\):



\begin{center}
\AXM{\neg A}
\AXM{A}
\BIM{\bot}
\UIM{B}
\DP
\end{center}

\sphinxAtStartPar
The second shows that \(B\) follows from \(A\) and \(\neg A \vee B\):



\begin{center}
\AXM{\neg A \vee B}
\AXM{}
\RLM{1}
\UIM{\neg A}
\AXM{A}
\BIM{\bot}
\UIM{B}
\AXM{}
\RLM{1}
\UIM{B}
\RLM{1}
\TIM{B}
\DP
\end{center}

\sphinxAtStartPar
In some proof systems, these rules are taken to be part of the system. But we do not need to that with our system: these two examples show that the rules can be \sphinxstyleemphasis{derived} from our other rules.


\section{Forward and Backward Reasoning}
\label{\detokenize{natural_deduction_for_propositional_logic:forward-and-backward-reasoning}}\label{\detokenize{natural_deduction_for_propositional_logic:id2}}
\sphinxAtStartPar
Natural deduction is supposed to represent an idealized model of the patterns of reasoning and argumentation we use, for example, when working with logic puzzles as in the last chapter. There are obvious differences: we describe natural deduction proofs with symbols and two\sphinxhyphen{}dimensional diagrams, whereas our informal arguments are written with words and paragraphs. It is worthwhile to reflect on what \sphinxstyleemphasis{is} captured by the model. Natural deduction is supposed to clarify the \sphinxstyleemphasis{form} and \sphinxstyleemphasis{structure} of our logical arguments, describe the appropriate means of justifying a conclusion, and explain the sense in which the rules we use are valid.

\sphinxAtStartPar
Constructing natural deduction proofs can be confusing, but it is helpful to think about \sphinxstyleemphasis{why} it is confusing. We could, for example, decide that natural deduction is not a good model for logical reasoning. Or we might come to the conclusion that the features of natural deduction that make it confusing tell us something interesting about ordinary arguments.

\sphinxAtStartPar
In the “official” description, natural deduction proofs are constructed by putting smaller proofs together to obtain bigger ones. To prove \(A \wedge B \to B \wedge A\), we start with the hypothesis \(A \wedge B\). Then we construct, separately, the following two proofs:



\begin{center}
\AXM{A \wedge B}
\UIM{B}
\DP
\quad\quad
\AXM{A \wedge B}
\UIM{A}
\DP
\end{center}

\sphinxAtStartPar
Then we use these two proofs to construct the following one:



\begin{center}
\AXM{A \wedge B}
\UIM{B}
\AXM{A \wedge B}
\UIM{A}
\BIM{B \wedge A}
\DP
\end{center}

\sphinxAtStartPar
Finally, we apply the implies\sphinxhyphen{}introduction rule to this proof to cancel the hypothesis and obtain the desired conclusion:



\begin{center}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{B}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{A}
\BIM{B \wedge A}
\RLM{1}
\UIM{A \wedge B \to B \wedge A}
\DP
\end{center}

\sphinxAtStartPar
The process is similar to what happens in an informal argument, where we start with some hypotheses, and work forward towards a conclusion.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose Susan is tall and John is happy.

\sphinxAtStartPar
Then, in particular, John is happy.

\sphinxAtStartPar
Also, Susan is tall.

\sphinxAtStartPar
So John is happy and Susan is tall.

\sphinxAtStartPar
Therefore we have shown that if Susan is tall and John is happy, then John is happy and Susan is tall.


\bigskip\hrule\bigskip


\sphinxAtStartPar
However, when we \sphinxstyleemphasis{read} natural deduction proofs, we often read them backward. First, we look at the bottom to see what is being proved. Then we consider the rule that is used to prove it, and see what premises the rule demands. Then we look to see how those claims are proved, and so on. Similarly, when we \sphinxstyleemphasis{construct} a natural deduction proof, we typically work backward as well: we start with the claim we are trying to prove, put that at the bottom, and look for rules to apply.

\sphinxAtStartPar
At times that process breaks down. Suppose we are left with a goal that is a single propositional variable, \(A\). There are no introduction rules that can be applied, so, unless \(A\) is a hypothesis, it has to come from an elimination rule. But that underspecifies the problem: perhaps the \(A\) comes from applying the and\sphinxhyphen{}elimination rule to \(A \wedge B\), or from applying the or\sphinxhyphen{}elimination rule to \(C\) and \(C \to A\). At that point, we look to the hypotheses, and start working forward. If, for example, our hypotheses are \(C\) and \(C \to A \wedge B\), we would then work forward to obtain \(A \wedge B\) and \(A\).

\sphinxAtStartPar
There is thus a general heuristic for proving theorems in natural deduction:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Start by working backward from the conclusion, using the introduction rules. For example, if you are trying to prove a statement of the form \(A \to B\), add \(A\) to your list of hypotheses and try to derive \(B\). If you are trying to prove a statement of the form \(A \wedge B\), use the and\sphinxhyphen{}introduction rule to reduce your task to proving \(A\), and then proving \(B\).

\item {} 
\sphinxAtStartPar
When you have run out things to do in the first step, use elimination rules to work forward. If you have hypotheses \(A \to B\) and \(A\), apply modus ponens to derive \(B\). If you have a hypothesis \(A \vee B\), use or\sphinxhyphen{}elimination to split on cases, considering \(A\) in one case and \(B\) in the other.

\end{enumerate}

\sphinxAtStartPar
In \hyperref[\detokenize{classical_reasoning:classical-reasoning}]{Chapter \ref{\detokenize{classical_reasoning:classical-reasoning}}} we will add one more element to this list: if all else fails, try a proof by contradiction.

\sphinxAtStartPar
The tension between forward and backward reasoning is found in informal arguments as well, in mathematics and elsewhere. When we prove a theorem, we typically reason forward, using assumptions, hypotheses, definitions, and background knowledge. But we also keep the goal in mind, and that helps us make sense of the forward steps.

\sphinxAtStartPar
When we turn to interactive theorem proving, we will see that \sphinxstyleemphasis{Lean} has mechanisms to support both forward and backward reasoning. These form a bridge between informal styles of argumentation and the natural deduction model, and thereby provide a clearer picture of what is going
on.

\sphinxAtStartPar
Another confusing feature of natural deduction proofs is that every hypothesis has a \sphinxstyleemphasis{scope}, which is to say, there are only certain points in the proof where an assumption is available for use. Of course, this is also a feature of informal mathematical arguments. Suppose a paragraph begins “Let \(x\) be any number less than 100,” argues that \(x\) has at most five prime factors, and concludes “thus we have shown that every number less than 100 has at most five factors.” The reference “\(x\)”, and the assumption that it is less than 100, is only active within the scope of the paragraph. If the next paragraph begins with the phrase “Now suppose \(x\) is any number greater than 100,” then, of course, the assumption that \(x\) is less than 100 no longer applies.

\sphinxAtStartPar
In natural deduction, a hypothesis is available from the point where it is assumed until the point where it is canceled. We will see that interactive theorem proving languages also have mechanisms to determine the scope of references and hypotheses, and that these, too, shed light on scoping issues in informal mathematics.


\section{Reasoning by Cases}
\label{\detokenize{natural_deduction_for_propositional_logic:reasoning-by-cases}}
\sphinxAtStartPar
The rule for eliminating a disjunction is confusing, but we can make sense of it with an example. Consider the following informal argument:


\bigskip\hrule\bigskip


\sphinxAtStartPar
George is either at home or on campus.

\sphinxAtStartPar
If he is at home, he is studying.

\sphinxAtStartPar
If he is on campus, he is with his friends.

\sphinxAtStartPar
Therefore, George is either studying or with his friends.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Let \(A\) be the statement that George is at home, let \(B\) be the statement that George is on campus, let \(C\) be the statement that George is studying, and let \(D\) be the statement the George is with his friends. Then the argument above has the following pattern: from \(A \vee B\), \(A \to C\), and \(B \to D\), conclude \(C \vee D\). In natural deduction, we cannot get away with drawing this conclusion in a single step, but it does not take too much work to flesh it out into a proper proof. Informally, we have to argue as follows.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Georges is either at home or on campus.
\begin{quote}

\sphinxAtStartPar
Case 1: Suppose he is at home. We know that if he is at home, then he is studying. So, in this case, he is studying. Therefore, in this case, he is either studying or with his friends.

\sphinxAtStartPar
Case 2: Suppose he is on campus. We know that if he is on campus, then he is with his friends. So, in this case, he is with his friends. Therefore, in this case, he is either studying or with his friends.
\end{quote}

\sphinxAtStartPar
Either way, George is either studying or with his friends.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The natural deduction proof looks as follows:



\begin{center}
\AXM{A \vee B}
\AXM{A \to C}
\AXM{}
\RLM{1}
\UIM{A}
\BIM{C}
\UIM{C \vee D}
\AXM{B \to D}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{D}
\UIM{C \vee D}
\RLM{1}
\TIM{C \vee D}
\DP
\end{center}

\sphinxAtStartPar
You should think about how the structure of this proof reflects the informal case\sphinxhyphen{}based argument above it.

\sphinxAtStartPar
For another example, here is a proof of \(A \wedge (B \vee C) \to (A \wedge B) \vee (A \wedge C)\):



\begin{center}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{B \vee C}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{A \wedge B}
\UIM{(A \wedge B) \vee (A \wedge C)}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{C}
\BIM{A \wedge C}
\UIM{(A \wedge B) \vee (A \wedge C)}
\RLM{1}
\TIM{(A \wedge B) \vee (A \wedge C)}
\RLM{2}
\UIM{(A \wedge (B \vee C)) \to ((A \wedge B) \vee (A \wedge C))}
\DP
\end{center}


\section{Some Logical Identities}
\label{\detokenize{natural_deduction_for_propositional_logic:some-logical-identities}}
\sphinxAtStartPar
Two propositional formulas, \(A\) and \(B\), are said to be \sphinxstyleemphasis{logically equivalent} if \(A \leftrightarrow B\) is provable. Logical equivalences are similar to identities like \(x + y = y + x\) that occur in algebra. In particular, one can show that if two formulas are equivalent, then one can substitute one for the other in any formula, and the results will also be equivalent. (Some proof systems take this to be a basic rule, and interactive theorem provers can accommodate it, but we will \sphinxstyleemphasis{not} take it to be a fundamental rule of natural deduction.)

\sphinxAtStartPar
For reference, the following list contains some commonly used propositional equivalences, along with some noteworthy formulas. Think about why, intuitively, these formulas should be true.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Commutativity of \(\wedge\): \(A \wedge B \leftrightarrow B \wedge A\)

\item {} 
\sphinxAtStartPar
Commutativity of \(\vee\): \(A \vee B \leftrightarrow B \vee A\)

\item {} 
\sphinxAtStartPar
Associativity of \(\wedge\): \((A \wedge B) \wedge C \leftrightarrow A \wedge (B \wedge C)\)

\item {} 
\sphinxAtStartPar
Associativity of \(\vee\) \((A \vee B) \vee C \leftrightarrow A \vee (B \vee C)\)

\item {} 
\sphinxAtStartPar
Distributivity of \(\wedge\) over \(\vee\): \(A \wedge (B \vee C) \leftrightarrow (A \wedge B) \vee (A \wedge C)\)

\item {} 
\sphinxAtStartPar
Distributivity of \(\vee\) over \(\wedge\): \(A \vee (B \wedge C) \leftrightarrow (A \vee B) \wedge (A \vee C)\)

\item {} 
\sphinxAtStartPar
\((A \to (B \to C)) \leftrightarrow (A \wedge B \to C)\).

\item {} 
\sphinxAtStartPar
\((A \to B) \to ((B \to C) \to (A \to C))\)

\item {} 
\sphinxAtStartPar
\(((A \vee B) \to C) \leftrightarrow (A \to C) \wedge (B \to C)\)

\item {} 
\sphinxAtStartPar
\(\neg (A \vee B) \leftrightarrow \neg A \wedge \neg B\)

\item {} 
\sphinxAtStartPar
\(\neg (A \wedge B) \leftrightarrow \neg A \vee \neg B\)

\item {} 
\sphinxAtStartPar
\(\neg (A \wedge \neg A)\)

\item {} 
\sphinxAtStartPar
\(\neg (A \to B) \leftrightarrow A \wedge \neg B\)

\item {} 
\sphinxAtStartPar
\(\neg A \to (A \to B)\)

\item {} 
\sphinxAtStartPar
\((\neg A \vee B) \leftrightarrow (A \to B)\)

\item {} 
\sphinxAtStartPar
\(A \vee \bot \leftrightarrow A\)

\item {} 
\sphinxAtStartPar
\(A \wedge \bot \leftrightarrow \bot\)

\item {} 
\sphinxAtStartPar
\(A \vee \neg A\)

\item {} 
\sphinxAtStartPar
\(\neg (A \leftrightarrow \neg A)\)

\item {} 
\sphinxAtStartPar
\((A \to B) \leftrightarrow (\neg B \to \neg A)\)

\item {} 
\sphinxAtStartPar
\((A \to C \vee D) \to ((A \to C) \vee (A \to D))\)

\item {} 
\sphinxAtStartPar
\((((A \to B) \to A) \to A)\)

\end{enumerate}

\sphinxAtStartPar
All of these can be derived in natural deduction using the fundamental rules listed in \hyperref[\detokenize{natural_deduction_for_propositional_logic:derivations-in-natural-deduction}]{Section \ref{\detokenize{natural_deduction_for_propositional_logic:derivations-in-natural-deduction}}}. But some of them require the use of the \sphinxstyleemphasis{reductio ad absurdum} rule, or proof by contradiction, which we have not yet discussed in detail. We will discuss the use of this rule, and other patterns of classical logic, in the \hyperref[\detokenize{classical_reasoning:classical-reasoning}]{Chapter \ref{\detokenize{classical_reasoning:classical-reasoning}}}.


\section{Exercises}
\label{\detokenize{natural_deduction_for_propositional_logic:exercises}}
\sphinxAtStartPar
When constructing proofs in natural deduction, use \sphinxstyleemphasis{only} the list of
rules given in \hyperref[\detokenize{natural_deduction_for_propositional_logic:derivations-in-natural-deduction}]{Section \ref{\detokenize{natural_deduction_for_propositional_logic:derivations-in-natural-deduction}}}.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(A \wedge B\) from hypothesis \(B \wedge A\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \((Q \to R) \to R\) from hypothesis \(Q\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg (A \wedge B) \to (A \to \neg B)\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(Q \wedge S\) from hypotheses \((P \wedge Q) \wedge R\) and \(S \wedge T\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \((A \to C) \wedge (B \to \neg C) \to \neg (A \wedge B)\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \((A \wedge B) \to ((A \to C) \to \neg (B \to \neg C))\).

\item {} 
\sphinxAtStartPar
Take another look at Exercise 3 in the last chapter. Using propositional variables \(A\), \(B\), and \(C\) for “Alan likes kangaroos,” “Betty likes frogs” and “Carl likes hamsters,” respectively, express the three hypotheses as symbolic formulas, and then derive a contradiction from them in natural deduction.

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(A \vee B \to B \vee A\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg A \wedge \neg B \to \neg (A \vee B)\)

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg (A \wedge B)\) from \(\neg A \vee \neg B\). (You do not need to use proof by contradiction.)

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg (A \leftrightarrow \neg A)\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \((\neg A \leftrightarrow \neg B)\) from hypothesis \(A \leftrightarrow B\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(P \to R\) from hypothesis \((P \vee Q) \to R\). How does this differ from a proof of \(((P \vee Q) \to R) \to (P \to R)\)?

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(C \to (A \vee B) \wedge C\) from hypothesis \(A \vee B\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(W \vee Y \to X \vee Z\) from hypotheses \(W \to X\) and \(Y \to Z\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \((A \vee (B \wedge A)) \to A\).

\end{enumerate}


\chapter{Propositional Logic in Lean}
\label{\detokenize{propositional_logic_in_lean:propositional-logic-in-lean}}\label{\detokenize{propositional_logic_in_lean::doc}}
\sphinxAtStartPar
In this chapter, you will learn how to write proofs in Lean. We will start with a purely mechanical translation that will enable you to represent any natural deduction proof in Lean. We will see, however, that such a style of writing proofs is not very intuitive, nor does it yield very readable proofs. It also does not scale well.

\sphinxAtStartPar
We will then consider some mechanisms that Lean offers that support a more forward\sphinxhyphen{}directed style of argumentation. Since these proofs look more like informal proofs but can be directly translated to natural deduction, they will help us understand the relationship between the two.


\section{Expressions for Propositions and Proofs}
\label{\detokenize{propositional_logic_in_lean:expressions-for-propositions-and-proofs}}
\sphinxAtStartPar
At its core, Lean is what is known as a \sphinxstyleemphasis{type checker}. This means that we can write expressions and ask the system to check that they are well formed, and also ask the system to tell us what type of object they denote. Try this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the online version of this text, you can press the “try it!” button to copy the example to an editor window, and then hover over the markers on the text to read the messages.

\sphinxAtStartPar
In the example, we declare three variables ranging over propositions, and ask Lean to check the expression \sphinxcode{\sphinxupquote{A ∧ ¬ B → C}}. The output of the \sphinxcode{\sphinxupquote{\#check}} command is \sphinxcode{\sphinxupquote{A ∧ ¬ B → C : Prop}}, which asserts that \sphinxcode{\sphinxupquote{A ∧ ¬ B → C}} is of type \sphinxcode{\sphinxupquote{Prop}}. In Lean, every well\sphinxhyphen{}formed expression has a type.

\sphinxAtStartPar
The logical connectives are rendered in unicode. The following chart shows you how you can type these symbols in the editor, and also provides ascii equivalents, for the purists among you.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxAtStartPar
Unicode
&
\sphinxAtStartPar
Ascii
&
\sphinxAtStartPar
Lean input
\\
\hline&
\sphinxAtStartPar
true
&\\
\hline&
\sphinxAtStartPar
false
&\\
\hline
\sphinxAtStartPar
¬
&
\sphinxAtStartPar
not
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}not}}, \sphinxcode{\sphinxupquote{\textbackslash{}neg}}
\\
\hline
\sphinxAtStartPar
∧
&
\sphinxAtStartPar
/\textbackslash{}
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}and}}
\\
\hline
\sphinxAtStartPar
∨
&
\sphinxAtStartPar
\textbackslash{}/
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}or}}
\\
\hline
\sphinxAtStartPar
→
&
\sphinxAtStartPar
\sphinxhyphen{}>
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}to}}, \sphinxcode{\sphinxupquote{\textbackslash{}r}}, \sphinxcode{\sphinxupquote{\textbackslash{}imp}}
\\
\hline
\sphinxAtStartPar
↔
&
\sphinxAtStartPar
<\sphinxhyphen{}>
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}iff}}, \sphinxcode{\sphinxupquote{\textbackslash{}lr}}
\\
\hline
\sphinxAtStartPar
∀
&
\sphinxAtStartPar
forall
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}all}}
\\
\hline
\sphinxAtStartPar
∃
&
\sphinxAtStartPar
exists
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}ex}}
\\
\hline
\sphinxAtStartPar
λ
&
\sphinxAtStartPar
fun
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}lam}}, \sphinxcode{\sphinxupquote{\textbackslash{}fun}}
\\
\hline
\sphinxAtStartPar
≠
&
\sphinxAtStartPar
\textasciitilde{}=
&
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\textbackslash{}ne}}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
So far, we have only talked about the first seven items on the list. We will discuss the quantifiers, lambda, and equality later. Try typing some expressions and checking them on your own. You should try changing one of the variables in the example above to \sphinxcode{\sphinxupquote{D}}, or inserting a nonsense symbol into the expression, and take a look at the error message that Lean returns.

\sphinxAtStartPar
In addition to declaring variables, if \sphinxcode{\sphinxupquote{P}} is any expression of type \sphinxcode{\sphinxupquote{Prop}}, we can declare the hypothesis that \sphinxcode{\sphinxupquote{P}} is true:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
Formally, what is going on is that any proposition can be viewed as a type, namely, the type of proofs of that proposition. A hypothesis, or premise, is just a variable of that type. Building proofs is then a matter of writing down expressions of the correct type. For example, if \sphinxcode{\sphinxupquote{h}} is any expression of type \sphinxcode{\sphinxupquote{A ∧ B}}, then \sphinxcode{\sphinxupquote{And.left h}} is an expression of type \sphinxcode{\sphinxupquote{A}}, and \sphinxcode{\sphinxupquote{And.right h}} is an expression of type \sphinxcode{\sphinxupquote{B}}. In other words, if \sphinxcode{\sphinxupquote{h}} is a proof of \sphinxcode{\sphinxupquote{A ∧ B}}, and \sphinxcode{\sphinxupquote{And.left h}} is a name for the proof you get by applying the left elimination rule for and:



\begin{center}
\AXM{\vdots}
\noLine
\UIM{P}
\noLine
\UIM{\vdots}
\noLine
\UIM{A \wedge B}
\UIM{A}
\DP
\end{center}

\sphinxAtStartPar
Similarly, \sphinxcode{\sphinxupquote{And.right h}} is the proof of \sphinxcode{\sphinxupquote{B}} you get by applying the right elimination rule. So, continuing the example above, we can write

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{And.left} \PYG{n}{h}
\PYG{k}{\PYGZsh{}check} \PYG{n}{And.right} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
The two expressions represent, respectively, these two proofs:



\begin{center}
\AXM{}
\RLM{h}
\UIM{A \wedge \neg B}
\UIM{A}
\DP
\quad\quad
\AXM{}
\RLM{h}
\UIM{A \wedge \neg B}
\UIM{\neg B}
\DP
\end{center}

\sphinxAtStartPar
Notice that in this way of representing natural deduction proofs, there are no “free floating” hypotheses. Every hypothesis has a label. In Lean, we will typically use expressions like \sphinxcode{\sphinxupquote{h}}, \sphinxcode{\sphinxupquote{h1}}, \sphinxcode{\sphinxupquote{h2}}, … to label hypotheses, but you can use any identifier you want.

\sphinxAtStartPar
If \sphinxcode{\sphinxupquote{h1}} is a proof of \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{h2}} is a proof of \sphinxcode{\sphinxupquote{B}}, then \sphinxcode{\sphinxupquote{And.intro h1 h2}} is a proof of \sphinxcode{\sphinxupquote{A ∧ B}}. So we can continue the example above:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
This corresponds to the following proof:



\begin{center}
\AXM{}
\RLM{h}
\UIM{A \wedge \neg B}
\UIM{\neg B}
\AXM{}
\RLM{h}
\UIM{A \wedge \neg B}
\UIM{A}
\BIM{\neg B \wedge A}
\DP
\end{center}

\sphinxAtStartPar
What about implication? The elimination rule is easy: if \sphinxcode{\sphinxupquote{h₁}} is a proof of \sphinxcode{\sphinxupquote{A → B}} and \sphinxcode{\sphinxupquote{h₂}} is a proof of \sphinxcode{\sphinxupquote{A}} then \sphinxcode{\sphinxupquote{h₁ h₂}} is a proof of \sphinxcode{\sphinxupquote{B}}. Notice that we do not even need to name the rule: you just write \sphinxcode{\sphinxupquote{h₁}} followed by \sphinxcode{\sphinxupquote{h₂}}, as though you are applying the first to the second. If \sphinxcode{\sphinxupquote{h₁}} and \sphinxcode{\sphinxupquote{h₂}} are compound expressions, put parentheses around them to make it clear where each one begins and ends.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{D} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{D}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{h2} \PYG{n}{h3}
\PYG{k}{\PYGZsh{}check} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)}\PYG{o}{)} \PYG{n}{h4}
\end{sphinxVerbatim}

\sphinxAtStartPar
Lean adopts the convention that applications associate to the left, so that an expression \sphinxcode{\sphinxupquote{h1 h2 h3}} is interpreted as \sphinxcode{\sphinxupquote{(h1 h2) h3}}. Implications associate to the \sphinxstyleemphasis{right}, so that \sphinxcode{\sphinxupquote{A → B → C}} is interpreted as \sphinxcode{\sphinxupquote{A → (B → C)}}. This may seem funny, but it is a convenient way to represent implications that take multiple hypotheses, since an expression \sphinxcode{\sphinxupquote{A → B → C → D → E}} means that \sphinxcode{\sphinxupquote{E}} follows from \sphinxcode{\sphinxupquote{A}}, \sphinxcode{\sphinxupquote{B}}, \sphinxcode{\sphinxupquote{C}}, and \sphinxcode{\sphinxupquote{D}}. So the example above could be written as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{D} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{D}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{h2} \PYG{n}{h3}
\PYG{k}{\PYGZsh{}check} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)} \PYG{n}{h4}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that parentheses are still needed in the expression \sphinxcode{\sphinxupquote{h1 (h2 h3)}}.

\sphinxAtStartPar
The implication introduction rule is the tricky one,
because it can cancel a hypothesis.
In terms of Lean expressions,
the rule translates as follows.
Suppose \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{B}} have type \sphinxcode{\sphinxupquote{Prop}},
and, assuming \sphinxcode{\sphinxupquote{hA}} is the premise that \sphinxcode{\sphinxupquote{A}} holds,
\sphinxcode{\sphinxupquote{hB}} is proof of \sphinxcode{\sphinxupquote{B}}, possibly involving \sphinxcode{\sphinxupquote{hA}}.
Then the expression \sphinxcode{\sphinxupquote{fun h : A ↦ hB}} is a proof of \sphinxcode{\sphinxupquote{A → B}}.
You can type \sphinxcode{\sphinxupquote{\textbackslash{}mapsto}} for the \sphinxcode{\sphinxupquote{↦}} symbol.
For example, we can construct a proof of \sphinxcode{\sphinxupquote{A → A ∧ A}} as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{n}{h} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can read \sphinxcode{\sphinxupquote{fun}} as “assume \sphinxcode{\sphinxupquote{h}}”.
In fact, \sphinxcode{\sphinxupquote{fun}} stands for “function”,
since a proof of \sphinxcode{\sphinxupquote{A → B}} is a function from the type of
proofs of \sphinxcode{\sphinxupquote{A}} to the type of proofs of \sphinxcode{\sphinxupquote{B}}.

\sphinxAtStartPar
Notice that we no longer have to declare \sphinxcode{\sphinxupquote{A}} as a premise;
we don’t have \sphinxcode{\sphinxupquote{variable (h : A)}}.
The expression \sphinxcode{\sphinxupquote{fun h : A ↦ hB}}
makes the premise \sphinxcode{\sphinxupquote{h}} local to the expression in parentheses,
and we can refer to \sphinxcode{\sphinxupquote{h}} later within the parentheses.
Given the assumption \sphinxcode{\sphinxupquote{h : A}},
\sphinxcode{\sphinxupquote{And.intro h h}} is a proof of \sphinxcode{\sphinxupquote{A ∧ A}},
and so the expression \sphinxcode{\sphinxupquote{fun h : A ↦ And.intro h h}}
is a proof of \sphinxcode{\sphinxupquote{A → A ∧ A}}.
In this case,
we could leave out the parentheses because the expression is unambiguous:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{n}{h} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
Above, we proved \sphinxcode{\sphinxupquote{¬ B ∧ A}} from the premise \sphinxcode{\sphinxupquote{A ∧ ¬ B}}. We can instead obtain a proof of \sphinxcode{\sphinxupquote{A ∧ ¬ B → ¬ B ∧ A}} as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
All we did was move the premise into a local \sphinxcode{\sphinxupquote{fun}} expression.

\sphinxAtStartPar
(By the way, the \sphinxcode{\sphinxupquote{fun}} command is just alternative syntax for the lambda symbol, so we could also have written this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n+nb+bp}{λ} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
You will learn more about the lambda symbol later.)


\section{More commands}
\label{\detokenize{propositional_logic_in_lean:more-commands}}
\sphinxAtStartPar
Let us introduce a new Lean command, \sphinxcode{\sphinxupquote{example}}. This command tells Lean that you are about to prove a theorem, or, more generally, write down an expression of the given type. It should then be followed by the proof or expression itself.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
When given this command,
Lean checks the expression after the \sphinxcode{\sphinxupquote{:=}} and makes sure it has the right type.
If so,
it accepts the expression as a valid proof. If not, it raises an error.

\sphinxAtStartPar
Because the \sphinxcode{\sphinxupquote{example}} command provides information as to the
type of the expression that follows
(in this case, the proposition being proved),
it sometimes enables us to omit other information.
For example, we can leave off the type of the assumption:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦}
\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Because Lean knows we are trying to prove an implication with premise
\sphinxcode{\sphinxupquote{A ∧ ¬ B}},
it can infer that when we write \sphinxcode{\sphinxupquote{fun h ↦}}, the identifier \sphinxcode{\sphinxupquote{h}} labels the assumption \sphinxcode{\sphinxupquote{A ∧ ¬ B}}.

\sphinxAtStartPar
We can also go in the other direction,
and provide the system with \sphinxstyleemphasis{more} information, with the word \sphinxcode{\sphinxupquote{show}}.
If \sphinxcode{\sphinxupquote{A}} is a proposition and \sphinxcode{\sphinxupquote{h : A}} is a proof,
the expression “\sphinxcode{\sphinxupquote{show A from h}}” means the same thing as \sphinxcode{\sphinxupquote{h}} alone,
but it signals the intention that \sphinxcode{\sphinxupquote{h}} is a proof of \sphinxcode{\sphinxupquote{A}}.
When Lean checks this expression,
it confirms that \sphinxcode{\sphinxupquote{h}} really is a proof of \sphinxcode{\sphinxupquote{A}},
before parsing the expression surrounding it.
So, in our example,
we could also write:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We could even annotate the smaller expressions \sphinxcode{\sphinxupquote{And.right h}} and \sphinxcode{\sphinxupquote{And.left h}}, as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.intro}
  \PYG{o}{(}\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{k}{from} \PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Although in the examples above the \sphinxcode{\sphinxupquote{show}} commands were not necessary,
there are a number of good reasons to use this style.
First, and perhaps most importantly,
it makes the proofs easier for us humans to read.
Second, it makes the proofs easier to \sphinxstyleemphasis{write}:
if you make a mistake in a proof,
it is easier for Lean to figure out where you went wrong and provide a
meaningful error message if you make your intentions clear.
Finally, proving information in the \sphinxcode{\sphinxupquote{show}}
clause often makes it possible for you to omit information in other places,
since Lean can infer that information from your stated intentions.

\sphinxAtStartPar
There are notational variants.
Rather than declare variables and premises beforehand,
you can also present them as “arguments” to the example, followed by a colon:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.intro}
  \PYG{o}{(}\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{k}{from} \PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
There are two more tricks that can help you write proofs in Lean.
The first is using \sphinxcode{\sphinxupquote{sorry}},
which is a magical term in Lean which provides a proof of anything at all.
It is also known as “cheating”.
But cheating can help you construct legitimate proofs incrementally:
if Lean accepts a proof with \sphinxcode{\sphinxupquote{sorry}}’s,
the parts of the proof you have written so far have passed
Lean’s checks for correctness.
All you need to do is replace each \sphinxcode{\sphinxupquote{sorry}}
with a real proof to complete the task.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{g+gr}{sorry} \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The second trick is the use of \sphinxstyleemphasis{placeholders},
represented by the underscore symbol.
When you write an underscore in an expression,
you are asking the system to try to fill in the value for you.
This falls short of calling full\sphinxhyphen{}blown automation to prove a theorem;
rather, you are asking Lean to infer the value from the context.
If you use an underscore where a proof should be,
Lean typically will \sphinxstyleemphasis{not} fill in the proof,
but it will give you an error message that tells you what is missing.
This will help you write proof terms incrementally,
in a backward\sphinxhyphen{}driven fashion.
In the example above, try replacing each \sphinxcode{\sphinxupquote{sorry}} by an underscore, \sphinxcode{\sphinxupquote{\_}},
and take a look at the resulting error messages.
In each case, the error tells you what needs to be filled in,
and the variables and hypotheses that are available to you at that stage.

\sphinxAtStartPar
One more tip: if you want to delimit the scope of variables or premises introduced with the \sphinxcode{\sphinxupquote{variable}} command, put them in a block that begins with the word \sphinxcode{\sphinxupquote{section}} and ends with the word \sphinxcode{\sphinxupquote{end}}.


\section{Building Natural Deduction Proofs}
\label{\detokenize{propositional_logic_in_lean:building-natural-deduction-proofs}}
\sphinxAtStartPar
In this section, we describe a mechanical translation from natural deduction proofs, by giving a translation for each natural deduction rule. We have already seen some of the correspondences, but we repeat them all here, for completeness.


\subsection{Implication}
\label{\detokenize{propositional_logic_in_lean:implication}}
\sphinxAtStartPar
We have already explained that implication introduction is implemented with \sphinxcode{\sphinxupquote{fun}}, and implication elimination is written as application.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{g+gr}{sorry}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k+kd}{end}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that there is a section within a section to further limit the scope of
two new variables.


\subsection{Conjunction}
\label{\detokenize{propositional_logic_in_lean:conjunction}}
\sphinxAtStartPar
We have already seen that and\sphinxhyphen{}introduction is implemented with \sphinxcode{\sphinxupquote{And.intro}}, and the elimination rules are \sphinxcode{\sphinxupquote{And.left}} and \sphinxcode{\sphinxupquote{And.right}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k+kd}{end}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h}
\PYG{k+kd}{end}
\end{sphinxVerbatim}


\subsection{Disjunction}
\label{\detokenize{propositional_logic_in_lean:disjunction}}
\sphinxAtStartPar
The or\sphinxhyphen{}introduction rules are given by \sphinxcode{\sphinxupquote{Or.inl}} and \sphinxcode{\sphinxupquote{Or.inr}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{Or.inl} \PYG{n}{h}
\PYG{k+kd}{end}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{Or.inr} \PYG{n}{h}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The elimination rule is the tricky one. To prove \sphinxcode{\sphinxupquote{C}} from \sphinxcode{\sphinxupquote{A ∨ B}}, you need three arguments: a proof \sphinxcode{\sphinxupquote{h}} of \sphinxcode{\sphinxupquote{A ∨ B}}, a proof of \sphinxcode{\sphinxupquote{C}} from \sphinxcode{\sphinxupquote{A}}, and a proof of \sphinxcode{\sphinxupquote{C}} from \sphinxcode{\sphinxupquote{B}}. Using line breaks and indentation to highlight the structure as a proof by cases, we can write it with the following form:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{ha} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hb} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{C} \PYG{o}{:=}
\PYG{n}{Or.elim} \PYG{n}{h}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{ha} \PYG{n}{h1}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{hb} \PYG{n}{h1}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that we can reuse the label \sphinxcode{\sphinxupquote{h1}} in each branch, since, conceptually, the two branches are disjoint.


\subsection{Negation}
\label{\detokenize{propositional_logic_in_lean:negation}}
\sphinxAtStartPar
Internally, negation \sphinxcode{\sphinxupquote{¬ A}} is defined by \sphinxcode{\sphinxupquote{A → False}}, which you can think of as saying that \sphinxcode{\sphinxupquote{A}} implies something impossible. The rules for negation are therefore similar to the rules for implication. To prove \sphinxcode{\sphinxupquote{¬ A}}, assume \sphinxcode{\sphinxupquote{A}} and derive a contradiction.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you have proved a negation \sphinxcode{\sphinxupquote{¬ A}}, you can get a contradiction by applying it to a proof of \sphinxcode{\sphinxupquote{A}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{False} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}


\subsection{Truth and falsity}
\label{\detokenize{propositional_logic_in_lean:truth-and-falsity}}
\sphinxAtStartPar
The \sphinxstyleemphasis{ex falso} rule is called \sphinxcode{\sphinxupquote{False.elim}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{False}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{False.elim} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
There isn’t much to say about \sphinxcode{\sphinxupquote{True}} beyond the fact that it is trivially true:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{True} \PYG{o}{:=} \PYG{n}{trivial}
\end{sphinxVerbatim}


\subsection{Bi\sphinxhyphen{}implication}
\label{\detokenize{propositional_logic_in_lean:bi-implication}}
\sphinxAtStartPar
The introduction rule for “if and only if” is \sphinxcode{\sphinxupquote{Iff.intro}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{Iff.intro}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As usual, we have chosen indentation to make the structure clear. Notice that the same label, \sphinxcode{\sphinxupquote{h}}, can be used on both branches, with a different meaning in each, because the scope of \sphinxcode{\sphinxupquote{fun}} is limited to the expression in which it appears.

\sphinxAtStartPar
The elimination rules are \sphinxcode{\sphinxupquote{Iff.mp}} and \sphinxcode{\sphinxupquote{Iff.mpr}} for “modus ponens”
and “modus ponens (reverse)”:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{B}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{Iff.mp} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k+kd}{end}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{B}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Iff.mpr} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k+kd}{end}
\end{sphinxVerbatim}


\subsection{Reductio ad absurdum (proof by contradiction)}
\label{\detokenize{propositional_logic_in_lean:reductio-ad-absurdum-proof-by-contradiction}}
\sphinxAtStartPar
Finally, there is the rule for proof by contradiction, which we will discuss in greater detail in \hyperref[\detokenize{classical_reasoning:classical-reasoning}]{Chapter \ref{\detokenize{classical_reasoning:classical-reasoning}}}. It is included for completeness here.

\sphinxAtStartPar
The rule is called \sphinxcode{\sphinxupquote{byContradiction}}.
It has one argument, which is a proof of \sphinxcode{\sphinxupquote{False}} from \sphinxcode{\sphinxupquote{¬ A}}.
To use the rule, you have to ask Lean to allow classical reasoning,
by writing \sphinxcode{\sphinxupquote{open Classical}}.
You can do this at the beginning of the file,
or any time before using it.
If you say \sphinxcode{\sphinxupquote{open Classical}} in a section,
it will remain in scope for that section.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kn}{open} \PYG{n}{Classical}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=}
  \PYG{n}{byContradiction}
    \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦}
      \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
\PYG{k+kd}{end}
\end{sphinxVerbatim}


\subsection{Examples}
\label{\detokenize{propositional_logic_in_lean:examples}}
\sphinxAtStartPar
In the last chapter, we constructed the following proof of \(A \to C\) from \(A \to B\) and \(B \to C\):



\begin{center}
\AXM{}
\RLM{1}
\UIM{A}
\AXM{A \to B}
\BIM{B}
\AXM{B \to C}
\BIM{C}
\RLM{1}
\UIM{A \to C}
\DP
\end{center}

\sphinxAtStartPar
We can model this in Lean as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{h2} \PYG{o}{(}\PYG{n}{h1} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that the hypotheses in the natural deduction proof that are not canceled are declared as variables in the Lean version.

\sphinxAtStartPar
We also constructed the following proof:



\begin{center}
\AXM{}
\RLM{2}
\UIM{A \to (B \to C)}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{A}
\BIM{B \to C}
\AXM{}
\RLM{1}
\UIM{A \wedge B}
\UIM{B}
\BIM{C}
\RLM{1}
\UIM{A \wedge B \to C}
\RLM{2}
\UIM{(A \to (B \to C)) \to (A \wedge B \to C)}
\DP
\end{center}

\sphinxAtStartPar
Here is how it is written in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{↦}
  \PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{↦}
  \PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h2}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h2}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
This works because \sphinxcode{\sphinxupquote{And.left h2}} is a proof of \sphinxcode{\sphinxupquote{A}}, and \sphinxcode{\sphinxupquote{And.right h2}} is a proof of \sphinxcode{\sphinxupquote{B}}.

\sphinxAtStartPar
Finally, we constructed the following proof of \(A \wedge (B \vee C) \to (A \wedge B) \vee (A \wedge C)\):



\begin{center}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{B \vee C}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{B}
\BIM{A \wedge B}
\UIM{(A \wedge B) \vee (A \wedge C)}
\AXM{}
\RLM{2}
\UIM{A \wedge (B \vee C)}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{C}
\BIM{A \wedge C}
\UIM{(A \wedge B) \vee (A \wedge C)}
\RLM{1}
\TIM{(A \wedge B) \vee (A \wedge C)}
\RLM{2}
\UIM{(A \wedge (B \vee C)) \to ((A \wedge B) \vee
  (A \wedge C))}
\DP
\end{center}

\sphinxAtStartPar
Here is a version in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{n}{Or.elim} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h1}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
      \PYG{k}{from} \PYG{n}{Or.inr} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact,
bearing in mind that \sphinxcode{\sphinxupquote{fun}} is alternative syntax for the symbol \sphinxcode{\sphinxupquote{λ}},
and that Lean can often infer the type of an assumption,
we can make the proof remarkably brief:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
\PYG{n+nb+bp}{λ} \PYG{n}{h1} \PYG{n+nb+bp}{↦} \PYG{n}{Or.elim} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h1}\PYG{o}{)}
  \PYG{o}{(}\PYG{n+nb+bp}{λ} \PYG{n}{h2} \PYG{n+nb+bp}{↦} \PYG{n}{Or.inl} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
  \PYG{o}{(}\PYG{n+nb+bp}{λ} \PYG{n}{h2} \PYG{n+nb+bp}{↦} \PYG{n}{Or.inr} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The proof is cryptic, though.
Using such a style makes proofs hard to write, read, understand, maintain, and debug.
Tactic mode is one way in which we can mitigate some of these issues.


\section{Tactic Mode}
\label{\detokenize{propositional_logic_in_lean:tactic-mode}}
\sphinxAtStartPar
So far we have only explained one mode for writing proofs in Lean,
namely “term mode”.
In term mode we can directly write proofs as syntactic expressions.
In this section we introduce “tactic mode”,
which allows us to write proofs more interactively,
with tactics as instructions to follow for building such a proof.
The statement to be proved at a given point is called the \sphinxstyleemphasis{goal},
and instructions make progress by transforming
the goal into something that is easier to prove.
Once the tactic mode proof is complete,
Lean should be able to turn it into a proof term by following the instructions.

\sphinxAtStartPar
Tactics can be very powerful tools,
bearing much of the tedious work and
allowing us to write much shorter proofs.
We will slowly introduce them as we go.

\sphinxAtStartPar
We can enter tactic mode by writing the keyword \sphinxcode{\sphinxupquote{by}} after \sphinxcode{\sphinxupquote{:=}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{n}{Or.elim} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h1}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
      \PYG{k}{from} \PYG{n}{Or.inr} \PYG{o}{(}\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{h1} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{h1} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{cases} \PYG{n}{h2} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{n}{apply} \PYG{n}{Or.inl}
      \PYG{n}{apply} \PYG{n}{And.intro}
      \PYG{n}{exact} \PYG{n}{h1}
      \PYG{n}{exact} \PYG{n}{h2}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{n}{apply} \PYG{n}{Or.inr}
      \PYG{n}{apply} \PYG{n}{And.intro}
      \PYG{n}{exact} \PYG{n}{h1}
      \PYG{n}{exact} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
Instead of \sphinxcode{\sphinxupquote{fun h1 ↦ h2}} we use \sphinxcode{\sphinxupquote{intro (h1 : A ∧ (B ∨ C))}}
to “introduce” the assumption \sphinxcode{\sphinxupquote{h1}},
then give instructions for \sphinxcode{\sphinxupquote{h2}}.

\sphinxAtStartPar
Instead of \sphinxcode{\sphinxupquote{Or.elim h}} and \sphinxcode{\sphinxupquote{And.elim h}} we use \sphinxcode{\sphinxupquote{cases h with}}
and use \sphinxcode{\sphinxupquote{|}} to list the possible cases in which the proof \sphinxcode{\sphinxupquote{h}} was made,
then continuing the proof in each case.
For conjunction, there is only one possible way in which \sphinxcode{\sphinxupquote{h}} was made,
which is by \sphinxcode{\sphinxupquote{And.intro h1 h2}} (Lean only allows \sphinxcode{\sphinxupquote{intro h1 h2}}).
For disjunction there are two cases,
\sphinxcode{\sphinxupquote{h}} could be either \sphinxcode{\sphinxupquote{Or.inl h1}} or \sphinxcode{\sphinxupquote{Or.inr h2}}
(again we must write \sphinxcode{\sphinxupquote{inl h1}} and \sphinxcode{\sphinxupquote{inr h2}}).

\sphinxAtStartPar
Instead of immediately supplying \sphinxcode{\sphinxupquote{Or.inl}}, \sphinxcode{\sphinxupquote{Or.inr}} and \sphinxcode{\sphinxupquote{And.intro}}
with all its arguments we can (for example) \sphinxcode{\sphinxupquote{apply Or.inl}} and
fill in the missing parts afterwards.
In fact, Lean sees \sphinxcode{\sphinxupquote{Or.inl : A → A ∨ B}} as a proof of a conditional,
and for any \sphinxcode{\sphinxupquote{h : A → B}},
\sphinxcode{\sphinxupquote{apply h}} will change the goal from \sphinxcode{\sphinxupquote{B}} to \sphinxcode{\sphinxupquote{A}}.
We can see this as “since \sphinxcode{\sphinxupquote{A}} implies \sphinxcode{\sphinxupquote{B}}, in order to prove \sphinxcode{\sphinxupquote{B}}
it suffices to prove \sphinxcode{\sphinxupquote{A}}”.
Finally, when our goal is \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{h1 : A}} we can close the goal
by writing \sphinxcode{\sphinxupquote{exact A}}.

\sphinxAtStartPar
We will mix tactics and terms in order to suit our needs.
We will slowly introduce more and more tactics throughout this textbook.

\sphinxAtStartPar
Note that tactic mode proofs are sensitive to indentation and returns.
On the other hand, term mode proofs are not sensitive to whitespace.
We could write every term mode proof on a single line.
For both modes,
we will adopt conventions for indentation and line breaks that
show the structure of proofs and make them easier to read.


\section{Forward Reasoning}
\label{\detokenize{propositional_logic_in_lean:forward-reasoning}}
\sphinxAtStartPar
Lean supports forward reasoning by allowing you to write
proofs using \sphinxcode{\sphinxupquote{have}},
which is both a term mode expression and a tactic.
Notice that \sphinxcode{\sphinxupquote{show}} is also a tactic.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{h}
  \PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{h2} \PYG{n}{h3}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{h}
  \PYG{k}{show} \PYG{n}{C}
  \PYG{n}{exact} \PYG{n}{h2} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
Writing a proof with
\sphinxcode{\sphinxupquote{have h : A := \_}} then continuing the proof with
\sphinxcode{\sphinxupquote{... h ...}} has the same effect as writing \sphinxcode{\sphinxupquote{... \_ ...}}.
This \sphinxcode{\sphinxupquote{have}} command checks that \sphinxcode{\sphinxupquote{\_}} is a proof of \sphinxcode{\sphinxupquote{A}},
and then give you the label \sphinxcode{\sphinxupquote{h}} to use in place of \sphinxcode{\sphinxupquote{\_}}.
Thus the last line of the previous proof can be thought of as
abbreviating \sphinxcode{\sphinxupquote{exact h2 (h1 h)}},
since \sphinxcode{\sphinxupquote{h3}} abbreviates \sphinxcode{\sphinxupquote{h1 h}}.
Such abbreviations can make a big difference,
especially when the proof \sphinxcode{\sphinxupquote{\_}} is long and repeatedly used.

\sphinxAtStartPar
There are a number of advantages to using \sphinxcode{\sphinxupquote{have}}.
For one thing, it makes the proof more readable:
the example above states \sphinxcode{\sphinxupquote{B}} explicitly as an auxiliary goal.
It can also save repetition:
\sphinxcode{\sphinxupquote{h3}} can be used repeatedly after it is introduced,
without duplicating the proof.
Finally, it makes it easier to construct and debug the proof:
stating \sphinxcode{\sphinxupquote{B}} as an auxiliary goal makes it easier for Lean to deliver an
informative error message when the goal is not properly met.

\sphinxAtStartPar
Note that \sphinxcode{\sphinxupquote{have}} and \sphinxcode{\sphinxupquote{exact}} are mixing term mode and tactic mode,
since the expression \sphinxcode{\sphinxupquote{h1 h}} is a term mode proof of \sphinxcode{\sphinxupquote{B}}
and \sphinxcode{\sphinxupquote{h2 h3}} is a term mode proof of \sphinxcode{\sphinxupquote{C}}.

\sphinxAtStartPar
Previously we have considered the following statement,
which we partially translate to tactic mode:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{↦}
  \PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{↦}
  \PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h2}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h2}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
  \PYG{n}{exact} \PYG{n}{h1} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h2}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h2}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that \sphinxcode{\sphinxupquote{intro}} can introduce multiple assumptions at once.
Using \sphinxcode{\sphinxupquote{have}}, it can be written more perspicuously as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h2}
  \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h2}
  \PYG{n}{exact} \PYG{n}{h1} \PYG{n}{h3} \PYG{n}{h4}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can be even more verbose, and add another line:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h2}
  \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h2}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{h3}
  \PYG{k}{show} \PYG{n}{C}
  \PYG{n}{exact} \PYG{n}{h5} \PYG{n}{h4}
\end{sphinxVerbatim}

\sphinxAtStartPar
Adding more information doesn’t always make a proof more readable; when the individual expressions are small and easy enough to understand, spelling them out in detail can introduce clutter. As you learn to use Lean, you will have to develop your own style, and use your judgment to decide which steps to make explicit.

\sphinxAtStartPar
Here is how some of the basic inferences look, when expanded with \sphinxcode{\sphinxupquote{have}}. In the and\sphinxhyphen{}introduction rule, it is a matter showing each conjunct first, and then putting them together:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h1}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h1}
  \PYG{k}{show} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A}
  \PYG{n}{exact} \PYG{n}{And.intro} \PYG{n}{h3} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
Compare that with this version, which instead states first that we will use the \sphinxcode{\sphinxupquote{And.intro}} rule, and then makes the two resulting goals explicit:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
  \PYG{n}{apply} \PYG{n}{And.intro}
  \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{B}
    \PYG{n}{exact} \PYG{n}{And.right} \PYG{n}{h1}
  \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{A}
    \PYG{n}{exact} \PYG{n}{And.left} \PYG{n}{h1}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice the use of \sphinxcode{\sphinxupquote{.}} to seperate the two remaining goals;
it is sensitive to indentation.

\sphinxAtStartPar
Once again, at issue is only readability.
Lean does just fine with the following short term mode version:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{n+nb+bp}{λ} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
When using the or\sphinxhyphen{}elimination rule, it is often clearest to state the relevant disjunction explicitly:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{C} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{k}{have} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n}{C}
\PYG{n}{apply} \PYG{n}{Or.elim} \PYG{n}{h}
\PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hA} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
  \PYG{g+gr}{sorry}
\PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hB} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}
  \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is a \sphinxcode{\sphinxupquote{have}}\sphinxhyphen{}structured presentation of an example from the previous section:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h1}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h1}
\PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
\PYG{n}{apply} \PYG{n}{Or.elim} \PYG{n}{h3}
\PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h2} \PYG{n}{h4}
  \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
  \PYG{n}{exact} \PYG{n}{Or.inl} \PYG{n}{h5}
\PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{C}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h2} \PYG{n}{h4}
  \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
  \PYG{n}{exact} \PYG{n}{Or.inr} \PYG{n}{h5}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h1}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h1}
\PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{k}{from}
  \PYG{n}{Or.elim} \PYG{n}{h3}
    \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
      \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h2} \PYG{n}{h4}
      \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{n}{h5}\PYG{o}{)}
    \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{↦}
      \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h2} \PYG{n}{h4}
      \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inr} \PYG{n}{h5}\PYG{o}{)}
\end{sphinxVerbatim}


\section{Definitions and Theorems}
\label{\detokenize{propositional_logic_in_lean:definitions-and-theorems}}\label{\detokenize{propositional_logic_in_lean:id1}}
\sphinxAtStartPar
Lean allows us to name definitions and theorems for later use. For example, here is a definition of a new “connective”:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{triple\PYGZus{}and} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As with the \sphinxcode{\sphinxupquote{example}} command, it does not matter whether the arguments \sphinxcode{\sphinxupquote{A}}, \sphinxcode{\sphinxupquote{B}}, and \sphinxcode{\sphinxupquote{C}} are declared beforehand with the \sphinxcode{\sphinxupquote{variable}} command, or with the definition itself. We can then apply the definition to any expressions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{D} \PYG{n}{E} \PYG{n}{F} \PYG{n}{G} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{triple\PYGZus{}and} \PYG{o}{(}\PYG{n}{D} \PYG{n+nb+bp}{∨} \PYG{n}{E}\PYG{o}{)} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{F} \PYG{n+nb+bp}{→} \PYG{n}{G}\PYG{o}{)} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{D}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Later, we will see more interesting examples of definitions, like the following function from natural numbers to natural numbers, which doubles its input:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kd}{def} \PYG{n}{double} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{ℕ} \PYG{o}{:=} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{n}
\end{sphinxVerbatim}

\sphinxAtStartPar
What is more interesting right now is that Lean also allows us to name theorems, and use them later, as rules of inference. For example, consider the following theorem:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{and\PYGZus{}commute} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once we have defined it, we can use it freely:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{C} \PYG{n}{D} \PYG{n}{E} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{D}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{D} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{n+nb+bp}{→} \PYG{n}{E}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{E} \PYG{o}{:=} \PYG{n}{h2} \PYG{o}{(}\PYG{n}{and\PYGZus{}commute} \PYG{n}{C} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{D}\PYG{o}{)} \PYG{n}{h1}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
It is annoying in this example that we have to give the arguments \sphinxcode{\sphinxupquote{C}} and \sphinxcode{\sphinxupquote{¬ D}} explicitly, because they are implicit in \sphinxcode{\sphinxupquote{h1}}. In fact, Lean allows us to tell this to Lean in the definition of \sphinxcode{\sphinxupquote{and\_commute}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{and\PYGZus{}commute} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here the squiggly braces indicate that the arguments \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{B}} are \sphinxstyleemphasis{implicit}, which is to say, Lean should infer them from the context when the theorem is used. We can then write the following instead:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{C} \PYG{n}{D} \PYG{n}{E} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{D}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{D} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{n+nb+bp}{→} \PYG{n}{E}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{E} \PYG{o}{:=} \PYG{n}{h2} \PYG{o}{(}\PYG{n}{and\PYGZus{}commute} \PYG{n}{h1}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Indeed, Lean’s library has a theorem, \sphinxcode{\sphinxupquote{and\_comm}},
defined in exactly this way.

\sphinxAtStartPar
The two definitions yield the same result.

\sphinxAtStartPar
Definitions and theorems are important in mathematics; they allow us to build up complex theories from fundamental principles. Lean also accepts the word \sphinxcode{\sphinxupquote{lemma}} instead of \sphinxcode{\sphinxupquote{theorem}}.

\sphinxAtStartPar
What is interesting is that in interactive theorem proving, we can even define familiar patterns of inference. For example, all of the following inferences were mentioned in the last chapter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{namespace} \PYG{n}{hidden}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{theorem} \PYG{n}{Or\PYGZus{}resolve\PYGZus{}left} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{Or.elim} \PYG{n}{h1}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{n}{False.elim} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{n}{h3}\PYG{o}{)}

\PYG{k+kd}{theorem} \PYG{n}{Or\PYGZus{}resolve\PYGZus{}right} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{Or.elim} \PYG{n}{h1}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{h3}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{False.elim} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{h3}\PYG{o}{)}\PYG{o}{)}

\PYG{k+kd}{theorem} \PYG{n}{absurd} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{False.elim} \PYG{o}{(}\PYG{n}{h1} \PYG{n}{h2}\PYG{o}{)}

\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, Lean’s library defines \sphinxcode{\sphinxupquote{Or.resolve\_left}}, \sphinxcode{\sphinxupquote{Or.resolve\_right}},
and \sphinxcode{\sphinxupquote{absurd}}.
We used the \sphinxcode{\sphinxupquote{namespace}} command to avoid naming conflicts,
which would have raised an error.

\sphinxAtStartPar
When we ask you to prove basic facts from propositional logic in Lean, as with propositional logic, our goal is to have you learn how to use Lean’s primitives. As a result, for those exercises, you should not use facts from the library. As we move towards real mathematics, however, you can use facts from the library more freely.


\section{Additional Syntax}
\label{\detokenize{propositional_logic_in_lean:additional-syntax}}
\sphinxAtStartPar
In this section, we describe some extra syntactic features of Lean, for power users. The syntactic gadgets are often convenient, and sometimes make proofs look prettier.

\sphinxAtStartPar
For one thing, you can use subscripted numbers with a backslash. For example, you can write \sphinxcode{\sphinxupquote{h₁}} by typing \sphinxcode{\sphinxupquote{h\textbackslash{}1}}. The labels are irrelevant to Lean, so the difference is only cosmetic.

\sphinxAtStartPar
Another feature is that you can omit the label in \sphinxcode{\sphinxupquote{fun}} and \sphinxcode{\sphinxupquote{intro}},
providing an “anonymous” assumption.
In tactic mode you can call the anonymous assumption
using the tactic \sphinxcode{\sphinxupquote{assumption}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro}
  \PYG{k}{show} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}
  \PYG{n}{apply} \PYG{n}{Or.inl}
  \PYG{n}{assumption}
\end{sphinxVerbatim}

\sphinxAtStartPar
In term mode you can call the anonymous assumption
by enclosing the proposition name in French quotes,
given by typing \sphinxcode{\sphinxupquote{\textbackslash{}f<}} and \sphinxcode{\sphinxupquote{\textbackslash{}f>}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{↦} \PYG{n}{Or.inl} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can also use the word \sphinxcode{\sphinxupquote{have}} without giving a label, and refer back to them using the same conventions. Here is an example that uses these features:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{my\PYGZus{}theorem} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
    \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h}
  \PYG{k}{have} \PYG{o}{:} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h}
  \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
  \PYG{n}{apply} \PYG{n}{Or.elim} \PYG{o}{‹}\PYG{n}{B} \PYG{n+nb+bp}{∨} \PYG{n}{C}\PYG{o}{›}
  \PYG{n+nb+bp}{.} \PYG{n}{intro}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{B}\PYG{o}{›}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{Or.inl}
    \PYG{n}{assumption}
  \PYG{n+nb+bp}{.} \PYG{n}{intro}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{C}\PYG{o}{›}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{Or.inr}
    \PYG{n}{assumption}
\end{sphinxVerbatim}

\sphinxAtStartPar
Another trick is that you can write \sphinxcode{\sphinxupquote{h.left}} and \sphinxcode{\sphinxupquote{h.right}} instead of
\sphinxcode{\sphinxupquote{And.left h}} and \sphinxcode{\sphinxupquote{And.right h}} whenever \sphinxcode{\sphinxupquote{h}} is a conjunction,
and you can write \sphinxcode{\sphinxupquote{⟨h1, h2⟩}}
using \sphinxcode{\sphinxupquote{\textbackslash{}<}} and \sphinxcode{\sphinxupquote{\textbackslash{}>}} (noting the difference with the French quotes)
instead of \sphinxcode{\sphinxupquote{And.intro h1 h2}}
whenever Lean can figure out that a conjunction is what you are trying to prove.
With these conventions, you can write the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{k}{from} \PYG{o}{⟨}\PYG{n}{h.right}\PYG{o}{,} \PYG{n}{h.left}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
This is nothing more than shorthand for the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{And.right} \PYG{n}{h}\PYG{o}{)} \PYG{o}{(}\PYG{n}{And.left} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Even more concisely, you can write this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{o}{⟨}\PYG{n}{h.right}\PYG{o}{,} \PYG{n}{h.left}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can even take apart a conjunction with \sphinxcode{\sphinxupquote{fun}}, so that this works:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{o}{⟨}\PYG{n}{h₁}\PYG{o}{,} \PYG{n}{h₂}\PYG{o}{⟩} \PYG{n+nb+bp}{↦} \PYG{o}{⟨}\PYG{n}{h₂}\PYG{o}{,} \PYG{n}{h₁}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
Similarly, if \sphinxcode{\sphinxupquote{h}} is a biconditional, you can write \sphinxcode{\sphinxupquote{h.mp}} and \sphinxcode{\sphinxupquote{h.mpr}} instead of \sphinxcode{\sphinxupquote{Iff.mp h}} and \sphinxcode{\sphinxupquote{Iff.mpr h}}, and you can write \sphinxcode{\sphinxupquote{⟨h1, h2⟩}} instead of \sphinxcode{\sphinxupquote{Iff.intro h1 h2}}. As a result, Lean understands these proofs:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{o}{⟨}\PYG{n}{hB}\PYG{o}{,} \PYG{n}{hAB}\PYG{o}{⟩} \PYG{n+nb+bp}{↦}
\PYG{n}{hAB.mpr} \PYG{n}{hB}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{↔} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=}
\PYG{o}{⟨}\PYG{k}{fun} \PYG{o}{⟨}\PYG{n}{h₁}\PYG{o}{,} \PYG{n}{h₂}\PYG{o}{⟩} \PYG{n+nb+bp}{↦} \PYG{o}{⟨}\PYG{n}{h₂}\PYG{o}{,} \PYG{n}{h₁}\PYG{o}{⟩}\PYG{o}{,} \PYG{k}{fun} \PYG{o}{⟨}\PYG{n}{h₁}\PYG{o}{,} \PYG{n}{h₂}\PYG{o}{⟩} \PYG{n+nb+bp}{↦} \PYG{o}{⟨}\PYG{n}{h₂}\PYG{o}{,} \PYG{n}{h₁}\PYG{o}{⟩}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally, you can add comments to your proofs in two ways. First, any text after a double\sphinxhyphen{}dash \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}}} until the end of a line is ignored by the Lean processor. Second, any text between \sphinxcode{\sphinxupquote{/\sphinxhyphen{}}} and \sphinxcode{\sphinxupquote{\sphinxhyphen{}/}} denotes a block comment, and is also ignored. You can nest block comments.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c}{/\PYGZhy{}}\PYG{c+cm}{ }\PYG{c+cm}{T}\PYG{c+cm}{h}\PYG{c+cm}{i}\PYG{c+cm}{s}\PYG{c+cm}{ }\PYG{c+cm}{i}\PYG{c+cm}{s}\PYG{c+cm}{ }\PYG{c+cm}{a}\PYG{c+cm}{ }\PYG{c+cm}{b}\PYG{c+cm}{l}\PYG{c+cm}{o}\PYG{c+cm}{c}\PYG{c+cm}{k}\PYG{c+cm}{ }\PYG{c+cm}{c}\PYG{c+cm}{o}\PYG{c+cm}{m}\PYG{c+cm}{m}\PYG{c+cm}{e}\PYG{c+cm}{n}\PYG{c+cm}{t}\PYG{c+cm}{.}
\PYG{c+cm}{ }\PYG{c+cm}{ }\PYG{c+cm}{ }\PYG{c+cm}{I}\PYG{c+cm}{t}\PYG{c+cm}{ }\PYG{c+cm}{c}\PYG{c+cm}{a}\PYG{c+cm}{n}\PYG{c+cm}{ }\PYG{c+cm}{f}\PYG{c+cm}{i}\PYG{c+cm}{l}\PYG{c+cm}{l}\PYG{c+cm}{ }\PYG{c+cm}{m}\PYG{c+cm}{u}\PYG{c+cm}{l}\PYG{c+cm}{t}\PYG{c+cm}{i}\PYG{c+cm}{p}\PYG{c+cm}{l}\PYG{c+cm}{e}\PYG{c+cm}{ }\PYG{c+cm}{l}\PYG{c+cm}{i}\PYG{c+cm}{n}\PYG{c+cm}{e}\PYG{c+cm}{s}\PYG{c+cm}{.}\PYG{c+cm}{ }\PYG{c+cm}{\PYGZhy{}/}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{a} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}      \PYG{c+c1}{\PYGZhy{}\PYGZhy{} assume the antecedent}
\PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{a}     \PYG{c+c1}{\PYGZhy{}\PYGZhy{} use it to establish the conclusion}
\end{sphinxVerbatim}


\section{Exercises}
\label{\detokenize{propositional_logic_in_lean:exercises}}
\sphinxAtStartPar
Prove the following in both term mode and tactic mode:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h₁} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₂} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{C}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₃} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{D}\PYG{o}{)} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{∨} \PYG{n}{D} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}


\chapter{Classical Reasoning}
\label{\detokenize{classical_reasoning:classical-reasoning}}\label{\detokenize{classical_reasoning:id1}}\label{\detokenize{classical_reasoning::doc}}
\sphinxAtStartPar
If we take all the rules of propositional logic we have seen so far and exclude \sphinxstyleemphasis{reductio ad absurdum}, or proof by contradiction, we have what is known as \sphinxstyleemphasis{intuitionistic logic}. In intuitionistic logic, it is possible to view proofs in computational terms: a proof of \(A \wedge B\) is a proof of \(A\) paired with a proof of \(B\), a proof of \(A \to B\) is a procedure which transforms evidence for \(A\) into evidence for \(B\), and a proof of \(A \vee B\) is a proof of one or the other, tagged so that we know which is the case. The \sphinxstyleemphasis{ex falso} rule makes sense only because we expect that there is no proof of falsity; it is like the empty data type.

\sphinxAtStartPar
Proof by contradiction does not fit in well with this world view: from a proof of a contradiction from \(\neg A\), we are supposed to magically produce a proof of \(A\). We will see that with proof by contradiction, we can prove the following law, known as the \sphinxstyleemphasis{law of the excluded middle}: \(\forall A, A \vee \neg A\). From a computational perspective, this says that for every \(A\) we can decide whether or not \(A\) is true.

\sphinxAtStartPar
Classical reasoning does introduce a number of principles into logic, however, that can be used to simplify reasoning. In this chapter, we will consider these principles, and see how they follow from the basic rules.


\section{Proof by Contradiction}
\label{\detokenize{classical_reasoning:proof-by-contradiction}}
\sphinxAtStartPar
Remember that in natural deduction, proof by contradiction is expressed by the following pattern:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\neg A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1}
\UIM{A}
\end{prooftree}

\sphinxAtStartPar
The assumption \(\neg A\) is canceled at the final inference.

\sphinxAtStartPar
In Lean, the inference is named \sphinxcode{\sphinxupquote{byContradiction}},
and since it is a classical rule,
we have to use the command \sphinxcode{\sphinxupquote{open Classical}} before it is available.
Once we do so, the pattern of inference is expressed as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{byContradiction}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
One of the most important consequences of this rule is a classical principle
that we mentioned above,
namely, the \sphinxstyleemphasis{law of the excluded middle},
which asserts that the following holds for all
\(A\): \(A \vee \neg A\).
In Lean we denote this law by \sphinxcode{\sphinxupquote{em}}.
In mathematical arguments, one often splits a proof into two cases,
assuming first \(A\) and then \(\neg A\).
Using the elimination rule for disjunction,
this is equivalent to using \(A \vee \neg A\),
which is the excluded middle principle for this particular \(A\).

\sphinxAtStartPar
Here is a proof of \sphinxcode{\sphinxupquote{em}}, in natural deduction, using proof by contradiction:



\begin{center}
\AXM{}
\RLM{2}
\UIM{\neg (A \vee \neg A)}
\AXM{}
\RLM{2}
\UIM{\neg (A \vee \neg A)}
\AXM{}
\RLM{1}
\UIM{A}
\UIM{A \vee \neg A}
\BIM{\bot}
\RLM{1}
\UIM{\neg A}
\UIM{A \vee \neg A}
\BIM{\bot}
\RLM{2}
\UIM{A \vee \neg A}
\DP
\end{center}

\sphinxAtStartPar
Here is the same proof rendered in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inl} \PYG{n}{h3}
    \PYG{k}{show} \PYG{n}{False}
    \PYG{n}{exact} \PYG{n}{h1} \PYG{n}{h4}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inr} \PYG{n}{h2}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h1} \PYG{n}{h5}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The principle is known as the law of the excluded middle because it says that a proposition \sphinxcode{\sphinxupquote{A}} is either true or false;
there is no middle ground. As a result,
the theorem is named \sphinxcode{\sphinxupquote{em}} in the Lean library.
For any proposition \sphinxcode{\sphinxupquote{A}}, \sphinxcode{\sphinxupquote{em A}} denotes a proof of \sphinxcode{\sphinxupquote{A ∨ ¬ A}},
and you are free to use it any time \sphinxcode{\sphinxupquote{Classical}} is open:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{Or.elim} \PYG{o}{(}\PYG{n}{em} \PYG{n}{A}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{n}{Or.inl} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{n}{Or.inr} \PYG{o}{‹}\PYG{n+nb+bp}{¬}\PYG{n}{A}\PYG{o}{›}\PYG{o}{)}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Or even more simply:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{em} \PYG{n}{A}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, we can go in the other direction,
and use the law of the excluded middle to justify proof by contradiction.
You are asked to do this in the exercises.

\sphinxAtStartPar
Proof by contradiction is also equivalent to the principle
\(\neg \neg A \leftrightarrow A\).
The implication from right to left holds intuitionistically;
the other implication is classical,
and is known as \sphinxstyleemphasis{double\sphinxhyphen{}negation elimination}.
Here is a proof in natural deduction:



\begin{center}
\AXM{}
\RLM{2}
\UIM{\neg \neg A}
\AXM{}
\RLM{1}
\UIM{\neg A}
\BIM{\bot}
\RLM{1}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{\neg A}
\AXM{}
\RLM{2}
\UIM{A}
\BIM{\bot}
\RLM{1}
\UIM{\neg \neg A}
\RLM{2}
\BIM{\neg \neg A \leftrightarrow A}
\DP
\end{center}

\sphinxAtStartPar
And here is the corresponding proof in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{Iff.intro}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{byContradiction}
      \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦}
        \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{h1} \PYG{n}{h2}\PYG{o}{)}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{k}{from} \PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{n}{h2} \PYG{n}{h1}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the next section, we will derive a number of classical rules and equivalences. These are tricky to prove. In general, to use classical reasoning in natural deduction, we need to extend the general heuristic presented in \hyperref[\detokenize{natural_deduction_for_propositional_logic:forward-and-backward-reasoning}]{Section \ref{\detokenize{natural_deduction_for_propositional_logic:forward-and-backward-reasoning}}} as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
First, work backward from the conclusion, using the introduction rules.

\item {} 
\sphinxAtStartPar
When you have run out things to do in the first step, use elimination rules to work forward.

\item {} 
\sphinxAtStartPar
If all else fails, use a proof by contradiction.

\end{enumerate}

\sphinxAtStartPar
Sometimes a proof by contradiction is necessary, but when it isn’t, it can be less informative than a direct proof. Suppose, for example, we want to prove \(A \wedge B \wedge C \to D\). In a direct proof, we assume \(A\), \(B\), and \(C\), and work towards \(D\). Along the way, we will derive other consequences of \(A\), \(B\), and \(C\), and these may be useful in other contexts. If we use proof by contradiction, on the other hand, we assume \(A\), \(B\), \(C\), and \(\neg D\), and try to prove \(\bot\). In that case, we are working in an inconsistent context; any auxiliary results we may obtain that way are subsumed by the fact that ultimately \(\bot\) is a consequence of the hypotheses.


\section{Some Classical Principles}
\label{\detokenize{classical_reasoning:some-classical-principles}}
\sphinxAtStartPar
We have already seen that \(A \vee \neg A\) and \(\neg \neg A \leftrightarrow A\) are two important theorems of classical propositional logic. In this section we will provide some more theorems, rules, and equivalences. Some will be proved here, but most will be left to you in the exercises. In ordinary mathematics, these are generally used without comment. It is nice to know, however, that they can all be justified using the basic rules of classical natural deduction.

\sphinxAtStartPar
If \(A \to B\) is any implication, the assertion \(\neg B \to \neg A\) is known as the \sphinxstyleemphasis{contrapositive}. Every implication implies its contrapositive, and the other direction is true classically:



\begin{center}
\AXM{\neg B \to \neg A}
\AXM{}
\RLM{1}
\UIM{\neg B}
\BIM{\neg A}
\AXM{}
\RLM{2}
\UIM{A}
\BIM{\bot}
\RLM{1}
\UIM{B}
\RLM{2}
\UIM{A \to B}
\DP
\end{center}

\sphinxAtStartPar
Here is another example. Intuitively, asserting “if A then B” is equivalent to saying that it cannot be the case that A is true and B is false. Classical reasoning is needed to get us from the second statement to the first.



\begin{center}
\AXM{}
\RLM{3}
\UIM{\neg (A \wedge \neg B)}
\AXM{}
\RLM{2}
\UIM{A}
\AXM{}
\RLM{1}
\UIM{\neg B}
\BIM{A \wedge \neg B}
\BIM{\bot}
\RLM{1}
\UIM{B}
\RLM{2}
\UIM{A \to B}
\RLM{3}
\UIM{\neg (A \wedge \neg B) \to (A \to B)}
\DP
\end{center}

\sphinxAtStartPar
Here are the same proofs, rendered in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
  \PYG{k}{show} \PYG{n}{B}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{h} \PYG{n}{h2}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h3} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
  \PYG{k}{show} \PYG{n}{B}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›} \PYG{o}{‹}\PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{›}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h} \PYG{n}{this}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that in the second example, we used an anonymous \sphinxcode{\sphinxupquote{intro}}
and an anonymous \sphinxcode{\sphinxupquote{have}}.
We used the brackets \sphinxcode{\sphinxupquote{\textbackslash{}f<}} and \sphinxcode{\sphinxupquote{\textbackslash{}f>}} to write \sphinxcode{\sphinxupquote{‹A›}} and \sphinxcode{\sphinxupquote{‹¬ B›}},
referring back to the first assumption.
The use of the word \sphinxcode{\sphinxupquote{this}} refers back to the \sphinxcode{\sphinxupquote{have}}.

\sphinxAtStartPar
Knowing that we can prove the law of the excluded middle,
it is convenient to use it in classical proofs.
Here is an example,
with a proof of \((A \to B) \vee (B \to A)\):



\begin{center}
\AXM{}
\UIM{B \vee \neg B}
\AXM{}
\RLM{1}
\UIM{B}
\UIM{A \to B}
\UIM{(A \to B) \vee (B \to A)}
\AXM{}
\RLM{1}
\UIM{\neg B}
\AXM{}
\RLM{2}
\UIM{B}
\BIM{\bot}
\UIM{A}
\RLM{2}
\UIM{B \to A}
\UIM{(A \to B) \vee (B \to A)}
\RLM{1}
\TIM{(A \to B) \vee (B \to A)}
\DP
\end{center}

\sphinxAtStartPar
Here is the corresponding proof in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:=}
\PYG{n}{Or.elim} \PYG{o}{(}\PYG{n}{em} \PYG{n}{B}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=}
      \PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦} \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{n}{h}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{n}{this}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{o}{:=}
      \PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{↦} \PYG{k}{have} \PYG{o}{:} \PYG{n}{False} \PYG{o}{:=} \PYG{n}{h} \PYG{o}{‹}\PYG{n}{B}\PYG{o}{›}
      \PYG{k}{show} \PYG{n}{A} \PYG{k}{from} \PYG{n}{False.elim} \PYG{n}{this}
    \PYG{k}{show} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inr} \PYG{n}{this}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Using classical reasoning, implication can be rewritten in terms of disjunction and negation:
\begin{equation*}
\begin{split}(A \to B) \leftrightarrow \neg A \vee B.\end{split}
\end{equation*}
\sphinxAtStartPar
The forward direction requires classical reasoning.

\sphinxAtStartPar
The following equivalences are known as De Morgan’s laws:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\neg (A \vee B) \leftrightarrow \neg A \wedge \neg B\)

\item {} 
\sphinxAtStartPar
\(\neg (A \wedge B) \leftrightarrow \neg A \vee \neg B\)

\end{itemize}

\sphinxAtStartPar
The forward direction of the second of these requires classical reasoning.

\sphinxAtStartPar
Using these identities, we can always push negations down to propositional variables. For example, we have



\begin{align*}
  \neg (\neg A \wedge B \to C)
    & \leftrightarrow \neg (\neg (\neg A \wedge B) \vee C) \\
    & \leftrightarrow \neg \neg (\neg A \wedge B) \wedge \neg C \\
    & \leftrightarrow \neg A \wedge B \wedge \neg C.
\end{align*}

\sphinxAtStartPar
A formula built up from \(\wedge\), \(\vee\), and \(\neg\) in which negations only occur at variables is said to be in \sphinxstyleemphasis{negation normal form}.

\sphinxAtStartPar
In fact, using distributivity laws, one can go on to ensure that all the disjunctions are on the outside, so that the formulas is a big or of and’s of propositional variables and negated propositional variables. Such a formula is said to be in \sphinxstyleemphasis{disjunctive normal form}. Alternatively, all the and’s can be brought to the outside. Such a formula is said to be in \sphinxstyleemphasis{conjunctive normal form}. An exercise below, however, shows that putting formulas in disjunctive or conjunctive normal form can make them much longer.


\section{The \sphinxstyleliteralintitle{\sphinxupquote{contradiction}} Tactic}
\label{\detokenize{classical_reasoning:the-contradiction-tactic}}
\sphinxAtStartPar
Once we reach a contradiction in our proof,
i.e. by having \sphinxcode{\sphinxupquote{h1 : A}} and \sphinxcode{\sphinxupquote{h2 : ¬A}},
we can apply the tactic \sphinxcode{\sphinxupquote{contradiction}}.
This will search for a contradiction among the hypotheses,
and complete the proof if it succeeds in finding one.
Revisiting our previous example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inl} \PYG{n}{h3}
    \PYG{k}{show} \PYG{n}{False}
    \PYG{n}{exact} \PYG{n}{h1} \PYG{n}{h4}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inr} \PYG{n}{h2}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h1} \PYG{n}{h5}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inl} \PYG{n}{h3}
    \PYG{n}{contradiction}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inr} \PYG{n}{h2}
  \PYG{n}{contradiction}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Since \sphinxcode{\sphinxupquote{contradiction}} does not require the names of
variables that form a contradiction
we can even remove all of the names.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{apply} \PYG{n}{byContradiction}
  \PYG{n}{intro}
  \PYG{k}{have} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
    \PYG{n}{intro}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inl} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›}
    \PYG{n}{contradiction}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{Or.inr} \PYG{n}{this}
  \PYG{n}{contradiction}

\PYG{k+kd}{end}
\end{sphinxVerbatim}


\section{Exercises}
\label{\detokenize{classical_reasoning:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Show how to derive the proof\sphinxhyphen{}by\sphinxhyphen{}contradiction rule from the law of the excluded middle, using the other rules of natural deduction. In other words, assume you have a proof of \(\bot\) from \(\neg A\). Using \(A \vee \neg A\) as a hypothesis, but \sphinxstyleemphasis{without} using the rule RAA, show how you can go on to derive \(A\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg (A \wedge B)\) from \(\neg A \vee \neg B\). (You do not need to use proof by contradiction.)

\item {} 
\sphinxAtStartPar
Construct a natural deduction proof of \(\neg A \vee \neg B\) from \(\neg (A \wedge B)\). You can do it as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
First, prove \(\neg B\), and hence \(\neg A \vee \neg B\), from \(\neg (A \wedge B)\) and \(A\).

\item {} 
\sphinxAtStartPar
Use this to construct a proof of \(\neg A\), and hence \(\neg A \vee \neg B\), from \(\neg (A \wedge B)\) and \(\neg (\neg A \vee \neg B)\).

\item {} 
\sphinxAtStartPar
Use this to construct a proof of a contradiction from \(\neg (A \wedge B)\) and \(\neg (\neg A \vee \neg B)\).

\item {} 
\sphinxAtStartPar
Using proof by contradiction, this gives you a proof of \(\neg A \vee \neg B\) from \(\neg (A \wedge B)\).

\end{enumerate}

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(P\) from \(\neg P \to (Q \vee R)\), \(\neg Q\), and \(\neg R\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg A \vee B\) from \(A \to B\). You may use the law of the excluded middle.

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(A \to ((A \wedge B) \vee (A \wedge \neg B))\). You may use the law of the excluded middle.

\item {} 
\sphinxAtStartPar
Put \((A \vee B) \wedge (C \vee D) \wedge (E \vee F)\) in disjunctive normal form, that is, write it as a big “or” of multiple “and” expressions.

\item {} 
\sphinxAtStartPar
Prove \sphinxcode{\sphinxupquote{¬ (A ∧ B) → ¬ A ∨ ¬ B}} by replacing the sorry’s below by proofs.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Tactic}

\PYG{k+kn}{section}

\PYG{k+kn}{open} \PYG{n}{Classical}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} Prove ¬ (A ∧ B) → ¬ A ∨ ¬ B by replacing the sorry\PYGZsq{}s below}
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} by proofs.}

\PYG{k+kd}{lemma} \PYG{n}{step1} \PYG{o}{(}\PYG{n}{h₁} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₂} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{have} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{k}{from} \PYG{n}{Or.inr} \PYG{n}{this}

\PYG{k+kd}{lemma} \PYG{n}{step2} \PYG{o}{(}\PYG{n}{h₁} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₂} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:} \PYG{n}{False} \PYG{o}{:=}
\PYG{k}{have} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{step1} \PYG{n}{h₁} \PYG{o}{‹}\PYG{n}{A}\PYG{o}{›}
  \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{h₂} \PYG{n}{this}
\PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{g+gr}{sorry}

\PYG{k+kd}{theorem} \PYG{n}{step3} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{byContradiction}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h\PYGZsq{}} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{step2} \PYG{n}{h} \PYG{n}{h\PYGZsq{}}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Complete these proofs in tactic mode

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Classical}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{g+gr}{sorry}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\end{enumerate}


\chapter{Semantics of Propositional Logic}
\label{\detokenize{semantics_of_propositional_logic:semantics-of-propositional-logic}}\label{\detokenize{semantics_of_propositional_logic:id1}}\label{\detokenize{semantics_of_propositional_logic::doc}}
\sphinxAtStartPar
Classically, we think of propositional variables as ranging over statements that can be true or false. And, intuitively, we think of a proof system as telling us what propositional formulas \sphinxstyleemphasis{have to} be true, no matter what the variables stand for. For example, the fact that we can prove \(C\) from the hypotheses \(A\), \(B\), and \(A \wedge B \to C\) seems to tell us that whenever the hypotheses are true, then \(C\) has to be true as well.

\sphinxAtStartPar
Making sense of this involves stepping outside the system and giving an account of truth—more precisely, the conditions under which a propositional formula is true. This is one of the things that symbolic logic was designed to do, and the task belongs to the realm of \sphinxstyleemphasis{semantics}. Formulas and formal proofs are \sphinxstyleemphasis{syntactic} notions, which is to say, they are represented by symbols and symbolic structures. Truth is a \sphinxstyleemphasis{semantic} notion, in that it ascribes a type of \sphinxstyleemphasis{meaning} to certain formulas.

\sphinxAtStartPar
Syntactically, we were able to ask and answer questions like the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Given a set of hypotheses, \(\Gamma\), and a formula, \(A\), can we derive \(A\) from \(\Gamma\)?

\item {} 
\sphinxAtStartPar
What formulas can be derived from \(\Gamma\)?

\item {} 
\sphinxAtStartPar
What hypotheses are needed to derive \(A\)?

\end{itemize}

\sphinxAtStartPar
The questions we consider semantically are different:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Given an assignment of truth values to the propositional variables occurring in a formula \(A\), is \(A\) true or false?

\item {} 
\sphinxAtStartPar
Is there any truth assignment that makes \(A\) true?

\item {} 
\sphinxAtStartPar
Which are the truth assignments that make \(A\) true?

\end{itemize}

\sphinxAtStartPar
In this chapter, we will not provide a fully rigorous mathematical treatment of syntax and semantics. That subject matter is appropriate to a more advanced and focused course on mathematical logic. But we will discuss semantic issues in enough detail to give you a good sense of what it means to think semantically, as well as a sense of how to make pragmatic use of semantic notions.


\section{Truth Values and Assignments}
\label{\detokenize{semantics_of_propositional_logic:truth-values-and-assignments}}
\sphinxAtStartPar
The first notion we will need is that of a \sphinxstyleemphasis{truth value}. We have already seen two, namely, “true” and “false.” We will use the symbols \(\mathbf{T}\) and \(\mathbf{F}\) to represent these in informal mathematics. These are the values that \(\top\) and \(\bot\) are intended to denote in natural deduction, and \sphinxcode{\sphinxupquote{True}} and \sphinxcode{\sphinxupquote{False}} are intended to denote in Lean.

\sphinxAtStartPar
In this text, we will adopt a “classical” notion of truth, following our discussion in \hyperref[\detokenize{classical_reasoning:classical-reasoning}]{Section \ref{\detokenize{classical_reasoning:classical-reasoning}}}. This can be understood in various ways, but, concretely, it comes down to this: we will assume that any proposition is either true or false (but, of course, not both). This conception of truth is what underlies the law of the excluded middle, \(A \vee \neg A\). Semantically, we read this sentence as saying “either \(A\) is true, or \(\neg A\) is true.” Since, in our semantic interpretation, \(\neg A\) is true exactly when \(A\) is false, the law of the excluded middle says that \(A\) is either true or false.

\sphinxAtStartPar
The next notion we will need is that of a \sphinxstyleemphasis{truth assignment}, which is simply a function that assigns a truth value to each element of a set of propositional variables. In this section, we will distinguish between propositional variables and arbitrary formulas by using letters \(P, Q, R, \ldots\) for the former and \(A, B, C, \ldots\) for the latter. For example, the function \(v\) defined by
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(v(P) := \mathbf{T}\)

\item {} 
\sphinxAtStartPar
\(v(Q) := \mathbf{F}\)

\item {} 
\sphinxAtStartPar
\(v(R) := \mathbf{F}\)

\item {} 
\sphinxAtStartPar
\(v(S) := \mathbf{T}\)

\end{itemize}

\sphinxAtStartPar
is a truth assignment for the set of variables \(\{ P, Q, R, S \}\).

\sphinxAtStartPar
Intuitively, a truth assignment describes a possible “state of the world.” Going back to the Malice and Alice puzzle, let’s suppose the following letters are shorthand for the statements:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(P\) := Alice’s brother was the victim

\item {} 
\sphinxAtStartPar
\(Q\) := Alice was the killer

\item {} 
\sphinxAtStartPar
\(R\) := Alice was in the bar

\end{itemize}

\sphinxAtStartPar
In the world described by the solution to the puzzle, the first and third statements are true, and the second is false. So our truth assignment gives the value \(\mathbf{T}\) to \(P\) and \(R\), and the value \(\mathbf{F}\) to \(Q\).

\sphinxAtStartPar
Once we have a truth assignment \(v\) to a set of propositional variables, we can extend it to a \sphinxstyleemphasis{valuation function} \(\bar v\), which assigns a value of true or false to every propositional formula that depends only on these variables. The function \(\bar v\) is defined recursively, which is to say, formulas are evaluated from the bottom up, so that value assigned to a compound formula is determined by the values assigned to its components. Formally, the function is defined as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\bar v(\top) = \mathbf{T}\).

\item {} 
\sphinxAtStartPar
\(\bar v(\bot) = \mathbf{F}\).

\item {} 
\sphinxAtStartPar
\(\bar v(\ell) = v(\ell)\), where \(\ell\) is any propositional variable.

\item {} 
\sphinxAtStartPar
\(\bar v(\neg A) = \mathbf{T}\) if \(\bar v(A)\) is \(\mathbf{F}\), and vice versa.

\item {} 
\sphinxAtStartPar
\(\bar v(A \wedge B) = \mathbf{T}\) if \(\bar v(A)\) and \(\bar v(B)\) are both \(\mathbf{T}\), and \(\mathbf{F}\) otherwise.

\item {} 
\sphinxAtStartPar
\(\bar v(A \vee B) = \mathbf{T}\) if at least one of \(\bar v(A)\) and \(\bar v(B)\) is \(\mathbf{T}\); otherwise \(\mathbf{F}\).

\item {} 
\sphinxAtStartPar
\(\bar v(A \to B) = \mathbf{T}\) if either \(\bar v(B)\) is \(\mathbf{T}\) or \(\bar v(A)\) is \(\mathbf{F}\), and \(\mathbf{F}\) otherwise. (Equivalently, \(\bar v(A \to B) = \mathbf{F}\) if \(\bar v(A)\) is \(\mathbf{T}\) and \(\bar v(B)\) is \(\mathbf{F}\), and \(\mathbf{T}\) otherwise.)

\end{itemize}

\sphinxAtStartPar
The rules for conjunction and disjunction are easy to understand. “\(A\) and \(B\)” is true exactly when \(A\) and \(B\) are both true; “\(A\) or \(B\)” is true when at least one of \(A\) or \(B\) is true.

\sphinxAtStartPar
Understanding the rule for implication is trickier. People are often surprised to hear that any if\sphinxhyphen{}then statement with a false hypothesis is supposed to be true. The statement “if I have two heads, then circles are squares” may sound like it ought to be false, but by our reckoning, it comes out true. To make sense of this, think about the difference between the two sentences:
\begin{itemize}
\item {} 
\sphinxAtStartPar
“If I have two heads, then circles are squares.”

\item {} 
\sphinxAtStartPar
“If I had two heads, then circles would be squares.”

\end{itemize}

\sphinxAtStartPar
The second sentence is an example of a \sphinxstyleemphasis{counterfactual} implication. It asserts something about how the world might change, if things were other than they actually are. Philosophers have studied counterfactuals for centuries, but mathematical logic is concerned with the first sentence, a \sphinxstyleemphasis{material} implication. The material implication asserts something about the way the world is right now, rather than the way it might have been. Since it is false that I have two heads, the statement “if I have two heads, then circles are squares” is true.

\sphinxAtStartPar
Why do we evaluate material implication in this way? Once again, let us consider the true sentence “every natural number that is prime and greater than two is odd.” We can interpret this sentence as saying that all of the (infinitely many) sentences in this list are true:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If 0 is prime and greater than 2, then 0 is odd.

\item {} 
\sphinxAtStartPar
If 1 is prime and greater than 2, then 1 is odd.

\item {} 
\sphinxAtStartPar
If 2 is prime and greater than 2, then 2 is odd.

\item {} 
\sphinxAtStartPar
If 3 is prime and greater than 2, then 3 is odd.

\item {} 
\sphinxAtStartPar
…

\end{itemize}

\sphinxAtStartPar
The first sentence on this list is a lot like our “two heads” example, since both the hypothesis and the conclusion are false. But since it is an instance of a statement that is true in general, we are committed to assigning it the value \(\mathbf{T}\). The second sentence is a different: the hypothesis is still false, but here the conclusion is true. Together, these tell us that whenever the hypothesis is false, the conditional statement should be true. The fourth sentence has a true hypothesis and a true conclusion. So from the second and fourth sentences, we see that whenever the conclusion is true, the conditional should be true as well. Finally, it seems clear that the sentence “if 3 is prime and greater than 2, then 3 is even” should \sphinxstyleemphasis{not} be true. This pattern, where the hypothesis is true and the conclusion is false, is the only one for which the conditional will be false.

\sphinxAtStartPar
Let us motivate the semantics for material implication another way, using the deductive rules described in the last chapter. Notice that, if \(B\) is true, we can prove \(A \to B\) without any assumptions about \(A\):



\begin{prooftree}
\AXM{B}
\UIM{A \to B}
\end{prooftree}

\sphinxAtStartPar
This follows from the proper reading of the implication introduction rule: given \(B\), one can always infer \(A \to B\), and then cancel an assumption \(A\), \sphinxstyleemphasis{if there is one}. If \(A\) was never used in the proof, the conclusion is simply weaker than it needs to be. This inference is validated in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hB} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{hA} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
  \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{n}{hB}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Similarly, if \(A\) is false, we can prove \(A \to B\) without any assumptions about \(B\):



\begin{prooftree}
\AXM{\neg A}
\AXM{}
\RLM{1}
\UIM{A}
\BIM{\bot}
\RLM{1}
\UIM{A \to B}
\end{prooftree}

\sphinxAtStartPar
In Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hnA} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{hA} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↦}
  \PYG{k}{show} \PYG{n}{B} \PYG{k}{from} \PYG{n}{False.elim} \PYG{o}{(}\PYG{n}{hnA} \PYG{n}{hA}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally, if \(A\) is true and \(B\) is false, we can prove \(\neg (A \to B)\):



\begin{prooftree}
\AXM{\neg B}
\AXM{}
\RLM{1}
\UIM{A \to B}
\AXM{A}
\BIM{B}
\BIM{\bot}
\RLM{1}
\UIM{\neg (A \to B)}
\end{prooftree}

\sphinxAtStartPar
Once again, in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hA} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hnB} \PYG{o}{:} \PYG{n+nb+bp}{¬}\PYG{n}{B}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{hB} \PYG{o}{:} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{h} \PYG{n}{hA}
  \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{hnB} \PYG{n}{hB}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Now that we have defined the truth of any formula relative to a truth assignment, we can answer our first semantic question: given an assignment \(v\) of truth values to the propositional variables occurring in some formula \(\varphi\), how do we determine whether or not \(\varphi\) is true? This amounts to evaluating \(\bar v(\varphi)\), and the recursive definition of \(\varphi\) gives a recipe: we evaluate the expressions occurring in \(\varphi\) from the bottom up, starting with the propositional variables, and using the evaluation of an expression’s components to evaluate the expression itself. For example, suppose our truth assignment \(v\) makes \(A\) and \(B\) true and \(C\) false. To evaluate \((B \to C) \vee (A \wedge B)\) under \(v\), note that the expression \(B \to C\) comes out false and the expression \(A \wedge B\) comes out true. Since a disjunction “false or true” is true, the entire formula is true.

\sphinxAtStartPar
We can also go in the other direction: given a formula, we can attempt to find a truth assignment that will make it true (or false). In fact, we can use Lean to evaluate formulas for us. In the example that follows, you can assign any set of values to the proposition symbols \sphinxcode{\sphinxupquote{A}}, \sphinxcode{\sphinxupquote{B}}, \sphinxcode{\sphinxupquote{C}}, \sphinxcode{\sphinxupquote{D}}, and \sphinxcode{\sphinxupquote{E}}. When you run Lean on this input, the output of the \sphinxcode{\sphinxupquote{eval}} statement is the value of the expression.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} Define your truth assignment here}
\PYG{k+kd}{def} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{true}
\PYG{k+kd}{def} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{false}
\PYG{k+kd}{def} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{true}
\PYG{k+kd}{def} \PYG{n}{D} \PYG{o}{:=} \PYG{n}{true}
\PYG{k+kd}{def} \PYG{n}{E} \PYG{o}{:=} \PYG{n}{false}

\PYG{k+kd}{def} \PYG{n}{test} \PYG{o}{(}\PYG{n}{p} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{[}\PYG{n}{Decidable} \PYG{n}{p}\PYG{o}{]} \PYG{o}{:} \PYG{n}{String} \PYG{o}{:=}
\PYG{k}{if} \PYG{n}{p} \PYG{k}{then} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{true}\PYG{l+s+s2}{\PYGZdq{}} \PYG{k}{else} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{false}\PYG{l+s+s2}{\PYGZdq{}}

\PYG{k}{\PYGZsh{}eval} \PYG{n}{test} \PYG{o}{(}\PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬} \PYG{n}{C}\PYG{o}{)}
\PYG{k}{\PYGZsh{}eval} \PYG{n}{test} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{D}\PYG{o}{)}
\PYG{k}{\PYGZsh{}eval} \PYG{n}{test} \PYG{o}{(}\PYG{n}{C} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{D} \PYG{n+nb+bp}{∨} \PYG{n+nb+bp}{¬}\PYG{n}{E}\PYG{o}{)}\PYG{o}{)}
\PYG{k}{\PYGZsh{}eval} \PYG{n}{test} \PYG{o}{(}\PYG{n+nb+bp}{¬}\PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{n+nb+bp}{∧} \PYG{n}{D}\PYG{o}{)}\PYG{o}{)}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
Try varying the truth assignments, to see what happens. You can add your own formulas to the end of the input, and evaluate them as well. Try to find truth assignments that make each of the formulas tested above evaluate to true. For an extra challenge, try finding a single truth assignment that makes them all true at the same time.


\section{Truth Tables}
\label{\detokenize{semantics_of_propositional_logic:truth-tables}}
\sphinxAtStartPar
The second and third semantic questions we asked are a little trickier than the first. Given a formula \(A\), is there any truth assignment that makes \(A\) true? If so, which truth assignments make \(A\) true? Instead of considering one particular truth assignment, these questions ask us to quantify over \sphinxstyleemphasis{all} possible truth assignments.

\sphinxAtStartPar
Of course, the number of possible truth assignments depends on the number of propositional letters we’re considering. Since each letter has two possible values, \(n\) letters will produce \(2^n\) possible truth assignments. This number grows very quickly, so we’ll mostly look at smaller formulas here.

\sphinxAtStartPar
We’ll use something called a \sphinxstyleemphasis{truth table} to figure out when, if ever, a formula is true. On the left hand side of the truth table, we’ll put all of the possible truth assignments for the present propositional letters. On the right hand side, we’ll put the truth value of the entire formula under the corresponding assignment.

\sphinxAtStartPar
To begin with, truth tables can be used to concisely summarize the semantics of our logical connectives:



\begin{center}
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \wedge B$ \\ \hline
$\mathbf{T}$  & $\mathbf{T}$  & $\mathbf{T}$      \\ \hline
$\mathbf{T}$  & $\mathbf{F}$ & $\mathbf{F}$     \\ \hline
$\mathbf{F}$ & $\mathbf{T}$  & $\mathbf{F}$     \\ \hline
$\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{F}$     \\ \hline
\end{tabular}
\quad
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \vee B$ \\ \hline
$\mathbf{T}$  & $\mathbf{T}$  & $\mathbf{T}$      \\ \hline
$\mathbf{T}$  & $\mathbf{F}$ & $\mathbf{T}$      \\ \hline
$\mathbf{F}$ & $\mathbf{T}$  & $\mathbf{T}$      \\ \hline
$\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{F}$     \\ \hline
\end{tabular}
\quad
\begin{tabular} {|c|c||c|}
\hline
$A$      & $B$      & $A \to B$ \\ \hline
$\mathbf{T}$  & $\mathbf{T}$  & $\mathbf{T}$      \\ \hline
$\mathbf{T}$  & $\mathbf{F}$ & $\mathbf{F}$     \\ \hline
$\mathbf{F}$ & $\mathbf{T}$  & $\mathbf{T}$      \\ \hline
$\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{T}$      \\ \hline
\end{tabular}
\end{center}

\sphinxAtStartPar
We will leave it to you to write the table for \(\neg A\), as an easy exercise.

\sphinxAtStartPar
For compound formulas, the style is much the same. Sometimes it can be helpful to include intermediate columns with the truth values of subformulas:



\begin{center}
\begin{tabular} {|c|c|c||c|c||c|}
\hline
$A$          & $B$          & $C$          & $A \to B$  & $B \to C$      & $(A \to B) \vee (B \to C)$ \\ \hline
$\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
$\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$   \\ \hline
$\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
$\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
$\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
$\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{F}$ & $\mathbf{T}$   \\ \hline
$\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
$\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{F}$ & $\mathbf{T}$ & $\mathbf{T}$ & $\mathbf{T}$   \\ \hline
\end{tabular}
\end{center}

\sphinxAtStartPar
By writing out the truth table for a formula, we can glance at the rows and see which truth assignments make the formula true. If all the entries in the final column are \(\mathbf{T}\), as in the above example, the formula is said to be \sphinxstyleemphasis{valid}.


\section{Soundness and Completeness}
\label{\detokenize{semantics_of_propositional_logic:soundness-and-completeness}}
\sphinxAtStartPar
Suppose we have a fixed deduction system in mind, such as natural deduction. A propositional formula is said to be \sphinxstyleemphasis{provable} if there is a formal proof of it in that system. A propositional formula is said to be a \sphinxstyleemphasis{tautology}, or \sphinxstyleemphasis{valid}, if it is true under any truth assignment. Provability is a syntactic notion, in that it asserts the existence of a syntactic object, namely, a proof. Validity is a semantic notion, in that it has to do with truth assignments and valuations. But, intuitively, these notions should coincide: both express the idea that a formula \(A\) \sphinxstyleemphasis{has} to be true, or is \sphinxstyleemphasis{necessarily} true, and one would expect a good proof system to enable us to derive the valid formulas.

\sphinxAtStartPar
The statement that every provable formula is valid is known as \sphinxstyleemphasis{soundness}. If \(A\) is any formula, logicians use the notation \(\vdash A\) to express the fact that \(A\) is provable and the notation \(\vDash A\) to express that \(A\) is valid. (The first symbol is sometimes called a “turnstile” and the second symbol is sometimes called a “double\sphinxhyphen{}turnstile.”) With this notation, soundness says that for every propositional formula \(A\), if \(\vdash A\), then \(\vDash A\). The converse, which says that every valid formula is provable, is known as \sphinxstyleemphasis{completeness}. In symbolic terms, it says that for every formula \(A\), if \(\vDash A\), then \(\vdash A\).

\sphinxAtStartPar
Because of the way we have chosen our inference rules and defined the notion of a valuation, this intuition that the two notions should coincide holds true. In other words, the system of natural deduction we have presented for propositional logic is sound and complete with respect to truth\sphinxhyphen{}table semantics.

\sphinxAtStartPar
These notions of soundness and completeness extend to provability from hypotheses. If \(\Gamma\) is a set of propositional formulas and \(A\) is a propositional formula, then \(A\) is said to be a \sphinxstyleemphasis{logical consequence} of \(\Gamma\) if, given any truth assignment that makes every formula in \(\Gamma\) true, \(A\) is true as well. In this extended setting, soundness says that if \(A\) is provable from \(\Gamma\), then \(A\) is a logical consequence of \(\Gamma\). Completeness runs the other way: if \(A\) is a logical consequence of \(\Gamma\), it is provable from \(\Gamma\). In symbolic terms, we write \(\Gamma \vdash A\) to express that \(A\) is provable from the formulas in \(\Gamma\) (or that \(\Gamma\) \sphinxstyleemphasis{proves} \(A\)), and we write \(\Gamma \vDash A\) to express that \(A\) is a logical consequence of \(\Gamma\) (or that \(\Gamma\) \sphinxstyleemphasis{entails} \(A\)). With this notation, soundness says that for every propositional formula \(A\) and set of propositional formulas \(\Gamma\), if \(\Gamma \vdash A\) then \(\Gamma \vDash A\), and completeness says that for every \(A\) and \(\Gamma\), if \(\Gamma \vDash A\) then \(\Gamma \vdash A\).

\sphinxAtStartPar
Given a set of propositional formulas \(\Gamma\) and a propositional formula \(A\), the previous section gives us a recipe for deciding whether \(\Gamma\) entails \(A\): construct a truth tables for all the formulas in \(\Gamma\) and \(A\), and check whether every \(A\) comes out true on every line of the table on which every formula of \(\Gamma\) is true. (It doesn’t matter what happens to \(A\) on the lines where some formula in \(\Gamma\) is false.)

\sphinxAtStartPar
Notice that with the rules of natural deduction, a formula \(A\) is provable from a set of hypotheses \(\{ B_1, B_2, \ldots, B_n \}\) if and only if the formula \(B_1 \wedge B_2 \wedge \cdots \wedge B_n \to A\) is provable outright, that is, from no hypotheses. So, at least for finite sets of formulas \(\Gamma\), the two statements of soundness and completeness are equivalent.

\sphinxAtStartPar
Proving soundness and completeness belongs to the realm of \sphinxstyleemphasis{metatheory}, since it requires us to reason about our methods of reasoning. This is not a central focus of this book: we are more concerned with \sphinxstyleemphasis{using} logic and the notion of truth than with establishing their properties. But the notions of soundness and completeness play an important role in helping us understand the nature of the logical notions, and so we will try to provide some hints here as to why these properties hold for propositional logic.

\sphinxAtStartPar
Proving soundness is easier than proving completeness. We wish to show that whenever \(A\) is provable from a set of hypotheses, \(\Gamma\), then \(A\) is a logical consequence of \(\Gamma\). In a later chapter, we will consider proofs by induction, which allows us to establish a property holds of a general collection of objects by showing that it holds of some “simple” ones and is preserved under the passage to objects that are more complex. In the case of natural deduction, it is enough to show that soundness holds of the most basic proofs—using the assumption rule—and that it is preserved under each rule of inference. The base case is easy: the assumption rule says that \(A\) is provable from hypothesis \(A\), and clearly every truth assignment that makes \(A\) true makes \(A\) true. The inductive steps are not much harder; they involve checking that the rules we have chosen mesh with the semantic notions. For example, suppose the last rule is the and\sphinxhyphen{}introduction rule. In that case, we have a proof of \(A\) from some hypotheses \(\Gamma\), and a proof of \(B\) from some hypotheses \(\Delta\), and we combine these to form a proof of \(A \wedge B\) from the hypotheses in \(\Gamma \cup \Delta\), that is, the hypotheses in both. Inductively, we can assume that \(A\) is a logical consequence of \(\Gamma\) and that \(B\) is a logical consequence of \(\Delta\). Let \(v\) be any truth assignment that makes every formula in \(\Gamma \cup \Delta\) true. Then by the inductive hypothesis, we have that it makes \(A\) true, and \(B\) true as well. By the definition of the valuation function, \(\bar v (A \wedge B) = \mathbf{T}\), as required.

\sphinxAtStartPar
Proving completeness is harder. It suffices to show that if \(A\) is any tautology, then \(A\) is provable. One strategy is to show that natural deduction can simulate the method of truth tables. For example, suppose \(A\) is build up from propositional variables \(B\) and \(C\). Then in natural deduction, we should be able to prove
\begin{equation*}
\begin{split}(B \wedge C) \vee (B \wedge \neg C) \vee (\neg B \wedge C) \vee (\neg B \wedge \neg C),\end{split}
\end{equation*}
\sphinxAtStartPar
with one disjunct for each line of the truth table. Then, we should be able to use each disjunct to “evaluate” each expression occurring in \(A\), proving it true or false in accordance with its valuation, until we have a proof of \(A\) itself.

\sphinxAtStartPar
A nicer way to proceed is to express the rules of natural deduction in a way that allows us to work backward from \(A\) in search of a proof. In other words, first, we give a procedure for constructing a derivation of \(A\) by working backward from \(A\). Then we argue that if the procedure fails, then, at the point where it fails, we can find a truth assignment that makes \(A\) false. As a result, if every truth assignment makes \(A\) true, the procedure returns a proof of \(A\).


\section{Exercises}
\label{\detokenize{semantics_of_propositional_logic:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Show that \(A \to B\), \(\neg A \vee B\), and \(\neg (A \wedge \neg B)\) are logically equivalent, by writing out the truth table and showing that they have the same values for all truth assignments.

\item {} 
\sphinxAtStartPar
Write out the truth table for \((A \to B) \wedge (B \wedge C \to A)\).

\item {} 
\sphinxAtStartPar
Show that \(A \to B\) and \(\neg B \to \neg A\) are equivalent, by writing out the truth tables and showing that they
have the same values for all truth assignments.

\item {} 
\sphinxAtStartPar
Does the following entailment hold?
\begin{equation*}
\begin{split}\{ A \to B \vee C, \neg B \to \neg C \} \models A \to B\end{split}
\end{equation*}
\sphinxAtStartPar
Justify your answer by writing out the truth table (sorry, it is long). Indicate clearly the rows where both hypotheses come out true.

\item {} 
\sphinxAtStartPar
Are the following formulas derivable? Justify your answer with either a derivation or a counterexample.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\neg (\neg A \vee B) \to A\)

\item {} 
\sphinxAtStartPar
\((\neg A \to \neg B) \to (A \to B)\)

\item {} 
\sphinxAtStartPar
\(((P \wedge Q) \to R) \to (R \vee \neg P)\)

\item {} 
\sphinxAtStartPar
\((\neg P \wedge \neg Q) \to \neg (Q \vee P)\)

\end{itemize}

\end{enumerate}


\chapter{First Order Logic}
\label{\detokenize{first_order_logic:first-order-logic}}\label{\detokenize{first_order_logic:id1}}\label{\detokenize{first_order_logic::doc}}
\sphinxAtStartPar
Propositional logic provides a good start at describing the general principles of logical reasoning, but it does not go far enough. Some of the limitations are apparent even in the “Malice and Alice” example from \hyperref[\detokenize{propositional_logic:propositional-logic}]{Chapter \ref{\detokenize{propositional_logic:propositional-logic}}}. Propositional logic does not give us the means to express a general principle that tells us that if Alice is with her son on the beach, then her son is with Alice; the general fact that no child is older than his or her parent; or the general fact that if someone is alone, they are not with someone else. To express principles like these, we need a way to talk about objects and individuals, as well as their properties and the relationships between them. These are exactly what is provided by a more expressive logical framework known as \sphinxstyleemphasis{first\sphinxhyphen{}order logic}, which will be the topic of the next few chapters.


\section{Functions, Predicates, and Relations}
\label{\detokenize{first_order_logic:functions-predicates-and-relations}}\label{\detokenize{first_order_logic:id2}}
\sphinxAtStartPar
Consider some ordinary statements about the natural numbers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Every natural number is even or odd, but not both.

\item {} 
\sphinxAtStartPar
A natural number is even if and only if it is divisible by two.

\item {} 
\sphinxAtStartPar
If some natural number, \(x\), is even, then so is \(x^2\).

\item {} 
\sphinxAtStartPar
A natural number \(x\) is even if and only if \(x + 1\) is odd.

\item {} 
\sphinxAtStartPar
Any prime number that is greater than 2 is odd.

\item {} 
\sphinxAtStartPar
For any three natural numbers \(x\), \(y\), and \(z\), if \(x\) divides \(y\) and \(y\) divides \(z\), then \(x\) divides \(z\).

\end{itemize}

\sphinxAtStartPar
These statements are true, but we generally do not think of them as \sphinxstyleemphasis{logically valid}: they depend on assumptions about the natural numbers, the meaning of the terms “even” and “odd,” and so on. But once we accept the first statement, for example, it seems to be a logical consequence that the number of stairs in the White House is either even or odd, and, in particular, if it is not even, it is odd. To make sense of inferences like these, we need a logical system that can deal with objects, their properties, and relations between them.

\sphinxAtStartPar
Rather than fix a single language once and for all, first\sphinxhyphen{}order logic allows us to specify the symbols we wish to use for any given domain of interest. In this section, we will use the following running example:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The domain of interest is the natural numbers, \(\mathbb{N}\).

\item {} 
\sphinxAtStartPar
There are objects, \(0\), \(1\), \(2\), \(3\), ….

\item {} 
\sphinxAtStartPar
There are functions, addition and multiplication, as well as the square function, on this domain.

\item {} 
\sphinxAtStartPar
There are predicates on this domain, “even,” “odd,” and “prime.”

\item {} 
\sphinxAtStartPar
There are relations between elements of this domain, “equal,” “less than”, and “divides.”

\end{itemize}

\sphinxAtStartPar
For our logical language, we will choose symbols 1, 2, 3, \(\mathit{add}\), \(\mathit{mul}\), \(\mathit{square}\), \(\mathit{even}\), \(\mathit{odd}\), \(\mathit{prime}\), \(\mathit{lt}\), and so on, to denote these things. We will also have variables \(x\), \(y\), and \(z\) ranging over the natural numbers. Note all of the following.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Functions can take different numbers of arguments: if \(x\) and \(y\) are natural numbers, it makes sense to write \(\mathit{mul}(x, y)\) and \(\mathit{square}(x)\). So \(\mathit{mul}\) takes two arguments, and \(\mathit{square}\) takes only one.

\item {} 
\sphinxAtStartPar
Predicates and relations can also be understood in these terms. The predicates \(\mathit{even}(x)\) and \(\mathit{prime}(x)\) take one argument, while the binary relations \(\mathit{divides}(x, y)\) and \(\mathit{lt}(x,y)\) take two arguments.

\item {} 
\sphinxAtStartPar
Functions are different from predicates! A function takes one or more arguments, and returns a \sphinxstyleemphasis{value}. A predicate takes one or more arguments, and is either true or false. We can think of predicates as returning propositions, rather than values.

\item {} 
\sphinxAtStartPar
In fact, we can think of the constant symbols \(1, 2, 3, \ldots\) as special sorts of function symbols that take zero arguments. Analogously, we can consider the predicates that take zero arguments to be the constant logical values, \(\top\) and \(\bot\).

\item {} 
\sphinxAtStartPar
In ordinary mathematics, we often use “infix” notation for binary functions and relations. For example, we usually write \(x \times y\) or \(x \cdot y\) instead of \(\mathit{mul}(x, y)\), and we write \(x < y\) instead of \(\mathit{lt}(x, y)\). We will use these conventions when writing proofs in natural deduction, and they are supported in Lean as well.

\item {} 
\sphinxAtStartPar
We will treat the equality relation, \(x = y\), as a special binary relation that is included in every first\sphinxhyphen{}order language.

\end{itemize}

\sphinxAtStartPar
First\sphinxhyphen{}order logic allows us to build complex expressions out of the basic ones. Starting with the variables and constants, we can use the function symbols to build up compound expressions like these:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x + y + z\)

\item {} 
\sphinxAtStartPar
\((x + 1) \times y \times y\)

\item {} 
\sphinxAtStartPar
\(\mathit{square} (x + y \times z)\)

\end{itemize}

\sphinxAtStartPar
Such expressions are called “terms.” Intuitively, they name objects in the intended domain of discourse.

\sphinxAtStartPar
Now, using the predicates and relation symbols, we can make assertions about these expressions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathit{even}(x + y + z)\)

\item {} 
\sphinxAtStartPar
\(\mathit{prime}((x + 1) \times y \times y)\)

\item {} 
\sphinxAtStartPar
\(\mathit{square}(x + y \times z) = w\)

\item {} 
\sphinxAtStartPar
\(x + y < z\)

\end{itemize}

\sphinxAtStartPar
Even more interestingly, we can use propositional connectives to build compound expressions like these:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathit{even}(x + y + z) \wedge \mathit{prime}((x + 1) \times y \times y)\)

\item {} 
\sphinxAtStartPar
\(\neg (\mathit{square} (x + y \times z) = w) \vee x + y < z\)

\item {} 
\sphinxAtStartPar
\(x < y \wedge \mathit{even}(x) \wedge \mathit{even}(y) \to x + 1 < y\)

\end{itemize}

\sphinxAtStartPar
The second one, for example, asserts that either \((x + yz)^2\) is not equal to \(w\), or \(x + y\) is less than \(z\). Remember, these are expressions in symbolic logic; in ordinary mathematics, we would express the notions using words like “is even” and “if and only if,” as we did above. We will use notation like this whenever we are in the realm of symbolic logic, for example, when we write proofs in natural deduction. Expressions like these are called \sphinxstyleemphasis{formulas}. In contrast to terms, which name things, formulas \sphinxstyleemphasis{say things}; in other words, they make assertions about objects in the domain of discourse.


\section{The Universal Quantifier}
\label{\detokenize{first_order_logic:the-universal-quantifier}}
\sphinxAtStartPar
What makes first\sphinxhyphen{}order logic powerful is that it allows us to make general assertions using \sphinxstyleemphasis{quantifiers}. The universal quantifier \(\forall\) followed by a variable \(x\) is meant to represent the phrase “for every \(x\).” In other words, it asserts that every value of \(x\) has the property that follows it. Using the universal quantifier, the examples with which we began the previous section can be expressed as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; ((\mathit{even}(x) \vee \mathit{odd}(x)) \wedge \neg (\mathit{even}(x) \wedge \mathit{odd}(x)))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{even}(x) \leftrightarrow 2 \mid x)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{even}(x) \to \mathit{even}(x^2))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{even}(x) \leftrightarrow \mathit{odd}(x+1))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{prime}(x) \wedge x > 2 \to \mathit{odd}(x))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; \forall y \; \forall z \; (x \mid y \wedge y \mid z \to x \mid z)\)

\end{itemize}

\sphinxAtStartPar
It is common to combine multiple quantifiers of the same kind, and write, for example, \(\forall x, y, z \; (x \mid y \wedge y \mid z \to x \mid z)\) in the last expression.

\sphinxAtStartPar
Here are some notes on syntax:
\begin{itemize}
\item {} 
\sphinxAtStartPar
In symbolic logic, the universal quantifier is usually taken to bind tightly. For example, \(\forall x \; P \vee Q\) is interpreted as \((\forall x \; P) \vee Q\), and we would write \(\forall x \; (P \vee Q)\) to extend the scope.

\item {} 
\sphinxAtStartPar
Be careful, however. In other contexts, especially in computer science, people often give quantifiers the \sphinxstyleemphasis{widest} scope possible. This is the case with Lean. For example, \sphinxcode{\sphinxupquote{∀ x, P ∨ Q}} is interpreted as \sphinxcode{\sphinxupquote{∀ x, (P ∨ Q)}}, and we would write \sphinxcode{\sphinxupquote{(∀ x, P) ∨ Q}} to limit the scope.

\item {} 
\sphinxAtStartPar
When you put the quantifier \(\forall x\) in front a formula that involves the variable \(x\), all the occurrences of that variable are \sphinxstyleemphasis{bound} by the quantifier. For example, the expression \(\forall x \; (\mathit{even}(x) \vee \mathit{odd}(x))\) is expresses that every number is even or odd. Notice that the variable \(x\) does not appear anywhere in the informal statement. The statement is not about \(x\) at all; rather \(x\) is a dummy variable, a placeholder that stands for the “thing” referred to within a phrase that beings with the words “every thing.” We think of the expression \(\forall x \; (\mathit{even}(x) \vee \mathit{odd}(x))\) as being the same as the expression \(\forall y \; (\mathit{even}(y) \vee \mathit{odd}(y))\). Lean also treats these expressions as the same.

\item {} 
\sphinxAtStartPar
In Lean, the expression \sphinxcode{\sphinxupquote{∀ x y z, x ∣ y → y ∣ z → x ∣ z}} is interpreted as \sphinxcode{\sphinxupquote{∀ x y z, x ∣ y → (y ∣ z → x ∣ z)}}, with parentheses associated to the \sphinxstyleemphasis{right}. The part of the expression after the universal quantifier can therefore be interpreted as saying “given that \sphinxcode{\sphinxupquote{x}} divides \sphinxcode{\sphinxupquote{y}} and that \sphinxcode{\sphinxupquote{y}} divides \sphinxcode{\sphinxupquote{z}}, \sphinxcode{\sphinxupquote{x}} divides \sphinxcode{\sphinxupquote{z}}.” The expression is logically equivalent to \sphinxcode{\sphinxupquote{∀ x y z, x ∣ y ∧ y ∣ z → x ∣ z}}, but we will see that, in Lean, it is often convenient to express facts like this as an iterated implication.

\end{itemize}

\sphinxAtStartPar
A variable that is not bound is called \sphinxstyleemphasis{free}. Notice that formulas in first\sphinxhyphen{}order logic say things about their free variables. For example, in the interpretation we have in mind, the formula \(\forall y \; (x \le y)\) says that \(x\) is less than or equal to every natural number. The formula \(\forall z \; (x \le z)\) says exactly the same thing; we can always rename a bound variable, as long as we pick a name that does not clash with another name that is already in use. On the other hand, the formula \(\forall y (w \le y)\) says that \(w\) is less than or equal to every natural number. This is an entirely different statement: it says something about \(w\), rather than \(x\). So renaming a \sphinxstyleemphasis{free} variable changes the meaning of a formula.

\sphinxAtStartPar
Notice also that some formulas, like \(\forall x, y \; (x \le y \vee y \le x)\), have no free variables at all. Such a formula is called a \sphinxstyleemphasis{sentence}, because it makes an outright assertion, a statement that is either true or false about the intended interpretation. In \hyperref[\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}]{Chapter \ref{\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}}} we will make the notion of an “intended interpretation” precise, and explain what it means to be “true in an interpretation.” For now, the idea that formulas say things about an object in an intended interpretation should motivate the rules for reasoning with such expressions.

\sphinxAtStartPar
In \hyperref[\detokenize{introduction:introduction}]{Chapter \ref{\detokenize{introduction:introduction}}} we proved that the square root of two is irrational. One way to construe the statement is as follows:
\begin{quote}

\sphinxAtStartPar
For every pair of integers, \(a\) and \(b\), if \(b \ne 0\), it is not the case that \(a^2 = 2 b^2\).
\end{quote}

\sphinxAtStartPar
The advantage of this formulation is that we can restrict our attention to the integers, without having to consider the larger domain of rationals. In symbolic logic, assuming our intended domain of discourse is the integers, we would express this theorem using the universal quantifier:
\begin{equation*}
\begin{split}\forall  a, b \; b \ne 0 \to \neg (a^2 = 2 b^2).\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that we have kept the conventional mathematical notation \(b \ne 0\) to say that \(b\) is not equal to 0, but we can think of this as an abbreviation for \(\neg (b = 0)\).  How do we prove such a theorem? Informally, we would use such a pattern:
\begin{quote}

\sphinxAtStartPar
Let \(a\) and \(b\) be arbitrary integers, suppose \(b \ne 0\), and suppose \(a^2 = 2 b^2\).

\sphinxAtStartPar
…

\sphinxAtStartPar
Contradiction.
\end{quote}

\sphinxAtStartPar
What we are really doing is proving that the universal statement holds, by showing that it holds of “arbitrary” values \(a\) and \(b\). In natural deduction, the proof would look something like this:



\begin{center}
\AXM{}
\RLM{1}
\UIM{b \ne 0}
\noLine
\UIM{\vdots}
\AXM{}
\RLM{2}
\UIM{a^2 = 2 \times b^2}
\noLine
\UIM{\vdots}
\noLine
\BIM{\bot}
\RLM{2}
\UIM{\neg (a^2 = 2 \times b^2)}
\RLM{1}
\UIM{b \ne 0 \to \neg (a^2 = 2 \times b^2)}
\UIM{\forall b \; (b \ne 0 \to \neg (a^2 = 2 \times b^2))}
\UIM{\forall a \; \forall b \; (b \ne 0 \to \neg (a^2 = 2 \times b^2))}
\DP
\end{center}

\sphinxAtStartPar
Notice that after the hypotheses are canceled, we have proved \(b \ne 0 \to \neg (a^2 = 2 \times b^2)\) without making any assumptions about \(a\) and \(b\); at this stage in the proof, they are “arbitrary,” justifying the application of the universal quantifiers in the next two rules.

\sphinxAtStartPar
This example motivates the following rule in natural deduction:



\begin{prooftree}
\AXM{A(x)}
\UIM{\forall x \; A(x)}
\end{prooftree}

\sphinxAtStartPar
provided \(x\) is not free in any uncanceled hypothesis. Here \(A(x)\) stands for any formula that (potentially) mentions \(x\). Also remember that if \(y\) is any “fresh” variable that does not occur in \(A\), we are thinking of \(\forall x \; A(x)\) as being the same as \(\forall y \; A(y)\).

\sphinxAtStartPar
What about the elimination rule? Suppose we know that every number is even or odd. Then, in an ordinary proof, we are free to assert “\(a\) is even or \(a\) is odd,” or “\(a^2\) is even or \(a^2\) is odd.” In terms of symbolic logic, this amounts to the following inference: from \(\forall x \; (\mathit{even}(x) \vee \mathit{odd}(x))\), we can conclude \(\mathit{even}(t) \vee \mathit{odd}(t)\) for any term \(t\). This motivates the elimination rule for the universal quantifier:



\begin{prooftree}
\AXM{\forall x A(x)}
\UIM{A(t)}
\end{prooftree}

\sphinxAtStartPar
where \(t\) is an arbitrary term, subject to the restriction described at the end of the next section.

\sphinxAtStartPar
In a sense, this feels like the elimination rule for implication; we might read the hypothesis as saying “if \(x\) is any thing, then \(x\) is even or odd.” The conclusion is obtained by applying it to the fact that \(n\) is a thing. Note that, in general, we could replace \(n\) by any \sphinxstyleemphasis{term} in the language, like \(n (m + 5) +2\). Similarly, the introduction rule feels like the introduction rule for implication. If we want to show that everything has a certain property, we temporarily let \(x\) denote an arbitrary thing, and then show that it has the relevant property.


\section{The Existential Quantifier}
\label{\detokenize{first_order_logic:the-existential-quantifier}}
\sphinxAtStartPar
Dual to the universal quantifier is the existential quantifier, \(\exists\), which is used to express assertions such as “some number is even,” or, “between any two even numbers there is an odd number.”

\sphinxAtStartPar
The following statements about the natural numbers assert the existence of some natural number:
\begin{itemize}
\item {} 
\sphinxAtStartPar
There exists an odd composite number. (Remember that a natural number is \sphinxstyleemphasis{composite} if it is greater than 1 and not prime.)

\item {} 
\sphinxAtStartPar
Every natural number greater than one has a prime divisor.

\item {} 
\sphinxAtStartPar
For every \(n\), if \(n\) has a prime divisor smaller than \(n\), then \(n\) is composite.

\end{itemize}

\sphinxAtStartPar
These statements can be expressed in first\sphinxhyphen{}order logic using the existential quantifier as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists n\;  (\mathit{odd}(n) \wedge \mathit{composite}(n))\)

\item {} 
\sphinxAtStartPar
\(\forall n \; (n > 1 \to \exists p \; (\mathit{prime}(p) \wedge p \mid n))\)

\item {} 
\sphinxAtStartPar
\(\forall n \; ((\exists p \; (p \mid n \wedge \mathit{prime}(p) \wedge p < n)) \to \mathit{composite}(n))\)

\end{itemize}

\sphinxAtStartPar
After we write \(\exists n\), the variable \(n\) is bound in the formula, just as for the universal quantifier. So the formulas \(\exists n \; \mathit{composite}(n)\) and \(\exists m \; \mathit{composite}(m)\) are considered the same.

\sphinxAtStartPar
How do we prove such existential statements? Suppose we want to prove that there exists an odd composite number. To do this, we just present a candidate, and show that the candidate satisfies the required properties. For example, we could choose 15, and then show that 15 is odd and that 15 is composite. Of course, there’s nothing special about 15, and we could have proven it also using a different number, like 9 or 35. The choice of candidate does not matter, as long as it has the required property.

\sphinxAtStartPar
In a natural deduction proof this would look like this:



\begin{center}
\AXM{\vdots}
\noLine
\UIM{\mathit{odd}(15)\wedge\mathit{composite}(15)}
\UIM{\exists n(\mathit{odd}(n)\wedge\mathit{composite}(n))}
\DP
\end{center}

\sphinxAtStartPar
This illustrates the introduction rule for the existential quantifier:



\begin{center}
\AXM{A(t)}
\UIM{\exists x A(x)}
\DP
\end{center}

\sphinxAtStartPar
where \(t\) is any term, subject to the restriction described below. So to prove an existential formula, we just have to give one particular term for which we can prove that formula. Such term is called a \sphinxstyleemphasis{witness} for the formula.

\sphinxAtStartPar
What about the elimination rule? Suppose that we know that \(n\) is some natural number and we know that there exists a prime \(p\) such that \(p < n\) and \(p \mid n\). How can we use this to prove that \(n\) is composite? We can reason as follows:
\begin{quote}

\sphinxAtStartPar
Let \(p\) be any prime such that \(p < n\) and \(p \mid n\).

\sphinxAtStartPar
…

\sphinxAtStartPar
Therefore, \(n\) is composite.
\end{quote}

\sphinxAtStartPar
First, we assume that there is some \(p\) which satisfies the properties \(p\) is prime, \(p < n\) and \(p \mid n\), and then we reason about that \(p\). As with case\sphinxhyphen{}based reasoning using “or,” the assumption is only temporary: if we can show that \(n\) is composite from that assumption, that we have essentially shown that \(n\) is composite assuming the existence of such a \(p\). Notice that in this pattern of reasoning, \(p\) should be “arbitrary.” In other words, we should not have assumed anything about \(p\) beforehand, we should not make any additional assumptions about \(p\) along the way, and the conclusion should not mention \(p\). Only then does it makes sense to say that the conclusion follows from the “mere” existence of a \(p\) with the assumed properties.

\sphinxAtStartPar
In natural deduction, the elimination rule is expressed as follows:



\begin{prooftree}
\AXM{\exists x A(x)}
\AXM{}
\RLM{1}
\UIM{A(y)}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1}
\BIM{B}
\end{prooftree}

\sphinxAtStartPar
Here we require that \(y\) is not free in \(B\), and that the only uncanceled hypotheses where \(y\) occurs freely are the hypotheses \(A(y)\) that are canceled when you apply this rule. Formally, this is what it means to say that \(y\) is “arbitrary.” As was the case for or elimination and implication introduction, you can use the hypothesis \(A(y)\) multiple times in the proof of \(B\), and cancel all of them at once. Intuitively, the rule says that you can prove \(B\) from the assumption \(\exists x A(x)\) by assuming \(A(y)\) for a fresh variable \(y\), and concluding, in any number of steps, that \(B\) follows. You should compare this rule to the rule for or elimination, which is somewhat analogous.

\sphinxAtStartPar
There is a restriction on the term \(t\) that appears in the elimination rule for the universal quantifier and the introduction rule for the existential quantifier, namely, that no variable that appears in \(t\) becomes bound when you plug it in for \(x\). To see what can go wrong if you violate this restriction, consider the sentence \(\forall x \; \exists y \; y > x\). If we interpret this as a statement about the natural numbers, it says that for every number \(x\), there is a bigger number \(y\). This is a true statement, and so it should hold whatever we substitute for \(x\). But what happens if we substitute \(y + 1\)? We get the statement \(\exists y \; y > y + 1\), which is false. The problem is that before the substitution the variable \(y\) in \(y + 1\) refers to an arbitrary number, but after the substitution, it refers to the number that is asserted to exist by the existential quantifier, and that is not what we want.

\sphinxAtStartPar
Violating the restriction in the introduction rule for the existential quantifier causes similar problems. For example, it allows us to derive \(\exists x \; \forall y \; y = x\), which says that there is exactly one number, from the hypothesis \(\forall y \; y = y\). The good news is that if you rely on your intuition, you are unlikely to make mistakes like these. But it is an important fact that the rules of natural deduction can be given a precise specification that rules out these invalid inferences.


\section{Relativization and Sorts}
\label{\detokenize{first_order_logic:relativization-and-sorts}}\label{\detokenize{first_order_logic:id3}}
\sphinxAtStartPar
In first\sphinxhyphen{}order logic as we have presented it, there is one intended “universe” of objects of discourse, and the universal and existential quantifiers range over that universe. For example, we could design a language to talk about people living in a certain town, with a relation \(\mathit{loves}(x, y)\) to express that \(x\) loves \(y\). In such a language, we might express the statement that “everyone loves someone” by writing \(\forall x \; \exists y \; \mathit{loves}(x, y)\).

\sphinxAtStartPar
You should keep in mind that, at this stage, \(\mathit{loves}\) is just a symbol. We have designed the language with a certain interpretation in mind, but one could also interpret the language as making statements about the natural numbers, where \(\mathit{loves}(x, y)\) means that \(x\) is less than or equal to \(y\). In that interpretation, the sentence
\begin{equation*}
\begin{split}\forall {x, y, z} \; (\mathit{loves}(x, y) \wedge \mathit{loves}(y, z) \to \mathit{loves}(x, z))\end{split}
\end{equation*}
\sphinxAtStartPar
is true, though in the original interpretation it makes an implausible claim about the nature of love triangles. In \hyperref[\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}]{Chapter \ref{\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}}}, we will spell out the notion that the deductive rules of first\sphinxhyphen{}order logic enable us to determine the statements that are true in \sphinxstyleemphasis{all} interpretations, just as the rules of propositional logic enable us to determine the statements that are true under all truth assignments.

\sphinxAtStartPar
Returning to the original example, suppose we want to represent the statement that, in our town, all the women are strong and all the men are good looking. We could do that with the following two sentences:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{woman}(x) \to \mathit{strong}(x))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{man}(x) \to \mathit{good{\mathord{\mbox{-}}}looking}(x))\)

\end{itemize}

\sphinxAtStartPar
These are instances of \sphinxstyleemphasis{relativization}. The universal quantifier ranges over all the people in the town, but this device gives us a way of using implication to restrict the scope of our statements to men and women, respectively. The trick also comes into play when we render “every prime number greater than two is odd”:
\begin{equation*}
\begin{split}\forall x \; (\mathit{prime}(x) \wedge x > 2 \to \mathit{odd}(x)).\end{split}
\end{equation*}
\sphinxAtStartPar
We could also read this more literally as saying “for every number \(x\), if \(x\) is prime and \(x\) is greater than to 2, then \(x\) is odd,” but it is natural to read it as a restricted quantifier.

\sphinxAtStartPar
It is also possible to relativize the existential quantifier to say things like “some woman is strong” and “some man is good\sphinxhyphen{}looking.” These are expressed as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; (\mathit{woman}(x) \wedge \mathit{strong}(x))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (\mathit{man}(x) \wedge \mathit{good\mathord{\mbox{-}}looking}(x))\)

\end{itemize}

\sphinxAtStartPar
Notice that although we used implication to relativize the universal quantifier, here we need to use conjunction instead of implication. The expression \(\exists x \; (\mathit{woman}(x) \to \mathit{strong}(x))\) says that there is something with the property that if it is a woman, then it is strong. Classically this is equivalent to saying that there is something which is either not a woman or is strong, which is a funny thing to say.

\sphinxAtStartPar
Now, suppose we are studying geometry, and we want to express the fact that given any two distinct points \(p\) and \(q\) and any two lines \(L\) and \(M\), if \(L\) and \(M\) both pass through \(p\) and \(q\), then they have to be the same. (In other words, there is at most one line between two distinct points.) One option is to design a first\sphinxhyphen{}order logic where the intended universe is big enough to include both points and lines, and use relativization:
\begin{equation*}
\begin{split}\forall {p, q, L, M} (\mathit{point}(p) \wedge \mathit{point}(q) \wedge
\mathit{line}(L) \wedge \mathit{line}(M) \\
\wedge q \neq p \wedge \mathit{on}(p,L) \wedge \mathit{on}(q,L) \wedge \mathit{on}(p,M) \wedge
\mathit{on}(q,M) \to L = M).\end{split}
\end{equation*}
\sphinxAtStartPar
But dealing with such predicates is tedious, and there is a mild extension of first\sphinxhyphen{}order logic, called \sphinxstyleemphasis{many\sphinxhyphen{}sorted first\sphinxhyphen{}order logic}, which builds in some of the bookkeeping. In many\sphinxhyphen{}sorted logic, one can have different sorts of objects—such as points and lines—and a separate stock of variables and quantifiers ranging over each. Moreover, the specification of function symbols and predicate symbols indicates what sorts of arguments they expect, and, in the case of function symbols, what sort of argument they return. For example, we might choose to have a sort with variables \(p, q, r, \ldots\) ranging over points, a sort with variables \(L, M, N, \ldots\) ranging over lines, and a relation \(\mathit{on}(p, L)\) relating the two. Then the assertion above is rendered more simply as follows:
\begin{equation*}
\begin{split}\forall {p, q, L, M} \; (p \neq q \wedge \mathit{on}(p,L) \wedge \mathit{on}(q,L) \wedge \mathit{on}(p,M) \wedge \mathit{on}(q,M) \to L = M).\end{split}
\end{equation*}

\section{Equality}
\label{\detokenize{first_order_logic:equality}}
\sphinxAtStartPar
In symbolic logic, we use the expression \(s = t\) to express the fact that \(s\) and \(t\) are “equal” or “identical.” The equality symbol is meant to model what we mean when we say, for example, “Alice’s brother is the victim,” or “2 + 2 = 4.” We are asserting that two different descriptions refer to the same object. Because the notion of identity can be applied to virtually any domain of objects, it is viewed as falling under the province of logic.

\sphinxAtStartPar
Talk of “equality” or “identity” raises messy philosophical questions, however. Am I the same person I was three days ago? Are the two copies of \sphinxstyleemphasis{Huckleberry Finn} sitting on my shelf the same book, or two different books? Using symbolic logic to model identity presupposes that we have in mind a certain way of carving up and interpreting the world. We assume that our terms refer to distinct entities, and writing \(s = t\) asserts that the two expressions refer to the same thing. Axiomatically, we assume that equality satisfies the following three properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{reflexivity}: \(t = t\), for any term \(t\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{symmetry}: if \(s = t\), then \(t = s\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{transitivity}: if \(r = s\) and \(s = t\), then \(r = t\)

\end{itemize}

\sphinxAtStartPar
These properties are not enough to characterize equality, however. If two expressions denote the same thing, then we should be able to substitute one for any other in any expression. It is convenient to adopt the following convention: if \(r\) is any term, we may write \(r(x)\) to indicate that the variable \(x\) may occur in \(r\). Then, if \(s\) is another term, we can thereafter write \(r(s)\) to denote the result of replacing \(s\) for \(x\) in \(r\). The substitution rule for terms thus reads as follows: if \(s = t\), then \(r(s) = r(t)\).

\sphinxAtStartPar
We already adopted a similar convention for formulas: if we introduce a formula as \(A(x)\), then \(A(t)\) denotes the result of substituting \(t\) for \(x\) in \(A\). With this in mind, we can write the rules for equality as follows:



\begin{center}
\AXM{}
\UIM{t = t}
\DP
\quad
\AXM{s = t}
\UIM{t = s}
\DP
\quad
\AXM{r = s}
\AXM{s = t}
\BIM{r = t}
\DP
\\
\ \\
\AXM{s = t}
\UIM{r(s) = r(t)}
\DP
\quad
\AXM{s = t}
\AXM{P(s)}
\BIM{P(t)}
\DP
\end{center}

\sphinxAtStartPar
Here, the first substitution rule governs terms and the second substitution rule governs formulas. In the next chapter, you will learn how to use them.

\sphinxAtStartPar
Using equality, we can define even more quantifiers.
\begin{itemize}
\item {} 
\sphinxAtStartPar
We can express “there are at least two elements \(x\) such that \(A(x)\) holds” as \(\exists x \; \exists y \; (x \neq y \wedge A(x) \wedge A(y))\).

\item {} 
\sphinxAtStartPar
We can express “there are at most two elements \(x\) such that \(A(x)\) holds” as \(\forall x \; \forall y \; \forall z \; (A(x) \wedge A(y) \wedge A(z) \to x = y \vee y = z \vee x = z)\). This states that if we have three elements \(a\) for which \(A(a)\) holds, then two of them must be equal.

\item {} 
\sphinxAtStartPar
We can express “there are exactly two elements \(x\) such that \(A(x)\) holds” as the conjunction of the above two statements.

\end{itemize}

\sphinxAtStartPar
As an exercise, write out in first order logic the statements that there are at least, at most, and exactly three elements \(x\) such that \(A(x)\) holds.

\sphinxAtStartPar
In logic, the expression \(\exists!x \; A(x)\) is used to express the fact that there is a \sphinxstyleemphasis{unique} \(x\) satisfying \(A(x)\), which is to say, there is exactly one such \(x\). As above, this can be expressed as follows:
\begin{equation*}
\begin{split}\exists x \; A(x) \wedge \forall y \; \forall {y'} \; (A(y) \wedge A(y') \to y = y').\end{split}
\end{equation*}
\sphinxAtStartPar
The first conjunct says that there is at least one object satisfying \(A\), and the second conjunct says that there is at most one. The same thing can be expressed more concisely as follows:
\begin{equation*}
\begin{split}\exists x \; (A(x) \wedge \forall y \; (A(y) \to y = x)).\end{split}
\end{equation*}
\sphinxAtStartPar
You should think about why this second expression works. In the next chapter we will see that, using the rules of natural deduction, we can prove that these two expressions are equivalent.


\section{Exercises}
\label{\detokenize{first_order_logic:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
A \sphinxstyleemphasis{perfect number} is a number that is equal to the sum of its proper divisors, that is, the numbers that divide it, other than itself. For example, 6 is perfect, because \(6 = 1 + 2 + 3\).

\sphinxAtStartPar
Using a language with variables ranging over the natural numbers and suitable functions and predicates, write down first\sphinxhyphen{}order sentences asserting the following. Use a predicate \(\mathit{perfect}\) to express that a number is perfect.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
28 is perfect.

\item {} 
\sphinxAtStartPar
There are no perfect numbers between 100 and 200.

\item {} 
\sphinxAtStartPar
There are (at least) two perfect numbers between 200 and 10,000. (Express this by saying that there are perfect numbers \(x\) and \(y\) between 200 and 10,000, with the property that \(x \neq y\).)

\item {} 
\sphinxAtStartPar
Every perfect number is even.

\item {} 
\sphinxAtStartPar
For every number, there is a perfect number that is larger than it. (This is one way to express the statement that there are infinitely many perfect numbers.)

\end{enumerate}

\sphinxAtStartPar
Here, the phrase “between \(a\) and \(b\)” is meant to include \(a\) and \(b\).

\sphinxAtStartPar
By the way, we do not know whether the last two statements are true. They are open questions.

\item {} 
\sphinxAtStartPar
Using a language with variables ranging over people, and predicates \(\mathit{trusts}(x,y)\), \(\mathit{politician}(x)\), \(\mathit{crazy(x)}\), \(\mathit{knows}(x, y)\), \(\mathit{related\mathord{\mbox{-}}to}(x, y)\), and \(\mathit{rich}(x)\), write down first\sphinxhyphen{}order sentences asserting the following:
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
Nobody trusts a politician.

\item {} 
\sphinxAtStartPar
Anyone who trusts a politician is crazy.

\item {} 
\sphinxAtStartPar
Everyone knows someone who is related to a politician.

\item {} 
\sphinxAtStartPar
Everyone who is rich is either a politician or knows a politician.

\end{enumerate}

\sphinxAtStartPar
In each case, some interpretation may be involved. Notice that writing down a logical expression is one way of helping to clarify the meaning.

\end{enumerate}


\chapter{Natural Deduction for First Order Logic}
\label{\detokenize{natural_deduction_for_first_order_logic:natural-deduction-for-first-order-logic}}\label{\detokenize{natural_deduction_for_first_order_logic::doc}}

\section{Rules of Inference}
\label{\detokenize{natural_deduction_for_first_order_logic:rules-of-inference}}
\sphinxAtStartPar
In the last chapter, we discussed the language of first\sphinxhyphen{}order logic, and the rules that govern their use. We summarize them here:

\sphinxAtStartPar
\sphinxstyleemphasis{The universal quantifier:}



\begin{quote}
\AXM{A(x)}
\RLM{\mathord{\forall}\mathrm{I}}
\UIM{\fa y A(y)}
\DP
\quad\quad
\AXM{\fa x A(x)}
\RLM{\mathord{\forall}\mathrm{E}}
\UIM{A(t)}
\DP
\end{quote}

\sphinxAtStartPar
In the introduction rule, \(x\) should not be free in any uncanceled hypothesis. In the elimination rule, \(t\) can be any term that does not clash with any of the bound variables in \(A\).

\sphinxAtStartPar
\sphinxstyleemphasis{The existential quantifier:}



\begin{quote}
\AXM{A(t)}
\RLM{\mathord{\exists}\mathrm{I}}
\UIM{\exists  x A(x)}
\DP
\quad\quad
\AXM{\exists  x A(x)}
\AXM{}
\RLM{1}
\UIM{A(y)}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1 \;\; \mathord{\exists}\mathrm{E}}
\BIM{B}
\DP
\end{quote}

\sphinxAtStartPar
In the introduction rule, \(t\) can be any term that does not clash with any of the bound variables in \(A\). In the elimination rule, \(y\) should not be free in \(B\) or any uncanceled hypothesis.

\sphinxAtStartPar
\sphinxstyleemphasis{Equality:}



\begin{center}
\AXM{}
\RLM{\mathrm{refl}}
\UIM{t = t}
\DP
\quad
\AXM{s = t}
\RLM{\mathrm{symm}}
\UIM{t = s}
\DP
\quad
\AXM{r = s}
\AXM{s = t}
\RLM{\mathrm{trans}}
\BIM{r = t}
\DP
\\
\ \\
\AXM{s = t}
\RLM{\mathrm{subst}}
\UIM{r(s) = r(t)}
\DP
\quad
\AXM{s = t}
\RLM{\mathrm{subst}}
\AXM{P(s)}
\BIM{P(t)}
\DP
\end{center}

\sphinxAtStartPar
Strictly speaking, only \(\mathrm{refl}\) and the second substitution rule are necessary. The others can be derived from them.


\section{The Universal Quantifier}
\label{\detokenize{natural_deduction_for_first_order_logic:the-universal-quantifier}}
\sphinxAtStartPar
The following example of a proof in natural deduction shows that if, for every \(x\), \(A(x)\) holds, and for every \(x\), \(B(x)\) holds, then for every \(x\), they both hold:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\fa x A(x)}
\UIM{A(y)}
\AXM{}
\RLM{2}
\UIM{\fa x B(x)}
\UIM{B(y)}
\BIM{A(y) \wedge B(y)}
\UIM{\fa y (A(y) \wedge B(y))}
\RLM{2}
\UIM{\fa x B(x) \to \fa y (A(y) \wedge B(y))}
\RLM{1}
\UIM{\fa x A(x) \to (\fa x B(x) \to \fa y (A(y) \wedge B(y)))}
\end{prooftree}

\sphinxAtStartPar
Notice that neither of the assumptions 1 or 2 mention \(y\), so that \(y\) is really “arbitrary” at the point where the universal quantifiers are introduced.

\sphinxAtStartPar
Here is another example:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\fa x A(x)}
\UIM{A(y)}
\UIM{A(y) \vee B(y)}
\UIM{\fa x (A(x) \vee B(x))}
\RLM{1}
\UIM{\fa x A(x) \to \fa x (A(x) \vee B(x))}
\end{prooftree}

\sphinxAtStartPar
As an exercise, try proving the following:
\begin{equation*}
\begin{split}\forall x \; (A(x) \to B(x)) \to (\forall x \; A(x) \to \forall x \; B(x)).\end{split}
\end{equation*}
\sphinxAtStartPar
Here is a more challenging exercise. Suppose I tell you that, in a town, there is a (male) barber that shaves all and only the men who do not shave themselves. You can show that this is a contradiction, arguing informally, as follows:
\begin{quote}

\sphinxAtStartPar
By the assumption, the barber shaves himself if and only if he does not shave himself. Call this statement (*).

\sphinxAtStartPar
Suppose the barber shaves himself. By (*), this implies that he does not shave himself, a contradiction. So, the barber does not shave himself.

\sphinxAtStartPar
But using (*) again, this implies that the barber shaves himself, which contradicts the fact we just showed, namely, that the barber does not shave himself.
\end{quote}

\sphinxAtStartPar
Try to turn this into a formal argument in natural deduction.

\sphinxAtStartPar
Let us return to the example of the natural numbers, to see how deductive notions play out there. Suppose we have defined \(\mathit{even}\) and \(\mathit{odd}\) in such a way that we can prove:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall n \; (\neg \mathit{even}(n) \to \mathit{odd}(n))\)

\item {} 
\sphinxAtStartPar
\(\forall n \; (\mathit{odd}(n) \to \neg \mathit{even}(n))\)

\end{itemize}

\sphinxAtStartPar
Then we can go on to derive \(\forall n \; (\mathit{even}(n) \vee \mathit{odd}(n))\) as follows:



\begin{prooftree}
\AXM{}
\UIM{\mathit{even}(n) \vee \neg \mathit{even}(n)}
\AXM{}
\RLM{1}
\UIM{\mathit{even}(n)}
\UIM{\mathit{even}(n) \vee \mathit{odd}(n)}
\AXM{}
\UIM{\fa n (\neg \mathit{even}(n) \to \mathit{odd}(n))}
\UIM{\neg \mathit{even} (n) \to \mathit{odd}(n)}
\AXM{}
\RLM{1}
\UIM{\neg \mathit{even}(n)}
\BIM{\mathit{odd}(n)}
\UIM{\mathit{even}(n) \vee \mathit{odd}(n)}
\RLM{1}
\TIM{\mathit{even}(n) \vee \mathit{odd}(n)}
\UIM{\fa n (\mathit{even} (n) \vee \mathit{odd}(n))}
\end{prooftree}

\sphinxAtStartPar
We can also prove and \(\forall n \; \neg (\mathit{even}(n) \wedge \mathit{odd}(n))\):



\begin{prooftree}
\AXM{}
\UIM{\mathit{odd}(n) \to \neg \mathit{even}(n)}
\AXM{}
\RLM{H}
\UIM{\mathit{even}(n) \wedge \mathit{odd}(n)}
\UIM{\mathit{odd}(n)}
\BIM{\neg \mathit{even}(n)}
\AXM{}
\RLM{H}
\UIM{\mathit{even}(n) \wedge \mathit{odd}(n)}
\UIM{\mathit{even}(n)}
\BIM{\bot}
\RLM{H}
\UIM{\neg (\mathit{even}(n) \wedge \mathit{odd}(n))}
\UIM{\fa n \neg (\mathit{even}(n) \wedge \mathit{odd}(n))}
\end{prooftree}

\sphinxAtStartPar
As we move from modeling basic rules of inference to modeling actual mathematical proofs, we will tend to shift focus from natural deduction to formal proofs in Lean. Natural deduction has its uses: as a model of logical reasoning, it provides us with a convenient means to study metatheoretic properties such as soundness and completeness. For working \sphinxstyleemphasis{within} the system, however, proof languages like Lean’s tend to scale better, and produce more readable proofs.


\section{The Existential Quantifier}
\label{\detokenize{natural_deduction_for_first_order_logic:the-existential-quantifier}}
\sphinxAtStartPar
Remember that the intuition behind the elimination rule for the existential quantifier is that if we know \(\exists x \; A(x)\), we can temporarily reason about an arbitrary element \(y\) satisfying \(A(y)\) in order to prove a conclusion that doesn’t depend on \(y\). Here is an example of how it can be used. The next proof says that if we know there is something satisfying both \(A\) and \(B\), then we know, in particular, that there is something satisfying \(A\).



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\exists  x (A(x) \wedge B(x))}
\AXM{}
\RLM{2}
\UIM{A(y) \wedge B(y)}
\UIM{A(y)}
\UIM{\exists  x A(x)}
\RLM{2}
\BIM{\exists  x A(x)}
\RLM{1}
\UIM{\exists  x (A(x) \wedge B(x)) \to \exists  x A(x)}
\end{prooftree}

\sphinxAtStartPar
The following proof shows that if there is something satisfying either \(A\) or \(B\), then either there is something satisfying \(A\), or there is something satisfying \(B\).



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\ex x (A(x) \vee B(x))}
\AXM{}
\RLM{2}
\UIM{A(y) \vee B(y)}
\AXM{}
\RLM{3}
\UIM{A(y)}
\UIM{\ex x A(x)}
\UIM{\ex x A(x) \vee \ex x B(x)}
\AXM{}
\RLM{3}
\UIM{B(y)}
\UIM{\ex x B(x)}
\UIM{\ex x A(x) \vee \ex x B(x)}
\RLM{3}
\TIM{\ex x A(x) \vee \ex x B(x)}
\RLM{2}
\BIM{\ex x A(x) \vee \ex x B(x)}
\RLM{1}
\UIM{\ex x (A(x) \vee B(x)) \to \ex x A(x) \vee \ex x B(x))}
\end{prooftree}

\sphinxAtStartPar
The following example is more involved:



\begin{prooftree}
\AXM{}
\RLM{2}
\UIM{\ex x (A(x) \wedge B(x))}
\AXM{}
\RLM{1}
\UIM{\fa x (A(x) \to \neg B(x))}
\UIM{A(x) \to \neg B(x)}
\AXM{}
\RLM{3}
\UIM{A(x) \wedge B(x)}
\UIM{A(x)}
\BIM{\neg B(x)}
\AXM{}
\RLM{3}
\UIM{A(x) \wedge B(x)}
\UIM{B(x)}
\BIM{\bot}
\RLM{3}
\BIM{\bot}
\RLM{2}
\UIM{\neg\ex x(A(x) \wedge B(x))}
\RLM{1}
\UIM{\fa x (A(x) \to \neg B(x)) \to \neg\ex x(A(x) \wedge B(x))}
\end{prooftree}

\sphinxAtStartPar
In this proof, the existential elimination rule (the line labeled \(3\)) is used to cancel two hypotheses at the same time. Note that when this rule is applied, the hypothesis \(\forall x \; (A(x) \to \neg B(x))\) has not yet been canceled. So we have to make sure that this formula doesn’t contain the variable \(x\) freely. But this is o.k., since this hypothesis contains \(x\) only as a bound variable.

\sphinxAtStartPar
Another example is that if \(x\) does not occur in \(P\), then \(\exists x \; P\) is equivalent to \(P\):



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\ex x P}
\AXM{}
\RLM{2}
\UIM{P}
\RLM{2}
\BIM{P}
\AXM{}
\RLM{1}
\UIM{P}
\UIM{\ex x P}
\RLM{1}
\BIM{\ex x P \leftrightarrow P}
\end{prooftree}

\sphinxAtStartPar
This is short but tricky, so let us go through it carefully. On the left, we assume \(\exists x \; P\) to conclude \(P\). We assume \(P\), and now we can immediately cancel this assumption by existential elimination, since \(x\) does not occur in \(P\), so it doesn’t occur freely in any assumption or in the conclusion. On the right we use existential introduction to conclude \(\exists x \; P\) from \(P\).


\section{Equality}
\label{\detokenize{natural_deduction_for_first_order_logic:equality}}\label{\detokenize{natural_deduction_for_first_order_logic:id1}}
\sphinxAtStartPar
Recall the natural deduction rules for equality:



\begin{center}
\AXM{}
\UIM{t = t}
\DP
\quad
\AXM{s = t}
\UIM{t = s}
\DP
\quad
\AXM{r = s}
\AXM{s = t}
\BIM{r = t}
\DP
\\
\ \\
\AXM{s = t}
\UIM{r(s) = r(t)}
\DP
\quad
\AXM{s = t}
\AXM{P(s)}
\BIM{P(t)}
\DP
\end{center}

\sphinxAtStartPar
Keep in mind that we have implicitly fixed some first\sphinxhyphen{}order language, and \(r\), \(s\), and \(t\) are any terms in that language. Recall also that we have adopted the practice of using functional notation with terms. For example, if we think of \(r(x)\) as the term \((x + y) \times (z + 0)\) in the language of arithmetic, then \(r(0)\) is the term \((0 + y) \times (z + 0)\) and \(r(u + v)\) is \(((u + v) + y) \times (z + 0)\). So one example of the first inference on the second line is this:



\begin{center}
\AXM{u + v = 0}
\UIM{((u + v) + y) \times (z + 0) = (0 + y) \times (z + 0)}
\DP
\end{center}

\sphinxAtStartPar
The second axiom on that line is similar, except now \(P(x)\) stands for any \sphinxstyleemphasis{formula}, as in the following inference:



\begin{center}
\AXM{u + v = 0}
\AXM{x + (u + v) < y}
\BIM{x + 0 < y}
\DP
\end{center}

\sphinxAtStartPar
Notice that we have written the reflexivity axiom, \(t = t\), as a rule with no premises. If you use it in a proof, it does not count as a hypothesis; it is built into the logic.

\sphinxAtStartPar
In fact, we can think of the first inference on the second line as a special case of the second one. Consider, for example, the formula \(((u + v) + y) \times (z + 0) = (x + y) \times (z + 0)\). If we plug \(u + v\) in for \(x\), we get an instance of reflexivity. If we plug in \(0\), we get the conclusion of the first example above. The following is therefore a derivation of the first inference, using only reflexivity and the second substitution rule above:



\begin{center}
\AXM{u + v = 0}
\AXM{}
\UIM{((u + v) + y) \times (z + 0) = ((u + v) + y) \times (z + 0)}
\BIM{((u + v) + y) \times (z + 0) = (0 + y) \times (z + 0)}
\DP
\end{center}

\sphinxAtStartPar
Roughly speaking, we are replacing the second instance of \(u + v\) in an instance of reflexivity with \(0\) to get the conclusion we
want.

\sphinxAtStartPar
Equality rules let us carry out calculations in symbolic logic. This typically amounts to using the equality rules we have already discussed, together with a list of general identities. For example, the following identities hold for any real numbers \(x\), \(y\), and \(z\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
commutativity of addition: \(x + y = y + x\)

\item {} 
\sphinxAtStartPar
associativity of addition: \((x + y) + z = x + (y + z)\)

\item {} 
\sphinxAtStartPar
additive identity: \(x + 0 = 0 + x = x\)

\item {} 
\sphinxAtStartPar
additive inverse: \(-x + x = x + -x = 0\)

\item {} 
\sphinxAtStartPar
multiplicative identity: \(x \cdot 1 = 1 \cdot x = x\)

\item {} 
\sphinxAtStartPar
commutativity of multiplication: \(x \cdot y = y \cdot x\)

\item {} 
\sphinxAtStartPar
associativity of multiplication: \((x \cdot y) \cdot z = x \cdot (y \cdot z)\)

\item {} 
\sphinxAtStartPar
distributivity: \(x \cdot (y + z) = x \cdot y + x \cdot z, \quad (x + y) \cdot z = x \cdot z + y \cdot z\)

\end{itemize}

\sphinxAtStartPar
You should imagine that there are implicit universal quantifiers in front of each statement, asserting that the statement holds for \sphinxstyleemphasis{any} values of \(x\), \(y\), and \(z\). Note that \(x\), \(y\), and \(z\) can, in particular, be integers or rational numbers as well. Calculations involving real numbers, rational numbers, or integers generally involve identities like this.

\sphinxAtStartPar
The strategy is to use the elimination rule for the universal quantifier to instantiate general identities, use symmetry, if necessary, to orient an equation in the right direction, and then using the substitution rule for equality to change something in a previous result. For example, here is a natural deduction proof of a simple identity, \(\forall x, y, z \; ((x + y) + z = (x + z) + y)\), using only commutativity and associativity of addition. We have taken the liberty of using a brief name to denote the relevant identities, and combining multiple instances of the universal quantifier introduction and elimination rules into a single step.



\begin{center}
\AXM{}
\UIM{\mathsf{assoc}\strut}
\UIM{(x + y) + z = x + (y + z)}

\AXM{}
\UIM{\mathsf{comm}\strut}
\UIM{y + z = z + y}
\UIM{x + (y + z) = x + (z + y)}

\AXM{}
\UIM{\mathsf{assoc}\strut}
\UIM{(x + z) + y = x + (z + y)}
\UIM{x + (z + y) = (x + z) + y}

\BIM{x + (y + z) = (x + z) + y}

\BIM{(x + y) + z = (x + z) + y}
\UIM{\fa {x, y, z} ((x + y) + z = (x + z) + y)}
\DP
\end{center}

\sphinxAtStartPar
There is generally nothing interesting to be learned from carrying out such calculations in natural deduction, but you should try one or two examples to get the hang of it, and then take pleasure in knowing that it is possible.


\section{Counterexamples and Relativized Quantifiers}
\label{\detokenize{natural_deduction_for_first_order_logic:counterexamples-and-relativized-quantifiers}}
\sphinxAtStartPar
Consider the statement:
\begin{quote}

\sphinxAtStartPar
Every prime number is odd.
\end{quote}

\sphinxAtStartPar
In first\sphinxhyphen{}order logic, we could formulate this as \(\forall p \; (\mathit{prime}(p) \to \mathit{odd}(p))\). This statement is false, because there is a prime number that is even, namely the number 2. This is called a \sphinxstyleemphasis{counterexample} to the statement.

\sphinxAtStartPar
More generally, given a formula \(\forall x \; A(x)\), a counterexample is a value \(t\) such that \(\neg A(t)\) holds. Such a counterexample shows that the original formula is false, because we have the following equivalence: \(\neg \forall x \; A(x) \leftrightarrow \exists x \; \neg A(x)\). So if we find a value \(t\) such that \(\neg A(t)\) holds, then by the existential introduction rule we can conclude that \(\exists x \; \neg A(x)\), and then by the above equivalence we have \(\neg \forall x \; A(x)\). Here is a proof of the equivalence:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\neg\fa x A(x)}
\AXM{}
\RLM{4}
\UIM{\neg(\ex x \neg A(x))}
\AXM{}
\RLM{5}
\UIM{\neg A(x)}
\UIM{\ex x \neg A(x)}
\BIM{\bot}
\RLM{5}
\UIM{A(x)}
\UIM{\fa x A(x)}
\BIM{\bot}
\RLM{4}
\UIM{\ex x \neg A(x)}
\AXM{}
\RLM{1}
\UIM{\ex x \neg A(x)}
\AXM{}
\RLM{3}
\UIM{\neg A(y)}
\AXM{}
\RLM{2}
\UIM{\fa x A(x)}
\UIM{A(y)}
\BIM{\bot}
\RLM{3}
\BIM{\bot}
\RLM{2}
\UIM{\neg\fa x A(x)}
\RLM{1}
\BIM{\neg\fa x A(x) \leftrightarrow \ex x \neg A(x)}
\end{prooftree}

\sphinxAtStartPar
One remark about the proof: at the step marked by \(4\) we \sphinxstyleemphasis{cannot} use the existential introduction rule, because at that point our only assumption is \(\neg \forall x \; A(x)\), and from that assumption we cannot prove \(\neg A(t)\) for a particular term \(t\). So we use a proof by contradiction there.

\sphinxAtStartPar
As an exercise, prove the “dual” equivalence yourself: \(\neg \exists x \; A(x) \leftrightarrow \forall x \; \neg A(x)\). This can be done without using proof by contradiction.

\sphinxAtStartPar
In \hyperref[\detokenize{first_order_logic:first-order-logic}]{Chapter \ref{\detokenize{first_order_logic:first-order-logic}}} we saw examples of how to use relativization to restrict the scope of a universal quantifier. Suppose we want to say “every prime number is greater than 1”. In first order logic this can be written as \(\forall n (\mathit{prime}(n) \to n > 1)\). The reason is that the original statement is equivalent to the statement “for every natural number, if it is prime, then it is greater than 1”. Similarly, suppose we want to say “there exists a prime number greater than 100.” This is equivalent to saying “there exists a natural number which is prime and greater than 100,” which can be expressed as \(\exists n \; (\mathit{prime}(n) \wedge n > 100)\).

\sphinxAtStartPar
As an exercise you can prove the above results about negations of quantifiers also for relativized quantifiers. Specifically, prove the following statements:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\neg \exists x \; (A(x) \wedge B(x)) \leftrightarrow \forall x \; ( A(x) \to \neg B(x))\)

\item {} 
\sphinxAtStartPar
\(\neg \forall x \; (A(x) \to B(x)) \leftrightarrow \exists x (A(x) \wedge \neg B(x))\)

\end{itemize}

\sphinxAtStartPar
For reference, here is a list of valid sentences involving quantifiers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; A \leftrightarrow A\) if \(x\) is not free in \(A\)

\item {} 
\sphinxAtStartPar
\(\exists x \; A \leftrightarrow A\) if \(x\) is not free in \(A\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (A(x) \land B(x)) \leftrightarrow \forall x \; A(x) \land \forall x \; B(x)\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (A(x) \land B) \leftrightarrow \exists \; x A(x) \land B\) if \(x\) is not free in \(B\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (A(x) \lor B(x)) \leftrightarrow \exists \; x A(x) \lor \exists \; x B(x)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (A(x) \lor B) \leftrightarrow \forall x \; A(x) \lor B\) if \(x\) is not free in \(B\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (A(x) \to B) \leftrightarrow (\exists x \; A(x) \to B)\) if \(x\) is not free in \(B\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (A(x) \to B) \leftrightarrow (\forall x \; A(x) \to B)\) if \(x\) is not free in \(B\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (A \to B(x)) \leftrightarrow (A \to \forall x \; B(x))\) if \(x\) is not free in \(A\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (A(x) \to B) \leftrightarrow (A(x) \to \exists \; x B)\) if \(x\) is not free in \(B\)

\item {} 
\sphinxAtStartPar
\(\exists x \; A(x) \leftrightarrow \neg \forall x \; \neg A(x)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; A(x) \leftrightarrow \neg \exists x \; \neg A(x)\)

\item {} 
\sphinxAtStartPar
\(\neg \exists x \; A(x) \leftrightarrow \forall x \; \neg A(x)\)

\item {} 
\sphinxAtStartPar
\(\neg \forall x \; A(x) \leftrightarrow \exists x \; \neg A(x)\)

\end{itemize}

\sphinxAtStartPar
All of these can be derived in natural deduction. The last two allow us to push negations inwards, so we can continue to put first\sphinxhyphen{}order formulas in negation normal form. Other rules allow us to bring quantifiers to the front of any formula, though, in general, there will be multiple ways of doing this. For example, the formula
\begin{equation*}
\begin{split}\forall x \; A(x) \to \exists y \; \forall z \; B(y, z)\end{split}
\end{equation*}
\sphinxAtStartPar
is equivalent to both
\begin{equation*}
\begin{split}\exists x, y \; \forall z \; (A(x) \to B(y, z))\end{split}
\end{equation*}
\sphinxAtStartPar
and
\begin{equation*}
\begin{split}\exists y \; \forall z \; \exists x \; (A(x) \to B(y, z)).\end{split}
\end{equation*}
\sphinxAtStartPar
A formula with all the quantifiers in front is said to be in \sphinxstyleemphasis{prenex} form.


\section{Exercises}
\label{\detokenize{natural_deduction_for_first_order_logic:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Give a natural deduction proof of
\begin{equation*}
\begin{split}\forall x \; (A(x) \to B(x)) \to (\forall x \; A(x) \to \forall x \; B(x)).\end{split}
\end{equation*}
\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\forall x \; B(x)\) from hypotheses \(\forall x \; (A(x) \vee B(x))\) and \(\forall y \; \neg A(y)\).

\item {} 
\sphinxAtStartPar
From hypotheses \(\forall x \; (\mathit{even}(x) \vee \mathit{odd}(x))\) and \(\forall x \; (\mathit{odd}(x) \to \mathit{even}(s(x)))\) give a natural deduction proof \(\forall x \; (\mathit{even}(x) \vee \mathit{even}(s(x)))\). (It might help to think of \(s(x)\) as the function defined by \(s(x) = x + 1\).)

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\exists x \; A(x) \vee \exists x \; B(x) \to \exists x \; (A(x) \vee B(x))\).

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\exists x \; (A(x) \wedge C(x))\) from the assumptions \(\exists x \; (A(x) \wedge B(x))\) and \(\forall x \; (A(x) \wedge B(x) \to C(x))\).

\item {} 
\sphinxAtStartPar
Prove some of the other equivalences in the last section.

\item {} 
\sphinxAtStartPar
Consider some of the various ways of expressing “nobody trusts a politician” in first\sphinxhyphen{}order logic:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{politician}(x) \to \forall y \; (\neg \mathit{trusts}(y,x)))\)

\item {} 
\sphinxAtStartPar
\(\forall x,y \; (\mathit{politician}(x) \to \neg \mathit{trusts}(y,x))\)

\item {} 
\sphinxAtStartPar
\(\neg \exists x,y \; (\mathit{politician}(x) \wedge \mathit{trusts}(y,x))\)

\item {} 
\sphinxAtStartPar
\(\forall x, y \; (\mathit{trusts}(y,x) \to \neg \mathit{politician}(x))\)

\end{itemize}

\sphinxAtStartPar
They are all logically equivalent. Show this for the second and the fourth, by giving natural deduction proofs of each from the other. (As a shortcut, in the \(\forall\) introduction and elimination rules, you can introduce / eliminate both variables in one step.)

\item {} 
\sphinxAtStartPar
Formalize the following statements, and give a natural deduction proof in which the first three statements appear as (uncancelled) hypotheses, and the last line is the conclusion:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Every young and healthy person likes baseball.

\item {} 
\sphinxAtStartPar
Every active person is healthy.

\item {} 
\sphinxAtStartPar
Someone is young and active.

\item {} 
\sphinxAtStartPar
Therefore, someone likes baseball.

\end{itemize}

\sphinxAtStartPar
Use \(Y(x)\) for “is young,” \(H(x)\) for “is healthy,” \(A(x)\) for “is active,” and \(B(x)\) for “likes baseball.”

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\forall x, y, z \; (x = z \to (y = z \to x = y))\) using the equality rules in \hyperref[\detokenize{natural_deduction_for_first_order_logic:equality}]{Section \ref{\detokenize{natural_deduction_for_first_order_logic:equality}}}.

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\forall x, y \; (x = y \to y = x)\) using only these two hypotheses (and none of the new equality rules):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (x = x)\)

\item {} 
\sphinxAtStartPar
\(\forall u, v, w \; (u = w \to (v = w \to u = v))\)

\end{itemize}

\sphinxAtStartPar
(Hint: Choose instantiations of \(u\), \(v\), and \(w\) carefully. You can instantiate all the universal quantifiers in one step, as on the last homework assignment.)

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg \exists x \; (A(x) \wedge B(x)) \leftrightarrow \forall x \; (A(x) \to \neg B(x))\)

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of \(\neg \forall x \; (A(x) \to B(x)) \leftrightarrow \exists x \; (A(x) \wedge \neg B(x))\)

\item {} 
\sphinxAtStartPar
Remember that both the following express \(\exists!x \; A(x)\), that is, the statement that there is a unique \(x\) satisfying \(A(x)\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; (A(x) \wedge \forall y \; (A(y) \to y = x))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; A(x) \wedge \forall y \; \forall y' \; (A(y) \wedge A(y') \to y = y')\)

\end{itemize}

\sphinxAtStartPar
Do the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Give a natural deduction proof of the second, assuming the first as a hypothesis.

\item {} 
\sphinxAtStartPar
Give a natural deduction proof of the first, assuming the second as a hypothesis.

\end{itemize}

\sphinxAtStartPar
(Warning: these are long.)

\end{enumerate}


\chapter{First Order Logic in Lean}
\label{\detokenize{first_order_logic_in_lean:first-order-logic-in-lean}}\label{\detokenize{first_order_logic_in_lean:id1}}\label{\detokenize{first_order_logic_in_lean::doc}}

\section{Functions, Predicates, and Relations}
\label{\detokenize{first_order_logic_in_lean:functions-predicates-and-relations}}
\sphinxAtStartPar
In the last chapter, we discussed the language of first\sphinxhyphen{}order logic. We will see in the course of this book that Lean’s built\sphinxhyphen{}in logic is much more expressive; but it \sphinxstyleemphasis{includes} first\sphinxhyphen{}order logic, which is to say, anything that can be expressed (and proved) in first\sphinxhyphen{}order logic can be expressed (and proved) in Lean.

\sphinxAtStartPar
Lean is based on a foundational framework called \sphinxstyleemphasis{type theory}, in which every variable is assumed to range elements of some \sphinxstyleemphasis{type}. You can think of a type as being a “universe,” or a “domain of discourse,” in the sense of first\sphinxhyphen{}order logic.

\sphinxAtStartPar
For example, suppose we want to work with a first\sphinxhyphen{}order language with one constant symbol, one unary function symbol, one binary function symbol, one unary relation symbol, and one binary relation symbol. We can declare a new type \sphinxcode{\sphinxupquote{U}} (for “universe”) and the relevant symbols as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{axiom} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}

\PYG{k+kd}{axiom} \PYG{n}{c} \PYG{o}{:} \PYG{n}{U}
\PYG{k+kd}{axiom} \PYG{n}{f} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U}
\PYG{k+kd}{axiom} \PYG{n}{g} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U}
\PYG{k+kd}{axiom} \PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{R} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can then use them as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{c}
\PYG{k}{\PYGZsh{}check} \PYG{n}{f} \PYG{n}{c}
\PYG{k}{\PYGZsh{}check} \PYG{n}{g} \PYG{n}{x} \PYG{n}{y}
\PYG{k}{\PYGZsh{}check} \PYG{n}{g} \PYG{n}{x} \PYG{o}{(}\PYG{n}{f} \PYG{n}{c}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{P} \PYG{o}{(}\PYG{n}{g} \PYG{n}{x} \PYG{o}{(}\PYG{n}{f} \PYG{n}{c}\PYG{o}{)}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}
\end{sphinxVerbatim}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{\#check}} command tells us that the first four expressions have type \sphinxcode{\sphinxupquote{U}}, and that the last two have type \sphinxcode{\sphinxupquote{Prop}}. Roughly, this means that the first four expressions correspond to terms of first\sphinxhyphen{}order logic, and that the last two correspond to formulas.

\sphinxAtStartPar
Note all the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A unary function is represented as an object of type \sphinxcode{\sphinxupquote{U → U}} and a binary function is represented as an object of type \sphinxcode{\sphinxupquote{U → U → U}}, using the same notation as for implication between propositions.

\item {} 
\sphinxAtStartPar
We write, for example, \sphinxcode{\sphinxupquote{f x}} to denote the result of applying \sphinxcode{\sphinxupquote{f}} to \sphinxcode{\sphinxupquote{x}}, and \sphinxcode{\sphinxupquote{g x y}} to denote the result of applying \sphinxcode{\sphinxupquote{g}} to \sphinxcode{\sphinxupquote{x}} and \sphinxcode{\sphinxupquote{y}}, again just as we did when using modus ponens for first\sphinxhyphen{}order logic. Parentheses are needed in the expression \sphinxcode{\sphinxupquote{g x (f c)}} to ensure that \sphinxcode{\sphinxupquote{f c}} is parsed as a single argument.

\item {} 
\sphinxAtStartPar
A unary predicate is presented as an object of type \sphinxcode{\sphinxupquote{U → Prop}} and a binary predicate is represented as an object of type \sphinxcode{\sphinxupquote{U → U → Prop}}. You can think of a binary relation \sphinxcode{\sphinxupquote{R}} as being a function that assumes two arguments in the universe, \sphinxcode{\sphinxupquote{U}}, and returns a proposition.

\item {} 
\sphinxAtStartPar
We write \sphinxcode{\sphinxupquote{P x}} to denote the assertion that \sphinxcode{\sphinxupquote{P}} holds of \sphinxcode{\sphinxupquote{x}}, and \sphinxcode{\sphinxupquote{R x y}} to denote that \sphinxcode{\sphinxupquote{R}} holds of \sphinxcode{\sphinxupquote{x}} and \sphinxcode{\sphinxupquote{y}}.

\end{itemize}

\sphinxAtStartPar
You may reasonably wonder what difference there is between
\sphinxcode{\sphinxupquote{axiom}} and \sphinxcode{\sphinxupquote{variable}} in Lean.
The following declarations also work:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{c} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{g} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{c}
\PYG{k}{\PYGZsh{}check} \PYG{n}{f} \PYG{n}{c}
\PYG{k}{\PYGZsh{}check} \PYG{n}{g} \PYG{n}{x} \PYG{n}{y}
\PYG{k}{\PYGZsh{}check} \PYG{n}{g} \PYG{n}{x} \PYG{o}{(}\PYG{n}{f} \PYG{n}{c}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{P} \PYG{o}{(}\PYG{n}{g} \PYG{n}{x} \PYG{o}{(}\PYG{n}{f} \PYG{n}{c}\PYG{o}{)}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}
\end{sphinxVerbatim}

\sphinxAtStartPar
Although the examples function in much the same way, the \sphinxcode{\sphinxupquote{axiom}} and \sphinxcode{\sphinxupquote{variable}} commands do very different things. The \sphinxcode{\sphinxupquote{constant}} command declares a new object, axiomatically, and adds it to the list of objects Lean knows about. In contrast, when it is first executed, the \sphinxcode{\sphinxupquote{variable}} command does not create anything. Rather, it tells Lean that whenever we enter an expression using the corresponding identifier, it should create a temporary variable of the corresponding type.

\sphinxAtStartPar
Many types are already declared in Lean’s standard library.
For example,
there is a type written \sphinxcode{\sphinxupquote{Nat}} that denotes the natural numbers.
We can introduce notation \sphinxcode{\sphinxupquote{ℕ}} for it.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n}{Nat}

\PYG{k+kd}{notation}\PYG{o}{:}\PYG{l+m+mi}{1} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ℕ}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{Nat}

\PYG{k}{\PYGZsh{}check} \PYG{n}{ℕ}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can enter the unicode \sphinxcode{\sphinxupquote{ℕ}} with \sphinxcode{\sphinxupquote{\textbackslash{}nat}} or \sphinxcode{\sphinxupquote{\textbackslash{}N}}. The two expressions mean the same thing.

\sphinxAtStartPar
Using this built\sphinxhyphen{}in type, we can model the language of arithmetic, as described in the last chapter, as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{namespace} \PYG{n}{hidden}
\PYG{k+kd}{notation}\PYG{o}{:}\PYG{l+m+mi}{1} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ℕ}\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{Nat}

\PYG{k+kd}{axiom} \PYG{n}{mul} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{k+kd}{axiom} \PYG{n}{add} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{k+kd}{axiom} \PYG{n}{square} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{k+kd}{axiom} \PYG{n}{even} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{odd} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{prime} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{divides} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{lt} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{zero} \PYG{o}{:} \PYG{n}{ℕ}
\PYG{k+kd}{axiom} \PYG{n}{one} \PYG{o}{:} \PYG{n}{ℕ}

\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
We have used the \sphinxcode{\sphinxupquote{namespace}} command to avoid conflicts with identifiers that are already declared in the Lean library. (Outside the namespace, the constant \sphinxcode{\sphinxupquote{mul}} we just declared is named \sphinxcode{\sphinxupquote{hidden.mul}}.) We can again use the \sphinxcode{\sphinxupquote{\#check}} command to try them out:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{namespace} \PYG{n}{hidden}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{w} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{mul} \PYG{n}{x} \PYG{n}{y}
\PYG{k}{\PYGZsh{}check} \PYG{n}{add} \PYG{n}{x} \PYG{n}{y}
\PYG{k}{\PYGZsh{}check} \PYG{n}{square} \PYG{n}{x}
\PYG{k}{\PYGZsh{}check} \PYG{n}{even} \PYG{n}{x}

\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can even declare infix notation of binary operations and relations:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{65}   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ + }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{add}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{70}   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ * }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{mul}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50}   \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ \PYGZlt{} }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{lt}
\end{sphinxVerbatim}

\sphinxAtStartPar
(Getting notation for numerals \sphinxcode{\sphinxupquote{1}}, \sphinxcode{\sphinxupquote{2}}, \sphinxcode{\sphinxupquote{3}}, … is trickier.) With all this in place, the examples above can be rendered as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n}{even} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n}{prime} \PYG{o}{(}\PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{one}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{square} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{w}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{z}
\PYG{k}{\PYGZsh{}check} \PYG{n}{x} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{even} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{even} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{one} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{y}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, all of the functions, predicates, and relations discussed here,
except for the “square” function, are defined in the Lean library.
They become available to us when we import the module
\sphinxcode{\sphinxupquote{import Mathlib.Data.Nat.Prime}} at the top of a file.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Prime}

\PYG{k+kd}{axiom} \PYG{n}{square} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{w} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{Even} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n}{Prime} \PYG{o}{(}\PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{square} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{w}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{z}
\PYG{k}{\PYGZsh{}check} \PYG{n}{x} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{Even} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{y}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, we declare the constant \sphinxcode{\sphinxupquote{square}} axiomatically,
but refer to the other operations and predicates in the Lean library.
In this book, we will often proceed in this way,
telling you explicitly what facts from the library you should use for exercises.

\sphinxAtStartPar
Again, note the following aspects of syntax:
\begin{itemize}
\item {} 
\sphinxAtStartPar
In contrast to ordinary mathematical notation, in Lean,
functions are applied without parentheses or commas.
For example, we write \sphinxcode{\sphinxupquote{square x}} and \sphinxcode{\sphinxupquote{add x y}}
instead of \(\mathit{square}(x)\) and \(\mathit{add}(x, y)\).

\item {} 
\sphinxAtStartPar
The same holds for predicates and relations:
we write \sphinxcode{\sphinxupquote{even x}} and \sphinxcode{\sphinxupquote{lt x y}} instead of \(\mathit{even}(x)\)
and \(\mathit{lt}(x, y)\), as one might do in symbolic logic.

\item {} 
\sphinxAtStartPar
The notation \sphinxcode{\sphinxupquote{add : ℕ → ℕ → ℕ}}
indicates that addition assumes two arguments, both natural numbers,
and returns a natural number.

\item {} 
\sphinxAtStartPar
Similarly, the notation \sphinxcode{\sphinxupquote{divides : ℕ → ℕ → Prop}}
indicates that \sphinxcode{\sphinxupquote{divides}} is a binary relation,
which assumes two natural numbers as arguments and forms a proposition.
In other words, \sphinxcode{\sphinxupquote{divides x y}} expresses the assertion that \sphinxcode{\sphinxupquote{x}}
divides \sphinxcode{\sphinxupquote{y}}.

\end{itemize}

\sphinxAtStartPar
Lean can help us distinguish between terms and formulas.
If we \sphinxcode{\sphinxupquote{\#check}} the expression \sphinxcode{\sphinxupquote{x + y + 1}} in Lean,
we are told it has type \sphinxcode{\sphinxupquote{ℕ}}, which is to say, it denotes a natural number.
If we \sphinxcode{\sphinxupquote{\#check}} the expression \sphinxcode{\sphinxupquote{even (x + y + 1)}},
we are told that it has type \sphinxcode{\sphinxupquote{Prop}}, which is to say,
it expresses a proposition.

\sphinxAtStartPar
In \hyperref[\detokenize{first_order_logic:first-order-logic}]{Chapter \ref{\detokenize{first_order_logic:first-order-logic}}} we considered many\sphinxhyphen{}sorted logic,
where one can have multiple universes.
For example, we might want to use first\sphinxhyphen{}order logic for geometry,
with quantifiers ranging over points and lines.
In Lean, we can model this as by introducing a new type for each sort:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{Point} \PYG{n}{Line} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{lies\PYGZus{}on} \PYG{o}{:} \PYG{n}{Point} \PYG{n+nb+bp}{→} \PYG{n}{Line} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can then express that two distinct points determine a line as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{p} \PYG{n}{q} \PYG{o}{:} \PYG{n}{Point}\PYG{o}{)} \PYG{o}{(}\PYG{n}{L} \PYG{n}{M} \PYG{o}{:} \PYG{n}{Line}\PYG{o}{)}\PYG{o}{,}
        \PYG{n}{p} \PYG{n+nb+bp}{≠} \PYG{n}{q} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{p} \PYG{n}{L} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{q} \PYG{n}{L} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{p} \PYG{n}{M} \PYG{n+nb+bp}{→}
          \PYG{n}{lies\PYGZus{}on} \PYG{n}{q} \PYG{n}{M} \PYG{n+nb+bp}{→} \PYG{n}{L} \PYG{n+nb+bp}{=} \PYG{n}{M}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that we have followed the convention of using iterated implication rather than conjunction in the antecedent. In fact, Lean is smart enough to infer what sorts of objects \sphinxcode{\sphinxupquote{p}}, \sphinxcode{\sphinxupquote{q}}, \sphinxcode{\sphinxupquote{L}}, and \sphinxcode{\sphinxupquote{M}} are from the fact that they are used with the relation \sphinxcode{\sphinxupquote{lies\_on}}, so we could have written, more simply, this:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{p} \PYG{n}{q} \PYG{n}{L} \PYG{n}{M}\PYG{o}{,} \PYG{n}{p} \PYG{n+nb+bp}{≠} \PYG{n}{q} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{p} \PYG{n}{L} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{q} \PYG{n}{L} \PYG{n+nb+bp}{→}
  \PYG{n}{lies\PYGZus{}on} \PYG{n}{p} \PYG{n}{M} \PYG{n+nb+bp}{→} \PYG{n}{lies\PYGZus{}on} \PYG{n}{q} \PYG{n}{M} \PYG{n+nb+bp}{→} \PYG{n}{L} \PYG{n+nb+bp}{=} \PYG{n}{M}
\end{sphinxVerbatim}


\section{Using the Universal Quantifier}
\label{\detokenize{first_order_logic_in_lean:using-the-universal-quantifier}}
\sphinxAtStartPar
In Lean, you can enter the universal quantifier by writing \sphinxcode{\sphinxupquote{\textbackslash{}all}}. The motivating examples from \hyperref[\detokenize{first_order_logic:functions-predicates-and-relations}]{Section \ref{\detokenize{first_order_logic:functions-predicates-and-relations}}} are rendered as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Prime}

\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{o}{(}\PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{Odd} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{Odd} \PYG{n}{x}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{↔} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{∣} \PYG{n}{x}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{Even} \PYG{o}{(}\PYG{n}{x}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{2}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{Even} \PYG{n}{x} \PYG{n+nb+bp}{↔} \PYG{n}{Odd} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{Prime} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{→} \PYG{n}{Odd} \PYG{n}{x}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∣} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{∣} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∣} \PYG{n}{z}
\end{sphinxVerbatim}

\sphinxAtStartPar
Remember that Lean expects a comma after the universal quantifier,
and gives it the \sphinxstyleemphasis{widest} scope possible.
For example, \sphinxcode{\sphinxupquote{∀ x, P ∨ Q}} is interpreted as \sphinxcode{\sphinxupquote{∀ x, (P ∨ Q)}},
and we would write \sphinxcode{\sphinxupquote{(∀ x, P) ∨ Q}} to limit the scope.
If you prefer,
you can use the plain ascii expression \sphinxcode{\sphinxupquote{forall}} instead of the unicode \sphinxcode{\sphinxupquote{∀}}.

\sphinxAtStartPar
In Lean, then, the pattern for proving a universal statement is rendered as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{P} \PYG{n}{x} \PYG{k}{from} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
Read \sphinxcode{\sphinxupquote{fun x}} as “fix an arbitrary value \sphinxcode{\sphinxupquote{x}} of \sphinxcode{\sphinxupquote{U}}.”
Since we are allowed to rename bound variables at will,
we can equivalently write either of the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{y}\PYG{o}{,} \PYG{n}{P} \PYG{n}{y} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{P} \PYG{n}{x} \PYG{k}{from} \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{P} \PYG{n}{y} \PYG{k}{from} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
This constitutes the introduction rule for the universal quantifier.
It is very similar to the introduction rule for implication:
instead of using \sphinxcode{\sphinxupquote{fun}} to temporarily introduce an assumption,
we use \sphinxcode{\sphinxupquote{fun}} to temporarily introduce a new object, \sphinxcode{\sphinxupquote{y}}. (In fact,
both are alternate syntax for a single internal construct in Lean, which can also be denoted by \sphinxcode{\sphinxupquote{λ}}.)

\sphinxAtStartPar
The elimination rule is, similarly, implemented as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{P} \PYG{n}{a} \PYG{o}{:=}
\PYG{k}{show} \PYG{n}{P} \PYG{n}{a} \PYG{k}{from} \PYG{n}{h} \PYG{n}{a}
\end{sphinxVerbatim}

\sphinxAtStartPar
Observe the notation: \sphinxcode{\sphinxupquote{P a}} is obtained by “applying” the hypothesis \sphinxcode{\sphinxupquote{h}} to \sphinxcode{\sphinxupquote{a}}. Once again, note the similarity to the elimination rule for implication.

\sphinxAtStartPar
Here is an example of how it is used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{h2} \PYG{n}{y}
\PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{y}
\PYG{k}{show} \PYG{n}{B} \PYG{n}{y} \PYG{k}{from} \PYG{n}{h4} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is an even shorter version of the same proof, where we avoid using \sphinxcode{\sphinxupquote{have}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{B} \PYG{n}{y} \PYG{k}{from} \PYG{n}{h1} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{n}{y}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
You should talk through the steps, here. Applying \sphinxcode{\sphinxupquote{h1}} to \sphinxcode{\sphinxupquote{y}} yields a proof of \sphinxcode{\sphinxupquote{A y → B y}}, which we then apply to \sphinxcode{\sphinxupquote{h2 y}}, which is a proof of \sphinxcode{\sphinxupquote{A y}}. The result is the proof of \sphinxcode{\sphinxupquote{B y}} that we are after.

\sphinxAtStartPar
In the last chapter, we considered the following proof in natural deduction:



\begin{prooftree}
\AXM{}
\RLM{1}
\UIM{\fa x A(x)}
\UIM{A(y)}
\AXM{}
\RLM{2}
\UIM{\fa x B(x)}
\UIM{B(y)}
\BIM{A(y) \wedge B(y)}
\UIM{\fa y (A(y) \wedge B(y))}
\RLM{2}
\UIM{\fa x B(x) \to \fa y (A(y) \wedge B(y))}
\RLM{1}
\UIM{\fa x A(x) \to (\fa x B(x) \to \fa y (A(y) \wedge B(y)))}
\end{prooftree}

\sphinxAtStartPar
Here is the same proof rendered in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{hA} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{↦}
  \PYG{k}{fun} \PYG{n}{hB} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
    \PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
      \PYG{k}{have} \PYG{n}{Ay} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hA} \PYG{n}{y}
      \PYG{k}{have} \PYG{n}{By} \PYG{o}{:} \PYG{n}{B} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hB} \PYG{n}{y}
      \PYG{k}{show} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{y} \PYG{k}{from} \PYG{n}{And.intro} \PYG{n}{Ay} \PYG{n}{By}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is an alternative version, using the “anonymous” versions of \sphinxcode{\sphinxupquote{have}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{hA} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{↦}
  \PYG{k}{fun} \PYG{n}{hB} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
    \PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
      \PYG{k}{have} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hA} \PYG{n}{y}
      \PYG{k}{have} \PYG{o}{:} \PYG{n}{B} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hB} \PYG{n}{y}
      \PYG{k}{show} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{y} \PYG{k}{from} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{A} \PYG{n}{y}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{B} \PYG{n}{y}\PYG{o}{›}
\end{sphinxVerbatim}

\sphinxAtStartPar
The exercises below ask you to prove the barber paradox, which was discussed in the last chapter. You can do that using only propositional reasoning and the rules for the universal quantifier that we have just discussed.


\section{Using the Existential Quantifier}
\label{\detokenize{first_order_logic_in_lean:using-the-existential-quantifier}}
\sphinxAtStartPar
In Lean, you can type the existential quantifier, \sphinxcode{\sphinxupquote{∃}}, by writing \sphinxcode{\sphinxupquote{\textbackslash{}ex}}.
If you prefer you can use the ascii equivalent, \sphinxcode{\sphinxupquote{Exists}}.
The introduction rule is \sphinxcode{\sphinxupquote{Exists.intro}} and requires two arguments:
a term, and a proof that term satisfies the required property.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{y} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{P} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
The elimination rule for the existential quantifier is given by \sphinxcode{\sphinxupquote{Exists.elim}}.
It follows the form of the natural deduction rule:
if we know \sphinxcode{\sphinxupquote{∃x, P x}} and we are trying to prove \sphinxcode{\sphinxupquote{Q}},
it suffices to introduce a new variable, \sphinxcode{\sphinxupquote{y}},
and prove \sphinxcode{\sphinxupquote{Q}} under the assumption that \sphinxcode{\sphinxupquote{P y}} holds.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{Q} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{Q}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Q} \PYG{o}{:=}
\PYG{n}{Exists.elim} \PYG{n}{h1}
  \PYG{o}{(}\PYG{k}{fun} \PYG{o}{(}\PYG{n}{y} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{P} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{P} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{Q} \PYG{o}{:=} \PYG{n}{h2} \PYG{n}{y}
  \PYG{k}{show} \PYG{n}{Q} \PYG{k}{from} \PYG{n}{h3} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As usual, we can leave off the information as to the data type of \sphinxcode{\sphinxupquote{y}} and the hypothesis \sphinxcode{\sphinxupquote{h}} after the \sphinxcode{\sphinxupquote{fun}}, since Lean can figure them out from the context. Deleting the \sphinxcode{\sphinxupquote{show}} and replacing \sphinxcode{\sphinxupquote{h3}} by its proof, \sphinxcode{\sphinxupquote{h2 y}}, yields a short (though virtually unreadable) proof of the conclusion.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{Q}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Q} \PYG{o}{:=}
\PYG{n}{Exists.elim} \PYG{n}{h1}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{y} \PYG{n}{h} \PYG{n+nb+bp}{↦} \PYG{n}{h2} \PYG{n}{y} \PYG{n}{h}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The following example uses both the introduction and the elimination rules for the existential quantifier.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h1}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h2}
  \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{k}{from} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice the parentheses in the hypothesis; if we left them out, everything after the first \sphinxcode{\sphinxupquote{∃ x}} would be included in the scope of that quantifier. From the hypothesis, we obtain a \sphinxcode{\sphinxupquote{y}} that satisfies \sphinxcode{\sphinxupquote{A y ∧ B y}}, and hence \sphinxcode{\sphinxupquote{A y}} in particular. So \sphinxcode{\sphinxupquote{y}} is enough to witness the conclusion.

\sphinxAtStartPar
It is sometimes annoying to enclose the proof after an \sphinxcode{\sphinxupquote{Exists.elim}} in parenthesis, as we did here with the \sphinxcode{\sphinxupquote{fun ... show}} block. To avoid that, we can use a bit of syntax from the programming world, and use a dollar sign instead. In Lean, an expression \sphinxcode{\sphinxupquote{f \$ t}} means the same thing as \sphinxcode{\sphinxupquote{f (t)}}, with the advantage that we do not have to remember to close the parenthesis. With this gadget, we can write the proof above as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h1} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h2}
\PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{k}{from} \PYG{o}{⟨}\PYG{n}{y}\PYG{o}{,} \PYG{n}{h3}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
Like with \sphinxcode{\sphinxupquote{And.intro}}, we can use the
use \sphinxcode{\sphinxupquote{\textbackslash{}<}} and \sphinxcode{\sphinxupquote{\textbackslash{}>}} as syntax for \sphinxcode{\sphinxupquote{Exists.intro}},
which we used in the last line of the example above.

\sphinxAtStartPar
The following example is more involved:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h1} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{n}{Or.elim} \PYG{n}{h2}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}
    \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{n}{h4}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n}{y} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}
    \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inr} \PYG{n}{h4}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note again the placement of parentheses in the statement.

\sphinxAtStartPar
In the last chapter, we considered the following natural deduction proof:



\begin{prooftree}
\AXM{}
\RLM{2}
\UIM{\ex x (A(x) \wedge B(x))}
\AXM{}
\RLM{1}
\UIM{\fa x (A(x) \to \neg B(x))}
\UIM{A(x) \to \neg B(x)}
\AXM{}
\RLM{3}
\UIM{A(x) \wedge B(x)}
\UIM{A(x)}
\BIM{\neg B(x)}
\AXM{}
\RLM{3}
\UIM{A(x) \wedge B(x)}
\UIM{B(x)}
\BIM{\bot}
\RLM{3}
\BIM{\bot}
\RLM{2}
\UIM{\neg\ex x(A(x) \wedge B(x))}
\RLM{1}
\UIM{\fa x (A(x) \to \neg B(x)) \to \neg \ex x (A(x) \wedge B(x))}
\end{prooftree}

\sphinxAtStartPar
Here is a proof of the same implication in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h2} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{x} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h3}
\PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h3}
\PYG{k}{have} \PYG{n}{h6} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{x} \PYG{n}{h4}
\PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{h6} \PYG{n}{h5}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, we use \sphinxcode{\sphinxupquote{Exists.elim}} to introduce a value \sphinxcode{\sphinxupquote{x}} satisfying \sphinxcode{\sphinxupquote{A x ∧ B x}}. The name is arbitrary; we could just as well have used \sphinxcode{\sphinxupquote{z}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h2} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{z} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{z} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{A} \PYG{n}{z} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h3}
\PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{B} \PYG{n}{z} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h3}
\PYG{k}{have} \PYG{n}{h6} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{B} \PYG{n}{z} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{z} \PYG{n}{h4}
\PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{h6} \PYG{n}{h5}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is another example of the exists\sphinxhyphen{}elimination rule:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{u} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{,} \PYG{n}{P}\PYG{o}{)} \PYG{n+nb+bp}{↔} \PYG{n}{P} \PYG{o}{:=}
\PYG{n}{Iff.intro}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃}\PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n+nb+bp}{↦}
    \PYG{n}{Exists.elim} \PYG{n}{h1} \PYG{n+nb+bp}{\PYGZdl{}}
    \PYG{k}{fun} \PYG{n}{x} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{P}\PYG{o}{)} \PYG{n+nb+bp}{↦}
    \PYG{n}{h2}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{P} \PYG{n+nb+bp}{↦}
    \PYG{o}{⟨}\PYG{n}{u}\PYG{o}{,} \PYG{n}{h1}\PYG{o}{⟩}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
This is subtle: the proof does not go through if we do not declare a variable \sphinxcode{\sphinxupquote{u}} of type \sphinxcode{\sphinxupquote{U}}, even though \sphinxcode{\sphinxupquote{u}} does not appear in the statement of the theorem. This highlights a difference between first\sphinxhyphen{}order logic and the logic implemented in Lean. In natural deduction, we can prove \(\forall x \; P(x) \to \exists x \; P(x)\), which shows that our proof system implicitly assumes that the universe has at least one object. In contrast, the statement \sphinxcode{\sphinxupquote{(∀ x : U, P x) → ∃ x : U, P x}} is not provable in Lean. In other words, in Lean, it is possible for a type to be empty, and so the proof above requires an explicit assumption that there is an element \sphinxcode{\sphinxupquote{u}} in \sphinxcode{\sphinxupquote{U}}.


\section{Equality}
\label{\detokenize{first_order_logic_in_lean:equality}}
\sphinxAtStartPar
In Lean, reflexivity, symmetry, and transitivity are called \sphinxcode{\sphinxupquote{Eq.refl}}, \sphinxcode{\sphinxupquote{Eq.symm}}, and \sphinxcode{\sphinxupquote{Eq.trans}}, and the second substitution rule is called \sphinxcode{\sphinxupquote{Eq.subst}}. Their uses are illustrated below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{k}{from} \PYG{n}{Eq.refl} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{k}{from} \PYG{n}{Eq.symm} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{k}{from} \PYG{n}{Eq.trans} \PYG{n}{h1} \PYG{n}{h2}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{P} \PYG{n}{y} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n}{P} \PYG{n}{y} \PYG{k}{from} \PYG{n}{Eq.subst} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
The rule \sphinxcode{\sphinxupquote{Eq.refl}} above assumes \sphinxcode{\sphinxupquote{x}} as an argument, because there is no hypothesis to infer it from. All the other rules assume their premises as arguments. Here is an example of equational reasoning:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{Eq.symm} \PYG{n}{h1}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{k}{from} \PYG{n}{Eq.trans} \PYG{n}{h3} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
This proof can be written more concisely:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{n}{h2} \PYG{n+nb+bp}{↦} \PYG{n}{Eq.trans} \PYG{o}{(}\PYG{n}{Eq.symm} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}
\end{sphinxVerbatim}


\section{Tactic Mode}
\label{\detokenize{first_order_logic_in_lean:tactic-mode}}

\subsection{Universal quantifiers}
\label{\detokenize{first_order_logic_in_lean:universal-quantifiers}}
\sphinxAtStartPar
Just like for conditionals,
in tactic mode we can also use \sphinxcode{\sphinxupquote{intro x}} to introduce a variable,
or “fix an arbitrary value \sphinxcode{\sphinxupquote{x : U}}”.
This would change the goal from \sphinxcode{\sphinxupquote{∀ x, A x}} to \sphinxcode{\sphinxupquote{A x}}.
Conversely when we have a proof \sphinxcode{\sphinxupquote{h : ∀ x, A x}} of a universal quantifier,
and our goal is \sphinxcode{\sphinxupquote{A a}} for some \sphinxcode{\sphinxupquote{a : U}},
we can use \sphinxcode{\sphinxupquote{apply h}} to close the goal.
Here is the example from earlier in tactic mode:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{y}
  \PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{apply} \PYG{n}{h1}
  \PYG{k}{show} \PYG{n}{B} \PYG{n}{y}
  \PYG{n}{apply} \PYG{n}{h3}
  \PYG{k}{show} \PYG{n}{A} \PYG{n}{y}
  \PYG{n}{apply} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
The tactic \sphinxcode{\sphinxupquote{apply}} can combine hypothesis and
only require us to provide those that remain.
For example, if we were to immediately do \sphinxcode{\sphinxupquote{apply h1}}
when showing \sphinxcode{\sphinxupquote{B y}}
Lean would recognize that we need to supply \sphinxcode{\sphinxupquote{y}}
in place of \sphinxcode{\sphinxupquote{x}} and then ask us to show \sphinxcode{\sphinxupquote{A y}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{y}
  \PYG{k}{show} \PYG{n}{B} \PYG{n}{y}
  \PYG{n}{apply} \PYG{n}{h1}
  \PYG{k}{show} \PYG{n}{A} \PYG{n}{y}
  \PYG{n}{apply} \PYG{n}{h2}
\end{sphinxVerbatim}


\subsection{Existential quantifiers}
\label{\detokenize{first_order_logic_in_lean:existential-quantifiers}}
\sphinxAtStartPar
Recall the example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h1} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h2}
\PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{k}{from} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
In tactic mode we could prove this in the following way

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{h1} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{y} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}
    \PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{y}
    \PYG{k}{show} \PYG{n}{A} \PYG{n}{x}
    \PYG{n}{cases} \PYG{n}{h2} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{h3} \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{n}{exact} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
By doing \sphinxcode{\sphinxupquote{cases h1}} we obtain only one possible case for how
a proof \sphinxcode{\sphinxupquote{h1 : ∃ x, A x ∧ B x}} was constructed \sphinxhyphen{}
namely by \sphinxcode{\sphinxupquote{Exists.intro y h2}} where \sphinxcode{\sphinxupquote{y : U}} and \sphinxcode{\sphinxupquote{h2 : A y ∧ B y}}
(Lean’s syntax omits the \sphinxcode{\sphinxupquote{Exists.}}).
Given a \sphinxcode{\sphinxupquote{y : U}}, Lean sees \sphinxcode{\sphinxupquote{Exists.intro y : A y → ∃ x, A x}}
as a conditional.
So we can use \sphinxcode{\sphinxupquote{apply Exists.intro y}} to change the goal
from \sphinxcode{\sphinxupquote{A x}} to \sphinxcode{\sphinxupquote{∃ x, A x}}.

\sphinxAtStartPar
A further example from before

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{n}{Exists.elim} \PYG{n}{h1} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{y} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{n}{Or.elim} \PYG{n}{h2}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{A} \PYG{n}{y} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}
    \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{n}{h4}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{B} \PYG{n}{y} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}
    \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{k}{from} \PYG{n}{Or.inr} \PYG{n}{h4}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{h1} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{y} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{n}{cases} \PYG{n}{h2} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{h3} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Or.inl}
      \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{y}
      \PYG{n}{exact} \PYG{n}{h3}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{h3} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Or.inr}
      \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{y}
      \PYG{n}{exact} \PYG{n}{h3}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term\PYGZhy{}tactic mix}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{h1} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{y} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{n}{cases} \PYG{n}{h2} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{h3} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inl} \PYG{o}{(}\PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}\PYG{o}{)}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{h3} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inr} \PYG{o}{(}\PYG{n}{Exists.intro} \PYG{n}{y} \PYG{n}{h3}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
If we don’t want to present our proof backwards using \sphinxcode{\sphinxupquote{apply}},
we might opt for the style of our final example above,
returning to term mode after breaking down the assumption \sphinxcode{\sphinxupquote{h1}} completely.

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{obtain}} tactic provides us an alternative to \sphinxcode{\sphinxupquote{cases}}
for eliminating existentials.
Again, we take a proof \sphinxcode{\sphinxupquote{h1 : ∃ y, P y}}
of an extenstential and break it up into a pair
\sphinxcode{\sphinxupquote{⟨x, (h2 : P x)⟩ := h1}}.
It can also do nested eliminations,
so that the second proof below is just a shorter version of the first:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
\PYG{n}{obtain} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}\PYG{o}{⟩} \PYG{o}{:=} \PYG{n}{h1}
\PYG{n}{obtain} \PYG{o}{⟨}\PYG{n}{y}\PYG{o}{,} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}\PYG{o}{⟩} \PYG{o}{:=} \PYG{n}{h2}
\PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{y}
\PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{x}
\PYG{n}{exact} \PYG{n}{h3}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
\PYG{n}{obtain} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{o}{⟨}\PYG{n}{y}\PYG{o}{,} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}\PYG{o}{⟩}\PYG{o}{⟩} \PYG{o}{:=} \PYG{n}{h1}
\PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{y}\PYG{o}{,} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{h3}\PYG{o}{⟩}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can also use \sphinxcode{\sphinxupquote{obtain}} to extract the components of an “and”:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)}
\PYG{n}{obtain} \PYG{o}{⟨}\PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}\PYG{o}{,} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{B}\PYG{o}{)} \PYG{o}{⟩} \PYG{o}{:=} \PYG{n}{h1}
\PYG{k}{show} \PYG{n}{B} \PYG{n+nb+bp}{∧} \PYG{n}{A}
\PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{h3}\PYG{o}{,} \PYG{n}{h2}\PYG{o}{⟩}
\end{sphinxVerbatim}


\subsection{Equality}
\label{\detokenize{first_order_logic_in_lean:id2}}
\sphinxAtStartPar
Because calculations are so important in mathematics,
Lean provides more efficient ways of carrying them out.
One method is to use the \sphinxcode{\sphinxupquote{`rewrite}} tactic,
which carries out substitutions along equalities on parts of the goal.

\sphinxAtStartPar
Recall the example

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{n}{h2} \PYG{n+nb+bp}{↦} \PYG{n}{Eq.trans} \PYG{o}{(}\PYG{n}{Eq.symm} \PYG{n}{h1}\PYG{o}{)} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
A tactic mode proof of this would look like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hyx} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hyz} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z}\PYG{o}{)}
  \PYG{n}{rewrite} \PYG{o}{[}\PYG{n+nb+bp}{←}\PYG{n}{hyx}\PYG{o}{]}
  \PYG{n}{exact} \PYG{n}{hyz}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you put the cursor before \sphinxcode{\sphinxupquote{rewrite}},
Lean will tell you that the goal at that point is to prove \sphinxcode{\sphinxupquote{x = z}}.
The first command changes the goal \sphinxcode{\sphinxupquote{x = z}} to \sphinxcode{\sphinxupquote{y = z}};
the left\sphinxhyphen{}facing arrow before \sphinxcode{\sphinxupquote{hyx}} (which you can enter as \sphinxcode{\sphinxupquote{\textbackslash{}<\sphinxhyphen{}}})
tells Lean to use the equation in the reverse direction.
If you put the cursor before \sphinxcode{\sphinxupquote{exact}}
Lean shows you the new goal, \sphinxcode{\sphinxupquote{y = z}}.
The \sphinxcode{\sphinxupquote{apply}} command uses \sphinxcode{\sphinxupquote{hyz}} to complete the proof.

\sphinxAtStartPar
An alternative is to rewrite the goal using \sphinxcode{\sphinxupquote{hyx}} and \sphinxcode{\sphinxupquote{hyz}},
which reduces the goal to \sphinxcode{\sphinxupquote{x = x}}.
When that happens, \sphinxcode{\sphinxupquote{rewrite}} automatically applies reflexivity.
Rewriting is such a common operation in Lean that we can use the shorthand
\sphinxcode{\sphinxupquote{rw}} in place of the full \sphinxcode{\sphinxupquote{rewrite}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hyx} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hyz} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z}\PYG{o}{)}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←}\PYG{n}{hyx}\PYG{o}{]}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{hyz}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, a sequence of rewrites can be combined, using square brackets:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hyx} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hyz} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z}\PYG{o}{)}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←}\PYG{n}{hyx}\PYG{o}{,} \PYG{n}{hyz}\PYG{o}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{assume} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x}\PYG{o}{,}
\PYG{k}{assume} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z}\PYG{o}{,}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z}\PYG{o}{,} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←}\PYG{n}{h1}\PYG{o}{,} \PYG{n}{h2}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you put the cursor after the \sphinxcode{\sphinxupquote{←h1}}, Lean shows you the goal at that point.

\sphinxAtStartPar
The tactic \sphinxcode{\sphinxupquote{rewrite}} can also be used for substituting along biconditionals.
For example, if our goal were \sphinxcode{\sphinxupquote{A ∧ B}} but we know that \sphinxcode{\sphinxupquote{hAC : A ↔ C}} and
\sphinxcode{\sphinxupquote{C ∧ B}}, then we could rewrite \sphinxcode{\sphinxupquote{A}} for \sphinxcode{\sphinxupquote{C}} using \sphinxcode{\sphinxupquote{hAC}},
changing out goal to \sphinxcode{\sphinxupquote{C ∧ B}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{hAC} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{C}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hCB} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{∧} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{hAC}\PYG{o}{]}
  \PYG{n}{exact} \PYG{n}{hCB}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the following example we use an \sphinxcode{\sphinxupquote{Iff}} lemma from Mathlib
and the fact that \sphinxcode{\sphinxupquote{1}} is odd to show that \sphinxcode{\sphinxupquote{1}} is not even.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Prime}
\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{k}{\PYGZsh{}check} \PYG{n}{odd\PYGZus{}iff\PYGZus{}not\PYGZus{}even}
\PYG{k}{\PYGZsh{}check} \PYG{n}{odd\PYGZus{}one}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{Even} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←} \PYG{n}{odd\PYGZus{}iff\PYGZus{}not\PYGZus{}even}\PYG{o}{]}
  \PYG{n}{exact} \PYG{n}{odd\PYGZus{}one}
\end{sphinxVerbatim}


\section{Calculational Proofs}
\label{\detokenize{first_order_logic_in_lean:calculational-proofs}}
\sphinxAtStartPar
We will see in the coming chapters that in ordinary mathematical proofs, one commonly carries out calculations in a format like this:
\begin{equation*}
\begin{split}t_1 &= t_2 \\
 \ldots & = t_3 \\
 \ldots &= t_4 \\
 \ldots &= t_5.\end{split}
\end{equation*}
\sphinxAtStartPar
Lean has a mechanism to model such calculational proofs. Whenever a proof of an equation is expected, you can provide a proof using the identifier \sphinxcode{\sphinxupquote{calc}}, following by a chain of equalities and justification, in the following form:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
calc
  e1 = e2 := justification 1
   \PYGZus{} = e3 := justification 2
   \PYGZus{} = e4 := justification 3
   \PYGZus{} = e5 := justification 4
\end{sphinxVerbatim}

\sphinxAtStartPar
The chain can go on as long as needed, and in this example the result is a proof of \sphinxcode{\sphinxupquote{e1 = e5}}. Each justification is the name of the assumption or theorem that is used. For example, the previous proof could be written as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{↦}
\PYG{k}{calc}
  \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{Eq.symm} \PYG{n}{h1}
  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
As usual, the syntax is finicky; notice that there are no commas in the
\sphinxcode{\sphinxupquote{calc}} expression,
and the \sphinxcode{\sphinxupquote{:=}} and underscores must be in the correct form.
It is also sensitive to whitespace
All that varies are the expressions \sphinxcode{\sphinxupquote{e1, e2, e3, ...}}
and the justifications themselves.

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{calc}} environment is most powerful when used in conjunction with \sphinxcode{\sphinxupquote{rewrite}},
since we can then rewrite expressions with facts from the library. For example, Lean’s library has a number of basic identities for the integers, such as these:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Int.Defs}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{Int.add\PYGZus{}zero} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{Int.zero\PYGZus{}add} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:=}
\PYG{n}{Int.add\PYGZus{}assoc} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{Int.add\PYGZus{}comm} \PYG{n}{x} \PYG{n}{y}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:=}
\PYG{n}{Int.mul\PYGZus{}assoc} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{Int.mul\PYGZus{}comm} \PYG{n}{x} \PYG{n}{y}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{z} \PYG{o}{:=}
\PYG{n}{Int.mul\PYGZus{}add} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{*} \PYG{n}{z} \PYG{o}{:=}
\PYG{n}{Int.add\PYGZus{}mul} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can also write the type of integers as \sphinxcode{\sphinxupquote{ℤ}},
entered with either \sphinxcode{\sphinxupquote{\textbackslash{}Z}} or \sphinxcode{\sphinxupquote{\textbackslash{}int}}.
We have imported the file \sphinxcode{\sphinxupquote{Mathlib.Data.Int.Defs}}
to make all the basic properties of the integers available to us.
(In later snippets,
we will suppress this line in the online and pdf versions of the textbook,
to avoid clutter.)
Notice that, for example,
\sphinxcode{\sphinxupquote{Int.add\_comm}} is the theorem \sphinxcode{\sphinxupquote{∀ x y, x + y = y + x}}.
So to instantiate it to \sphinxcode{\sphinxupquote{s + t = t + s}},
you write \sphinxcode{\sphinxupquote{Int.add\_comm s t}}.
Using these axioms,
here is the calculation above rendered in Lean, as a theorem about the integers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=}
\PYG{k}{calc}
      \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z}
    \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{Int.add\PYGZus{}assoc} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}
  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{n+nb+bp}{@}\PYG{n}{Eq.subst} \PYG{n}{\PYGZus{}} \PYG{o}{(}\PYG{n+nb+bp}{λ} \PYG{n}{w} \PYG{n+nb+bp}{↦} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{w}\PYG{o}{)} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{o}{(}\PYG{n}{Int.add\PYGZus{}comm} \PYG{n}{y} \PYG{n}{z}\PYG{o}{)} \PYG{n}{rfl}
  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{Eq.symm} \PYG{o}{(}\PYG{n}{Int.add\PYGZus{}assoc} \PYG{n}{x} \PYG{n}{z} \PYG{n}{y}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We had to use \sphinxcode{\sphinxupquote{@}} on \sphinxcode{\sphinxupquote{Eq.subst}} to fill in some of the implicit arguments,
because the provided information was insufficient.
Using \sphinxcode{\sphinxupquote{rewrite}} simplifies the work,
though at times we have to provide information to specify where the rules are used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=}
\PYG{k}{calc}
  \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{]}
          \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}comm} \PYG{n}{y} \PYG{n}{z}\PYG{o}{]}
          \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
In this case, we can use a single \sphinxcode{\sphinxupquote{rewrite}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)} \PYG{o}{:} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=}
\PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{,} \PYG{n}{Int.add\PYGZus{}comm} \PYG{n}{y} \PYG{n}{z}\PYG{o}{,} \PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is another example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{n}{d} \PYG{n}{c} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{d}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{o}{:=}
\PYG{k}{calc}
  \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{d}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.mul\PYGZus{}add}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{c}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{d}         \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}mul}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{c}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{d}\PYG{o}{)}     \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.add\PYGZus{}mul}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{d}         \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←}\PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once again, there is a shorter proof:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{n}{d} \PYG{n}{c} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{+} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{d}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{c} \PYG{n+nb+bp}{+} \PYG{n}{a} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{n+nb+bp}{+} \PYG{n}{b} \PYG{n+nb+bp}{*} \PYG{n}{d} \PYG{o}{:=}
\PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Int.mul\PYGZus{}add}\PYG{o}{,} \PYG{n}{Int.add\PYGZus{}mul}\PYG{o}{,} \PYG{n}{Int.add\PYGZus{}mul}\PYG{o}{,} \PYG{n+nb+bp}{←}\PYG{n}{Int.add\PYGZus{}assoc}\PYG{o}{]}
\end{sphinxVerbatim}


\section{Exercises}
\label{\detokenize{first_order_logic_in_lean:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}} in term mode.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{P} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)}\PYG{o}{)}

  \PYG{c+c1}{\PYGZhy{}\PYGZhy{} Show the following:}
  \PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{y}\PYG{o}{,} \PYG{n}{P} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{P} \PYG{o}{(}\PYG{n}{f} \PYG{o}{(}\PYG{n}{f} \PYG{n}{y}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}} in tactic mode.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}
(assume that this means in your preferred style,
unless specified otherwise).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{n}{x}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{n}{x}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{C} \PYG{n}{x} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}’s below, to prove the barber paradox.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{open} \PYG{n}{Classical}   \PYG{c+c1}{\PYGZhy{}\PYGZhy{} not needed, but you can use it}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} This is an exercise from Chapter 4. Use it as an axiom here.}
\PYG{k+kd}{axiom} \PYG{n}{not\PYGZus{}iff\PYGZus{}not\PYGZus{}self} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{P} \PYG{n+nb+bp}{↔} \PYG{n+nb+bp}{¬} \PYG{n}{P}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{Q} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{Q} \PYG{n+nb+bp}{↔} \PYG{n+nb+bp}{¬} \PYG{n}{Q}\PYG{o}{)} \PYG{o}{:=}
\PYG{n}{not\PYGZus{}iff\PYGZus{}not\PYGZus{}self} \PYG{n}{Q}

\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{Person} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{shaves} \PYG{o}{:} \PYG{n}{Person} \PYG{n+nb+bp}{→} \PYG{n}{Person} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{barber} \PYG{o}{:} \PYG{n}{Person}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{shaves} \PYG{n}{barber} \PYG{n}{x} \PYG{n+nb+bp}{↔} \PYG{n+nb+bp}{¬} \PYG{n}{shaves} \PYG{n}{x} \PYG{n}{x}\PYG{o}{)}

  \PYG{c+c1}{\PYGZhy{}\PYGZhy{} Show the following:}
  \PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{False} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∨} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{B} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{C} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:}
    \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{n+nb+bp}{∧} \PYG{n}{C} \PYG{n}{x} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Complete these proofs.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{¬} \PYG{n}{A} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{A} \PYG{n}{x} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∀} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∀} \PYG{n}{y}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
The following exercise shows that in the presence of reflexivity, the rules for symmetry and transitivity are equivalent to a single rule.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{foo} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{c} \PYG{n+nb+bp}{=} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{c} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} notice that you can now use foo as a rule. The curly braces mean that}
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} you do not have to give A, a, b, or c}

\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{c} \PYG{n+nb+bp}{=} \PYG{n}{b}\PYG{o}{)} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{c} \PYG{o}{:=}
  \PYG{n}{foo} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k+kd}{end}

\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
  \PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}}

  \PYG{c+c1}{\PYGZhy{}\PYGZhy{} replace the sorry with a proof, using foo and rfl, without using eq.symm.}
  \PYG{k+kd}{theorem} \PYG{n}{my\PYGZus{}symm} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{=} \PYG{n}{a}\PYG{o}{)} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b} \PYG{o}{:=}
  \PYG{g+gr}{sorry}

  \PYG{c+c1}{\PYGZhy{}\PYGZhy{} now use foo and my\PYGZus{}symm to prove transitivity}
  \PYG{k+kd}{theorem} \PYG{n}{my\PYGZus{}trans} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{=} \PYG{n}{c}\PYG{o}{)} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{c} \PYG{o}{:=}
  \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Replace each \sphinxcode{\sphinxupquote{sorry}} below by the correct axiom from the list.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Algebra.Ring.Int}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} these are the axioms for a commutative ring}

\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{add\PYGZus{}assoc}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{add\PYGZus{}comm}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{add\PYGZus{}zero}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{zero\PYGZus{}add}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mul\PYGZus{}assoc}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mul\PYGZus{}comm}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mul\PYGZus{}one}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{one\PYGZus{}mul}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{left\PYGZus{}distrib}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{right\PYGZus{}distrib}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{add\PYGZus{}left\PYGZus{}neg}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{add\PYGZus{}right\PYGZus{}neg}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{sub\PYGZus{}eq\PYGZus{}add\PYGZus{}neg}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{Int}\PYG{o}{)}

\PYG{k+kd}{theorem} \PYG{n}{t1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{o}{:=}
\PYG{k}{calc}
\PYG{n}{x} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{sub\PYGZus{}eq\PYGZus{}add\PYGZus{}neg}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0}      \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}right\PYGZus{}neg}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{t2} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{calc}
\PYG{n}{y}     \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{y}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{zero\PYGZus{}add}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}left\PYGZus{}neg}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}assoc}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{z} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}assoc}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{z}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}left\PYGZus{}neg}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{z}            \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{zero\PYGZus{}add}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{t3} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{o}{:=}
\PYG{k}{calc}
\PYG{n}{x}     \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{z}            \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}

\PYG{k+kd}{theorem} \PYG{n}{t4} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y} \PYG{o}{:=}
\PYG{k}{calc}
\PYG{n}{x}     \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}zero}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}right\PYGZus{}neg}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}assoc}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}       \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}           \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{zero\PYGZus{}add}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{t5} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{o}{:=}
  \PYG{k}{calc}
    \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
                \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0}       \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
                \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{k}{from} \PYG{n}{t2} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{h1}

\PYG{k+kd}{theorem} \PYG{n}{t6} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{o}{:=}
  \PYG{k}{calc}
    \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y} \PYG{n+nb+bp}{+} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
                \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{0}        \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
                \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0}            \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{t5} \PYG{n}{x}\PYG{o}{]}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)} \PYG{k}{from} \PYG{n}{t4} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{h1}

\PYG{k+kd}{theorem} \PYG{n}{t7} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{o}{:=}
\PYG{k}{calc}
\PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{one\PYGZus{}mul}\PYG{o}{]}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{l+m+mi}{1} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{x}   \PYG{o}{:=} \PYG{g+gr}{sorry}
    \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{x}         \PYG{o}{:=} \PYG{n}{rfl}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}. Remember that you can use \sphinxcode{\sphinxupquote{rewrite}}
to substitute along biconditionals.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Prime}
\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} You can use the following facts.}
\PYG{k}{\PYGZsh{}check} \PYG{n}{odd\PYGZus{}add}
\PYG{k}{\PYGZsh{}check} \PYG{n}{odd\PYGZus{}mul}
\PYG{k}{\PYGZsh{}check} \PYG{n}{odd\PYGZus{}iff\PYGZus{}not\PYGZus{}even}
\PYG{k}{\PYGZsh{}check} \PYG{n}{not\PYGZus{}even\PYGZus{}one}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} Show the following:}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{,}
    \PYG{n}{Odd} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{Odd} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{Even} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{Odd} \PYG{o}{(}\PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{z} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\end{enumerate}


\chapter{Semantics of First Order Logic}
\label{\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}}\label{\detokenize{semantics_of_first_order_logic:id1}}\label{\detokenize{semantics_of_first_order_logic::doc}}
\sphinxAtStartPar
In \hyperref[\detokenize{semantics_of_propositional_logic:semantics-of-propositional-logic}]{Chapter \ref{\detokenize{semantics_of_propositional_logic:semantics-of-propositional-logic}}}, we emphasized a distinction between the \sphinxstyleemphasis{syntax} and the \sphinxstyleemphasis{semantics} of propositional logic. Syntactic questions have to do with the formal structure of formulas and the conditions under which different types of formulas can be derived. Semantic questions, on the other hand, concern the \sphinxstyleemphasis{truth} of a formula relative to some truth assignment.

\sphinxAtStartPar
As you might expect, we can make a similar distinction in the setting of first order logic. The previous two chapters have focused on syntax, but some semantic ideas have slipped in. Recall the running example with domain of interest \({\mathbb N}\), constant symbols 0, 1, 2, 3, function symbols \(\mathit{add}\) and \(\mathit{mul}\), and predicate symbols \(\mathit{even}, \mathit{prime}, \mathit{equals}, \mathit{le}\), etc. We know that the sentence \(\forall y \; \mathit{le}(0, y)\) is true in this example, if \(\mathit{le}\) is interpreted as the less\sphinxhyphen{}than\sphinxhyphen{}or\sphinxhyphen{}equal\sphinxhyphen{}to relation on the natural numbers. But if we consider the domain \({\mathbb Z}\) instead of \({\mathbb N}\), that same formula becomes false. The sentence \(\forall y \; \mathit{lt}(0,y)\) is also false if we consider the domain \({\mathbb N}\), but (somewhat perversely) interpret the predicate \(\mathit{lt}(x, y)\) as the relation “\(x\) is greater than \(y\)” on the natural numbers.

\sphinxAtStartPar
This indicates that the truth or falsity or a first order sentence can depend on how we interpret the quantifiers and basic relations of the language. But some formulas are true under any interpretation: for instance, \(\forall y \; (\mathit{le}(0, y) \to \mathit{le}(0, y))\) is true under all the interpretations considered in the last paragraph, and, indeed, under any interpretation we choose. A sentence like this is said to be \sphinxstyleemphasis{valid}; this is the analogue of a tautology in propositional logic, which is true under every possible truth assignment.

\sphinxAtStartPar
We can broaden the analogy: a “model” in first order logic is the analogue of a truth assignment in propositional logic. In the propositional case, choosing a truth assignment allowed us to assign truth values to all formulas of the language; now, choosing a model will allow us to assign truth values to all sentences of a first order language. The aim of the next section is to make this notion more precise.


\section{Interpretations}
\label{\detokenize{semantics_of_first_order_logic:interpretations}}
\sphinxAtStartPar
The symbols of the language in our running example—0, 1, \(\mathit{add}\), \(\mathit{prime}\), and so on—have very suggestive names. When we interpret sentences of this language over the domain \({\mathbb N}\), for example, it is clear for which elements of the domain \(\mathit{prime}\) “should” be true, and for which it “should” be false. But let us consider a first order language that has only two unary predicate symbols \(\mathit{fancy}\) and \(\mathit{tall}\). If we take our domain to be \({\mathbb N}\), is the sentence \(\forall x \; (\mathit{fancy}(x) \to \mathit{tall}(x))\) true or false?

\sphinxAtStartPar
The answer, of course, is that we don’t have enough information to say. There’s no obvious meaning to the predicates \(\mathit{fancy}\) or \(\mathit{tall}\), at least not when we apply them to natural numbers. To make sense of the sentence, we need to know which numbers are fancy and which ones are tall. Perhaps multiples of 10 are fancy, and even numbers are tall; in this case, the formula is true, since every multiple of 10 is even. Perhaps prime numbers are fancy and odd numbers are tall; then the formula is false, since 2 is fancy but not tall.

\sphinxAtStartPar
We call each of these descriptions an \sphinxstyleemphasis{interpretation} of the predicate symbols \(\mathit{fancy}\) and \(\mathit{tall}\) in the domain \({\mathbb N}\). Formally, an interpretation of a unary predicate \(P\) in a domain \(D\) is the set of elements of \(D\) for which \(P\) is true. For an example, the standard interpretation of \(\mathit{prime}\) in \({\mathbb N}\) that we used above was just the set of prime natural numbers.

\sphinxAtStartPar
We can interpret constant, function, and relation symbols in a similar way. An interpretation of constant symbol \(c\) in domain \(D\) is an element of \(D\). An interpretation of a function symbol \(f\) with arity \(n\) is a function that maps \(n\) elements of \(D\) to another element of \(D\). An interpretation of a relation symbol \(R\) with arity \(n\) is the set of \(n\) tuples of elements of \(D\) for which \(R\) is true.

\sphinxAtStartPar
It is important to emphasize the difference between a syntactic predicate symbol (or function symbol, or constant symbol) and the semantic predicate (or function, or object) to which it is interpreted. The former is a symbol, relates to other symbols, and has no meaning on its own until we specify an interpretation. Strictly speaking, it makes no sense to write \(\mathit{prime}(3)\), where \(\mathit{prime}\) is a predicate symbol and 3 is a natural number, since the argument to \(\mathit{prime}\) is supposed to be a syntactic term. Sometimes we may obscure this distinction, as above when we specified a language with constant symbols 0, 1, and 2. But there is still a fundamental distinction between the objects of the domain and the symbols we use to represent them.

\sphinxAtStartPar
Sometimes, when we interpret a language in a particular domain, it is useful to implicitly introduce new constant symbols into the language to denote elements of this domain. Specifically, for each element \(a\) of the domain, we introduce a constant symbol \(\bar a\), which is interpreted as \(a\). Then the expression \(\mathit{prime}(\bar 3)\) does make sense. Interpreting the predicate symbol \(\mathit{prime}\) in the natural way, this expression will evaluate to true. We think of \(\bar 3\) as a linguistic “name” that represents the natural number 3, in the same way that the phrase “Aristotle” is a name that represents the ancient Greek philosopher.


\section{Truth in a Model}
\label{\detokenize{semantics_of_first_order_logic:truth-in-a-model}}
\sphinxAtStartPar
Fix a first\sphinxhyphen{}order language. Suppose we have chosen a domain \(D\) in which to interpret the language, along with an interpretation in \(D\) of each of the symbols of that language. We will call this structure—the domain \(D\), paired with the interpretation—a \sphinxstyleemphasis{model} for the language. A model for a first\sphinxhyphen{}order language is directly analogous to a truth assignment for propositional logic, because it provides all the information we need to determine the truth value of each sentence in the language.

\sphinxAtStartPar
The procedure for evaluating the truth of a sentence based on a model works the way you think it should, but the formal description is subtle. Recall the difference between \sphinxstyleemphasis{terms} and \sphinxstyleemphasis{assertions} that we made earlier in Chapter 4. Terms, like \(a\), \(x + y\), or \(f(c)\), are meant to represent objects. A term does not have a truth value, since (for example) it makes no sense to ask whether 3 is true or false. Assertions, like \(P(a)\), \(R(x, f(y))\), or \(a + b > a \wedge \mathit{prime}(c)\), apply predicate or relation symbols to terms to produce statements that could be true or false.

\sphinxAtStartPar
The interpretation of a term in a model is an element of the domain of that model. The model directly specifies how to interpret constant symbols. To interpret a term \(f(t)\) created by applying a function symbol to another term, we interpret the term \(t\), and then apply the interpretation of \(f\) to this term. (This process makes sense, since the interpretation of \(f\) is a function on the domain.) This generalizes to functions of higher arity in the obvious way. We will not yet interpret terms that include free variables like \(x\) and \(y\), since these terms do not pick out unique elements of the domain. (The variable \(x\) could potentially refer to any object.)

\sphinxAtStartPar
For example, suppose we have a language with two constant symbols, \(a\) and \(b\), a unary function symbol \(f\), and a binary function symbol \(g\). Let \({\mathcal M}\) be the model with domain \({\mathbb N}\), where \(a\) and \(b\) are interpreted as \(3\) and \(5\), respectively, \(f(x)\) is interpreted as the function which maps any natural number \(n\) to \(n^2\), and \(g\) is the addition function. Then the term \(g(f(a),b)\) denotes the natural number \(3^2+5 = 14\).

\sphinxAtStartPar
Similarly, the interpretation of an assertion is a value \(\mathbf{T}\) or \(\mathbf{F}\). For the sake of brevity, we will introduce new notation here: if \(A\) is an assertion and \({\mathcal M}\) is a model of the language of \(A\), we write \({\mathcal M} \models A\) to mean that \(A\) evaluates to \(\mathbf{T}\) in \({\mathcal M}\), and \({\mathcal M} \not\models A\) to mean that \(A\) evaluates to \(\mathbf{F}\). (You can read the symbol \(\models\) as “models” or “satisfies” or “validates.”)

\sphinxAtStartPar
To interpret a predicate or relation applied to some terms, we first interpret the terms as objects in the domain, and then see if the interpretation of the relation symbol is true of those objects. To continue with the example, suppose our language also has a relation symbol \(\mathit{R}\), and we extend \({\mathcal M}\) to interpret \(R\) as the greater\sphinxhyphen{}than\sphinxhyphen{}or\sphinxhyphen{}equal\sphinxhyphen{}to relation. Then we have \({\mathcal M} \not \models R(a, b)\), since 3 is not greater than 5, but \({\mathcal M} \models R(g(f(a),b),b)\), since 14 is greater than 5.

\sphinxAtStartPar
Interpreting expressions using the logical connectives \(\wedge\), \(\vee\), \(\to\), and \(\neg\) works exactly as it did in the propositional setting. \({\mathcal M} \models A \wedge B\) exactly when \({\mathcal M} \models A\) and \({\mathcal M} \models B\), and so on.

\sphinxAtStartPar
We still need to explain how to interpret existential and universal expressions. We saw that \(\exists x \; A\) intuitively meant that there was \sphinxstyleemphasis{some} element of the domain that would make \(A\) true, when we “replaced” the variable \(x\) with that element. To make this a bit more precise, we say that \({\mathcal M} \models \exists x A\) exactly when there is an element \(a\) in the domain of \({\mathcal M}\) such that, when we interpret \(x\) as \(a\), then \({\mathcal M} \models A\). To continue the example above, we have \({\mathcal M} \models \exists x \; (R(x, b))\), since when we interpret \(x\) as 6 we have \({\mathcal M} \models R(x, b)\).

\sphinxAtStartPar
More concisely, we can say that \({\mathcal M} \models \exists x \; A\) when there is an \(a\) in the domain of \({\mathcal M}\) such that \({\mathcal M} \models A[\bar a / x]\). The notation \(A[\bar a / x]\) indicates that every occurrence of \(x\) in \(A\) has been replaced by the symbol \(\bar a\).

\sphinxAtStartPar
Finally, remember, \(\forall x \; A\) means that \(A\) is true for all possible values of \(x\). We make this precise by saying that \({\mathcal M} \models \forall x \; A\) exactly when for every element \(a\) in the domain of \({\mathcal M}\), interpreting \(x\) as \(a\) gives that \({\mathcal M} \models A\). Alternatively, we can say that \({\mathcal M} \models \forall x \; A\) when for every \(a\) in the domain of \({\mathcal M}\), we have \({\mathcal M} \models A[\bar a / x]\). In our example above, \({\mathcal M} \not\models \forall x \; (R(x, b))\), since when we interpret \(x\) as 2 we do not have \({\mathcal M} \models R(x, b)\).

\sphinxAtStartPar
These rules allow us to determine the truth value of any \sphinxstyleemphasis{sentence} in a model. (Remember, a sentence is a formula with no free variables.) There are some subtleties: for instance, we’ve implicitly assumed that our formula doesn’t quantify over the same variable twice, as in \(\forall x \; \exists x \; A\). But for the most part, the interpretation process tells us to “read” a formula as talking directly about objects in the domain.


\section{Examples}
\label{\detokenize{semantics_of_first_order_logic:examples}}
\sphinxAtStartPar
Take a simple language with no constant symbols, one relation symbol \(\leq\), and one binary function symbol \(+\). Our model \({\mathcal M}\) will have domain \({\mathbb N}\), and the symbols will be interpreted as the standard less\sphinxhyphen{}than\sphinxhyphen{}or\sphinxhyphen{}equal\sphinxhyphen{}to relation and addition function.

\sphinxAtStartPar
Think about the following questions before you read the answers below. Remember, our domain is \({\mathbb N}\), not \({\mathbb Z}\) or any other number system.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Is it true that \({\mathcal M} \models \exists x \; (x \leq x)\)? What about \({\mathcal M} \models \forall x \; (x \leq x)\)?

\item {} 
\sphinxAtStartPar
Similarly, what about \({\mathcal M} \models \exists x \; (x + x \leq x)\)? \({\mathcal M} \models \forall x \; (x + x \leq x)\)?

\item {} 
\sphinxAtStartPar
Do the sentences \(\exists x \; \forall y \; (x \leq y)\) and \(\forall x \; \exists y \; (x \leq y)\) mean the same thing? Are they true or false?

\item {} 
\sphinxAtStartPar
Can you think of a formula \(A\) in this language, with one free variable \(x\), such that \({\mathcal M} \models \forall x \; A\) but \({\mathcal M} \not \models \exists x \; A\)?

\end{enumerate}

\sphinxAtStartPar
These questions indicate a subtle, and often tricky, interplay between the universal and existential quantifiers. Once you’ve thought about them a bit, read the answers:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Both of these statements are true. For the former, we can (for example) interpret \(x\) as the natural number 0. Then, \({\mathcal M} \models x \leq x\), so the existential is true. For the latter, pick an arbitrary natural number \(n\); it is still the case that when we interpret \(x\) as \(n\), we have \({\mathcal M} \models x \leq x\).

\item {} 
\sphinxAtStartPar
The first statement is true, since we can interpret \(x\) as 0. The second statement, though, is false. When we interpret \(x\) as 1 (or, in fact, as any natural number besides 0), we see that \({\mathcal M} \not \models x + x \leq x\).

\item {} 
\sphinxAtStartPar
These sentences do \sphinxstyleemphasis{not} mean the same thing, although in the specified model, both are true. The first expresses that some natural number is less than or equal to every natural number. This is true: 0 is less than or equal to every natural number. The second sentence says that for every natural number, there is another natural number at least as big. Again, this is true: every natural number \(a\) is less than or equal to \(a\). If we took our domain to be \({\mathbb Z}\) instead of \({\mathbb N}\), the first sentence would be false, while the second would still be true.

\item {} 
\sphinxAtStartPar
The situation described here is impossible in our model. If \({\mathcal M} \models \forall x A\), then \({\mathcal M} \models A [\bar 0 / x]\), which implies that \({\mathcal M} \models \exists x A\). The only time this situation can happen is when the domain of our model is empty.

\end{enumerate}

\sphinxAtStartPar
Now consider a different language with constant symbol 2, predicate symbols \(\mathit{prime}\) and \(\mathit{odd}\), and binary relation \(<\), interpreted in the natural way over domain \({\mathbb N}\). The sentence \(\forall x \; (2 < x \wedge \mathit{prime}(x) \to \mathit{odd}(x))\) expresses the fact that every prime number bigger than 2 is odd. It is an example of \sphinxstyleemphasis{relativization}, discussed in \hyperref[\detokenize{first_order_logic:relativization-and-sorts}]{Section \ref{\detokenize{first_order_logic:relativization-and-sorts}}}. We can now see semantically how relativization works. This sentence is true in our model if, for every natural number \(n\), interpreting \(x\) as \(n\) makes the sentence true. If we interpret \(x\) as 0, 1, or 2, or as any non\sphinxhyphen{}prime number, the hypothesis of the implication is false, and thus \(2 < x \wedge \mathit{prime}(x) \to \mathit{odd}(x)\) is true. Otherwise, if we interpret \(x\) as a prime number bigger than 2, both the hypothesis and conclusion of the implication are true, and \(2 < x \wedge \mathit{prime}(x) \to \mathit{odd}(x)\) is again true. Thus the universal statement holds. It was an example like this that partially motivated our semantics for implication back in Chapter 3; any other choice would make relativization impossible.

\sphinxAtStartPar
For the next example, we will consider models that are given by a rectangular grid of “dots.” Each dot has a color (red, blue, or green) and a size (small or large). We use the letter \(R\) to represent a large red dot and \(r\) to represent a small red dot, and similarly for \(G, g, B, b\).

\sphinxAtStartPar
The logical language we use to describe our dot world has predicates \(\mathit{red}\), \(\mathit{green}\), \(\mathit{blue}\), \(\mathit{small}\) and \(\mathit{large}\), which are interpreted in the obvious ways. The relation \(\mathit{adj}(x, y)\) is true if the dots referred to by \(x\) and \(y\) are touching, not on a diagonal. The relations \(\mathit{same{\mathord{\mbox{-}}}color}(x, y)\), \(\mathit{same{\mathord{\mbox{-}}}size}(x, y)\), \(\mathit{same{\mathord{\mbox{-}}}row}(x, y)\), and \(\mathit{same{\mathord{\mbox{-}}}column}(x, y)\) are also self\sphinxhyphen{}explanatory. The relation \(\mathit{left{\mathord{\mbox{-}}}of}(x, y)\) is true if the dot referred to by \(x\) is left of the dot referred to by \(y\), regardless of what rows the dots are in. The interpretations of \(\mathit{right{\mathord{\mbox{-}}}of}\), \(\mathit{above}\), and \(\mathit{below}\) are similar.

\sphinxAtStartPar
Consider the following sentences:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{green}(x) \vee \mathit{blue}(x))\)

\item {} 
\sphinxAtStartPar
\(\exists x, y \;  (\mathit{adj}(x, y) \wedge \mathit{green}(x) \wedge \mathit{green}(y))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; ((\exists z \; \mathit{right{\mathord{\mbox{-}}}of}(z, x)) \wedge (\forall y \; (\mathit{left{\mathord{\mbox{-}}}of}(x, y) \to \mathit{blue}(y) \vee \mathit{small}(y))))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{large}(x) \to \exists y \; (\mathit{small}(y) \wedge \mathit{adj}(x, y)))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{green}(x) \to \exists y \; (\mathit{same{\mathord{\mbox{-}}}row}(x, y) \wedge \mathit{blue}(y)))\)

\item {} 
\sphinxAtStartPar
\(\forall x, y \; (\mathit{same{\mathord{\mbox{-}}}row}(x, y) \wedge \mathit{same{\mathord{\mbox{-}}}column}(x, y) \to x = y)\)

\item {} 
\sphinxAtStartPar
\(\exists x \; \forall y \; (\mathit{adj}(x, y) \to \neg \mathit{same{\mathord{\mbox{-}}}size}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; \exists y \; (\mathit{adj}(x, y) \wedge \mathit{same{\mathord{\mbox{-}}}color}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\exists y \; \forall x \; (\mathit{adj}(x, y) \wedge \mathit{same{\mathord{\mbox{-}}}color}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (\mathit{blue}(x) \wedge \exists y \; (\mathit{green}(y) \wedge \mathit{above}(x, y)))\)

\end{enumerate}

\sphinxAtStartPar
We can evaluate them in this particular model:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline

\sphinxAtStartPar
R
&
\sphinxAtStartPar
r
&
\sphinxAtStartPar
g
&
\sphinxAtStartPar
b
\\
\hline
\sphinxAtStartPar
R
&
\sphinxAtStartPar
b
&
\sphinxAtStartPar
G
&
\sphinxAtStartPar
b
\\
\hline
\sphinxAtStartPar
B
&
\sphinxAtStartPar
B
&
\sphinxAtStartPar
B
&
\sphinxAtStartPar
b
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
There they have the following truth values:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
false

\item {} 
\sphinxAtStartPar
true

\item {} 
\sphinxAtStartPar
true

\item {} 
\sphinxAtStartPar
false

\item {} 
\sphinxAtStartPar
true

\item {} 
\sphinxAtStartPar
true

\item {} 
\sphinxAtStartPar
false

\item {} 
\sphinxAtStartPar
true

\item {} 
\sphinxAtStartPar
false

\item {} 
\sphinxAtStartPar
true

\end{enumerate}

\sphinxAtStartPar
For each sentence, see if you can find a model that makes the sentence true, and another that makes it false. For an extra challenge, try to make all of the sentences true simultaneously. Notice that you can use any number of rows and any number of columns.


\section{Validity and Logical Consequence}
\label{\detokenize{semantics_of_first_order_logic:validity-and-logical-consequence}}
\sphinxAtStartPar
We have seen that whether a formula is true or false often depends on the model we choose. Some formulas, though, are true in every possible model. An example we saw earlier was \(\forall y \; (\mathit{le}(0, y) \to \mathit{le}(0, y))\). Why is this sentence valid? Suppose \({\mathcal M}\) is an arbitrary model of the language, and suppose \(a\) is an arbitrary element of the domain of \({\mathcal M}\). Either \({\mathcal M} \models \mathit{le}(0, \bar a)\) or \({\mathcal M} \models \neg \mathit{le}(0, \bar a)\). In either case, the propositional semantics of implication guarantee that \({\mathcal M} \models \mathit{le}(0, \bar a) \to \mathit{le}(0, \bar a)\). We often write \(\models A\) to mean that \(A\) is valid.

\sphinxAtStartPar
In the propositional setting, there is an easy method to figure out if a formula is a tautology or not. Writing the truth table and checking for any rows ending with \(\mathbf{F}\) is algorithmic, and we know from the beginning exactly how large the truth table will be. Unfortunately, we cannot do the same for first\sphinxhyphen{}order formulas. Any language has infinitely many models, so a “first\sphinxhyphen{}order” truth table would be infinitely long. To make matters worse, even checking whether a formula is true in a single model can be a non\sphinxhyphen{}algorithmic task. To decide whether a universal statement like \(\forall x \; P(x)\) is true in a model with an infinite domain, we might have to check whether \(P\) is true of infinitely many elements.

\sphinxAtStartPar
This is not to say that we can \sphinxstyleemphasis{never} figure out if a first\sphinxhyphen{}order sentence is a tautology. For example, we have argued that \(\forall y \; (\mathit{lt}(0, y) \to \mathit{lt}(0, y))\) was one. It is just a more difficult question than for propositional logic.

\sphinxAtStartPar
As was the case with propositional logic, we can extend the notion of validity to a notion of logical consequence. Fix a first\sphinxhyphen{}order language, \(L\). Suppose \(\Gamma\) is a set of sentences in \(L\), and \(A\) is a sentence of \(L\). We will say that \(A\) \sphinxstyleemphasis{is a logical consequence of} \(\Gamma\) if every model of \(\Gamma\) is a model of \(A\). This is one way of spelling out that \(A\) is a “necessary consequence” of \(A\): under any interpretation, if the hypotheses in \(\Gamma\) come out true, \(A\) is true as well.


\section{Soundness and Completeness}
\label{\detokenize{semantics_of_first_order_logic:soundness-and-completeness}}
\sphinxAtStartPar
In propositional logic, we saw a close connection between the provable formulas and the tautologies—specifically, a formula is provable if and only if it is a tautology. More generally, we say that a formula \(A\) is a logical consequence of a set of hypotheses, \(\Gamma\), if and only if there is a natural deduction proof of \(A\) from \(\Gamma\). It turns out that the analogous statements hold for first order logic.

\sphinxAtStartPar
The “soundness” direction—the fact that if \(A\) is provable from \(\Gamma\) then \(A\) is true in any model of \(\Gamma\)—holds for reasons that are similar to the reasons it holds in the propositional case. Specifically, the proof proceeds by showing that each rule of natural deduction preserves the truth in a model.

\sphinxAtStartPar
The completeness theorem for first order logic was first proved by Kurt Gödel in his 1929 dissertation. Another, simpler proof was later provided by Leon Henkin.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If a formula \(A\) is a logical consequence of a set of sentences \(\Gamma\), then \(A\) is provable from \(\Gamma\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Compared to the version for propositional logic, the first order completeness theorem is harder to prove. We will not go into too much detail here, but will indicate some of the main ideas. A set of sentences is said to be \sphinxstyleemphasis{consistent} if you cannot prove a contradiction from those hypotheses. Most of the work in Henkin’s proof is done by the following “model existence” theorem:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every consistent set of sentences has a model.


\bigskip\hrule\bigskip


\sphinxAtStartPar
From this theorem, it is easy to deduce the completeness theorem. Suppose there is no proof of \(A\) from \(\Gamma\). Then the set \(\Gamma \cup \{ \neg A \}\) is consistent. (If we could prove \(\bot\) from \(\Gamma \cup \{ \neg A \}\), then by the \sphinxstyleemphasis{reductio ad absurdum} rule we could prove \(A\) from \(\Gamma\).) By the model existence theorem, that means that there is a model \({\mathcal M}\) of \(\Gamma \cup \{ \neg A \}\). But this is a model of \(\Gamma\) that is not a model of \(A\), which means that \(A\) is not a logical consequence of \(\Gamma\).

\sphinxAtStartPar
The proof of the model existence theorem is intricate. Somehow, from a consistent set of sentences, one has to build a model. The strategy is to build the model out of syntactic entities, in other words, to use terms in an expanded language as the elements of the domain.

\sphinxAtStartPar
The moral here is much the same as it was for propositional logic. Because we have developed our syntactic rules with a certain semantics in mind, the two exhibit different sides of the same coin: the provable sentences are exactly the ones that are true in all models, and the sentences that are provable from a set of hypotheses are exactly the ones that are true in all models of those hypotheses.

\sphinxAtStartPar
We therefore have another way to answer the question posed in the previous section. To show that a sentence is valid, there is no need to check its truth in every possible model. Rather, it suffices to produce a proof.


\section{Exercises}
\label{\detokenize{semantics_of_first_order_logic:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
In a first\sphinxhyphen{}order language with a binary relation, \(R(x,y)\), consider the following sentences:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; \forall y \; R(x, y)\)

\item {} 
\sphinxAtStartPar
\(\exists y \; \forall x \; R(x, y)\)

\item {} 
\sphinxAtStartPar
\(\forall x,y \; (R(x,y) \wedge x \neq y \to \exists z \; (R(x,z) \wedge R(z,y) \wedge x \neq z \wedge y \neq z))\)

\end{itemize}

\sphinxAtStartPar
For each of the following structures, determine whether of each of
those sentences is true or false.
\begin{itemize}
\item {} 
\sphinxAtStartPar
the structure \((\mathbb N, \leq)\), that is, the interpretation in the natural numbers where \(R\) is \(\leq\)

\item {} 
\sphinxAtStartPar
the structure \((\mathbb Z, \leq)\)

\item {} 
\sphinxAtStartPar
the structure \((\mathbb Q, \leq)\)

\item {} 
\sphinxAtStartPar
the structure \((\mathbb N, \mid)\), that is, the interpretation in the natural numbers where \(R\) is the “divides” relation

\item {} 
\sphinxAtStartPar
the structure \((P(\mathbb N), \subseteq)\), that is, the interpretation where variables range over sets of natural numbers,
where \(R\) is interpreted as the subset relation.

\end{itemize}

\item {} 
\sphinxAtStartPar
Create a 4 x 4 “dots” world that makes all of the following sentences
true:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{green}(x) \vee \mathit{blue}(x))\)

\item {} 
\sphinxAtStartPar
\(\exists x, y \; (\mathit{adj}(x, y) \wedge \mathit{green}(x) \wedge \mathit{green}(y))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (\exists z \; \mathit{right{\mathord{\mbox{-}}}of}(z, x) \wedge \forall y \; (\mathit{left{\mathord{\mbox{-}}}of}(x, y) \to \mathit{blue}(y) \vee \mathit{small}(y)))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{large}(x) \to \exists y \; (\mathit{small}(y) \wedge \mathit{adj}(x, y)))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (\mathit{green}(x) \to \exists y \; (\mathit{same{\mathord{\mbox{-}}}row}(x, y) \wedge \mathit{blue}(y)))\)

\item {} 
\sphinxAtStartPar
\(\forall x, y \; (\mathit{same{\mathord{\mbox{-}}}row}(x, y) \wedge \mathit{same\mathord{\mbox{-}} column}(x, y) \to x = y)\)

\item {} 
\sphinxAtStartPar
\(\exists x \; \forall y \; (\mathit{adj}(x, y) \to \neg \mathit{same{\mathord{\mbox{-}}}size}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; \exists y \; (\mathit{adj}(x, y) \wedge \mathit{same{\mathord{\mbox{-}}}color}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\exists y \; \forall x \; (\mathit{adj}(x, y) \to \mathit{same{\mathord{\mbox{-}}}color}(x, y))\)

\item {} 
\sphinxAtStartPar
\(\exists x \; (\mathit{blue}(x) \wedge \exists y \; (\mathit{green}(y) \wedge \mathit{above}(x, y)))\)

\end{itemize}

\item {} 
\sphinxAtStartPar
Fix a first\sphinxhyphen{}order language \(L\), and let \(A\) and \(B\) be any two sentences in \(L\). Remember that \(\vDash A\) means that \(A\) is valid. Unpacking the definitions, show that if \(\vDash A \wedge B\), then \(\vDash A\) and \(\vDash B\).

\item {} 
\sphinxAtStartPar
Give a concrete example to show that \(\vDash A \vee B\) does not necessarily imply \(\vDash A\) or \(\vDash B\). In other words, pick a language \(L\) and choose particular sentences \(A\) and \(B\) such that \(A \vee B\) is valid but neither \(A\) nor \(B\) is valid.

\item {} 
\sphinxAtStartPar
Consider the three formulas \(\forall x \; R(x, x)\), \(\forall x\; \forall y \; (R (x, y) \to R (y, x))\), and \(\forall x \; \forall y \; \forall z \; (R(x, y) \wedge R(y, z) \to R(x, z))\).
These sentences say that \(R\) is reflexive, symmetric, and trainsitive.
For each pair of sentences, find a model that makes those two sentences true and the third false.
This shows that these sentences are logically independent: no one is entailed by the others.

\item {} 
\sphinxAtStartPar
Show that if a set of formulas \(\{\psi_1, \ldots, \psi_n\}\) is semantically inconsistent, then it entails every formula \(\phi\).
Does the converse also hold?

\item {} 
\sphinxAtStartPar
Give a formula \(\psi\) such that the set \(\{P(c), \neg P(D), \psi \}\) is consistent, and so is the set \(\{P(c), \neg P(D), \neg \psi \}\).

\item {} 
\sphinxAtStartPar
For each the following formulas, show whether the formula is valid, satisfiable, or unsatisfiable.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; \forall y \; R (y, x) \wedge R (x, y)\)

\item {} 
\sphinxAtStartPar
\((\exists x \; \forall y \; R (x, y)) \to (\exists x \; \exists y \; R (x, y))\)

\item {} 
\sphinxAtStartPar
\((\exists x\; P (x)) \wedge (\exists x \; \neg P(x))\)

\end{itemize}

\end{enumerate}


\chapter{Sets}
\label{\detokenize{sets:sets}}\label{\detokenize{sets:id1}}\label{\detokenize{sets::doc}}
\sphinxAtStartPar
We have come to a turning point in this textbook. We will henceforth abandon natural deduction, for the most part, and focus on ordinary mathematical proofs. We will continue to think about how informal mathematics can be represented in symbolic terms, and how the rules of natural deduction play out in the informal setting. But the emphasis will be on writing ordinary mathematical arguments, not designing proof trees. Lean will continue to serve as a bridge between the informal and formal realms.

\sphinxAtStartPar
In this chapter, we consider a notion that has come to play a fundamental role in mathematical reasoning, namely, that of a “set.”


\section{Elementary Set Theory}
\label{\detokenize{sets:elementary-set-theory}}\label{\detokenize{sets:id2}}
\sphinxAtStartPar
In a publication in the journal \sphinxstyleemphasis{Mathematische Annalen} in 1895, the German mathematician Georg Cantor presented the following
characterization of the notion of a \sphinxstyleemphasis{set} (or \sphinxstyleemphasis{Menge}, in his terminology):
\begin{quote}

\sphinxAtStartPar
By a \sphinxstyleemphasis{set} we mean any collection M of determinate, distinct objects (called the \sphinxstyleemphasis{elements} of M) of our intuition or thought into a whole.
\end{quote}

\sphinxAtStartPar
Since then, the notion of a set has been used to unify a wide range of abstractions and constructions. Axiomatic set theory, which we will discuss in a later chapter, provides a foundation for mathematics in which everything can be viewed as a set.

\sphinxAtStartPar
On a broad construal, \sphinxstyleemphasis{any} collection can be a set; for example, we can consider the set whose elements are Ringo Star, the number 7, and the set whose only member is the Empire State Building. With such a broad notion of set we have to be careful: Russell’s paradox has us consider the set \(S\) of all sets that are not elements of themselves, which leads to a contradiction when we ask whether \(S\) is an element of itself. (Try it!) The axioms of set theory tell us which sets exist, and have been carefully designed to avoid paradoxical sets like that of the Russell paradox.

\sphinxAtStartPar
In practice, mathematicians are not so freewheeling in their use of sets. Typically, one fixes a domain such as the natural numbers, and consider subsets of that domain. In other words, we consider sets of numbers, sets of points, sets of lines, and so on, rather than arbitrary “sets.” In this text, we will adopt this convention: when we talk about sets, we are always implicitly talking about sets of elements of some domain.

\sphinxAtStartPar
Given a set \(A\) of objects in some domain and an object \(x\), we write \(x \in A\) to say that \(x\) is an element of \(A\). Cantor’s characterization suggests that whenever we have some property, \(P\), of a domain, we can form the set of elements that have that property. This is denoted using “set\sphinxhyphen{}builder notation” as \(\{ x \mid P(x) \}\). For example, we can consider all the following sets of natural numbers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\{n \mid \mbox{$n$ is even} \}\)

\item {} 
\sphinxAtStartPar
\(\{n \mid \mbox{$n$ is prime} \}\)

\item {} 
\sphinxAtStartPar
\(\{n \mid \mbox{$n$ is prime and greater than 2} \}\)

\item {} 
\sphinxAtStartPar
\(\{n \mid \mbox{$n$ can be written as a sum of squares} \}\)

\item {} 
\sphinxAtStartPar
\(\{n \mid \mbox{$n$ is equal to 1, 2, or 3}\}\)

\end{itemize}

\sphinxAtStartPar
This last set is written more simply \(\{1, 2, 3\}\). If the domain is not clear from the context, we can specify it by writing it explicitly, for example, in the expression \(\{n \in \mathbb{N} \mid \text{$n$ is even} \}\).

\sphinxAtStartPar
Using set\sphinxhyphen{}builder notation, we can define a number of common sets and operations. The \sphinxstyleemphasis{empty set}, \(\emptyset\), is the set with no elements:
\begin{equation*}
\begin{split}\emptyset = \{ x \mid \mbox{false} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
Dually, we can define the \sphinxstyleemphasis{universal set}, \(\mathcal U\), to be the set consisting of every element of the domain:
\begin{equation*}
\begin{split}\mathcal U = \{ x \mid \mbox{true} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
Given two sets \(A\) and \(B\), we define their \sphinxstyleemphasis{union} to be the set of elements in either one:
\begin{equation*}
\begin{split}A \cup B = \{ x \mid \mbox{$x \in A$ or $x \in B$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
And we define their \sphinxstyleemphasis{intersection} to be the set of elements of both:
\begin{equation*}
\begin{split}A \cap B = \{ x \mid \mbox{$x \in A$ and $x \in B$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
We define the \sphinxstyleemphasis{complement} of a set of \(A\) to be the set of elements that are not in \(A\):
\begin{equation*}
\begin{split}\overline A = \{ x \mid \mbox{$x \notin A$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
We define the \sphinxstyleemphasis{set difference} of two sets \(A\) and \(B\) to be the set of elements in \(A\) but not \(B\):
\begin{equation*}
\begin{split}A \setminus B = \{ x \mid \mbox{$x \in A$ and $x \notin B$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
Two sets are said to be equal if they have exactly the same elements. If \(A\) and \(B\) are sets, \(A\) is said to be a \sphinxstyleemphasis{subset} of \(B\), written \(A \subseteq B\), if every element of \(A\) is an element of \(B\). Notice that \(A\) is equal to \(B\) if and only if \(A\) is a subset of \(B\) and \(B\) is a subset of \(A\).

\sphinxAtStartPar
Notice also that everything we have said about sets so far is readily representable in symbolic logic. We can render the defining properties of the basic sets and constructors as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in \emptyset \leftrightarrow \bot)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in \mathcal U \leftrightarrow \top)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in A \cup B \leftrightarrow x \in A \vee x \in B)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in A \cap B \leftrightarrow x \in A \wedge x \in B)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in \overline A \leftrightarrow x \notin A)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in A \setminus B \leftrightarrow  x \in A \wedge x \notin B)\)

\end{itemize}

\sphinxAtStartPar
The assertion that \(A\) is a subset of \(B\) can be written \(\forall x \; (x \in A \to x \in B)\), and the assertion that \(A\) is equal to \(B\) can be written \(\forall x \; (x \in A \leftrightarrow  x \in B)\). These are all \sphinxstyleemphasis{universal} statements, that is, statements with universal quantifiers in front, followed by basic assertions and propositional connectives. What this means is that reasoning about sets formally often amounts to using nothing more than the rules for the universal quantifier together with the rules for propositional logic.

\sphinxAtStartPar
Logicians sometimes describe ordinary mathematical proofs as \sphinxstyleemphasis{informal}, in contrast to the \sphinxstyleemphasis{formal proofs} in natural deduction. When writing informal proofs, the focus is on readability. Here is an example.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\), \(B\), and \(C\) denote sets of elements of some domain. Then \(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(x\) be arbitrary, and suppose \(x\) is in \(A \cap (B \cup C)\). Then \(x\) is in \(A\), and either \(x\) is in \(B\) or \(x\) is in \(C\). In the first case, \(x\) is in \(A\) and \(B\), and hence in \(A \cap B\). In the second case, \(x\) is in \(A\) and \(C\), and hence \(A \cap C\). Either way, we have that \(x\) is in \((A \cap B) \cup (A \cap C)\).

\sphinxAtStartPar
Conversely, suppose \(x\) is in \((A \cap B) \cup (A \cap C)\). There are now two cases.

\sphinxAtStartPar
First, suppose \(x\) is in \(A \cap B\). Then \(x\) is in both \(A\) and \(B\). Since \(x\) is in \(B\), it is also in \(B \cup C\), and so \(x\) is in \(A \cap (B \cup C)\).

\sphinxAtStartPar
The second case is similar: suppose \(x\) is in \(A \cap C\). Then \(x\) is in both \(A\) and \(C\), and so also in \(B \cup C\). Hence, in this case also, \(x\) is in \(A \cap (B \cup C)\), as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that this proof does not look anything like a proof in symbolic logic. For one thing, ordinary proofs tend to favor words over symbols. Of course, mathematics uses symbols all the time, but not in place of words like “and” and “not”; you will rarely, if ever, see the symbols \(\wedge\) and \(\neg\) in a mathematics textbook, unless it is a textbook specifically about logic.

\sphinxAtStartPar
Similarly, the structure of an informal proof is conveyed with ordinary paragraphs and punctuation. Don’t rely on pictorial diagrams, line breaks, and indentation to convey the structure of a proof. Rather, you should rely on literary devices like signposting and foreshadowing. It is often helpful to present an outline of a proof or the key ideas before delving into the details, and the introductory sentence of a paragraph can help guide a reader’s expectations, just as it does in an expository essay.

\sphinxAtStartPar
Nonetheless, you should be able to see elements of natural deduction implicitly in the proof above. In formal terms, the theorem is equivalent to the assertion
\begin{equation*}
\begin{split}\forall x \; (x \in A \cap (B \cup C) \leftrightarrow  x \in (A \cap B) \cup (A \cap C)),\end{split}
\end{equation*}
\sphinxAtStartPar
and the proof proceeds accordingly. The phrase “let \(x\) be arbitrary” is code for the \(\forall\) introduction rule, and the form of the rest of the proof is a \(\leftrightarrow\) introduction. Saying that \(x\) is in \(A \cap (B \cup C)\) is implicitly an “and,” and the argument uses \(\wedge\) elimination to get \(x \in A\) and \(x \in B \cup C\). Saying \(x \in B \cup C\) is implicitly an “or,” and the proof then splits on cases, depending on whether \(x \in B\) or \(x \in C\).

\sphinxAtStartPar
Modulo the unfolding of definition of intersection and union in terms of “and” and “or,” the “only if” direction of the previous proof could be represented in natural deduction like this:



\begin{prooftree}
\small
\AXM{y \in A \cap (B \cup C)}
\UIM{y \in B \cup C}

\AXM{y \in A \cap (B \cup C)}
\UIM{y \in A}
\AXM{}
\RLM{1}
\UIM{y \in B}
\BIM{y \in A \cap B}
\UIM{y \in (A \cap B) \cup (A \cap C)}

\AXM{y \in A \cap (B \cup C)}
\UIM{y \in A}
\AXM{}
\RLM{1}
\UIM{y \in C}
\BIM{y \in A \cap C}
\UIM{y \in (A \cap B) \cup (A \cap C)}
\RLM{1}
\TIM{y \in (A \cap B) \cup (A \cap C)}
\end{prooftree}

\sphinxAtStartPar
In the next chapter, we will see that this logical structure is made manifest in Lean. But writing long proofs in natural deduction is not the most effective to communicate the mathematical ideas. So our goal here is to teach you to think in terms of natural deduction rules, but express the steps in ordinary English.

\sphinxAtStartPar
Here is another example.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} \((A \setminus B) \setminus C = A \setminus (B \cup C)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(x\) be arbitrary, and suppose \(x\) is in \((A \setminus B) \setminus C\). Then \(x\) is in \(A \setminus B\) but not \(C\), and hence it is in \(A\) but not in \(B\) or \(C\). This means that \(x\) is in \(A\) but not \(B \cup C\), and so in \(A \setminus (B \cup C)\).

\sphinxAtStartPar
Conversely, suppose \(x\) is in \(A \setminus (B \cup C)\). Then \(x\) is in \(A\), but not in \(B \cup C\). In particular, \(x\) is in neither \(B\) nor \(C\), because otherwise it would be in \(B \cup C\). So \(x\) is in \(A \setminus B\), and hence in \((A \setminus B) \setminus C\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Perhaps the biggest difference between informal proofs and formal proofs is the level of detail. Informal proofs will often skip over details that are taken to be “straightforward” or “obvious,” devoting more effort to spelling out inferences that are novel or unexpected.

\sphinxAtStartPar
Writing a good proof is like writing a good essay. To convince your readers that the conclusion is correct, you have to get them to understand the argument, without overwhelming them with unnecessary details. It helps to have a specific audience in mind. Try speaking the argument aloud to friends, roommates, and family members; if their eyes glaze over, it is unreasonable to expect anonymous readers to do better.

\sphinxAtStartPar
One of the best ways to learn to write good proofs is to \sphinxstyleemphasis{read} good proofs, and pay attention to the style of writing. Pick an example of a textbook that you find especially clear and engaging, and think about what makes it so.

\sphinxAtStartPar
Natural deduction and formal verification can help you understand the components that make a proof \sphinxstyleemphasis{correct}, but you will have to develop an intuitive feel for what makes a proof easy and enjoyable to read.


\section{Calculations with Sets}
\label{\detokenize{sets:calculations-with-sets}}
\sphinxAtStartPar
Calculation is a central to mathematics, and mathematical proofs often involve carrying out a sequence of calculations. Indeed, a calculation can be viewed as a proof in and of itself that two expressions describe the same entity.

\sphinxAtStartPar
In high school algebra, students are often asked to prove identities like the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} \(\frac{n(n+1)}{2} + (n + 1) = \frac{(n+1)(n+2)}{2}\), for every natural number \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
In some places, students are asked to write proofs like this:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof.}
\begin{equation*}
\begin{split}\frac{n(n+1)}{2} + (n + 1) & =? \frac{(n+1)(n+2)}{2} \\
\frac{n^2+n}{2} + \frac{2n + 2}{2} & =? \frac{n^2 + 3n + 2}{2} \\
\frac{n^2+n + 2n + 2}{2} & =? \frac{n^2 + 3n + 2}{2} \\
\frac{n^2+3n + 2}{2} & = \frac{n^2 + 3n + 2}{2}. \\\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
Mathematicians generally cringe when they see this. \sphinxstyleemphasis{Don’t do it!} It looks like an instance of forward reasoning, where we start with a complex identity and end up proving \(x = x\). Of course, what is really meant is that each line follows from the next. There is a way of expressing this, with the phrase “it suffices to show.” The following presentation comes closer to mathematical vernacular:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof.} We want to show
\begin{equation*}
\begin{split}\frac{n(n+1)}{2} + (n + 1) = \frac{(n+1)(n+2)}{2}.\end{split}
\end{equation*}
\sphinxAtStartPar
To do that, it suffices to show
\begin{equation*}
\begin{split}\frac{n^2+n}{2} + \frac{2n + 2}{2} = \frac{n^2 + 3n + 2}{2}.\end{split}
\end{equation*}
\sphinxAtStartPar
For that, it suffices to show
\begin{equation*}
\begin{split}\frac{n^2+n + 2n + 2}{2} = \frac{n^2 + 3n + 2}{2}.\end{split}
\end{equation*}
\sphinxAtStartPar
But this last equation is clearly true.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The narrative doesn’t flow well, however. Sometimes there are good reasons to work backward in a proof, but in this case it is easy to present the proof in a more forward\sphinxhyphen{}directed manner. Here is one example:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof.} Calculating on the left\sphinxhyphen{}hand side, we have
\begin{equation*}
\begin{split}\frac{n(n+1)}{2} + (n + 1) & = \frac{n^2+n}{2} + \frac{2n + 2}{2} \\
  & = \frac{n^2+n + 2n + 2}{2} \\
  & = \frac{n^2 + 3n + 2}{2}.\end{split}
\end{equation*}
\sphinxAtStartPar
On the right\sphinxhyphen{}hand side, we also have
\begin{equation*}
\begin{split}\frac{(n+1)(n+2)}{2} = \frac{n^2 + 3n + 2}{2}.\end{split}
\end{equation*}
\sphinxAtStartPar
So \(\frac{n(n+1)}{2} + (n + 1) = \frac{n^2 + 3n + 2}{2}\), as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Mathematicians often use the abbreviations “LHS” and “RHS” for “left\sphinxhyphen{}hand side” and “right\sphinxhyphen{}hand side,” respectively, in situations like this. In fact, here we can easily write the proof as a single forward\sphinxhyphen{}directed calculation:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof.}
\begin{equation*}
\begin{split}\frac{n(n+1)}{2} + (n + 1) & = \frac{n^2+n}{2} + \frac{2n + 2}{2} \\
  & = \frac{n^2+n + 2n + 2}{2} \\
  & = \frac{n^2 + 3n + 2}{2} \\
  & = \frac{(n+1)(n+2)}{2}.\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
Such a proof is clear, compact, and easy to read. The main challenge to the reader is to figure out what justifies each subsequent step. Mathematicians sometimes annotate such a calculation with additional information, or add a few words of explanation in the text before and/or after. But the ideal situation is to carry out the calculation in small enough steps so that each step is straightforward, and needs no explanation. (And, once again, what counts as “straightforward” will vary depending on who is reading the proof.)

\sphinxAtStartPar
We have said that two sets are equal if they have the same elements. In the previous section, we proved that two sets are equal by reasoning about the elements of each, but we can often be more efficient. Assuming \(A\), \(B\), and \(C\) are subsets of some domain \(\mathcal U\), the following identities hold:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \cup \overline A = \mathcal U\)

\item {} 
\sphinxAtStartPar
\(A \cap \overline A = \emptyset\)

\item {} 
\sphinxAtStartPar
\(\overline {\overline A} = A\)

\item {} 
\sphinxAtStartPar
\(A \cup A = A\)

\item {} 
\sphinxAtStartPar
\(A \cap A = A\)

\item {} 
\sphinxAtStartPar
\(A \cup \emptyset = A\)

\item {} 
\sphinxAtStartPar
\(A \cap \emptyset = \emptyset\)

\item {} 
\sphinxAtStartPar
\(A \cup \mathcal U = \mathcal U\)

\item {} 
\sphinxAtStartPar
\(A \cap \mathcal U = A\)

\item {} 
\sphinxAtStartPar
\(A \cup B = B \cup A\)

\item {} 
\sphinxAtStartPar
\(A \cap B = B \cap A\)

\item {} 
\sphinxAtStartPar
\((A \cup B) \cup C = A \cup (B \cup C)\)

\item {} 
\sphinxAtStartPar
\((A \cap B) \cap C = A \cap (B \cap C)\)

\item {} 
\sphinxAtStartPar
\(\overline{A \cap B} = \overline A \cup \overline B\)

\item {} 
\sphinxAtStartPar
\(\overline{A \cup B} = \overline A \cap \overline B\)

\item {} 
\sphinxAtStartPar
\(A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\)

\item {} 
\sphinxAtStartPar
\(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\)

\item {} 
\sphinxAtStartPar
\(A \cap (A \cup B) = A\)

\item {} 
\sphinxAtStartPar
\(A \cup (A \cap B) = A\)

\end{itemize}

\sphinxAtStartPar
This allows us to prove further identities by calculating. Here is an example.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem}. Let \(A\) and \(B\) be subsets of some domain \(\mathcal U\). Then \((A \cap \overline B) \cup B = A \cup B\).

\sphinxAtStartPar
\sphinxstylestrong{Proof}.
\begin{equation*}
\begin{split}(A \cap \overline B) \cup B & = (A \cup B) \cap (\overline B \cup B)
\\
& = (A \cup B) \cap \mathcal U \\
& = A \cup B.\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
Here is another example.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem}. Let \(A\) and \(B\) be subsets of some domain \(\mathcal U\). Then \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof}.
\begin{equation*}
\begin{split}(A \setminus B) \cup (B \setminus A) & = (A \cap \overline B) \cup (B \cap \overline A) \\
& = ((A \cap \overline B) \cup B) \cap ((A \cap \overline B) \cup \overline A) \\
& = ((A \cup B) \cap (\overline B \cup B)) \cap ((A \cup \overline A) \cap (\overline B \cup \overline A)) \\
& = ((A \cup B) \cap \mathcal U) \cap (\mathcal U \cap \overline{B \cap A}) \\
& = (A \cup B) \cap (\overline{A \cap B}) \\
& = (A \cup B) \setminus (A \cap B).\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
Classically, you may have noticed that propositions, under logical equivalence, satisfy identities similar to sets. That is no coincidence; both are instances of \sphinxstyleemphasis{boolean algebras}. Here are the identities above translated to the language of a boolean algebra:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \vee \neg A = \top\)

\item {} 
\sphinxAtStartPar
\(A \wedge \neg A = \bot\)

\item {} 
\sphinxAtStartPar
\(\neg \neg A = A\)

\item {} 
\sphinxAtStartPar
\(A \vee A = A\)

\item {} 
\sphinxAtStartPar
\(A \wedge A = A\)

\item {} 
\sphinxAtStartPar
\(A \vee \bot = A\)

\item {} 
\sphinxAtStartPar
\(A \wedge \bot = \bot\)

\item {} 
\sphinxAtStartPar
\(A \vee \top = \top\)

\item {} 
\sphinxAtStartPar
\(A \wedge \top = A\)

\item {} 
\sphinxAtStartPar
\(A \vee B = B \vee A\)

\item {} 
\sphinxAtStartPar
\(A \wedge B = B \wedge A\)

\item {} 
\sphinxAtStartPar
\((A \vee B) \vee C = A \vee (B \vee C)\)

\item {} 
\sphinxAtStartPar
\((A \wedge B) \wedge C = A \wedge (B \wedge C)\)

\item {} 
\sphinxAtStartPar
\(\neg(A \wedge B) = \neg A \vee \neg B\)

\item {} 
\sphinxAtStartPar
\(\neg(A \vee B) = \neg A \wedge \neg B\)

\item {} 
\sphinxAtStartPar
\(A \wedge (B \vee C) = (A \wedge B) \vee (A \wedge C)\)

\item {} 
\sphinxAtStartPar
\(A \vee (B \wedge C) = (A \vee B) \wedge (A \vee C)\)

\item {} 
\sphinxAtStartPar
\(A \wedge (A \vee B) = A\)

\item {} 
\sphinxAtStartPar
\(A \vee (A \wedge B) = A\)

\end{itemize}

\sphinxAtStartPar
Translated to the language of boolean algebras, the first theorem above is as follows:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) and \(B\) be elements of a boolean algebra. Then \((A \wedge \neg B) \vee B = B\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.}
\begin{equation*}
\begin{split}(A \wedge \neg B) \vee B & = (A \vee B) \wedge (\neg B \vee B)
\\
& = (A \vee B) \wedge \top \\
& = (A \vee B).\end{split}
\end{equation*}

\bigskip\hrule\bigskip



\section{Indexed Families of Sets}
\label{\detokenize{sets:indexed-families-of-sets}}
\sphinxAtStartPar
If \(I\) is a set, we will sometimes wish to consider a \sphinxstyleemphasis{family} \((A_i)_{i \in I}\) of sets indexed by elements of \(I\). For example, we might be interested in a sequence
\begin{equation*}
\begin{split}A_0, A_1, A_2, \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
of sets indexed by the natural numbers. The concept is best illustrated by some examples.
\begin{itemize}
\item {} 
\sphinxAtStartPar
For each natural number \(n\), we can define the set \(A_n\) to be the set of people alive today that are of age \(n\). For each age we have the corresponding set. Someone of age 20 is an element of the set \(A_{20}\), while a newborn baby is an element of \(A_0\). The set \(A_{200}\) is empty. This family \((A_n)_{n\in\mathbb{N}}\) is a is a family of sets indexed by the natural numbers.

\item {} 
\sphinxAtStartPar
For every real number \(r\) we can define \(B_r\) to be the set of positive real numbers larger than \(r\), so \(B_r = \{x\in \mathbb{R} \mid x > r \text{ and } x > 0\}\). Then \((B_r)_{r\in\mathbb{R}}\) is a family of sets indexed by the real numbers.

\item {} 
\sphinxAtStartPar
For every natural number \(n\) we can define \(C_n=\{k\in\mathbb{N} \mid k \text{ is a divisor of } n\}\) as the set of divisors of \(n\).

\end{itemize}

\sphinxAtStartPar
Given a family \((A_i)_{i\in I}\) of sets indexed by \(I\), we can form its \sphinxstyleemphasis{union}:
\begin{equation*}
\begin{split}\bigcup_{i \in I} A_i = \{ x \mid x \in A_i \text{ for some $i \in I$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
We can also form the \sphinxstyleemphasis{intersection} of a family of sets:
\begin{equation*}
\begin{split}\bigcap_{i \in I} A_i = \{ x \mid x \in A_i \text{ for every $i \in I$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
So an element \(x\) is in \(\bigcup_{i \in I} A_i\) if and only if \(x\) is in \(A_i\) for \sphinxstyleemphasis{some} \(i\) in \(I\), and \(x\) is in \(\bigcap_{i \in I} A_i\) if and only if \(x\) is in \(A_i\) for every \(i\) in \(I\). These operations are represented in symbolic logic by the existential and the universal quantifiers. We have:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in \bigcup_{i \in I} A_i \leftrightarrow \exists i \in I \; (x \in A_i))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \in \bigcap_{i \in I} A_i \leftrightarrow \forall i \in I \; (x \in A_i))\)

\end{itemize}

\sphinxAtStartPar
Returning to the examples above, we can compute the union and intersection of each family. For the first example, \(\bigcup_{n \in \mathbb{N}} A_n\) is the set of all living people, and \(\bigcap_{n \in \mathbb{N}} A_n = \emptyset\). Also, \(\bigcup_{r \in \mathbb{R}} B_r = \mathbb{R}_{>0}\), the set of all positive real numbers, and \(\bigcap_{r \in \mathbb{R}} B_r = \emptyset\). For the last example, we have \(\bigcup_{n \in \mathbb{N}} C_n = \mathbb{N}\) and \(\bigcap_{n \in \mathbb{N}} C_n = \{1\}\), since 1 is a divisor of every natural number.

\sphinxAtStartPar
Suppose that \(I\) contains just two elements, say \(I=\{c, d\}\). Let \((A_i)_{i\in I}\) be a family of sets indexed by \(I\). Because \(I\) has two elements, this family consists of just the two sets \(A_c\) and \(A_d\). Then the union and intersection of this family are just the union and intersection of the two sets:
\begin{equation*}
\begin{split}\bigcup_{i \in I} A_i &= A_c \cup A_d\\
\bigcap_{i \in I} A_i &= A_c \cap A_d.\end{split}
\end{equation*}
\sphinxAtStartPar
This means that the union and intersection of two sets are just a special case of the union and intersection of a family of sets.

\sphinxAtStartPar
We also have equalities for unions and intersections of families of sets. Here are a few of them:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \cap \bigcup_{i \in I} B_i = \bigcup_{i \in I} (A \cap B_i)\)

\item {} 
\sphinxAtStartPar
\(A \cup \bigcap_{i \in I} B_i = \bigcap_{i \in I} (A \cup B_i)\)

\item {} 
\sphinxAtStartPar
\(\overline{\bigcap_{i \in I} A_i} = \bigcup_{i \in I} \overline{A_i}\)

\item {} 
\sphinxAtStartPar
\(\overline{\bigcup_{i \in I} A_i} = \bigcap_{i \in I} \overline{A_i}\)

\item {} 
\sphinxAtStartPar
\(\bigcup_{i \in I} \bigcup_{j \in J} A_{i,j} = \bigcup_{j \in J} \bigcup_{i \in I} A_{i,j}\)

\item {} 
\sphinxAtStartPar
\(\bigcap_{i \in I} \bigcap_{j \in J} A_{i,j} = \bigcap_{j \in J} \bigcap_{i \in I} A_{i,j}\)

\end{itemize}

\sphinxAtStartPar
In the last two lines, \(A_{i,j}\) is indexed by two sets \(I\) and \(J\). This means that for every \(i \in I\) and \(j\in J\) we have a set \(A_{i,j}\). For the first four equalities, try to figure out what the rule means if the index set \(I\) contains two elements.

\sphinxAtStartPar
Let’s prove the first identity. Notice how the logical forms of the assertions \(x \in A \cap \bigcup_{i \in I} B_i\) and \(x \in \bigcup_{i \in I} (A \cap B_i)\) dictate the structure of the proof.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) be any subset of some domain \(U\), and let \((B_i)_{i \in I}\) be a family of subsets of \(U\) indexed by \(I\). Then
\begin{equation*}
\begin{split}A \cap \bigcup_{i \in I} B_i = \bigcup_{i \in I} (A \cap B_i).\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(x\) is in \(A \cap \bigcup_{i \in I} B_i\). Then \(x\) is in \(A\) and \(x\) is in \(B_j\) for some \(j \in I\). So \(x\) is in \(A \cap B_j\), and hence in \(\bigcup_{i \in I} (A \cap B_i)\).

\sphinxAtStartPar
Conversely, suppose \(x\) is in \(\bigcup_{i \in I} (A \cap B_i)\). Then, for some \(j\) in \(I\), \(x\) is in \(A \cap B_j\). Hence \(x\) is in \(A\), and since \(x\) is in \(B_j\), it is in \(\bigcup_{i \in I} B_i\). Hence \(x\) is in \(A \cap \bigcup_{i \in I} B_i\), as required.


\bigskip\hrule\bigskip



\section{Cartesian Product and Power Set}
\label{\detokenize{sets:cartesian-product-and-power-set}}\label{\detokenize{sets:id3}}
\sphinxAtStartPar
The \sphinxstyleemphasis{ordered pair} of two objects \(a\) and \(b\) is denoted \((a, b)\). We say that \(a\) is the \sphinxstyleemphasis{first component} and \(b\) is the \sphinxstyleemphasis{second component} of the pair. Two pairs are only equal if the first component are equal and the second components are equal. In symbols, \((a, b) = (c, d)\) if and only if \(a = c\) and \(b = d\).

\sphinxAtStartPar
Given two sets \(A\) and \(B\), we define the \sphinxstyleemphasis{cartesian product} \(A \times B\) of these two sets as the set of all pairs where the first component is an element in \(A\) and the second component is an element in \(B\). In set\sphinxhyphen{}builder notation this means
\begin{equation*}
\begin{split}A \times B = \{(a, b) \; \mid a \; \in A \text{ and } b \in B\}.\end{split}
\end{equation*}
\sphinxAtStartPar
Note that if \(A\) and \(B\) are subsets of a particular domain \(\mathcal U\), the set \(A \times B\) need not be a subset of the same domain. However, it will be a subset of \(\mathcal U \times \mathcal U\).

\sphinxAtStartPar
Some axiomatic foundations take the notion of a pair to be primitive. In axiomatic set theory, it is common to \sphinxstyleemphasis{define} an ordered pair to be a particular set, namely
\begin{equation*}
\begin{split}(a, b) = \{\{a\}, \{a, b\}\}.\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that if \(a = b\), this set has only one element:
\begin{equation*}
\begin{split}(a, a) = \{\{a\},\{a, a\}\} = \{\{a\},\{a\}\} = \{\{a\}\}.\end{split}
\end{equation*}
\sphinxAtStartPar
The following theorem shows that this definition is reasonable.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Using the definition of ordered pairs above, we have \((a, b) = (c, d)\) if and only if \(a = c\) and \(b = d\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} If \(a = c\) and \(b = d\) then clearly \((a, b) = (c, d)\). For the other direction, suppose that \((a, b) = (c, d)\), which means
\begin{equation*}
\begin{split}\underbrace{\{\{a\}, \{a, b\}\}}_L = \underbrace{\{\{c\}, \{c, d\}\}}_R.\end{split}
\end{equation*}
\sphinxAtStartPar
Suppose first that \(a = b\). Then \(L = \{\{a\}\}\). This means that \(\{c\} = \{a\}\) and \(\{c, d\} = \{a\}\), from which we conclude that \(c = a\) and \(d = a = b\).

\sphinxAtStartPar
Now suppose that \(a \neq b\). If \(\{c\} = \{a, b\}\) then we conclude that \(a\) and \(b\) are both equal to \(c\), contradicting \(a \neq b\). Since \(\{c\}\in L\), \(\{c\}\) must be equal to \(\{a\}\), which means that \(a = c\). We know that \(\{a, b\} \in R\), and since we know \(\{a, b\}\neq \{c\}\), we conclude \(\{a, b\} = \{c, d\}\). This means that \(b \in\{c, d\}\), since \(b \neq a = c\), we conclude that \(b = d\).

\sphinxAtStartPar
Hence in both cases we conclude that \(a = c\) and \(b = d\), proving the theorem.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Using ordered pairs we can define the \sphinxstyleemphasis{ordered triple} \((a, b, c)\) to be \((a, (b, c))\). Then we can prove that \((a, b, c) = (d, e, f)\) if and only if \(a = d\), \(b = e\) and \(c = f\), which you are asked to do in the exercises. We can also define ordered \(n\)\sphinxhyphen{}tuples, which are sequence of \(n\) objects, in a similar way.

\sphinxAtStartPar
Given a set \(A\) we can define the \sphinxstyleemphasis{power set} \(\mathcal P(A)\) to be the set of all subsets of \(A\). In set\sphinxhyphen{}builder notation we can write this as
\begin{equation*}
\begin{split}\mathcal P(A) = \{B \mid B \subseteq A\}.\end{split}
\end{equation*}
\sphinxAtStartPar
If \(A\) is a subset of \(\mathcal U\), \(\mathcal P(A)\) may not be a subset of \(\mathcal U\), but it is always a subset of \(\mathcal P(\mathcal U)\).


\section{Exercises}
\label{\detokenize{sets:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Prove the following theorem: Let \(A\), \(B\), and \(C\) be sets of elements of some domain. Then \(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\). (Henceforth, if we don’t specify natural deduction or Lean, ``prove’’ and ``show’’ mean give an ordinary mathematical proof, using ordinary mathematical language rather than symbolic logic.)

\item {} 
\sphinxAtStartPar
Prove the following theorem: Let \(A\) and \(B\) be sets of elements of some domain. Then \(\overline{A \setminus B} = \overline{A} \cup B\).

\item {} 
\sphinxAtStartPar
Two sets \(A\) and \(B\) are said to be \sphinxstyleemphasis{disjoint} if they have no element in common. Show that if \(A\) and \(B\) are disjoint, \(C \subseteq A\), and \(D \subseteq B\), then \(C\) and \(D\) are disjoint.

\item {} 
\sphinxAtStartPar
Let \(A\) and \(B\) be sets. Show \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\), by showing that both sides have the same elements.

\item {} 
\sphinxAtStartPar
Let \(A\), \(B\), and \(C\) be subsets of some domain \(\mathcal U\). Give a calculational proof of the identity \(A \setminus (B \cup C) = (A \setminus B) \setminus C\), using the identities above. Also use the fact that, in general, \(C \setminus D = C \cap \overline D\).

\item {} 
\sphinxAtStartPar
Similarly, give a calculational proof of \((A \setminus B) \cup (A \cap B) = A\).

\item {} 
\sphinxAtStartPar
Give calculational proofs of the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \setminus B = A \setminus (A \cap B)\)

\item {} 
\sphinxAtStartPar
\(A \setminus B = (A \cup B) \setminus B\)

\item {} 
\sphinxAtStartPar
\((A \cap B) \setminus C = (A \setminus C) \cap B\)

\end{itemize}

\item {} 
\sphinxAtStartPar
Prove that if \((A_{i,j})_{i \in I, j \in J}\) is a family indexed by two sets \(I\) and \(J\), then
\begin{equation*}
\begin{split}\bigcup_{i \in I}\bigcap_{j \in J} A_{i, j} \subseteq \bigcap_{j \in J}\bigcup_{i \in I} A_{i, j}.\end{split}
\end{equation*}
\sphinxAtStartPar
Also, find a family \((A_{i,j})_{i \in I, j \in J}\) where the reverse inclusion does not hold.

\item {} 
\sphinxAtStartPar
Prove using calculational reasoning that
\begin{equation*}
\begin{split}\left(\bigcup_{i \in I}A_i\right)\cap \left(\bigcup_{j \in J}B_j\right) = \bigcup_{\substack{i \in I \\ j \in J}}(A_i \cap B_j).\end{split}
\end{equation*}
\sphinxAtStartPar
The notation \(\bigcup_{\substack{i \in I \\ j \in J}}(A_i \cap B_j)\) means \(\bigcup_{i \in I} \bigcup_{j \in J}(A_i \cap B_j)\).

\item {} 
\sphinxAtStartPar
Using the definition \((a, b, c) = (a, (b, c))\), show that \((a, b, c) = (d, e, f)\) if and only if \(a = d\), \(b = e\) and \(c = f\).

\item {} 
\sphinxAtStartPar
Prove that \(A \times (B \cup C) = (A \times B) \cup (A \times C)\)

\item {} 
\sphinxAtStartPar
Prove that \((A \cap B) \times (C \cap D) = (A \times C) \cap (B \times D)\). Find an expression for \((A \cup B) \times (C \cup D)\) consisting of unions of cartesian products, and prove that your expression is correct.

\item {} 
\sphinxAtStartPar
Prove that that \(A \subseteq B\) if and only if \(\mathcal P(A) \subseteq \mathcal P(B)\).

\end{enumerate}


\chapter{Sets in Lean}
\label{\detokenize{sets_in_lean:sets-in-lean}}\label{\detokenize{sets_in_lean::doc}}
\sphinxAtStartPar
In the last chapter, we noted that although in axiomatic set theory one considers sets of disparate objects, it is more common in mathematics to consider subsets of some fixed domain, \(\mathcal U\). This is the way sets are handled in Lean. For any data type \sphinxcode{\sphinxupquote{U}}, Lean gives us a new data type, \sphinxcode{\sphinxupquote{Set U}}, consisting of the sets of elements of \sphinxcode{\sphinxupquote{U}}. Thus, for example, we can reason about sets of natural numbers, or sets of integers, or sets of pairs of natural numbers.


\section{Basics}
\label{\detokenize{sets_in_lean:basics}}\label{\detokenize{sets_in_lean:sets-in-lean-basics}}
\sphinxAtStartPar
Given \sphinxcode{\sphinxupquote{A : Set U}} and \sphinxcode{\sphinxupquote{x : U}}, we can write \sphinxcode{\sphinxupquote{x ∈ A}} to state that \sphinxcode{\sphinxupquote{x}} is a member of the set \sphinxcode{\sphinxupquote{A}}. The character \sphinxcode{\sphinxupquote{∈}} can be typed using \sphinxcode{\sphinxupquote{\textbackslash{}in}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Basic}
\PYG{k+kn}{open} \PYG{n}{Set}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
\PYG{k}{\PYGZsh{}check} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}
\PYG{k}{\PYGZsh{}check} \PYG{n}{B} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{C}
\PYG{k}{\PYGZsh{}check} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n}{A}
\PYG{k}{\PYGZsh{}check} \PYG{n}{C}\PYG{n+nb+bp}{ᶜ}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{⊆} \PYG{n}{A}
\PYG{k}{\PYGZsh{}check} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{univ}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can type the symbols \sphinxcode{\sphinxupquote{⊆}}, \sphinxcode{\sphinxupquote{∅}}, \sphinxcode{\sphinxupquote{∪}}, \sphinxcode{\sphinxupquote{∩}}, \sphinxcode{\sphinxupquote{\textbackslash{}}} as \sphinxcode{\sphinxupquote{\textbackslash{}subeq}}
\sphinxcode{\sphinxupquote{\textbackslash{}empty}}, \sphinxcode{\sphinxupquote{\textbackslash{}un}}, \sphinxcode{\sphinxupquote{\textbackslash{}i}}, and \sphinxcode{\sphinxupquote{\textbackslash{}\textbackslash{}}}, respectively.
We have made the type variable \sphinxcode{\sphinxupquote{U}} implicit,
because it can typically be inferred from context.
The universal set is denoted \sphinxcode{\sphinxupquote{univ}},
and set complementation is denoted with the superscripted letter “c,”
which you can enter as \sphinxcode{\sphinxupquote{\textbackslash{}\textasciicircum{}c}} or \sphinxcode{\sphinxupquote{\textbackslash{}compl}}.
Basic set\sphinxhyphen{}theoretic notions like these are defined in Lean’s core library,
but additional theorems and notation are available in an auxiliary library that
we have loaded with the command \sphinxcode{\sphinxupquote{import Mathlib.Data.Set.Basic}},
which has to appear at the beginning of a file.
The command \sphinxcode{\sphinxupquote{open Set}} lets us refer to a theorem named
\sphinxcode{\sphinxupquote{Set.mem\_union}} as \sphinxcode{\sphinxupquote{mem\_union}}.

\sphinxAtStartPar
The following patterns can be used to show that \sphinxcode{\sphinxupquote{A}} is a subset of \sphinxcode{\sphinxupquote{B}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{k}{from} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{n}{x}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
The slogan is \sphinxcode{\sphinxupquote{A ⊆ B}} is the same as \sphinxcode{\sphinxupquote{∀ x, x ∈ A → x ∈ B}}.
For Lean this is true \sphinxstyleemphasis{by definition},
which is why the terms and tactics above are very familiar.

\sphinxAtStartPar
The following patterns can be used to show that \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{B}} are equal:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{=} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{eq\PYGZus{}of\PYGZus{}subset\PYGZus{}of\PYGZus{}subset}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
    \PYG{k}{fun} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
    \PYG{k}{fun} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The slogan is \sphinxcode{\sphinxupquote{A = B}} is the same as \sphinxcode{\sphinxupquote{A ⊆ B ∧ B ⊆ A}} is the same
as \sphinxcode{\sphinxupquote{∀ x, x ∈ A ↔ x ∈ B}}.
Hence, we can use the following alternatives:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} term mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{=} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{ext} \PYG{o}{(}\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦} \PYG{n}{Iff.intro}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{↦}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{g+gr}{sorry}\PYG{o}{)}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} tactic mode}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{=} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{x}
  \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↔} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
  \PYG{n}{apply} \PYG{n}{Iff.intro}
  \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
    \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
    \PYG{g+gr}{sorry}
  \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
    \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{)}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
    \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, \sphinxcode{\sphinxupquote{ext}} is short for “extensionality.”
In term mode, \sphinxcode{\sphinxupquote{Set.ext}} is the following fact:
\begin{equation*}
\begin{split}\forall x \; (x \in A \leftrightarrow x \in B) \to A = B.\end{split}
\end{equation*}
\sphinxAtStartPar
This reduces proving \(A = B\) to proving \(\forall x \; (x \in A \leftrightarrow x \in B)\), which we can do using \(\forall\) and \(\leftrightarrow\) introduction.
Then, the tactic \sphinxcode{\sphinxupquote{ext}} is the instruction to apply \sphinxcode{\sphinxupquote{Set.ext}} if possible.
We write \sphinxcode{\sphinxupquote{ext x}} to specify the variable name we want to use.

\sphinxAtStartPar
Lean supports the following nifty feature: the defining rules for union,
intersection and other operations on sets are considered to hold “definitionally.”
This means that the expressions \sphinxcode{\sphinxupquote{x ∈ A ∩ B}} and \sphinxcode{\sphinxupquote{x ∈ A ∧ x ∈ B}}
mean the same thing to Lean.
This is the same for the other constructions on sets;
for example \sphinxcode{\sphinxupquote{x ∈ A \textbackslash{} B}} and \sphinxcode{\sphinxupquote{x ∈ A ∧ ¬ (x ∈ B)}}
mean the same thing to Lean.
You can also write \sphinxcode{\sphinxupquote{x ∉ B}} for \sphinxcode{\sphinxupquote{¬ (x ∈ B)}},
where \sphinxcode{\sphinxupquote{∉}} is written using \sphinxcode{\sphinxupquote{\textbackslash{}notin}}.
The following example illustrates these features.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{k}{from} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{›}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{›}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{⊆} \PYG{n}{A}  \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{n}{False.elim} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n+nb+bp}{∅} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}\PYG{o}{›}
\end{sphinxVerbatim}

\sphinxAtStartPar
Remember from \hyperref[\detokenize{propositional_logic_in_lean:definitions-and-theorems}]{Section \ref{\detokenize{propositional_logic_in_lean:definitions-and-theorems}}} that we can use \sphinxcode{\sphinxupquote{assume}}
without a label, and refer back to hypotheses using French quotes,
entered with \sphinxcode{\sphinxupquote{\textbackslash{}f<}} and \sphinxcode{\sphinxupquote{\textbackslash{}f>}}.
We have used this feature in the previous example.
Without that feature, we could have written the examples above as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{hA} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{hB} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{k}{from} \PYG{n}{And.intro} \PYG{n}{hA} \PYG{n}{hB}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{⊆} \PYG{n}{A}  \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{n}{False.elim} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
From now on,
we will begin to use \sphinxcode{\sphinxupquote{fun}} and \sphinxcode{\sphinxupquote{have}} command without labels,
but you should feel free to adopt whatever style you prefer.

\sphinxAtStartPar
Notice also that in the last example,
we had to annotate the empty set by writing \sphinxcode{\sphinxupquote{(∅ : Set U)}}
to tell Lean which empty set we mean.
Lean can often infer information like this from the context
(for example, from the fact that we are trying to show \sphinxcode{\sphinxupquote{x ∈ A}},
where \sphinxcode{\sphinxupquote{A}} has type \sphinxcode{\sphinxupquote{Set U}}), but in this case, it needs a bit more help.

\sphinxAtStartPar
Alternatively, we can use theorems in the Lean library that are designed specifically for use with sets:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{k}{from} \PYG{n}{mem\PYGZus{}inter} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{›}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{k}{from} \PYG{n}{mem\PYGZus{}union\PYGZus{}left} \PYG{n}{B} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{⊆} \PYG{n}{A}  \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{∅} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{n}{absurd} \PYG{n}{h} \PYG{o}{(}\PYG{n}{not\PYGZus{}mem\PYGZus{}empty} \PYG{n}{x}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Remember that \sphinxcode{\sphinxupquote{absurd}} can be used to prove any fact from two contradictory hypotheses \sphinxcode{\sphinxupquote{h1 : P}} and \sphinxcode{\sphinxupquote{h2 : ¬ P}}. Here the \sphinxcode{\sphinxupquote{not\_mem\_empty x}} is the fact \sphinxcode{\sphinxupquote{x ∉ ∅}}. You can see the statements of the theorems using the \sphinxcode{\sphinxupquote{\#check}} command in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}inter}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}of\PYGZus{}mem\PYGZus{}inter\PYGZus{}left}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}of\PYGZus{}mem\PYGZus{}inter\PYGZus{}right}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}union\PYGZus{}left}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}union\PYGZus{}right}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{mem\PYGZus{}or\PYGZus{}mem\PYGZus{}of\PYGZus{}mem\PYGZus{}union}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{not\PYGZus{}mem\PYGZus{}empty}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here, the \sphinxcode{\sphinxupquote{@}} symbol in Lean prevents it from trying to fill in implicit arguments automatically, forcing it to display the full statement of the theorem.

\sphinxAtStartPar
The fact that Lean can identify sets with their logical definitions makes it easy to prove inclusions between sets:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{n}{And.left} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∉} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ} \PYG{k}{from} \PYG{n}{this}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once again, we can use the theorems designed specifically for sets:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{k}{from} \PYG{n}{mem\PYGZus{}of\PYGZus{}mem\PYGZus{}diff} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{\PYGZbs{}} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∉} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{not\PYGZus{}mem\PYGZus{}of\PYGZus{}mem\PYGZus{}diff} \PYG{n}{h}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ} \PYG{k}{from} \PYG{n}{this}
\end{sphinxVerbatim}


\section{Some Identities}
\label{\detokenize{sets_in_lean:some-identities}}
\sphinxAtStartPar
Here is the proof of the first identity that we proved informally in the previous chapter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{x}
  \PYG{n}{apply} \PYG{n}{Iff.intro}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hx} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
    \PYG{k}{have} \PYG{n}{hA}\PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{hx.left}
    \PYG{k}{have} \PYG{n}{hBC}\PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{hx.right}
    \PYG{n}{cases} \PYG{n}{hBC} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{hB} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{o}{:=} \PYG{o}{⟨}\PYG{n}{hA}\PYG{o}{,} \PYG{n}{hB}\PYG{o}{⟩}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Or.inl}
      \PYG{n}{assumption}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{hC} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C} \PYG{o}{:=} \PYG{o}{⟨}\PYG{n}{hA}\PYG{o}{,} \PYG{n}{hC}\PYG{o}{⟩}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{Or.inr}
      \PYG{n}{assumption}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hx} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
    \PYG{n}{cases} \PYG{n}{hx} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{h} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{And.intro}
      \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
        \PYG{n}{exact} \PYG{n}{h.left}
      \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}
        \PYG{n}{apply} \PYG{n}{Or.inl}
        \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
        \PYG{n}{exact} \PYG{n}{h.right}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{h} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}
      \PYG{n}{apply} \PYG{n}{And.intro}
      \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
        \PYG{n}{exact} \PYG{n}{h.left}
      \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}
        \PYG{n}{apply} \PYG{n}{Or.inr}
        \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{C}
        \PYG{n}{exact} \PYG{n}{h.right}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that it is considerably longer than the
informal proof in the last chapter,
because we have spelled out every last detail.
Unfortunately, this does not necessarily make it more readable.
Keep in mind that you can always write long proofs incrementally,
using \sphinxcode{\sphinxupquote{sorry}}.
You can also break up long proofs into smaller pieces:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{inter\PYGZus{}union\PYGZus{}subset} \PYG{o}{\PYGZob{}}\PYG{n}{x}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
    \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hx} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{hA}\PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{o}{:=} \PYG{n}{hx.left}
  \PYG{k}{have} \PYG{n}{hBC}\PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{hx.right}
  \PYG{n}{cases} \PYG{n}{hBC} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{hB} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{o}{:=} \PYG{o}{⟨}\PYG{n}{hA}\PYG{o}{,} \PYG{n}{hB}\PYG{o}{⟩}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{Or.inl}
    \PYG{n}{assumption}
  \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{hC} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C} \PYG{o}{:=} \PYG{o}{⟨}\PYG{n}{hA}\PYG{o}{,} \PYG{n}{hC}\PYG{o}{⟩}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{Or.inr}
    \PYG{n}{assumption}

\PYG{k+kd}{theorem} \PYG{n}{inter\PYGZus{}union\PYGZus{}inter\PYGZus{}subset} \PYG{o}{\PYGZob{}}\PYG{n}{x}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
    \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hx} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{hx} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{h} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{And.intro}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
      \PYG{n}{exact} \PYG{n}{h.left}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}
      \PYG{n}{apply} \PYG{n}{Or.inl}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}
      \PYG{n}{exact} \PYG{n}{h.right}
  \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{h} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)}
    \PYG{n}{apply} \PYG{n}{And.intro}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}
      \PYG{n}{exact} \PYG{n}{h.left}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}
      \PYG{n}{apply} \PYG{n}{Or.inr}
      \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{C}
      \PYG{n}{exact} \PYG{n}{h.right}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B} \PYG{n+nb+bp}{∪} \PYG{n}{C}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{x}
  \PYG{n}{constructor}
  \PYG{n+nb+bp}{.} \PYG{n}{exact} \PYG{n}{inter\PYGZus{}union\PYGZus{}subset} \PYG{n}{A} \PYG{n}{B} \PYG{n}{C}
  \PYG{n+nb+bp}{.} \PYG{n}{exact} \PYG{n}{inter\PYGZus{}union\PYGZus{}inter\PYGZus{}subset} \PYG{n}{A} \PYG{n}{B} \PYG{n}{C}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that the two theorems depend on the variables \sphinxcode{\sphinxupquote{A}}, \sphinxcode{\sphinxupquote{B}}, and \sphinxcode{\sphinxupquote{C}}, which have to be supplied as arguments when they are applied. They also depend on the underlying type, \sphinxcode{\sphinxupquote{U}}, but because the variable \sphinxcode{\sphinxupquote{U}} was marked implicit, Lean figures it out from the context.

\sphinxAtStartPar
Notice also that instead of using \sphinxcode{\sphinxupquote{apply Iff.intro}} to convert the goal
\sphinxcode{\sphinxupquote{x ∈ A ∩ (B ∪ C) ↔ x ∈ A ∩ B ∪ A ∩ C}} into
proving each direction,
we can simply use the tactic \sphinxcode{\sphinxupquote{constructor}}.
The tactic \sphinxcode{\sphinxupquote{constructor}} also works for splitting up the goal \sphinxcode{\sphinxupquote{A ∧ B}}
and the goal \sphinxcode{\sphinxupquote{∃ x, P x}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{B} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{constructor}
\PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{A}
    \PYG{g+gr}{sorry}
\PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{B}
    \PYG{g+gr}{sorry}
\PYG{k+kd}{end}


\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{constructor}
\PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n}{P} \PYG{n}{a}
    \PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the last chapter, we showed \((A \cap \overline B) \cup B = B\).
Here is the corresponding proof in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{n+nb+bp}{=} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{calc}
  \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{B}\PYG{n+nb+bp}{ᶜ}\PYG{o}{)} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n}{B}\PYG{n+nb+bp}{ᶜ} \PYG{n+nb+bp}{∪} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{inter\PYGZus{}union\PYGZus{}distrib\PYGZus{}right}\PYG{o}{]}
             \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{n}{univ}     \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{compl\PYGZus{}union\PYGZus{}self}\PYG{o}{]}
             \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}              \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{inter\PYGZus{}univ}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Translated to propositions, the theorem above states that for every pair of elements \(A\) and \(B\) in a Boolean algebra, \((A \wedge \neg B) \vee B = B\).


\section{Indexed Families}
\label{\detokenize{sets_in_lean:indexed-families}}
\sphinxAtStartPar
Remember that if \((A_i)_{i \in I}\)
is a family of sets indexed by \(I\),
then \(\bigcap_{i \in I} A_i\) denotes the intersection of all the sets \(A_i\), and \(\bigcup_{i \in I} A_i\) denotes their union.
In Lean, we can specify that \sphinxcode{\sphinxupquote{A}} is a family of sets by writing
\sphinxcode{\sphinxupquote{A : I → Set U}} where \sphinxcode{\sphinxupquote{I}} is a \sphinxcode{\sphinxupquote{Type}}.
In other words, a family of sets is really a function which for each element
\sphinxcode{\sphinxupquote{i}} of type \sphinxcode{\sphinxupquote{I}} returns a set \sphinxcode{\sphinxupquote{A i}}.
We can then define the union and intersection as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Basic}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{def} \PYG{n}{iUnion} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U} \PYG{o}{:=} \PYG{o}{\PYGZob{}} \PYG{n}{x} \PYG{n+nb+bp}{|} \PYG{n+nb+bp}{∃} \PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{\PYGZcb{}}

\PYG{k+kd}{def} \PYG{n}{iInter} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U} \PYG{o}{:=} \PYG{o}{\PYGZob{}} \PYG{n}{x} \PYG{n+nb+bp}{|} \PYG{n+nb+bp}{∀} \PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{\PYGZcb{}}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{iUnion} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{h}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{iInter} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{h}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The examples show that Lean can unfold the definitions so that \sphinxcode{\sphinxupquote{x ∈ iInter A}} can be treated as \sphinxcode{\sphinxupquote{∀ i, x ∈ A i}} and \sphinxcode{\sphinxupquote{x ∈ iUnion A}} can be treated as \sphinxcode{\sphinxupquote{∃ i, x ∈ A i}}. To refresh your memory as to how to work with the universal and existential quantifiers in Lean, see \hyperref[\detokenize{first_order_logic_in_lean:first-order-logic-in-lean}]{Chapters \ref{\detokenize{first_order_logic_in_lean:first-order-logic-in-lean}}}. We can then define notation for the indexed union and intersection:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{notation3} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{⋃ }\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{(}\PYG{n+nb+bp}{.}\PYG{n+nb+bp}{.}\PYG{n+nb+bp}{.}\PYG{o}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{, }\PYG{l+s+s2}{\PYGZdq{}}\PYG{n}{r}\PYG{o}{:}\PYG{l+m+mi}{60}\PYG{o}{:}\PYG{o}{(}\PYG{n}{scoped} \PYG{n}{f} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{iUnion} \PYG{n}{f}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{r}

\PYG{n}{notation3} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{⋂ }\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{(}\PYG{n+nb+bp}{.}\PYG{n+nb+bp}{.}\PYG{n+nb+bp}{.}\PYG{o}{)}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{, }\PYG{l+s+s2}{\PYGZdq{}}\PYG{n}{r}\PYG{o}{:}\PYG{l+m+mi}{60}\PYG{o}{:}\PYG{o}{(}\PYG{n}{scoped} \PYG{n}{f} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{iInter} \PYG{n}{f}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{r}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{h}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
You can type \sphinxcode{\sphinxupquote{⋂}} and \sphinxcode{\sphinxupquote{⋃}} with \sphinxcode{\sphinxupquote{\textbackslash{}I}} and \sphinxcode{\sphinxupquote{\textbackslash{}Un}}, respectively. As with quantifiers, the notation \sphinxcode{\sphinxupquote{⋃ i, A i}} and \sphinxcode{\sphinxupquote{⋂ i, A i}} bind the variable \sphinxcode{\sphinxupquote{i}} in the expression, and the scope extends as widely as possible. For example, if you write \sphinxcode{\sphinxupquote{⋂ i, A i ∪ B}}, Lean assumes that the ith element of the sequence is \sphinxcode{\sphinxupquote{A i ∪ B}}. If you want to restrict the scope more narrowly, use parentheses.

\sphinxAtStartPar
The good news is that Lean’s library does define indexed union and intersection, with this notation, and the definitions are made available with \sphinxcode{\sphinxupquote{import Mathlib.Order.SetNotation}}.
The bad news is that it uses a different definition, so that \sphinxcode{\sphinxupquote{x ∈ iInter A}} and \sphinxcode{\sphinxupquote{x ∈ iUnion A}} are \sphinxstyleemphasis{not} definitionally equal to \sphinxcode{\sphinxupquote{∀ i, x ∈ A i}} and \sphinxcode{\sphinxupquote{∃ i, x ∈ A i}}, as above.
The good news is that Lean at least knows that they are equivalent,
by two lemmas called \sphinxcode{\sphinxupquote{mem\_iUnion}} and \sphinxcode{\sphinxupquote{mem\_iInter}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.SetNotation}
\PYG{k+kn}{open} \PYG{n}{Set}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{\PYGZcb{}}

\PYG{k}{\PYGZsh{}check} \PYG{n}{mem\PYGZus{}iUnion}
\PYG{k}{\PYGZsh{}check} \PYG{n}{mem\PYGZus{}iInter}

\PYG{k+kd}{theorem} \PYG{n}{exists\PYGZus{}of\PYGZus{}mem\PYGZus{}Union} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:}
    \PYG{n+nb+bp}{∃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←} \PYG{n}{mem\PYGZus{}iUnion}\PYG{o}{]}
  \PYG{n}{assumption}

\PYG{k+kd}{theorem} \PYG{n}{mem\PYGZus{}Union\PYGZus{}of\PYGZus{}exists} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:}
    \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iUnion}\PYG{o}{]}
  \PYG{n}{assumption}

\PYG{k+kd}{theorem} \PYG{n}{forall\PYGZus{}of\PYGZus{}mem\PYGZus{}Inter} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:}
    \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←} \PYG{n}{mem\PYGZus{}iInter}\PYG{o}{]}
  \PYG{n}{assumption}

\PYG{k+kd}{theorem} \PYG{n}{mem\PYGZus{}Inter\PYGZus{}of\PYGZus{}forall} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:}
    \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iInter}\PYG{o}{]}
  \PYG{n}{assumption}
\end{sphinxVerbatim}

\sphinxAtStartPar
The lemma \sphinxcode{\sphinxupquote{mem\_iUnion}} says that for any \sphinxcode{\sphinxupquote{x}} we have
\sphinxcode{\sphinxupquote{x ∈ ⋃ i, s i ↔ ∃ i, x ∈ s i}}.
Being a biconditional,
we can use \sphinxcode{\sphinxupquote{rewrite}} to substitute instances of each side of the other.

\sphinxAtStartPar
Here is an example of how these can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{x}
  \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i} \PYG{n+nb+bp}{↔} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iInter}\PYG{o}{,} \PYG{n}{mem\PYGZus{}iInter}\PYG{o}{,} \PYG{n}{mem\PYGZus{}iInter}\PYG{o}{]}
  \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{↔}
    \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)}
  \PYG{n}{constructor}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)}
    \PYG{k}{show} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}
    \PYG{n}{constructor}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}
      \PYG{n}{exact} \PYG{k}{fun} \PYG{n}{j} \PYG{n+nb+bp}{↦} \PYG{n}{And.left} \PYG{n+nb+bp}{\PYGZdl{}} \PYG{n}{h} \PYG{n}{j}
    \PYG{n+nb+bp}{.} \PYG{k}{show} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}
      \PYG{n}{exact} \PYG{k}{fun} \PYG{n}{j} \PYG{n+nb+bp}{↦} \PYG{n}{And.right} \PYG{n+nb+bp}{\PYGZdl{}} \PYG{n}{h} \PYG{n}{j}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∧} \PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)}
    \PYG{k}{show} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i}
    \PYG{n}{exact} \PYG{k}{fun} \PYG{n}{j} \PYG{n+nb+bp}{↦} \PYG{o}{⟨}\PYG{n}{h.left} \PYG{n}{j}\PYG{o}{,} \PYG{n}{h.right} \PYG{n}{j}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
We first applied extensionality.
Then we force Lean to interpret \sphinxcode{\sphinxupquote{x ∈ (⋂ i, A i) ∩ (⋂ i, B i)}}
as the definitionally equal \sphinxcode{\sphinxupquote{x ∈ (⋂ i, A i) ∧ x ∈ ⋂ i, B i}}
by writing the latter after \sphinxcode{\sphinxupquote{show}}.
Then we used repeated \sphinxcode{\sphinxupquote{rewrite}} tactics to reduce what it means
to be a member of an indexed intersection.
Then we again force Lean to interpret \sphinxcode{\sphinxupquote{x ∈ A i ∩ B i}} as
\sphinxcode{\sphinxupquote{x ∈ A i ∧ x ∈ B i}} using show.
Finally, we prove the biconditional,
which is now entirely in terms of first order logic.

\sphinxAtStartPar
Even better,
we can prove introduction and elimination rules for intersection and union:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.SetNotation}
\PYG{k+kn}{open} \PYG{n}{Set}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{theorem} \PYG{n}{Inter.intro} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iInter}\PYG{o}{]}
  \PYG{k}{show} \PYG{n+nb+bp}{∀} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}
  \PYG{n}{assumption}

\PYG{k+kd}{theorem} \PYG{n}{Inter.elim} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iInter}\PYG{o}{]} \PYG{n}{at} \PYG{n}{h}
  \PYG{n}{apply} \PYG{n}{h}

\PYG{k+kd}{theorem} \PYG{n}{Union.intro} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iUnion}\PYG{o}{]}
  \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}
  \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{i}\PYG{o}{,} \PYG{n}{h}\PYG{o}{⟩}

\PYG{k+kd}{theorem} \PYG{n}{Union.elim} \PYG{o}{\PYGZob{}}\PYG{n}{b} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{\PYGZcb{}}
\PYG{o}{(}\PYG{n}{h₁} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₂} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{→} \PYG{n}{b}\PYG{o}{)} \PYG{o}{:} \PYG{n}{b} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{mem\PYGZus{}iUnion}\PYG{o}{]} \PYG{n}{at} \PYG{n}{h₁}
  \PYG{n}{cases} \PYG{n}{h₁} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{i} \PYG{n}{hi} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{h₂} \PYG{n}{i} \PYG{n}{hi}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that here we did \sphinxcode{\sphinxupquote{rw {[}mem\_iInter{]} at h}} instructs Lean
to do the substitution along the biconditional proven by \sphinxcode{\sphinxupquote{mem\_iInter}} at
the hypothesis \sphinxcode{\sphinxupquote{h}}.
If you look at the type of \sphinxcode{\sphinxupquote{h}} before and after this tactic
you will notice the change.

\sphinxAtStartPar
We could not use \sphinxcode{\sphinxupquote{rewrite}},
and just the introduction and elimination rules:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=}
\PYG{n}{Inter.intro} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{k}{from} \PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=}
\PYG{n}{Inter.elim} \PYG{n}{h} \PYG{n}{i}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{i} \PYG{o}{:} \PYG{n}{I}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=}
\PYG{n}{Union.intro} \PYG{n}{i} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{C} \PYG{o}{:} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:} \PYG{n}{C} \PYG{o}{:=}
\PYG{n}{Union.elim} \PYG{n}{h} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{C} \PYG{k}{from} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\sphinxAtStartPar
Remember that the dollar sign saves us the trouble of having to put parentheses around the rest of the proof. Notice that with \sphinxcode{\sphinxupquote{Inter.intro}} and \sphinxcode{\sphinxupquote{Inter.elim}}, proofs using indexed intersections looks just like proofs using the universal quantifier. Similarly, \sphinxcode{\sphinxupquote{Union.intro}} and \sphinxcode{\sphinxupquote{Union.elim}} mirror the introduction and elimination rules for the existential quantifier.
The following example provides one direction of an equivalence proved above,
just using the introduction and elimination rules:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{C} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=}
  \PYG{n}{Inter.intro} \PYG{n+nb+bp}{\PYGZdl{}}
  \PYG{k}{fun} \PYG{n}{i} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{Inter.elim} \PYG{n}{h} \PYG{n}{i}
  \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{k}{from} \PYG{n}{And.left} \PYG{n}{h2}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i} \PYG{o}{:=}
    \PYG{n}{Inter.intro} \PYG{n+nb+bp}{\PYGZdl{}}
    \PYG{k}{fun} \PYG{n}{i} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{Inter.elim} \PYG{n}{h} \PYG{n}{i}
    \PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n}{i} \PYG{k}{from} \PYG{n}{And.right} \PYG{n}{h2}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{k}{from} \PYG{n}{And.intro} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
You are asked to prove the other direction in the exercises below.
Here is an example that shows how to use the introduction and elimination rules for indexed union:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{C} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{n}{Union.elim} \PYG{n}{h} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{C} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h1}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h1}
\PYG{k}{have} \PYG{n}{h4} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=} \PYG{n}{Union.intro} \PYG{n}{i} \PYG{n}{h3}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n+nb+bp}{⋃} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{k}{from} \PYG{n}{And.intro} \PYG{n}{h2} \PYG{n}{h4}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once again, we ask you to prove the other direction in the exercises below.

\sphinxAtStartPar
Sometimes we want to work with families \((A_{i, j})_{i \in I, j \in J}\)
indexed by two variables.
This is also easy to manage in Lean: if we declare \sphinxcode{\sphinxupquote{A : I → J → Set U}},
then given \sphinxcode{\sphinxupquote{i : I}} and \sphinxcode{\sphinxupquote{j : J}},
we have that \sphinxcode{\sphinxupquote{A i j : Set U}}.
(You should interpret the expression \sphinxcode{\sphinxupquote{I → J → Set U}} as
\sphinxcode{\sphinxupquote{I → (J → Set U)}},
so that \sphinxcode{\sphinxupquote{A i}} has type \sphinxcode{\sphinxupquote{J → Set U}},
and then \sphinxcode{\sphinxupquote{A i j}} has type \sphinxcode{\sphinxupquote{Set U}}.)
Here is an example of a proof involving a such a doubly\sphinxhyphen{}indexed family:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{J} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n+nb+bp}{⋂}\PYG{n}{j}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{o}{(}\PYG{n+nb+bp}{⋂}\PYG{n}{j}\PYG{o}{,} \PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{o}{:} \PYG{n}{U} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n+nb+bp}{⋂}\PYG{n}{j}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j} \PYG{n+nb+bp}{↦}
\PYG{n}{Union.elim} \PYG{n}{h} \PYG{n+nb+bp}{\PYGZdl{}}
\PYG{k}{fun} \PYG{n}{i} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂} \PYG{n}{j}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n+nb+bp}{⋂}\PYG{n}{j}\PYG{o}{,} \PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j} \PYG{k}{from}
    \PYG{n}{Inter.intro} \PYG{n+nb+bp}{\PYGZdl{}}
    \PYG{k}{fun} \PYG{n}{j} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n}{i} \PYG{n}{j} \PYG{o}{:=} \PYG{n}{Inter.elim} \PYG{n}{h1} \PYG{n}{j}
    \PYG{n}{Union.intro} \PYG{n}{i} \PYG{n}{h2}
\PYG{k+kd}{end}
\end{sphinxVerbatim}


\section{Power Sets}
\label{\detokenize{sets_in_lean:power-sets}}
\sphinxAtStartPar
We can also define the power set in Lean:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{def} \PYG{n}{powerset} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Set} \PYG{o}{(}\PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:=} \PYG{o}{\PYGZob{}}\PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U} \PYG{n+nb+bp}{|} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{A}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{∈} \PYG{n}{powerset} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
As the example shows,
\sphinxcode{\sphinxupquote{B ∈ powerset A}} is then definitionally the same as \sphinxcode{\sphinxupquote{B ⊆ A}}.

\sphinxAtStartPar
In fact, \sphinxcode{\sphinxupquote{powerset}} is defined in Lean in exactly this way,
and is available to you when you \sphinxcode{\sphinxupquote{import Mathlib.Data.Set.Basic}}
and \sphinxcode{\sphinxupquote{open Set}}.
Here is an example of how it is used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n}{powerset} \PYG{n}{A}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{∈} \PYG{n}{powerset} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{\PYGZus{}} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{k}{from} \PYG{n}{Or.inl} \PYG{o}{‹}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{›}
\end{sphinxVerbatim}

\sphinxAtStartPar
In essence, the example proves \sphinxcode{\sphinxupquote{A ⊆ A ∪ B}}.
In the exercises below, we ask you to prove,
formally, that for every \sphinxcode{\sphinxupquote{A B : Set U}},
we have \sphinxcode{\sphinxupquote{powerset A ⊆ powerset B}}


\section{Exercises}
\label{\detokenize{sets_in_lean:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}’s.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∩} \PYG{n}{C} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{o}{(}\PYG{n}{A} \PYG{n+nb+bp}{∪} \PYG{n}{B}\PYG{o}{)}\PYG{n+nb+bp}{ᶜ} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{n+nb+bp}{ᶜ} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Basic}
\PYG{k+kn}{open} \PYG{n}{Set}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{c}{/\PYGZhy{}}\PYG{c+cm}{ }\PYG{c+cm}{d}\PYG{c+cm}{e}\PYG{c+cm}{f}\PYG{c+cm}{i}\PYG{c+cm}{n}\PYG{c+cm}{i}\PYG{c+cm}{n}\PYG{c+cm}{g}\PYG{c+cm}{ }\PYG{c+cm}{\PYGZdq{}}\PYG{c+cm}{d}\PYG{c+cm}{i}\PYG{c+cm}{s}\PYG{c+cm}{j}\PYG{c+cm}{o}\PYG{c+cm}{i}\PYG{c+cm}{n}\PYG{c+cm}{t}\PYG{c+cm}{\PYGZdq{}}\PYG{c+cm}{ }\PYG{c+cm}{\PYGZhy{}/}

\PYG{k+kd}{def} \PYG{n}{disj} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=} \PYG{n+nb+bp}{∀} \PYG{o}{⦃}\PYG{n}{x}\PYG{o}{⦄}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{False}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{disj} \PYG{n}{A} \PYG{n}{B} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{And.intro} \PYG{n}{h1} \PYG{n}{h2}
\PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{n}{h} \PYG{n}{x} \PYG{n}{h3}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} notice that we do not have to mention x when applying}
\PYG{c+c1}{\PYGZhy{}\PYGZhy{}   h : disj A B}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{disj} \PYG{n}{A} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{False} \PYG{o}{:=}
\PYG{n}{h1} \PYG{n}{h2} \PYG{n}{h3}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} the same is true of ⊆}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{n}{D} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{disj} \PYG{n}{A} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{⊆} \PYG{n}{A}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{D} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{disj} \PYG{n}{C} \PYG{n}{D} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Prove the following facts about indexed unions and intersections, using the theorems \sphinxcode{\sphinxupquote{Inter.intro}}, \sphinxcode{\sphinxupquote{Inter.elim}}, \sphinxcode{\sphinxupquote{Union.intro}}, and \sphinxcode{\sphinxupquote{Union.elim}} listed above.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{I} \PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{I} \PYG{n+nb+bp}{→} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)} \PYG{o}{(}\PYG{n}{C} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{o}{(}\PYG{n+nb+bp}{⋂} \PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i} \PYG{n+nb+bp}{∩} \PYG{n}{B} \PYG{n}{i}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{o}{(}\PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n}{A} \PYG{n}{i}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{n+nb+bp}{⋃}\PYG{n}{i}\PYG{o}{,} \PYG{n}{C} \PYG{n+nb+bp}{∩} \PYG{n}{A} \PYG{n}{i} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Prove the following fact about power sets.
You can use the theorems \sphinxcode{\sphinxupquote{Subset.trans}} and \sphinxcode{\sphinxupquote{Subset.refl}}.
\begin{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{U} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{n}{C} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{U}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} For this exercise these two facts are useful}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{C}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{C} \PYG{o}{:=}
\PYG{n}{Subset.trans} \PYG{n}{h1} \PYG{n}{h2}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{A} \PYG{o}{:=}
\PYG{n}{Subset.refl} \PYG{n}{A}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n}{powerset} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{powerset} \PYG{n}{B} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{powerset} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{powerset} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{⊆} \PYG{n}{B} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}
\end{quote}

\end{enumerate}


\chapter{Relations}
\label{\detokenize{relations:relations}}\label{\detokenize{relations:id1}}\label{\detokenize{relations::doc}}
\sphinxAtStartPar
In \hyperref[\detokenize{first_order_logic:first-order-logic}]{Chapter \ref{\detokenize{first_order_logic:first-order-logic}}} we discussed the notion of a \sphinxstyleemphasis{relation symbol} in first\sphinxhyphen{}order logic, and in \hyperref[\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}]{Chapter \ref{\detokenize{semantics_of_first_order_logic:semantics-of-first-order-logic}}} we saw how to interpret such a symbol in a model. In mathematics, we are generally interested in different sorts of relationships between mathematical objects, and so the notion of a relation is ubiquitous. In this chapter, we will consider some common kinds of relations.

\sphinxAtStartPar
In some axiomatic foundations, the notion of a relation is taken to be primitive, but in axiomatic set theory, a relation is taken to be a set of tuples of the corresponding arity. For example, we can take a binary relation on \(A\) to be a subset of \(A \times A\), where \(R(a, b)\) means that \((a, b) \in R\). The foundational definition is generally irrelevant to everyday mathematical practice; what is important is simply that we can write expressions like \(R(a, b)\), and that they are true or false, depending on the values of \(a\) and \(b\). In mathematics, we often use \sphinxstyleemphasis{infix} notation, writing \(a \mathrel{R} b\) instead of \(R(a, b)\).


\section{Order Relations}
\label{\detokenize{relations:order-relations}}\label{\detokenize{relations:id2}}
\sphinxAtStartPar
We will start with a class of important binary relations in mathematics, namely, \sphinxstyleemphasis{partial orders}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A binary relation \(\leq\) on a domain \(A\) is a \sphinxstyleemphasis{partial order} if it has the following three properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{reflexivity}: \(a \leq a\), for every \(a\) in \(A\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{transitivity}: if \(a \leq b\) and \(b \leq c\), then \(a \leq c\), for every \(a\), \(b\), and \(c\) in \(A\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{antisymmetry}: if \(a \leq b\) and \(b \leq a\) then \(a = b\), for every \(a\) and \(b\) in \(A\)

\end{itemize}


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice the compact way of introducing the symbol \(\leq\) in the statement of the definition, and the fact that \(\leq\) is written as an infix symbol. Notice also that even though the relation is written with the symbol \(\leq\), it is the only symbol occurring in the definition; mathematical practice favors natural language to describe its properties.

\sphinxAtStartPar
You now know enough, however, to recognize the universal quantifiers that are present in the three clauses. In symbolic logic, we would write them as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall a \; (a \leq a)\)

\item {} 
\sphinxAtStartPar
\(\forall a, b, c \; (a \leq b \wedge b \leq c \to a \leq c)\)

\item {} 
\sphinxAtStartPar
\(\forall a, b \; (a \leq b \wedge b \leq a \to a = b)\)

\end{itemize}

\sphinxAtStartPar
Here the variables \(a\), \(b\), and \(c\) implicitly range over the domain \(A\).

\sphinxAtStartPar
The use of the symbol \(\leq\) is meant to be suggestive, and, indeed, the following are all examples of partial orders:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\leq\) on the natural numbers

\item {} 
\sphinxAtStartPar
\(\leq\) on the integers

\item {} 
\sphinxAtStartPar
\(\leq\) on the rational numbers

\item {} 
\sphinxAtStartPar
\(\leq\) on the real numbers

\end{itemize}

\sphinxAtStartPar
But keep in mind that \(\leq\) is only a symbol; it can have unexpected interpretations as well. For example, the \(\geq\) relation on any of these domains is also a partial order, and can interpret the \(\leq\) symbol just as well.

\sphinxAtStartPar
These are not fully representative of the class of partial orders, in that they all have an additional property:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A partial order \(\leq\) on a domain \(A\) is a \sphinxstyleemphasis{total order} (also called a \sphinxstyleemphasis{linear order}) if it also has the following property:
\begin{itemize}
\item {} 
\sphinxAtStartPar
for every \(a\) and \(b\) in \(A\), either \(a \leq b\) or \(b \leq a\)

\end{itemize}


\bigskip\hrule\bigskip


\sphinxAtStartPar
You can check these these are two examples of partial orders that are not total orders:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the divides relation, \(x \mid y\), on the integers

\item {} 
\sphinxAtStartPar
the subset relation, \(x \subseteq y\), on sets of elements of some domain \(A\)

\end{itemize}

\sphinxAtStartPar
On the integers, we also have the strict order relation, \(<\), which is not a partial order, since it is not reflexive. It is, rather, an instance of a \sphinxstyleemphasis{strict partial order}:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A binary relation \(<\) on a domain \(A\) is a \sphinxstyleemphasis{strict partial order} if it satisfies the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{irreflexivity}: \(a \nless a\) for every \(a\) in \(A\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{transitivity}: \(a < b\) and \(b < c\) implies \(a < c\), for every \(a\), \(b\), and \(c\) in \(A\)

\end{itemize}

\sphinxAtStartPar
A strict partial order is a \sphinxstyleemphasis{strict total order} (or \sphinxstyleemphasis{strict linear order}) if, in addition, we have the following property:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{trichotomy}: \(a < b\), \(a = b\), or \(a > b\) for every \(a\) and \(b\) in \(A\)

\end{itemize}


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here, \(b \nless a\) means, of course, that it is not the case that \(a < b\), and \(a > b\) is alternative notation for \(b < a\). To distinguish an ordinary partial order from a strict one, an ordinary partial order is sometimes called a \sphinxstyleemphasis{weak} partial order.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition}. A strict partial order \(<\) on \(A\) is \sphinxstyleemphasis{asymmetric}: for every \(a\) and \(b\), \(a < b\) implies \(b \nless a\).

\sphinxAtStartPar
\sphinxstylestrong{Proof}. Suppose \(a < b\) and \(b < a\). Then, by transitivity, \(a < a\), contradicting irreflexivity.


\bigskip\hrule\bigskip


\sphinxAtStartPar
On the integers, there are precise relationships between \(<\) and \(\leq\): \(x \leq y\) if and only if \(x < y\) or \(x = y\), and \(x < y\) if and only if \(x \leq y\) and \(x \neq y\). This illustrates a more general phenomenon.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Suppose \(\leq\) is a partial order on a domain \(A\). Define \(a < b\) to mean that \(a \leq b\) and \(a \neq b\). Then \(<\) is a strict partial order. Moreover, if \(\leq\) is total, so is \(<\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Suppose \(<\) is a strict partial order on a domain \(A\). Define \(a \leq b\) to mean \(a < b\) or \(a = b\). Then \(\leq\) is a partial order. Moreover, if \(<\) is total, so is \(\leq\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
We will prove the first here, and leave the second as an exercise. This proof is a nice illustration of how universal quantification, equality, and propositional reasoning are combined in a mathematical argument.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof}. Suppose \(\leq\) is a partial order on \(A\), and \(<\) be defined as in the statement of the theorem. Irreflexivity is immediate, since \(a < a\) implies \(a \neq a\), which is a contradiction.

\sphinxAtStartPar
To show transitivity, suppose \(a < b\) and \(b < c\). Then we have \(a \leq b\), \(b \leq c\), \(a \neq b\), and \(b \neq c\). By the transitivity of \(\leq\), we have \(a \leq c\). To show \(a < c\), we only have to show \(a \neq c\). So suppose \(a = c\). then, from the hypotheses, we have \(c < b\) and \(b < c\). From the definition of \(<\), we have \(c \leq b\), \(b \leq c\), and \(c \neq b\). But the first two imply \(c = b\), a contradiction. So \(a \neq c\), as required.

\sphinxAtStartPar
To establish the last claim in the theorem, suppose \(\leq\) is total, and let \(a\) and \(b\) be any elements of \(A\). We need to show that \(a < b\), \(a = b\), or \(a > b\). If \(a = b\), we are done, so we can assume \(a \neq b\). Since \(\leq\) is total, we have \(a \leq b\) or \(b \leq a\). Since \(a \neq b\), in the first case we have \(a < b\), and in the second case, we have \(a > b\).


\bigskip\hrule\bigskip



\section{More on Orderings}
\label{\detokenize{relations:more-on-orderings}}
\sphinxAtStartPar
Let \(\leq\) be a partial order on a domain, \(A\), and let \(<\) be the associated strict order, as defined in the last section. It is possible to show that if we go in the other direction, and define \(\leq'\) to be the partial order associated to \(<\), then \(\leq\) and \(\leq'\) are the same, which is to say, for every \(a\) and \(b\) in \(A\), \(a \leq b\) if and only if \(a \leq' b\). So we can think of every partial order as really being a pair, consisting of a weak partial order and an associated strict one. In other words, we can assume that \(x < y\) holds if and only if \(x \leq y\) and \(x \neq y\), and we can assume \(x \leq y\) holds if and only if \(x < y\) or \(x = y\).

\sphinxAtStartPar
We will henceforth adopt this convention. Given a partial order \(\leq\) and the associated strict order \(<\), we leave it to you to show that if \(x \leq y\) and \(y < z\), then \(x < z\), and, similarly, if \(x < y\) and \(y \leq z\), then \(x < z\).

\sphinxAtStartPar
Consider the natural numbers with the less\sphinxhyphen{}than\sphinxhyphen{}or\sphinxhyphen{}equal relation. It has a least element, \(0\). We can express the fact that \(0\) is the least element in at least two ways:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(0\) is less than or equal to every natural number.

\item {} 
\sphinxAtStartPar
There is no natural number that is less than \(0\).

\end{itemize}

\sphinxAtStartPar
In symbolic logic, we could formalize these statements as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall x \; (0 \leq x)\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (x \nless 0)\)

\end{itemize}

\sphinxAtStartPar
Using the existential quantifier, we could render the second statement more faithfully as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\neg \exists x \; (x < 0)\)

\end{itemize}

\sphinxAtStartPar
Notice that this more faithful statement is equivalent to the original, using deMorgan’s laws for quantifiers.

\sphinxAtStartPar
Are the two statements above equivalent? Say an element \(y\) is \sphinxstyleemphasis{minimum} for a partial order if it is less than or equal to any other element, that is, if it takes the place of 0 in the first statement. Say that an element \(y\) is \sphinxstyleemphasis{minimal} for a partial order if no element is less than it, that is, if it takes the place of 0 in the second statement. Two facts are immediate.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Any minimum element is minimal.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(x\) is minimum for \(\leq\). We need to show that \(x\) is minimal, that is, for every \(y\), it is not the case that \(y < x\). Suppose \(y < x\). Since \(x\) is minimum, we have \(x \leq y\). From \(y < x\) and \(x \leq y\), we have \(y < y\), contradicting the irreflexivity of \(<\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If a partial order \(\leq\) has a minimum element, it is unique.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(x_1\) and \(x_2\) are both minimum. Then \(x_1 \leq x_2\) and \(x_2 \leq x_1\). By antisymmetry, \(x_1 = x_2\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that we have interpreted the second theorem as the statement that if \(x_1\) and \(x_2\) are both minimum, then \(x_1 = x_2\). Indeed, this is exactly what we mean when we say that something is “unique.” When a partial order has a minimum element \(x\), uniqueness is what justifies calling \(x\) \sphinxstyleemphasis{the} minimum element. Such an \(x\) is also called the \sphinxstyleemphasis{least} element or the \sphinxstyleemphasis{smallest} element, and the terms are generally interchangeable.

\sphinxAtStartPar
The converse to the first theorem – that is, the statement that every minimal element is minimum – is false. As an example, consider the nonempty subsets of the set \(\{ 1, 2 \}\) with the subset relation. In other words, consider the collection of sets \(\{ 1 \}\), \(\{ 2 \}\), and \(\{1, 2\}\), where \(\{ 1 \} \subseteq \{1, 2\}\), \(\{ 2 \} \subseteq \{1, 2\}\), and, of course, every element is a subset of itself. Then you can check that \(\{1\}\) and \(\{2\}\) are each minimal, but neither is minimum. (One can also exhibit such a partial order by drawing a diagram, with dots labeled \(a\), \(b\), \(c\), etc., and upwards edges between elements to indicate that one is less than or equal to the other.)

\sphinxAtStartPar
Notice that the statement “a minimal element of a partial order is not necessarily minimum” makes an “existential” assertion: it says that there is a partial order \(\leq\), and an element \(x\) of the domain, such that \(x\) is minimal but not minimum. For a fixed partial order \(\leq\), we can express the assertion that such an \(x\) exists as follows:
\begin{equation*}
\begin{split}\exists x \; (\forall y \; (y \nless x) \wedge \neg \forall y \; (x \leq y)).\end{split}
\end{equation*}
\sphinxAtStartPar
The assertion that there exists a domain \(A\), and a partial order \(\leq\) on that domain \(A\), is more dramatic: it is a “higher order” existential assertion. But symbolic logic provides us with the means to make assertions like these as well, as we will see later on.

\sphinxAtStartPar
We can consider other properties of orders. An order is said to be \sphinxstyleemphasis{dense} if between any two distinct elements, there is another element. More precisely, an order is dense if, whenever \(x < y\), there is an element \(z\) satisfying \(x < z\) and \(z < y\). For example, the rational numbers are dense with the usual \(\leq\) ordering, but not the integers. Saying that an order is dense is another example of an implicit use of existential quantification.


\section{Equivalence Relations and Equality}
\label{\detokenize{relations:equivalence-relations-and-equality}}\label{\detokenize{relations:id3}}
\sphinxAtStartPar
In ordinary mathematical language, an \sphinxstyleemphasis{equivalence relation} is defined as follows.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition}. A binary relation \(\equiv\) on some domain \(A\) is said to be an \sphinxstyleemphasis{equivalence relation} if it is reflexive, symmetric, and transitive. In other words, \(\equiv\) is an equivalent relation if it satisfies these three properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{reflexivity}: \(a \equiv a\), for every \(a\) in \(A\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{symmetry}: if \(a \equiv b\), then \(b \equiv a\), for every \(a\) and \(b\) in \(A\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{transitivity}: if \(a \equiv b\) and \(b \equiv c\), then \(a \equiv c\), for every \(a\), \(b\), and \(c\) in \(A\)

\end{itemize}


\bigskip\hrule\bigskip


\sphinxAtStartPar
We leave it to you to think about how you could write these statements in first\sphinxhyphen{}order logic. (Note the similarity to the rules for a partial order.) We will also leave you with an exercise: by a careful choice of how to instantiate the quantifiers, you can actually prove the three properties above from the following two:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall a \; (a \equiv a)\)

\item {} 
\sphinxAtStartPar
\(\forall {a, b, c} \; (a \equiv b \wedge c \equiv b \to a \equiv c)\)

\end{itemize}

\sphinxAtStartPar
Try to verify this using natural deduction or Lean.

\sphinxAtStartPar
These three properties alone are not strong enough to characterize equality. You should check that the following informal examples are all instances of equivalence relations:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the relation on days on the calendar, given by “\(x\) and \(y\) fall on the same day of the week”

\item {} 
\sphinxAtStartPar
the relation on people currently alive on the planet, given by “\(x\) and \(y\) have the same age”

\item {} 
\sphinxAtStartPar
the relation on people currently alive on the planet, given by “\(x\) and \(y\) have the same birthday”

\item {} 
\sphinxAtStartPar
the relation on cities in the United States, given by “\(x\) and \(y\) are in the same state”

\end{itemize}

\sphinxAtStartPar
Here are two common mathematical examples:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the relation on lines in a plane, given by “\(x\) and \(y\) are parallel”

\item {} 
\sphinxAtStartPar
for any fixed natural number \(m \geq 0\), the relation on natural numbers, given by “\(x\) is congruent to \(y\) modulo \(m\)” (see \hyperref[\detokenize{elementary_number_theory:elementary-number-theory}]{Chapter \ref{\detokenize{elementary_number_theory:elementary-number-theory}}})

\end{itemize}

\sphinxAtStartPar
Here, we say that \(x\) is congruent to \(y\) modulo \(m\) if they leave the same remainder when divided by \(m\). Soon, you will be able to prove rigorously that this is equivalent to saying that \(x - y\) is divisible by \(m\).

\sphinxAtStartPar
Consider the equivalence relation on citizens of the United States, given by “\(x\) and \(y\) have the same age.” There are some properties that respect that equivalence. For example, suppose I tell you that John and Susan have the same age, and I also tell you that John is old enough to vote. Then you can rightly infer that Susan is old enough to vote. On the other hand, if I tell you nothing more than the facts that John and Susan have the same age and John lives in South Dakota, you cannot infer that Susan lives in South Dakota. This little example illustrates what is special about the \sphinxstyleemphasis{equality} relation: if two things are equal, then they have exactly the same properties.

\sphinxAtStartPar
Let \(A\) be a set and let \(\equiv\) be an equivalence relation on \(A\). There is an important mathematical construction known as forming the \sphinxstyleemphasis{quotient} of \(A\) under the equivalence relation. For every element \(a\) in \(A\), let \([a]\) be the set of elements \(\{ c \mid c \equiv a \}\), that is, the set of elements of \(A\) that are equivalent to \(a\). We call \([a]\) the equivalence class of \(A\). The set \(A / \mathord{\equiv}\), the \sphinxstyleemphasis{quotient of} \(A\) \sphinxstyleemphasis{by} \(\equiv\), is defined to be the set \(\{ [a] : a \in A \}\), that is, the set of all the equivalence classes of elements in \(A\). The exercises below as you to show that if \([a]\) and \([b]\) are elements of such a quotient, then \([a] = [b]\) if and only if \(a \equiv b\).

\sphinxAtStartPar
The motivation is as follows. Equivalence tries to capture a weak notion of equality: if two elements of \(A\) are equivalent, they are not necessarily the same, but they are similar in some way. Equivalence classes collect similar objects together, essentially glomming them into new objects.  Thus \(A / \mathord{\equiv}\) is a version of the set \(A\) where similar elements have been compressed into a single element. For example, given the equivalence relation \(\equiv\) of congruence modulo 5 on the integers, \(\mathbb{N} / \mathord{\equiv}\) is the set \(\{ [0], [1], [2], [3], [4] \}\), where, for example, \([0]\) is the set of all multiples of 5.


\section{Exercises}
\label{\detokenize{relations:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Suppose \(<\) is a strict partial order on a domain \(A\), and define \(a \leq b\) to mean that \(a < b\) or \(a = b\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Show that \(\leq\) is a partial order.

\item {} 
\sphinxAtStartPar
Show that if \(<\) is moreover a strict total order, then \(\leq\) is a total order.

\end{itemize}

\sphinxAtStartPar
(Above we proved the analogous theorem going in the other direction.)

\item {} 
\sphinxAtStartPar
Suppose \(<\) is a strict partial order on a domain \(A\). (In other words, it is transitive and asymmetric.) Suppose that \(\leq\) is defined so that \(a \leq b\) if and only if \(a < b\) or \(a = b\). We saw in class that \(\leq\) is a partial order on a domain \(A\), i.e.\textasciitilde{}it is reflexive, transitive, and antisymmetric.

\sphinxAtStartPar
Prove that for every \(a\) and \(b\) in \(A\), we have \(a < b\) iff \(a \leq b\) and \(a \neq b\), using the facts above.

\item {} 
\sphinxAtStartPar
An \sphinxstyleemphasis{ordered graph} is a collection of vertices (points), along with a collection of arrows between vertices. For each pair of vertices, there is at most one arrow between them: in other words, every pair of vertices is either unconnected, or one vertex is “directed” toward the other. Note that it is possible to have an arrow from a vertex to itself.

\sphinxAtStartPar
Define a relation \(\leq\) on the set of vertices, such that for two vertices \(a\) and \(b\), \(a \leq b\) means that there is an arrow from \(a\) pointing to \(b\).

\sphinxAtStartPar
On an arbitrary graph, is \(\leq\) a partial order, a strict partial order, a total order, a strict total order, or none of the above? If possible, give examples of graphs where \(\leq\) fails to have these properties.

\item {} 
\sphinxAtStartPar
Let \(\equiv\) be an equivalence relation on a set \(A\). For every element \(a\) in \(A\), let \([a]\) be the equivalence class of \(a\): that is, the set of elements \(\{ c \mid c \equiv a \}\). Show that for every \(a\) and \(b\), \([a] = [b]\) if and only if \(a \equiv b\).

\sphinxAtStartPar
(Hints and notes:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Remember that since you are proving an ``if and only if’’ statement, there are two directions to prove.

\item {} 
\sphinxAtStartPar
Since that \([a]\) and \([b]\) are sets, \([a] = [b]\) means that for every element \(c\), \(c\) is in \([a]\) if and only if \(c\) is in \([b]\).

\item {} 
\sphinxAtStartPar
By definition, an element \(c\) is in \([a]\) if and only if \(c \equiv a\). In particular, \(a\) is in \([a]\).)

\end{itemize}

\item {} 
\sphinxAtStartPar
Let the relation \(\sim\) on the natural numbers \(\mathbb{N}\) be defined as follows: if \(n\) is even, then \(n \sim n+1\), and if \(n\) is odd, then \(n \sim n-1\). Furthermore, for every \(n\), \(n \sim n\). Show that \(\sim\) is an equivalence relation. What is the equivalence class of the number 5? Describe the set of equivalence classes \(\{ [n] \mid n \in \mathbb{N} \}\).

\item {} 
\sphinxAtStartPar
Show that the relation on lines in the plane, given by “\(l_1\) and \(l_2\) are parallel,” is an equivalence relation. What is the equivalence class of the x\sphinxhyphen{}axis? Describe the set of equivalence classes \(\{ [l] \mid l\text{ is a line in the plane} \}\).

\item {} 
\sphinxAtStartPar
A binary relation \(\leq\) on a domain \(A\) is said to be a \sphinxstyleemphasis{preorder} it is is reflexive and transitive. This is weaker than saying it is a partial order; we have removed the requirement that the relation is asymmetric. An example is the ordering on people currently alive on the planet defined by setting \(x \leq y\) if and only if \(x\) ‘s birth date is earlier than \(y\) ‘s. Asymmetry fails, because different people can be born on the same day. But, prove that the following theorem holds:

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(\leq\) be a preorder on a domain \(A\). Define the relation \(\equiv\), where \(x \equiv y\) holds if and only if \(x \leq y\) and \(y \leq x\). Then \(\equiv\) is an equivalence relation on \(A\).

\end{enumerate}


\chapter{Relations in Lean}
\label{\detokenize{relations_in_lean:relations-in-lean}}\label{\detokenize{relations_in_lean::doc}}
\sphinxAtStartPar
In the last chapter, we noted that set theorists think of a binary relation
\(R\) on a set \(A\) as a set of ordered pairs,
so that \(R(a, b)\) really means \((a, b) \in R\).
An alternative is to think of \(R\) as a function which,
when applied to \(a\) and \(b\),
returns the proposition that \(R(a, b)\) holds.
This is the viewpoint adopted by Lean:
a binary relation on a type \sphinxcode{\sphinxupquote{A}} is a function \sphinxcode{\sphinxupquote{A → A → Prop}}.
Remember that the arrows associate to the right,
so \sphinxcode{\sphinxupquote{A → A → Prop}} really means \sphinxcode{\sphinxupquote{A → (A → Prop)}}.
So, given \sphinxcode{\sphinxupquote{a : A}},
\sphinxcode{\sphinxupquote{R a}} is a predicate (the property of being related to \sphinxcode{\sphinxupquote{A}}),
and given \sphinxcode{\sphinxupquote{a b : A}}, \sphinxcode{\sphinxupquote{R a b}} is a proposition.


\section{Order Relations}
\label{\detokenize{relations_in_lean:order-relations}}
\sphinxAtStartPar
With first\sphinxhyphen{}order logic,
we can say what it means for a relation to be reflexive,
symmetric, transitive, antisymmetric, and so on:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{namespace} \PYG{n}{hidden}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{def} \PYG{n}{Reflexive} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x}

\PYG{k+kd}{def} \PYG{n}{Symmetric} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x}

\PYG{k+kd}{def} \PYG{n}{Transitive} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{x} \PYG{n}{z}

\PYG{k+kd}{def} \PYG{n}{AntiSymmetric} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x} \PYG{n+nb+bp}{→} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y}

\PYG{k+kd}{def} \PYG{n}{Irreflexive} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{¬} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x}

\PYG{k+kd}{def} \PYG{n}{Total} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{∨} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x}

\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that Lean will unfold the definitions when necessary,
for example, treating \sphinxcode{\sphinxupquote{Reflexive R}} as \sphinxcode{\sphinxupquote{∀ x, R x x}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{Symmetric} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{x} \PYG{n}{y} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{R} \PYG{n}{x} \PYG{n}{z} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{n}{h1} \PYG{n}{h2}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{AntiSymmetric} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{x} \PYG{n}{y} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the command \sphinxcode{\sphinxupquote{variable \{A : Type\}}},
we put curly braces around \sphinxcode{\sphinxupquote{A}} to indicate that it is an \sphinxstyleemphasis{implicit} argument,
which is to say, you do not have to write it explicitly;
Lean can infer it from the argument \sphinxcode{\sphinxupquote{R}}.
That is why we can write \sphinxcode{\sphinxupquote{Reflexive R}} rather than \sphinxcode{\sphinxupquote{Reflexive A R}}:
Lean knows that \sphinxcode{\sphinxupquote{R}} is a binary relation on \sphinxcode{\sphinxupquote{A}},
so it can infer that we mean reflexivity for binary relations on \sphinxcode{\sphinxupquote{A}}.

\sphinxAtStartPar
Given \sphinxcode{\sphinxupquote{h : Transitive R}}, \sphinxcode{\sphinxupquote{h1 : R x y}}, and \sphinxcode{\sphinxupquote{h2 : R y z}},
it is annoying to have to write \sphinxcode{\sphinxupquote{h x y z h1 h2}} to prove \sphinxcode{\sphinxupquote{R x z}}.
After all,
Lean should be able to infer that we are talking about transitivity at
\sphinxcode{\sphinxupquote{x}}, \sphinxcode{\sphinxupquote{y}}, and \sphinxcode{\sphinxupquote{z}},
from the fact that \sphinxcode{\sphinxupquote{h1}} is \sphinxcode{\sphinxupquote{R x y}} and \sphinxcode{\sphinxupquote{h2}} is \sphinxcode{\sphinxupquote{R y z}}.
Indeed, we can replace that information by underscores:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{R} \PYG{n}{x} \PYG{n}{z} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
But typing underscores is annoying, too.
The best solution is to declare the arguments \sphinxcode{\sphinxupquote{x y z}}
to a transitivity hypothesis to be implicit as well.
We can do this by introducing curly braces around the
variables in the definition.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{Transitive\PYGZsq{}} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{x}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{y}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{z}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{x} \PYG{n}{z}

\PYG{k+kd}{def} \PYG{n}{Transitive} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{x} \PYG{n}{z}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{z}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{R} \PYG{n}{x} \PYG{n}{z} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{h1} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, the notions
\sphinxcode{\sphinxupquote{Reflexive}}, \sphinxcode{\sphinxupquote{Symmetric}}, \sphinxcode{\sphinxupquote{Transitive}},
and so on are defined in Mathlib in exactly this way,
so we are free to use them by doing \sphinxcode{\sphinxupquote{import Mathlib.Init.Logic}}
at the top of the file.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Init.Logic}

\PYG{k}{\PYGZsh{}check} \PYG{n}{Reflexive}
\PYG{k}{\PYGZsh{}check} \PYG{n}{Symmetric}
\PYG{k}{\PYGZsh{}check} \PYG{n}{Transitive}
\PYG{k}{\PYGZsh{}check} \PYG{n}{AntiSymmetric}
\PYG{k}{\PYGZsh{}check} \PYG{n}{Irreflexive}
\end{sphinxVerbatim}

\sphinxAtStartPar
We put our temporary definitions of in a namespace \sphinxcode{\sphinxupquote{hidden}};
that means that the full name of our version of \sphinxcode{\sphinxupquote{Reflexive}} is
\sphinxcode{\sphinxupquote{hidden.Reflexive}},
which would not conflict with the one defined in the library
were we to import that module.

\sphinxAtStartPar
In \hyperref[\detokenize{relations:order-relations}]{Section \ref{\detokenize{relations:order-relations}}} we showed that a strict partial order \sphinxhyphen{}
that is, a binary relation that is transitive and irreflexive \sphinxhyphen{}
is also asymmetric. Here is a proof of that fact in Lean.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{Irreflexive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{:}
    \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{x} \PYG{n}{y}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h2} \PYG{n}{h3} \PYG{n}{h4}
  \PYG{k}{have} \PYG{n}{h6} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{x}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h6} \PYG{n}{h5}
\PYG{k+kd}{variable} \PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}
\PYG{k+kd}{variable} \PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\end{sphinxVerbatim}

\sphinxAtStartPar
In mathematics,
it is common to use infix notation and a symbol like \sphinxcode{\sphinxupquote{≼}}
to denote a partial order,
which you can input by typing \sphinxcode{\sphinxupquote{\textbackslash{}preceq}}.
Lean supports this practice:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} type \PYGZbs{}preceq for the symbol ≼}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≼ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{R}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{Irreflexive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{:}
    \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n}{y}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{≼} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{¬} \PYG{n}{y} \PYG{n+nb+bp}{≼} \PYG{n}{x} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{x} \PYG{n}{y}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{≼} \PYG{n}{y}\PYG{o}{)}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h4} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{≼} \PYG{n}{x}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h5} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{≼} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h2} \PYG{n}{h3} \PYG{n}{h4}
  \PYG{k}{have} \PYG{n}{h6} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{x} \PYG{n+nb+bp}{≼} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h1} \PYG{n}{x}
  \PYG{k}{show} \PYG{n}{False}
  \PYG{n}{exact} \PYG{n}{h6} \PYG{n}{h5}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The structure of a partial order consists of a type \sphinxcode{\sphinxupquote{A}}
(traditionally a set \sphinxcode{\sphinxupquote{A}})
with a binary relation \sphinxcode{\sphinxupquote{le : A → A → Prop}}
(short for “lesser or equal”)
on it that is reflexive,
transitive, and antisymmetric.
We can package this structure as a “class” in Lean.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{class} \PYG{n}{PartialOrder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
  \PYG{n}{le} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
  \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{le}
  \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{le}
  \PYG{n}{antisymm} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{le} \PYG{n}{a} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{le} \PYG{n}{b} \PYG{n}{a} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} type \PYGZbs{}preceq for the symbol ≼}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≼ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{PartialOrder.le}
\end{sphinxVerbatim}

\sphinxAtStartPar
Assuming we have a type \sphinxcode{\sphinxupquote{A}} that is a partial order,
we can define the corresponding strict partial order \sphinxcode{\sphinxupquote{lt : A → A → Prop}}
(short for “lesser than”)
and prove that it is,
indeed, a strict order.
We also introduce notation \sphinxcode{\sphinxupquote{≺}} for \sphinxcode{\sphinxupquote{le}},
which you can write by typing \sphinxcode{\sphinxupquote{\textbackslash{}prec}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{namespace} \PYG{n}{PartialOrder}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}} \PYG{o}{[}\PYG{n}{PartialOrder} \PYG{n}{A}\PYG{o}{]}

\PYG{k+kd}{def} \PYG{n}{lt} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{b} \PYG{n+nb+bp}{∧} \PYG{n}{a} \PYG{n+nb+bp}{≠} \PYG{n}{b}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} type \PYGZbs{}prec for the symbol ≺}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≺ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{lt}

\PYG{k+kd}{theorem} \PYG{n}{irrefl\PYGZus{}lt} \PYG{o}{(}\PYG{n}{a} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{a}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{a}\PYG{o}{)}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≠} \PYG{n}{a} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{a} \PYG{o}{:=} \PYG{n}{rfl}
  \PYG{n}{contradiction}

\PYG{k+kd}{theorem} \PYG{n}{trans\PYGZus{}lt} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h₁} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h₂} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≺} \PYG{n}{c}\PYG{o}{)} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{c} \PYG{o}{:=}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{b} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h₁}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≠} \PYG{n}{b} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h₁}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≼} \PYG{n}{c} \PYG{o}{:=} \PYG{n}{And.left} \PYG{n}{h₂}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≠} \PYG{n}{c} \PYG{o}{:=} \PYG{n}{And.right} \PYG{n}{h₂}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{c} \PYG{o}{:=} \PYG{n}{trans} \PYG{o}{‹}\PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{b}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{b} \PYG{n+nb+bp}{≼} \PYG{n}{c}\PYG{o}{›}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≠} \PYG{n}{c} \PYG{o}{:=}
    \PYG{k}{fun} \PYG{n}{hac} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{c} \PYG{n+nb+bp}{↦}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{c} \PYG{n+nb+bp}{≼} \PYG{n}{b} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←} \PYG{n}{hac}\PYG{o}{]}\PYG{n+nb+bp}{;} \PYG{n}{assumption}
    \PYG{k}{have} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{=} \PYG{n}{c} \PYG{o}{:=} \PYG{n}{antisymm} \PYG{o}{‹}\PYG{n}{b} \PYG{n+nb+bp}{≼} \PYG{n}{c}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{c} \PYG{n+nb+bp}{≼} \PYG{n}{b}\PYG{o}{›}
    \PYG{k}{show} \PYG{n}{False} \PYG{k}{from} \PYG{o}{‹}\PYG{n}{b} \PYG{n+nb+bp}{≠} \PYG{n}{c}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{b} \PYG{n+nb+bp}{=} \PYG{n}{c}\PYG{o}{›}
  \PYG{k}{show} \PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{c} \PYG{k}{from} \PYG{n}{And.intro} \PYG{o}{‹}\PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{c}\PYG{o}{›} \PYG{o}{‹}\PYG{n}{a} \PYG{n+nb+bp}{≠} \PYG{n}{c}\PYG{o}{›}

\PYG{k+kd}{end} \PYG{n}{PartialOrder}
\end{sphinxVerbatim}

\sphinxAtStartPar
The variable declaration \sphinxcode{\sphinxupquote{{[}PartialOrder A{]}}} can be read as
“assume \sphinxcode{\sphinxupquote{A}} is a partial order”.
Then Lean will use this “instance” of the class \sphinxcode{\sphinxupquote{PartialOrder}}
to figure out what \sphinxcode{\sphinxupquote{le}} and \sphinxcode{\sphinxupquote{lt}} are referring to.

\sphinxAtStartPar
The proofs use anonymous \sphinxcode{\sphinxupquote{have}},
referring back to them with the French quotes, \sphinxcode{\sphinxupquote{`\textbackslash{}f<}} and \sphinxcode{\sphinxupquote{\textbackslash{}f>}},
or \sphinxcode{\sphinxupquote{assumption}} (in tactic mode).
The proof of transitivity switches from term mode to tactic mode,
to use \sphinxcode{\sphinxupquote{rewrite}} to replace \sphinxcode{\sphinxupquote{c}} for \sphinxcode{\sphinxupquote{a}} in \sphinxcode{\sphinxupquote{a ≤ b}}.
Recall that \sphinxcode{\sphinxupquote{contradiction}} instructs Lean to find
a hypothesis and its negation in the context, and hence complete the proof.

\sphinxAtStartPar
We could even define the class \sphinxcode{\sphinxupquote{StrictPartialOrder}} in a similar manner,
then use the above theorems to show that any (weak) \sphinxcode{\sphinxupquote{PartialOrder}} is also a
\sphinxcode{\sphinxupquote{StrictPartialOrder}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{class} \PYG{n}{StrictPartialOrder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
  \PYG{n}{lt} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
  \PYG{n}{irrefl} \PYG{o}{:} \PYG{n}{Irreflexive} \PYG{n}{lt}
  \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{lt}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} type \PYGZbs{}prec for the symbol ≺}
\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≺ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{StrictPartialOrder.lt}

\PYG{k+kd}{instance} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}} \PYG{o}{[}\PYG{n}{PartialOrder} \PYG{n}{A}\PYG{o}{]} \PYG{o}{:} \PYG{n}{StrictPartialOrder} \PYG{n}{A} \PYG{n}{where}
  \PYG{n}{lt}          \PYG{o}{:=} \PYG{n}{PartialOrder.lt}
  \PYG{n}{irrefl}      \PYG{o}{:=} \PYG{n}{PartialOrder.irrefl\PYGZus{}lt}
  \PYG{n}{trans} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{o}{:=} \PYG{n}{PartialOrder.trans\PYGZus{}lt}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{a} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{[}\PYG{n}{PartialOrder} \PYG{n}{A}\PYG{o}{]} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{a} \PYG{o}{:=}
\PYG{n}{StrictPartialOrder.irrefl} \PYG{n}{a}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once we have shown this instance, we would be able to use the inherited
\sphinxcode{\sphinxupquote{≺}} (not the one we defined in the \sphinxcode{\sphinxupquote{PartialOrder}} namespace!)
and facts about \sphinxcode{\sphinxupquote{StrictPartialOrder}} on any partial order.

\sphinxAtStartPar
In Section \hyperref[\detokenize{relations:order-relations}]{Section \ref{\detokenize{relations:order-relations}}},
we also noted that you can define a (weak) partial order from a strict one.
We ask you to do this formally in the exercises below.

\sphinxAtStartPar
Mathlib defines \sphinxcode{\sphinxupquote{PartialOrder}} in roughly the same way as we have,
which is why we enclosed our definitions in the \sphinxcode{\sphinxupquote{hidden}} namespace,
so that our definition is called \sphinxcode{\sphinxupquote{hidden.PartialOrder}}
rather than just \sphinxcode{\sphinxupquote{PartialOrder}} outside the namespace.
There is no \sphinxcode{\sphinxupquote{StrictPartialOrder}} definition,
but we can refer to the strict partial order, given a partial order.
The notation used by Mathlib is the more common \sphinxcode{\sphinxupquote{≤}}
(input \sphinxcode{\sphinxupquote{\textbackslash{}le}}) and \sphinxcode{\sphinxupquote{<}}.

\sphinxAtStartPar
Here is one more example. Suppose \sphinxcode{\sphinxupquote{R}} is a binary relation on a type \sphinxcode{\sphinxupquote{A}}, and we define \sphinxcode{\sphinxupquote{S x y}} to mean that both \sphinxcode{\sphinxupquote{R x y}} and \sphinxcode{\sphinxupquote{R y x}} holds. Below we show that the resulting relation is reflexive and symmetric.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{section}
\PYG{k+kd}{axiom} \PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}
\PYG{k+kd}{axiom} \PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{R}\PYG{o}{)}

\PYG{k+kd}{def} \PYG{n}{S} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{∧} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{S} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h2} \PYG{n}{x}
  \PYG{k}{show} \PYG{n}{S} \PYG{n}{x} \PYG{n}{x} \PYG{k}{from} \PYG{n}{And.intro} \PYG{n}{this} \PYG{n}{this}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Symmetric} \PYG{n}{S} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h} \PYG{o}{:} \PYG{n}{S} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{↦}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{h.left}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{R} \PYG{n}{y} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h.right}
\PYG{k}{show} \PYG{n}{S} \PYG{n}{y} \PYG{n}{x} \PYG{k}{from} \PYG{o}{⟨}\PYG{n}{h2}\PYG{o}{,} \PYG{n}{h1}\PYG{o}{⟩}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the exercises below, we ask you to show that \sphinxcode{\sphinxupquote{S}} is transitive as well.

\sphinxAtStartPar
In the first example,
we use the anonymous \sphinxcode{\sphinxupquote{have}},
and then refer back to the \sphinxcode{\sphinxupquote{have}} with the keyword \sphinxcode{\sphinxupquote{this}}.
In the second example,
we abbreviate \sphinxcode{\sphinxupquote{And.left h}} and \sphinxcode{\sphinxupquote{And.right h}} as \sphinxcode{\sphinxupquote{h.left}} and \sphinxcode{\sphinxupquote{h.right}},
respectively.
We also abbreviate \sphinxcode{\sphinxupquote{And.intro h2 h1}} with an anonymous constructor,
writing \sphinxcode{\sphinxupquote{⟨h2, h1⟩}}.
Lean figures out that we are trying to prove a conjunction,
and figures out that \sphinxcode{\sphinxupquote{And.intro}} is the relevant introduction principle.
You can type the corner brackets with \sphinxcode{\sphinxupquote{\textbackslash{}<}} and \sphinxcode{\sphinxupquote{\textbackslash{}>}}, respectively.


\section{Orderings on Numbers}
\label{\detokenize{relations_in_lean:orderings-on-numbers}}
\sphinxAtStartPar
Conveniently,
Lean has the normal orderings on the natural numbers, integers,
and so on defined already in Mathlib.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{open} \PYG{n}{Nat}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{n} \PYG{n}{m} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{≤} \PYG{n}{n}
\PYG{k}{\PYGZsh{}check} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{≤} \PYG{n}{n} \PYG{o}{:=} \PYG{n}{Nat.zero\PYGZus{}le} \PYG{n}{n}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{n}{lt\PYGZus{}succ\PYGZus{}self} \PYG{n}{n}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{≤} \PYG{n}{m}\PYG{o}{)} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{n}{lt\PYGZus{}succ\PYGZus{}self} \PYG{n}{n}
\PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{m} \PYG{o}{:=} \PYG{n}{lt\PYGZus{}of\PYGZus{}lt\PYGZus{}of\PYGZus{}le} \PYG{n}{h1} \PYG{n}{h}
\PYG{k}{have} \PYG{n}{h3} \PYG{o}{:} \PYG{n}{m} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{n}{lt\PYGZus{}succ\PYGZus{}self} \PYG{n}{m}
\PYG{k}{show} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{k}{from} \PYG{n}{lt\PYGZus{}trans} \PYG{n}{h2} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
There are many theorems in Lean that are useful for proving facts about inequality relations. We list some common ones here.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{[}\PYG{n}{PartialOrder} \PYG{n}{A}\PYG{o}{]}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{le\PYGZus{}trans} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≤} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{≤} \PYG{n}{c} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{≤} \PYG{n}{c}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{lt\PYGZus{}trans} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{c} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{c}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{lt\PYGZus{}of\PYGZus{}lt\PYGZus{}of\PYGZus{}le} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{≤} \PYG{n}{c} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{c}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{lt\PYGZus{}of\PYGZus{}le\PYGZus{}of\PYGZus{}lt} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≤} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{c} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{c}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{le\PYGZus{}of\PYGZus{}lt} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{≤} \PYG{n}{b}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that we assume an instance of \sphinxcode{\sphinxupquote{PartialOrder}} on \sphinxcode{\sphinxupquote{A}}.
There are also properties that are specific to some domains,
like the natural numbers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{Nat.zero\PYGZus{}le} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{,} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{≤} \PYG{n}{n}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{Nat.lt\PYGZus{}succ\PYGZus{}self} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{,} \PYG{n}{n} \PYG{n+nb+bp}{\PYGZlt{}} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)}
\PYG{k}{\PYGZsh{}check} \PYG{o}{(}\PYG{n}{Nat.le\PYGZus{}succ} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{,} \PYG{n}{n} \PYG{n+nb+bp}{≤} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)}
\end{sphinxVerbatim}


\section{Equivalence Relations}
\label{\detokenize{relations_in_lean:equivalence-relations}}
\sphinxAtStartPar
In \hyperref[\detokenize{relations:equivalence-relations-and-equality}]{Section \ref{\detokenize{relations:equivalence-relations-and-equality}}} we saw that an \sphinxstyleemphasis{equivalence relation} is a binary relation on some domain \(A\) that is reflexive, symmetric, and transitive. We will see such relations in Lean in a moment, but first let’s define another kind of relation called a \sphinxstyleemphasis{preorder}, which is a binary relation that is reflexive and transitive.
Again, we use a \sphinxcode{\sphinxupquote{class}} to capture this data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

\PYG{k+kn}{namespace} \PYG{n}{hidden}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{class} \PYG{n}{Preorder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
  \PYG{n}{le} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
  \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{le}
  \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{le}

\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
Lean’s library provides its own formulation of preorders.
In order to use the same name, we have to put it in the \sphinxcode{\sphinxupquote{hidden}} namespace.
Lean’s library defines other properties of relations, such as these:

\sphinxAtStartPar
Building on our definition of a preorder,
we can describe partial orders as antisymmetric preorders,
and equivalences as symmetric preorders.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

 \PYG{k+kn}{namespace} \PYG{n}{hidden}

 \PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

 \PYG{k+kd}{class} \PYG{n}{Preorder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
   \PYG{n}{le} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
   \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{le}
   \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{le}

 \PYG{k+kd}{class} \PYG{n}{PartialOrder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{k+kd}{extends} \PYG{n}{Preorder} \PYG{n}{A} \PYG{n}{where}
   \PYG{n}{antisymm} \PYG{o}{:} \PYG{n}{AntiSymmetric} \PYG{n}{le}

\PYG{k+kd}{class} \PYG{n}{Equivalence} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{k+kd}{extends} \PYG{n}{Preorder} \PYG{n}{A} \PYG{n}{where}
  \PYG{n}{symm} \PYG{o}{:} \PYG{n}{Symmetric} \PYG{n}{le}

 \PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{extends Preorder A}} in this definition now makes
\sphinxcode{\sphinxupquote{PartialOrder}} a class that automatically
inherits all the definitions and theorems from \sphinxcode{\sphinxupquote{Preorder}}.
In particular \sphinxcode{\sphinxupquote{le}}, \sphinxcode{\sphinxupquote{refl}}, and \sphinxcode{\sphinxupquote{trans}} become part of the data of
\sphinxcode{\sphinxupquote{PartialOrder}}.
Using classes in this way we can write very general proofs
(for example proofs just about preorders)
and apply them in contexts that are more specific
(for example proofs about equivalence relations and partial orders).

\sphinxAtStartPar
Note: we might \sphinxstyleemphasis{not} want to design the library in this way specifically.
Since we might want to use \sphinxcode{\sphinxupquote{≤}} as notation for a partial order,
but for an equivalence relation.
Indeed \sphinxcode{\sphinxupquote{Mathlib}} does not define \sphinxcode{\sphinxupquote{Equivalence}} as an extension of
\sphinxcode{\sphinxupquote{PartialOrder}}.

\sphinxAtStartPar
In \hyperref[\detokenize{relations:equivalence-relations-and-equality}]{Section \ref{\detokenize{relations:equivalence-relations-and-equality}}} we claimed that there is
another way to define an equivalence relation,
namely as a binary relation satisfying the following two properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\forall a \; (a \equiv a)\)

\item {} 
\sphinxAtStartPar
\(\forall {a, b, c} \; (a \equiv b \wedge c \equiv b \to a \equiv c)\)

\end{itemize}

\sphinxAtStartPar
We derive the two definitions from each other in the following

\begin{sphinxVerbatim}[commandchars=\\\{\}]
 \PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

 \PYG{k+kn}{namespace} \PYG{n}{hidden}

 \PYG{k+kd}{class} \PYG{n}{Equivalence} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
   \PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
   \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{R}
   \PYG{n}{symm} \PYG{o}{:} \PYG{n}{Symmetric} \PYG{n}{R}
   \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{R}

 \PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ \PYGZti{} }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{Equivalence.R}

 \PYG{k+kd}{class} \PYG{n}{Equivalence\PYGZsq{}} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
   \PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
   \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{R}
   \PYG{n}{trans\PYGZsq{}} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{R} \PYG{n}{a} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{c} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{R} \PYG{n}{a} \PYG{n}{c}

 \PYG{c+c1}{\PYGZhy{}\PYGZhy{} type ``≈`` as ``\PYGZbs{}\PYGZti{}\PYGZti{}``}
 \PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≈ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{Equivalence\PYGZsq{}.R}

 \PYG{k+kn}{section}
 \PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{\PYGZcb{}}

 \PYG{k+kd}{theorem} \PYG{n}{Equivalence.trans\PYGZsq{}} \PYG{o}{[}\PYG{n}{Equivalence} \PYG{n}{A}\PYG{o}{]} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
     \PYG{n}{a} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{c} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{c} \PYG{o}{:=} \PYG{k+kd}{by}
   \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hab} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{b}\PYG{o}{)}
   \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hcb} \PYG{o}{:} \PYG{n}{c} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{b}\PYG{o}{)}
   \PYG{n}{apply} \PYG{n}{trans} \PYG{n}{hab}
   \PYG{k}{show} \PYG{n}{b} \PYG{n+nb+bp}{\PYGZti{}} \PYG{n}{c}
   \PYG{n}{exact} \PYG{n}{symm} \PYG{n}{hcb}

 \PYG{k+kd}{example} \PYG{o}{[}\PYG{n}{Equivalence} \PYG{n}{A}\PYG{o}{]} \PYG{o}{:} \PYG{n}{Equivalence\PYGZsq{}} \PYG{n}{A} \PYG{n}{where}
   \PYG{n}{R} \PYG{o}{:=} \PYG{n}{Equivalence.R}
   \PYG{n}{refl} \PYG{o}{:=} \PYG{n}{Equivalence.refl}
   \PYG{n}{trans\PYGZsq{}}\PYG{o}{:=} \PYG{n}{Equivalence.trans\PYGZsq{}}

 \PYG{k+kd}{theorem} \PYG{n}{Equivalence\PYGZsq{}.symm} \PYG{o}{[}\PYG{n}{Equivalence\PYGZsq{}} \PYG{n}{A}\PYG{o}{]} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
     \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{≈} \PYG{n}{a} \PYG{o}{:=} \PYG{k+kd}{by}
   \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hab} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{b}\PYG{o}{)}
   \PYG{k}{have} \PYG{n}{hbb} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≈} \PYG{n}{b} \PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.refl} \PYG{n}{b}
   \PYG{k}{show} \PYG{n}{b} \PYG{n+nb+bp}{≈} \PYG{n}{a}
   \PYG{n}{exact} \PYG{n}{Equivalence\PYGZsq{}.trans\PYGZsq{}} \PYG{n}{hbb} \PYG{n}{hab}

 \PYG{k+kd}{theorem} \PYG{n}{Equivalence\PYGZsq{}.trans} \PYG{o}{[}\PYG{n}{Equivalence\PYGZsq{}} \PYG{n}{A}\PYG{o}{]} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
   \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{b} \PYG{n+nb+bp}{→} \PYG{n}{b} \PYG{n+nb+bp}{≈} \PYG{n}{c} \PYG{n+nb+bp}{→} \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{c} \PYG{o}{:=} \PYG{k+kd}{by}
   \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hab} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hbc} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≈} \PYG{n}{c}\PYG{o}{)}
   \PYG{k}{have} \PYG{n}{hcb} \PYG{o}{:} \PYG{n}{c} \PYG{n+nb+bp}{≈} \PYG{n}{b} \PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.symm} \PYG{n}{hbc}
   \PYG{k}{show} \PYG{n}{a} \PYG{n+nb+bp}{≈} \PYG{n}{c}
   \PYG{n}{exact} \PYG{n}{Equivalence\PYGZsq{}.trans\PYGZsq{}} \PYG{n}{hab} \PYG{n}{hcb}

\PYG{k+kd}{example} \PYG{o}{[}\PYG{n}{Equivalence\PYGZsq{}} \PYG{n}{A}\PYG{o}{]} \PYG{o}{:} \PYG{n}{Equivalence} \PYG{n}{A} \PYG{n}{where}
  \PYG{n}{R} \PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.R}
  \PYG{n}{refl} \PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.refl}
  \PYG{n}{symm} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}}\PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.symm}
  \PYG{n}{trans} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{n}{\PYGZus{}} \PYG{o}{:=} \PYG{n}{Equivalence\PYGZsq{}.trans}

 \PYG{k+kd}{end}
 \PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\sphinxAtStartPar
For one of the definitions we use the infix notation \sphinxcode{\sphinxupquote{\textasciitilde{}}} and we use
\sphinxcode{\sphinxupquote{≈}} for the other. (You can type \sphinxcode{\sphinxupquote{≈}} as \sphinxcode{\sphinxupquote{\textbackslash{}\textasciitilde{}\textasciitilde{}}}.)
We use \sphinxcode{\sphinxupquote{example}} instead of \sphinxcode{\sphinxupquote{instance}} so that we don’t actually
instantiate instances of the classes.


\section{Exercises}
\label{\detokenize{relations_in_lean:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Replace the \sphinxcode{\sphinxupquote{sorry}} commands in the following proofs to show that we can
create a partial order \sphinxcode{\sphinxupquote{R'​}} out of a strict partial order \sphinxcode{\sphinxupquote{R}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

\PYG{k+kd}{class} \PYG{n}{StrictPartialOrder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
  \PYG{n}{lt} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
  \PYG{n}{irrefl} \PYG{o}{:} \PYG{n}{Irreflexive} \PYG{n}{lt}
  \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{lt}

\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≺ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{StrictPartialOrder.lt}

\PYG{k+kn}{section}
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{\PYGZcb{}} \PYG{o}{[}\PYG{n}{StrictPartialOrder} \PYG{n}{A}\PYG{o}{]}

\PYG{k+kd}{def} \PYG{n}{R\PYGZsq{}} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{o}{(}\PYG{n}{a} \PYG{n+nb+bp}{≺} \PYG{n}{b}\PYG{o}{)} \PYG{n+nb+bp}{∨} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b}

\PYG{k+kn}{local} \PYG{k+kd}{infix}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ≼ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{R\PYGZsq{}}

\PYG{k+kd}{theorem} \PYG{n}{reflR\PYGZsq{}} \PYG{o}{(}\PYG{n}{a} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{a} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{k+kd}{theorem} \PYG{n}{transR\PYGZsq{}} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≼} \PYG{n}{c}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{c} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{theorem} \PYG{n}{antisymmR\PYGZsq{}} \PYG{o}{\PYGZob{}}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{a} \PYG{n+nb+bp}{≼} \PYG{n}{b}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{b} \PYG{n+nb+bp}{≼} \PYG{n}{a}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{b} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Replace the \sphinxcode{\sphinxupquote{sorry}} by a proof.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

\PYG{k+kn}{namespace} \PYG{n}{hidden}
\PYG{k+kd}{class} \PYG{n}{Preorder} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{n}{where}
    \PYG{n}{le} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
    \PYG{n}{refl} \PYG{o}{:} \PYG{n}{Reflexive} \PYG{n}{le}
    \PYG{n}{trans} \PYG{o}{:} \PYG{n}{Transitive} \PYG{n}{le}

\PYG{k+kn}{namespace} \PYG{n}{Preorder}
\PYG{k+kd}{def} \PYG{n}{S} \PYG{o}{(}\PYG{n}{a} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}\PYG{o}{)} \PYG{o}{[}\PYG{n}{Preorder} \PYG{n}{A}\PYG{o}{]} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=} \PYG{n}{le} \PYG{n}{a} \PYG{n}{b} \PYG{n+nb+bp}{∧} \PYG{n}{le} \PYG{n}{b} \PYG{n}{a}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type} \PYG{n}{u}\PYG{o}{)} \PYG{o}{[}\PYG{n}{Preorder} \PYG{n}{A}\PYG{o}{]} \PYG{o}{\PYGZob{}}\PYG{n}{x} \PYG{n}{y} \PYG{n}{z} \PYG{o}{:} \PYG{n}{A}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
  \PYG{n}{S} \PYG{n}{x} \PYG{n}{y} \PYG{n+nb+bp}{→} \PYG{n}{S} \PYG{n}{y} \PYG{n}{z} \PYG{n+nb+bp}{→} \PYG{n}{S} \PYG{n}{x} \PYG{n}{z} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{end} \PYG{n}{Preorder}
\PYG{k+kd}{end} \PYG{n}{hidden}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Only one of the following two theorems is provable. Figure out which one is true, and replace the \sphinxcode{\sphinxupquote{sorry}} command with a complete proof.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Order.Basic}

\PYG{k+kd}{axiom} \PYG{n}{A} \PYG{o}{:} \PYG{k+kt}{Type}
\PYG{k+kd}{axiom} \PYG{n}{a} \PYG{o}{:} \PYG{n}{A}
\PYG{k+kd}{axiom} \PYG{n}{b} \PYG{o}{:} \PYG{n}{A}
\PYG{k+kd}{axiom} \PYG{n}{c} \PYG{o}{:} \PYG{n}{A}
\PYG{k+kd}{axiom} \PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}
\PYG{k+kd}{axiom} \PYG{n}{Rab} \PYG{o}{:} \PYG{n}{R} \PYG{n}{a} \PYG{n}{b}
\PYG{k+kd}{axiom} \PYG{n}{Rbc} \PYG{o}{:} \PYG{n}{R} \PYG{n}{b} \PYG{n}{c}
\PYG{k+kd}{axiom} \PYG{n}{nRac} \PYG{o}{:} \PYG{n+nb+bp}{¬} \PYG{n}{R} \PYG{n}{a} \PYG{n}{c}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} Prove one of the following two theorems:}

\PYG{k+kd}{theorem} \PYG{n}{R\PYGZus{}is\PYGZus{}strict\PYGZus{}partial\PYGZus{}order} \PYG{o}{:}
  \PYG{n}{Irreflexive} \PYG{n}{R} \PYG{n+nb+bp}{∧} \PYG{n}{Transitive} \PYG{n}{R} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{theorem} \PYG{n}{R\PYGZus{}is\PYGZus{}not\PYGZus{}strict\PYGZus{}partial\PYGZus{}order} \PYG{o}{:}
  \PYG{n+nb+bp}{¬}\PYG{o}{(}\PYG{n}{Irreflexive} \PYG{n}{R} \PYG{n+nb+bp}{∧} \PYG{n}{Transitive} \PYG{n}{R}\PYG{o}{)} \PYG{o}{:=}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Complete the following proof. You may use results from Mathlib.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{section}
\PYG{k+kn}{open} \PYG{n}{Nat}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{n} \PYG{n}{m} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{≤} \PYG{l+m+mi}{4} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{end}
\end{sphinxVerbatim}

\end{enumerate}


\chapter{Functions}
\label{\detokenize{functions:functions}}\label{\detokenize{functions:id1}}\label{\detokenize{functions::doc}}
\sphinxAtStartPar
In the late nineteenth century, developments in a number of branches of mathematics pushed towards a uniform treatment of sets, functions, and relations. We have already considered sets and relations. In this chapter, we consider functions and their properties.

\sphinxAtStartPar
A function, \(f\), is ordinary understood as a mapping from a domain \(X\) to another domain \(Y\). In set\sphinxhyphen{}theoretic foundations, \(X\) and \(Y\) are arbitrary sets. We have seen that in a type\sphinxhyphen{}based system like Lean, it is natural to distinguish between types and subsets of a type. In other words, we can consider a type \sphinxcode{\sphinxupquote{X}} of elements, and a set \sphinxcode{\sphinxupquote{A}} of elements of that type. Thus, in the type\sphinxhyphen{}theoretic formulation, it is natural to consider functions between types \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y}}, and consider their behavior with respect to subsets of \sphinxcode{\sphinxupquote{X}} and \sphinxcode{\sphinxupquote{Y}}.

\sphinxAtStartPar
In everyday mathematics, however, set\sphinxhyphen{}theoretic language is common, and most mathematicians think of a function as a map between sets. When discussing functions from a mathematical standpoint, therefore, we will also adopt this language, and later switch to the type\sphinxhyphen{}theoretic representation when we talk about formalization in Lean.


\section{The Function Concept}
\label{\detokenize{functions:the-function-concept}}
\sphinxAtStartPar
If \(X\) and \(Y\) are any sets, we write \(f : X \to Y\) to express the fact that \(f\) is a function from \(X\) to \(Y\). This means that \(f\) assigns a value \(f(x)\) in \(Y\) to every element \(x\) of \(X\). The set \(X\) is called the \sphinxstyleemphasis{domain} of \(f\), and the set \(Y\) is called the \sphinxstyleemphasis{codomain}. (Some authors use the word “range” for the codomain, but today it is more common to use the word “range” for what we call the \sphinxstyleemphasis{image} of \(A\) below. We will avoid the ambiguity by avoiding the word range altogether.)

\sphinxAtStartPar
The simplest way to define a function is to give its value at every \(x\) with an explicit expression. For example, we can write any of the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Let \(f : \mathbb{N} \to \mathbb{N}\) be the function defined by \(f(n) = n + 1\).

\item {} 
\sphinxAtStartPar
Let \(g : \mathbb{R} \to \mathbb{R}\) be the function defined by \(g(x) = x^2\).

\item {} 
\sphinxAtStartPar
Let \(h : \mathbb{N} \to \mathbb{N}\) be the function defined by \(h(n) = n^2\).

\item {} 
\sphinxAtStartPar
Let \(k : \mathbb{N} \to \{0, 1\}\) be the function defined by
\begin{equation*}
\begin{split}k(n) =
  \left\{\begin{array}{ll}
    0 & \mbox{if $n$ is even} \\
    1 & \mbox{if $n$ is odd.}
  \end{array}\right.\end{split}
\end{equation*}
\end{itemize}

\sphinxAtStartPar
The ability to define functions using an explicit expression raises the foundational question as to what counts as legitimate “expression.” For the moment, let us set that question aside, and simply note that modern mathematics is comfortable with all kinds of exotic definitions. For example, we can define a function \(f : \mathbb{R} \to \{0, 1\}\) by
\begin{equation*}
\begin{split}f(x) =
  \left\{\begin{array}{ll}
    0 & \mbox{if $x$ is rational} \\
    1 & \mbox{if $x$ is irrational.}
  \end{array}\right.\end{split}
\end{equation*}
\sphinxAtStartPar
This is at odds with a view of functions as objects that are computable in some sense. It is not at all clear what it means to be presented with a real number as input, let alone whether it is possible to determine, algorithmically, whether such a number is rational or not. We will return to such issues in a later chapter.

\sphinxAtStartPar
Notice that the choice of the variables \(x\) and \(n\) in the definitions above are arbitrary. They are bound variables in that the functions being defined do not depend on \(x\) or \(n\). The values remain the same under renaming, just as the truth values of “for every \(x\), \(P(x)\)” and “for every \(y\), \(P(y)\)” are the same. Given an expression \(e(x)\) that depends on the variable \(x\), logicians often use the notation \(\lambda x \; e(x)\) to denote the function that maps \(x\) to \(e(x)\). This is called “lambda notation,” for the obvious reason, and it is often quite handy. Instead of saying “let \(f\) be the function defined by \(f(x) = x+1\),” we can say “let \(f = \lambda \; x (x + 1)\).” This is \sphinxstyleemphasis{not} common mathematical notation, and it is best to avoid it unless you are talking to logicians or computer scientists. We will see, however, that lambda notation is built in to Lean.

\sphinxAtStartPar
For any set \(X\), we can define a function \(i_X(x)\) by the equation \(i_X(x) = x\). This function is called the \sphinxstyleemphasis{identity function}. More interestingly, let \(f : X \to Y\) and \(g : Y \to Z\). We can define a new function \(k : X \to Z\) by \(k(x) = g(f(x))\). The function \(k\) is called \sphinxstyleemphasis{the composition of} \(f\) \sphinxstyleemphasis{and} \(g\) or \(f\) \sphinxstyleemphasis{composed with} \(g\) and it is written \(g \circ f\). The order is somewhat confusing; you just have to keep in mind that to evaluate the expression \(g(f(x))\) you first evaluate \(f\) on input \(x\), and then evaluate \(g\).

\sphinxAtStartPar
We think of two functions \(f, g : X \to Y\) as being equal, or the same function, when for they have the same values on every input; in other words, for every \(x\) in \(X\), \(f(x) = g(x)\). For example, if \(f, g : \mathbb{R} \to \mathbb{R}\) are defined by \(f(x) = x + 1\) and \(g(x) = 1 + x\), then \(f = g\). Notice that the statement that two functions are equal is a universal statement (that is, for the form “for every \(x\), …”).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every \(f : X \to Y\), \(f \circ i_X = f\) and \(i_Y \circ f = f\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(x\) be any element of \(X\). Then \((f \circ i_X)(x) = f(i_X(x)) = f(x)\), and \((i_Y \circ f)(x) = i_Y(f(x)) = x\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose \(f : X \to Y\) and \(g : Y \to X\) satisfy \(g \circ f = i_X\). Remember that this means that \(g(f(x)) = x\) for every \(x\) in \(X\). In that case, \(g\) is said to be a \sphinxstyleemphasis{left inverse} to \(f\), and \(f\) is said to be a \sphinxstyleemphasis{right inverse} to \(g\). Here are some examples:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Define \(f, g : \mathbb{R} \to \mathbb{R}\) by \(f(x) = x + 1\) and \(g(x) = x - 1\). Then \(g\) is both a left and a right inverse to \(f\), and vice\sphinxhyphen{}versa.

\item {} 
\sphinxAtStartPar
Write \(\mathbb{R}^{\geq 0}\) to denote the nonnegative reals. Define \(f : \mathbb{R} \to \mathbb{R}^{\geq 0}\) by \(f(x) = x^2\), and define \(g : \mathbb{R}^{\geq 0} \to \mathbb{R}\) by \(g(x) = \sqrt x\). Then \(f(g(x)) = (\sqrt x)^2 = x\) for every \(x\) in the domain of \(g\), so \(f\) is a left inverse to \(g\), and \(g\) is a right inverse to \(f\). On the other hand, \(g(f(x)) = \sqrt{x^2} = | x |\), which is not the same as \(x\) when \(x\) is negative. So \(g\) is not a left inverse to \(f\), and \(f\) is not a right inverse to \(g\).

\end{itemize}

\sphinxAtStartPar
The following fact is not at all obvious, even though the proof is short:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(f : X \to Y\) has a left inverse, \(h\), and a right inverse, \(k\). Then \(h = k\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(y\) be any element in \(Y\). The idea is to compute \(h(f(k(y))\) in two different ways. Since \(h\) is a left inverse to \(f\), we have \(h(f(k(y))) = k(y)\). On the other hand, since \(k\) is a right inverse to \(f\), \(f(k(y)) = y\), and so \(h(f(k(y)) = h(y)\). So \(k(y) = h(y)\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
If \(g\) is both a right and left inverse to \(f\), we say that \(g\) is simply the inverse of \(f\). A function \(f\) may have more than one left or right inverse (we leave it to you to cook up examples), but it can have at most one inverse.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(g_1, g_2 : Y \to X\) are both inverses to \(f\). Then \(g_1 = g_2\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} This follows from the previous proposition, since (say) \(g_1\) is a left inverse to \(f\), and \(g_2\) is a right inverse.


\bigskip\hrule\bigskip


\sphinxAtStartPar
When \(f\) has an inverse, \(g\), this justifies calling \(g\) \sphinxstyleemphasis{the} inverse to \(f\), and writing \(f^{-1}\) to denote \(g\). Notice that if \(f^{-1}\) is an inverse to \(f\), then \(f\) is an inverse to \(f^{-1}\). So if \(f\) has an inverse, then so does \(f^{-1}\), and \((f^{-1})^{-1} = f\). For any set \(A\), clearly we have \(i_X^{-1} = i_X\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(f : X \to Y\) and \(g : Y \to Z\). If \(h : Y \to X\) is a left inverse to \(f\) and \(k : Z \to Y\) is a left inverse to \(g\), then \(h \circ k\) is a left inverse to \(g \circ f\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} For every \(x\) in \(X\),
\begin{equation*}
\begin{split}(h \circ k) \circ (g \circ f) (x) = h(k(g(f(x)))) = h(f(x)) = x.\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Corollary.} The previous proposition holds with “left” replaced by “right.”

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Switch the role of \(f\) with \(h\) and \(g\) with \(k\) in the previous proposition.

\sphinxAtStartPar
\sphinxstylestrong{Corollary.} If \(f : X \to Y\) and \(g : Y \to Z\) both have inverses, then \((f \circ g)^{-1} = g^{-1} \circ f^{-1}\).


\bigskip\hrule\bigskip



\section{Injective, Surjective, and Bijective Functions}
\label{\detokenize{functions:injective-surjective-and-bijective-functions}}\label{\detokenize{functions:id2}}
\sphinxAtStartPar
A function \(f : X \to Y\) is said to be \sphinxstyleemphasis{injective}, or an \sphinxstyleemphasis{injection}, or \sphinxstyleemphasis{one\sphinxhyphen{}one}, if given any \(x_1\) and \(x_2\) in \(A\), if \(f(x_1) = f(x_2)\), then \(x_1 = x_2\). Notice that the conclusion is equivalent to its contrapositive: if \(x_1 \neq x_2\), then \(f(x_1) \neq f(x_2)\). So \(f\) is injective if it maps distinct element of \(X\) to distinct elements of \(Y\).

\sphinxAtStartPar
A function \(f : X \to Y\) is said to be \sphinxstyleemphasis{surjective}, or a \sphinxstyleemphasis{surjection}, or \sphinxstyleemphasis{onto}, if for every element \(y\) of \(Y\), there is an \(x\) in \(X\) such that \(f(x) = y\). In other words, \(f\) is surjective if every element in the codomain is the value of \(f\) at some element in the domain.

\sphinxAtStartPar
A function \(f : X \to Y\) is said to be \sphinxstyleemphasis{bijective}, or a \sphinxstyleemphasis{bijection}, or a \sphinxstyleemphasis{one\sphinxhyphen{}to\sphinxhyphen{}one correspondence}, if it is both injective and surjective. Intuitively, if there is a bijection between \(X\) and \(Y\), then \(X\) and \(Y\) have the same size, since \(f\) makes each element of \(X\) correspond to exactly one element of \(Y\) and vice\sphinxhyphen{}versa. For example, it makes sense to interpret the statement that there were four Beatles as the statement that there is a bijection between the set \(\{1, 2, 3, 4\}\) and the set \(\{ \text{John, Paul, George, Ringo} \}\). If we claimed that there were \sphinxstyleemphasis{five} Beatles, as evidenced by the function \(f\) which assigns 1 to John, 2 to Paul, 3 to George, 4 to Ringo, and 5 to John, you should object that we double\sphinxhyphen{}counted John—that is, \(f\) is not injective. If we claimed there were only three Beatles, as evidenced by the function \(f\) which assigns 1 to John, 2 to Paul, and 3 to George, you should object that we left out poor Ringo—that is, \(f\) is not surjective.

\sphinxAtStartPar
The next two propositions show that these notions can be cast in terms of the existence of inverses.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(f : X \to Y\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f\) has a left inverse, then \(f\) is injective.

\item {} 
\sphinxAtStartPar
If \(f\) has a right inverse, then \(f\) is surjective.

\item {} 
\sphinxAtStartPar
If \(f\) has an inverse, then it is \(f\) bijective.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Proof.} For the first claim, suppose \(f\) has a left inverse \(g\), and suppose \(f(x_1) = f(x_2)\). Then \(g(f(x_1)) = g(f(x_2))\), and so \(x_1 = x_2\).

\sphinxAtStartPar
For the second claim, suppose \(f\) has a right inverse \(h\). Let \(y\) be any element of \(Y\), and let \(x = g(y)\). Then \(f(x) = f(g(y)) = y\).

\sphinxAtStartPar
The third claim follows from the first two.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The following proposition is more interesting, because it requires us to define new functions, given hypotheses on \(f\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(f : X \to Y\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(X\) is nonempty and \(f\) is injective, then \(f\) has a left inverse.

\item {} 
\sphinxAtStartPar
If \(f\) is surjective, then \(f\) has a right inverse.

\item {} 
\sphinxAtStartPar
If \(f\) if bijective, then it has an inverse.

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Proof.} For the first claim, let \(\hat x\) be any element of \(X\), and suppose \(f\) is injective. Define \(g : Y \to X\) by setting \(g(y)\) equal to any \(x\) such that \(f(x) = y\), if there is one, and \(\hat x\) otherwise. Now, suppose \(g(f(x)) = x'\). By the definition of \(g\), \(x'\) has to have the property that \(f(x) = f(x')\). Since \(f\) is injective, \(x = x'\), so \(g(f(x)) = x\).

\sphinxAtStartPar
For the second claim, because \(f\) is surjective, we know that for every \(y\) in \(Y\) there is any \(x\) such that \(f(x) = y\). Define \(h : B \to A\) by again setting \(h(y)\) equal to any such \(x\). (In contrast to the previous paragraph, here we know that such an \(x\) exists, but it might not be unique.) Then, by the definition of \(h\), we have \(f(h(y)) = y\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that the definition of \(g\) in the first part of the proof requires the function to “decide” whether there is an \(x\) in \(X\) such that \(f(x) = y\). There is nothing mathematically dubious about this definition, but in many situations, this cannot be done \sphinxstyleemphasis{algorithmically}; in other words, \(g\) might not be computable from the data. More interestingly, the definition of \(h\) in the second part of the proof requires the function to “choose” a suitable value of \(x\) from among potentially many candidates. We will see in \hyperref[\detokenize{axiomatic_foundations:the-remaining-axioms}]{Section \ref{\detokenize{axiomatic_foundations:the-remaining-axioms}}} that this is a version of the \sphinxstyleemphasis{axiom of choice}. In the early twentieth century, the use of the axiom of choice in mathematics was hotly debated, but today it is commonplace.

\sphinxAtStartPar
Using these equivalences and the results in the previous section, we can prove the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(f : X \to B\) and \(g : Y \to Z\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f\) and \(g\) are injective, then so is \(g \circ f\).

\item {} 
\sphinxAtStartPar
If \(f\) and \(g\) are surjective, then so is \(g \circ f\).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Proof.} If \(f\) and \(g\) are injective, then they have left inverses \(h\) and \(k\), respectively, in which case \(h \circ k\) is a left inverse to \(g \circ f\). The second statement is proved similarly.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can prove these two statements, however, without mentioning inverses at all. We leave that to you as an exercise.

\sphinxAtStartPar
Notice that the expression \(f(n) = 2 n\) can be used to define infinitely many functions with domain \(\mathbb{N}\), such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
a function \(f : \mathbb{N} \to \mathbb{N}\)

\item {} 
\sphinxAtStartPar
a function \(f : \mathbb{N} \to \mathbb{R}\)

\item {} 
\sphinxAtStartPar
a function \(f: \mathbb{N} \to \{ n \mid n \text{ is even} \}\)

\end{itemize}

\sphinxAtStartPar
Only the third one is surjective. Thus a specification of the function’s codomain as well as the domain is essential to making sense of whether a function is surjective.


\section{Functions and Subsets of the Domain}
\label{\detokenize{functions:functions-and-subsets-of-the-domain}}
\sphinxAtStartPar
Suppose \(f\) is a function from \(X\) to \(Y\). We may wish to reason about the behavior of \(f\) on some subset \(A\) of \(X\). For example, we can say that \(f\) \sphinxstyleemphasis{is injective on} \(A\) if for every \(x_1\) and \(x_2\) in \(A\), if \(f(x_1) = f(x_2)\), then \(x_1 = x_2\).

\sphinxAtStartPar
If \(f\) is a function from \(X\) to \(Y\) and \(A\) is a subset of \(X\), we write \(f[A]\) to denote the \sphinxstyleemphasis{image of} \(f\) \sphinxstyleemphasis{on} \(A\), defined by
\begin{equation*}
\begin{split}f[A] = \{ y \in Y \mid y = f(x) \; \mbox{for some $x$ in $A$} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
In words, \(f[A]\) is the set of elements of \(Y\) that are “hit” by elements of \(A\) under the mapping \(f\). Notice that there is an implicit existential quantifier here, so that reasoning about images invariably involves the corresponding rules.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(f : X \to Y\), and \(A\) is a subset of \(X\). Then for any \(x\) in \(A\), \(f(x)\) is in \(f[A]\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By definition, \(f(x)\) is in \(f[A]\) if and only if there is some \(x'\) in \(A\) such that \(f(x') = f(x)\). But that holds for \(x' = x\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(f : X \to Y\) and \(g : Y \to Z\). Let \(A\) be a subset of \(X\). Then
\begin{equation*}
\begin{split}(g \circ f)[A] = g[f[A]].\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(z\) is in \((g \circ f)[A]\). Then for some \(x \in A\), \(z = (g \circ f)(x) = g(f(x))\). By the previous proposition, \(f(x)\) is in \(f[A]\). Again by the previous proposition, \(g(f(x))\) is in \(g[f[A]]\).

\sphinxAtStartPar
Conversely, suppose \(z\) is in \(g[f[A]]\). Then there is a \(y\) in \(f[A]\) such that \(f(y) = z\), and since \(y\) is in \(f[D]\), there is an \(x\) in \(A\) such that \(f(x) = y\). But then \((g \circ f)(x) = g(f(x)) = g(y) = z\), so \(z\) is in \((g \circ f)[A]\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that if \(f\) is a function from \(X\) to \(Y\), then \(f\) is surjective if and only if \(f[X] = Y\). So the previous proposition is a generalization of the fact that the composition of surjective functions is surjective.

\sphinxAtStartPar
Suppose \(f\) is a function from \(X\) to \(Y\), and \(A\) is a subset of \(X\). We can \sphinxstyleemphasis{view} \(f\) as a function from \(A\) to \(Y\), by simply ignoring the behavior of \(f\) on elements outside of \(A\). Properly speaking, this is another function, denoted \(f \upharpoonright A\) and called “the restriction of \(f\) to \(A\).” In other words, given \(f : X \to Y\) and \(A \subseteq X\), \(f \upharpoonright A : A \to Y\) is the function defined by \((f \upharpoonright A)(x) = x\) for every \(x\) in \(A\). Notice that now “\(f\) is injective on \(A\)” means simply that the restriction of \(f\) to \(A\) is injective.

\sphinxAtStartPar
There is another important operation on functions, known as the \sphinxstyleemphasis{preimage}. If \(f : X \to Y\) and \(B \subseteq Y\), then the \sphinxstyleemphasis{preimage of} \(B\) \sphinxstyleemphasis{under} \(f\), denoted \(f^{-1}[B]\), is defined by
\begin{equation*}
\begin{split}f^{-1}[B] = \{ x \in X \mid f(x) \in B \},\end{split}
\end{equation*}
\sphinxAtStartPar
that is, the set of elements of \(X\) that get mapped into \(B\). Notice that this makes sense even if \(f\) does not have an inverse; for a given \(y\) in \(B\), there may be no \(x\)’s with the property \(f(x) \in B\), or there may be many. If \(f\) has an inverse, \(f^{-1}\), then for every \(y\) in \(B\) there is exactly one \(x \in X\) with the property \(f(x) \in B\), in which case, \(f^{-1}[B]\) means the same thing whether you interpret it as the image of \(B\) under \(f^{-1}\) or the preimage of \(B\) under \(f\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Suppose \(f : X \to Y\) and \(g : Y \to Z\). Let \(C\) be a subset of \(Z\). Then
\begin{equation*}
\begin{split}(g \circ f)^{-1}[C] = f^{-1}[g^{-1}[C]].\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Proof.} For any \(y\) in \(C\), \(y\) is in \((g \circ f)^{-1}[C]\) if and only if \(g(f(y))\) is in \(C\). This, in turn, happens if and only if \(f(y)\) is in \(g^{-1}[C]\), which in turn happens if and only if \(y\) is in \(f^{-1}[g^{-1}[C]]\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here we give a long list of facts properties of images and preimages. Here, \(f\) denotes an arbitrary function from \(X\) to \(Y\), \(A, A_1, A_2, \ldots\) denote arbitrary subsets of \(X\), and \(B, B_1, B_2, \ldots\) denote arbitrary subsets of \(Y\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \subseteq f^{-1}[f[A]]\), and if \(f\) is injective, \(A = f^{-1}[f[A]]\).

\item {} 
\sphinxAtStartPar
\(f[f^{-1}[B]] \subseteq B\), and if \(f\) is surjective, \(B = f[f^{-1}[B]]\).

\item {} 
\sphinxAtStartPar
If \(A_1 \subseteq A_2\), then \(f[A_1] \subseteq f[A_2]\).

\item {} 
\sphinxAtStartPar
If \(B_1 \subseteq B_2\), then \(f^{-1}[B_1] \subseteq f^{-1}[B_2]\).

\item {} 
\sphinxAtStartPar
\(f[A_1 \cup A_2] = f[A_1] \cup f[A_2]\).

\item {} 
\sphinxAtStartPar
\(f^{-1}[B_1 \cup B_2] = f^{-1}[B_1] \cup f^{-1}[B_2]\).

\item {} 
\sphinxAtStartPar
\(f[A_1 \cap A_2] \subseteq f[A_1] \cap f[A_2]\), and if \(f\) is injective, \(f[A_1 \cap A_2] = f[A_1] \cap f[A_2]\).

\item {} 
\sphinxAtStartPar
\(f^{-1}[B_1 \cap B_2] = f^{-1}[B_1] \cap f^{-1}[B_2]\).

\item {} 
\sphinxAtStartPar
\(f[A_1] \setminus f[A_2] \subseteq f[A_1 \setminus A_2]\).

\item {} 
\sphinxAtStartPar
\(f^{-1}[B_1] \setminus f^{-1}[B_2] \subseteq f^{-1}[B_1 \setminus B_2]\).

\item {} 
\sphinxAtStartPar
\(f[A] \cap B = f[A \cap f^{-1}[B]]\).

\item {} 
\sphinxAtStartPar
\(f[A] \cup B \supseteq f[A \cup f^{-1}[B]]\).

\item {} 
\sphinxAtStartPar
\(A \cap f^{-1}[B] \subseteq f^{-1}[f[A] \cap B]\).

\item {} 
\sphinxAtStartPar
\(A \cup f^{-1}[B] \subseteq f^{-1}[f[A] \cup B]\).

\end{itemize}

\sphinxAtStartPar
Proving identities like this is typically a matter of unfolding definitions and using basic logical inferences. Here is an example.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(X\) and \(Y\) be sets, \(f : X \to Y\), \(A \subseteq X\), and \(B \subseteq Y\). Then \(f[A] \cap B = f[A \cap f^{-1}[B]]\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(y \in f[A] \cap B\). Then \(y \in B\), and for some \(x \in A\), \(f(x) = y\). But this means that \(x\) is in \(f^{-1}[B]\), and so \(x \in A \cap f^{-1}[B]\). Since \(f(x) = y\), we have \(y \in f[A \cap f^{-1}[B]]\), as needed.

\sphinxAtStartPar
Conversely, suppose \(y \in f[A \cap f^{-1}[B]]\). Then for some \(x \in A \cap f^{-1}[B]\), we have \(f(x) = y\). For this \(x\), have \(x \in A\) and \(f(x) \in B\). Since \(f(x) = y\), we have \(y \in B\), and since \(x \in A\), we also have \(y \in f[A]\), as required.


\bigskip\hrule\bigskip



\section{Functions and Relations}
\label{\detokenize{functions:functions-and-relations}}\label{\detokenize{functions:id3}}
\sphinxAtStartPar
A binary relation \(R(x,y)\) on \(A\) and \(B\) is \sphinxstyleemphasis{functional} if for every \(x\) in \(A\) there exists a unique \(y\) in \(B\) such that \(R(x,y)\). If \(R\) is a functional relation, we can define a function \(f_R : X \to B\) by setting \(f_R(x)\) to be equal to the unique \(y\) in \(B\) such that \(R(x,y)\). Conversely, it is not hard to see that if \(f : X \to B\) is any function, the relation \(R_f(x, y)\) defined by \(f(x) = y\) is a functional relation. The relation \(R_f(x,y)\) is known as the \sphinxstyleemphasis{graph} of \(f\).

\sphinxAtStartPar
It is not hard to check that functions and relations travel in pairs: if \(f\) is the function associated with a functional relation \(R\), then \(R\) is the functional relation associated the function \(f\), and vice\sphinxhyphen{}versa. In set\sphinxhyphen{}theoretic foundations, a function is often defined to be a functional relation. Conversely, we have seen that in type\sphinxhyphen{}theoretic foundations like the one adopted by Lean, relations are often defined to be certain types of functions. We will discuss these matters later on, and in the meanwhile only remark that in everyday mathematical practice, the foundational details are not so important; what is important is simply that every function has a graph, and that any functional relation can be used to define a corresponding function.

\sphinxAtStartPar
So far, we have been focusing on functions that take a single argument. We can also consider functions \(f(x, y)\) or \(g(x, y, z)\) that take multiple arguments. For example, the addition function \(f(x, y) = x + y\) on the integers takes two integers and returns an integer. Remember, we can consider binary functions, ternary functions, and so on, and the number of arguments to a function is called its “arity.” One easy way to make sense of functions with multiple arguments is to think of them as unary functions from a cartesian product. We can think of a function \(f\) which takes two arguments, one in \(A\) and one in \(B\), and returns an argument in \(C\) as a unary function from \(A \times B\) to \(C\), whereby \(f(a, b)\) abbreviates \(f((a, b))\). We have seen that in dependent type theory (and in Lean) it is more convenient to think of such a function \(f\) as a function which takes an element of \(A\) and returns a function from \(B \to C\), so that \(f(a, b)\) abbreviates \((f(a))(b)\). Such a function \(f\) maps \(A\) to \(B \to C\), where \(B \to C\) is the set of functions from \(B\) to \(C\).

\sphinxAtStartPar
We will return to these different ways of modeling functions of higher arity later on, when we consider set\sphinxhyphen{}theoretic and type\sphinxhyphen{}theoretic foundations. One again, we remark that in ordinary mathematics, the foundational details do not matter much. The two choices above are inter\sphinxhyphen{}translatable, and sanction the same principles for reasoning about functions informally.

\sphinxAtStartPar
In mathematics, we often also consider the notion of a \sphinxstyleemphasis{partial function} from \(X\) to \(Y\), which is really a function from some subset of \(X\) to \(Y\). The fact that \(f\) is a partial function from \(X\) to \(Y\) is sometimes written \(f : X \nrightarrow Y\), which should be interpreted as saying that \(f : A \to Y\) for some subset \(A\) of \(Y\). Intuitively, we think of \(f\) as a function from \(X \to Y\) which is simply “undefined” at some of its inputs; for example, we can think of \(f : \mathbb{R} \nrightarrow \mathbb{R}\) defined by \(f(x) = 1 / x\), which is undefined at \(x = 0\), so that in reality \(f : \mathbb{R} \setminus \{ 0 \} \to R\). The set \(A\) is sometimes called the \sphinxstyleemphasis{domain of} \(f\), in which case, there is no good name for \(X\); others continue to call \(X\) the domain, and refer to \(A\) as the \sphinxstyleemphasis{domain of definition}. To indicate that a function \(f\) is defined at \(x\), that is, that \(x\) is in the domain of definition of \(f\), we sometimes write \(f(x) \downarrow\). If \(f\) and \(g\) are two partial functions from \(X\) to \(Y\), we write \(f(x) \simeq g(x)\) to mean that either \(f\) and \(g\) are both defined at \(x\) and have the same value, or are both undefined at \(x\). Notions of injectivity, surjectivity, and composition are extended to partial functions, generally as you would expect them to be.

\sphinxAtStartPar
In terms of relations, a partial function \(f\) corresponds to a relation \(R_f(x,y)\) such that for every \(x\) there is at most one \(y\) such that \(R_f(x,y)\) holds. Mathematicians also sometimes consider \sphinxstyleemphasis{multifunctions} from \(X\) to \(Y\), which correspond to relations \(R_f(x,y)\) such that for every \(x\) in \(X\), there is \sphinxstyleemphasis{at least} one \(y\) such that \(R_f(x,y)\) holds. There may be many such \(y\); you can think of these as functions which have more than one output value. If you think about it for a moment, you will see that a \sphinxstyleemphasis{partial multifunction} is essentially nothing more than an arbitrary relation.


\section{Exercises}
\label{\detokenize{functions:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Let \(f\) be any function from \(X\) to \(Y\), and let \(g\) be any function from \(Y\) to \(Z\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Show that if \(g \circ f\) is injective, then \(f\) is injective.

\item {} 
\sphinxAtStartPar
Give an example of functions \(f\) and \(g\) as above, such that that \(g \circ f\) is injective, but \(g\) is not injective.

\item {} 
\sphinxAtStartPar
Show that if \(g \circ f\) is injective and \(f\) is surjective, then \(g\) is injective.

\end{itemize}

\item {} 
\sphinxAtStartPar
Let \(f\) and \(g\) be as in the last problem. Suppose \(g \circ f\) is surjective.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Is \(f\) necessarily surjective? Either prove that it is, or give a counterexample.

\item {} 
\sphinxAtStartPar
Is \(g\) necessarily surjective? Either prove that it is, or give a counterexample.

\end{itemize}

\item {} 
\sphinxAtStartPar
A function \(f\) from \(\mathbb{R}\) to \(\mathbb{R}\) is said to be
\sphinxstyleemphasis{strictly increasing} if whenever \(x_1 < x_2\), \(f(x_1) < f(x_2)\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Show that if \(f : \mathbb{R} \to \mathbb{R}\) is strictly increasing, then it is injective (and hence it has a left inverse).

\item {} 
\sphinxAtStartPar
Show that if \(f : \mathbb{R} \to \mathbb{R}\) is strictly increasing, and \(g\) is a right inverse to \(f\), then \(g\) is
strictly increasing.

\end{itemize}

\item {} 
\sphinxAtStartPar
Let \(f : X \to Y\) be any function, and let \(A\) and \(B\) be subsets of \(X\). Show that \(f [A \cup B] = f[A] \cup f[B]\).

\item {} 
\sphinxAtStartPar
Let \(f: X \to Y\) be any function, and let \(A\) and \(B\) be any subsets of \(X\). Show \(f[A] \setminus f[B] \subseteq f[A \setminus B]\).

\item {} 
\sphinxAtStartPar
Define notions of composition and inverse for binary relations that generalize the notions for functions.

\end{enumerate}


\chapter{Functions in Lean}
\label{\detokenize{functions_in_lean:functions-in-lean}}\label{\detokenize{functions_in_lean::doc}}

\section{Functions and Symbolic Logic}
\label{\detokenize{functions_in_lean:functions-and-symbolic-logic}}
\sphinxAtStartPar
Let us now consider functions in formal terms. Even though we have avoided the use of quantifiers and logical symbols in the definitions in the last chapter, by now you should be seeing them lurking beneath the surface. That fact that two functions \(f, g : X \to Y\) are equal if and only if they take the same values at every input can be expressed as follows:
\begin{equation*}
\begin{split}\forall x \in X \; (f(x) = g(x)) \leftrightarrow f = g .\end{split}
\end{equation*}
\sphinxAtStartPar
This principle is a known as \sphinxstyleemphasis{function extensionality}, analogous to the principle of extensionality for sets, discussed in \hyperref[\detokenize{sets_in_lean:sets-in-lean-basics}]{Section \ref{\detokenize{sets_in_lean:sets-in-lean-basics}}}. Recall that the notation \(\forall x \in X \; P(x)\) abbreviates \(\forall x \; (x \in X \to P(x))\), and \(\exists x \in X \; P(x)\) abbreviates \(\exists x \; (x \in X \wedge P(x))\), thereby relativizing the quantifiers to \(X\).

\sphinxAtStartPar
We can avoid set\sphinxhyphen{}theoretic notation if we assume we are working in a logical formalism with basic types for \(X\) and \(Y\), so that we can specify that \(x\) ranges over \(X\). In that case, we will write instead
\begin{equation*}
\begin{split}\forall x : X \; (f(x) = g(x) \leftrightarrow f = g)\end{split}
\end{equation*}
\sphinxAtStartPar
to indicate that the quantification is over \(X\). Henceforth, we will assume that all our variables range over some type, though we will sometimes omit the types in the quantifiers when they can be inferred from context.

\sphinxAtStartPar
The function \(f\) is injective if it satisfies
\begin{equation*}
\begin{split}\forall x_1, x_2 : X \; (f(x_1) = f(x_2) \to x_1 = x_2),\end{split}
\end{equation*}
\sphinxAtStartPar
and \(f\) is surjective if
\begin{equation*}
\begin{split}\forall y : Y \; \exists x : X \; f(x) = y.\end{split}
\end{equation*}
\sphinxAtStartPar
If \(f : X \to Y\) and \(g: Y \to X\), \(g\) is a left inverse to \(f\) if
\begin{equation*}
\begin{split}\forall x : X \; g(f(x)) = x.\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that this is a universal statement, and it is equivalent to the statement that \(f\) is a right inverse to \(g\).

\sphinxAtStartPar
Remember that in logic it is common to use lambda notation to define functions. We can denote the identity function by \(\lambda x \; x\), or perhaps \(\lambda x : X \; x\) to emphasize that the domain of the function is \(X\). If \(f : X \to Y\) and \(g : Y \to Z\), we can define the composition \(g \circ f\) by \(g \circ f = \lambda x : X \; g(f(x))\).

\sphinxAtStartPar
Also remember that if \(P(x)\) is any predicate, then in first\sphinxhyphen{}order logic we can assert that there exists a unique \(x\) satisfying \(P(x)\), written \(\exists! x \; P(x)\), with the conjunction of the following two statements:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; P(x)\)

\item {} 
\sphinxAtStartPar
\(\forall x_1, x_2 \; (P(x_1) \wedge P(x_2) \to x_1 = x_2)\)

\end{itemize}

\sphinxAtStartPar
Equivalently, we can write
\begin{equation*}
\begin{split}\exists (P(x) \wedge \forall x' \; (P(x') \to x' = x)).\end{split}
\end{equation*}
\sphinxAtStartPar
Assuming \(\exists! x \; P(x)\), the following two statements are equivalent:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists x \; (P(x) \wedge Q(x))\)

\item {} 
\sphinxAtStartPar
\(\forall x \; (P(x) \to Q(x))\)

\end{itemize}

\sphinxAtStartPar
and both can be taken to assert that “the \(x\) satisfying \(P\) also satisfies \(Q\).”

\sphinxAtStartPar
A binary relation \(R\) on \(X\) and \(Y\) is functional if it satisfies
\begin{equation*}
\begin{split}\forall x \; \exists! y \; R(x,y).\end{split}
\end{equation*}
\sphinxAtStartPar
In that case, a logician might use \sphinxstyleemphasis{iota notation},
\begin{equation*}
\begin{split}f(x) = \iota y \; R(x, y)\end{split}
\end{equation*}
\sphinxAtStartPar
to define \(f(x)\) to be equal to the unique \(y\) satisfying \(R(x,y)\). If \(R\) satisfies the weaker property
\begin{equation*}
\begin{split}\forall x \; \exists y \; R(x,y),\end{split}
\end{equation*}
\sphinxAtStartPar
a logician might use the \sphinxstyleemphasis{Hilbert epsilon} to define a function
\begin{equation*}
\begin{split}f(x) = \varepsilon y \; R(x, y)\end{split}
\end{equation*}
\sphinxAtStartPar
to “choose” a value of \(y\) satisfying \(R(x, y)\). As we have noted above, this is an implicit use of the axiom of choice.


\section{Second\sphinxhyphen{} and Higher\sphinxhyphen{}Order Logic}
\label{\detokenize{functions_in_lean:second-and-higher-order-logic}}
\sphinxAtStartPar
In contrast to first\sphinxhyphen{}order logic, where we start with a fixed stock of function and relation symbols, the topics we have been considering in the last few chapters encourage us to consider a more expressive language with variables ranging over functions and relations as well. For example, saying that a function \(f : X \to Y\) has a left\sphinxhyphen{}inverse implicitly involves a quantifying over functions,
\begin{equation*}
\begin{split}\exists g \; \forall x \; g(f(x)) = x.\end{split}
\end{equation*}
\sphinxAtStartPar
The theorem that asserts that if any function \(f\) from \(X\) to \(Y\) is injective then it has a left\sphinxhyphen{}inverse can be expressed as follows:
\begin{equation*}
\begin{split}\forall x_1, x_2 \; (f(x_1) = f(x_2) \to x_1 = x_2) \to \exists g \; \forall x \; g(f(x)) = x.\end{split}
\end{equation*}
\sphinxAtStartPar
Similarly, saying that two sets \(X\) and \(Y\) have a one\sphinxhyphen{}to\sphinxhyphen{}one correspondence asserts the existence of a function \(f : X \to Y\) as well as an inverse to \(f\). For another example, in \hyperref[\detokenize{functions:functions-and-relations}]{Section \ref{\detokenize{functions:functions-and-relations}}} we asserted that every functional relation gives rise to a corresponding function, and vice\sphinxhyphen{}versa.

\sphinxAtStartPar
What makes these statements interesting is that they involve quantification, both existential and universal, over functions and relations. This takes us outside the realm of first\sphinxhyphen{}order logic. One option is to develop a theory in the language of first\sphinxhyphen{}order logic in which the universe contains functions and relations as objects; we will see later that this is what axiomatic set theory does. An alternative is to extend first\sphinxhyphen{}order logic to involve new kinds of quantifiers and variables, to range over functions and relations. This is what higher\sphinxhyphen{}order logic does.

\sphinxAtStartPar
There are various ways to go about this. In view of the relationship between functions and relations described earlier, one can take relations as basic, and define functions in terms of them, or vice\sphinxhyphen{}versa. The following formulation of higher\sphinxhyphen{}order logic, due to the logician Alonzo Church, follows the latter approach. It is sometimes known as \sphinxstyleemphasis{simple type theory}.

\sphinxAtStartPar
Start with some basic types, \(X, Y, Z, \ldots\) and a special type, \(\mathrm{Prop}\), of propositions. Add the following two rules to build new types:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(U\) and \(V\) are types, so is \(U \times V\).

\item {} 
\sphinxAtStartPar
If \(U\) and \(V\) are types, so is \(U \to V\).

\end{itemize}

\sphinxAtStartPar
The first intended to denote the type of ordered pairs \((u, v)\), where \(u\) is in \(U\) and \(v\) is in \(V\). The second is intended to denote the type of functions from \(U\) to \(V\). Simple type theory now adds the following means of forming expressions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(u\) is of type \(U\) and \(v\) is of type \(V\), \((u, v)\) is of type \(U \times V\).

\item {} 
\sphinxAtStartPar
If \(p\) is of type \(U \times V\), then \((p)_1\) is of type \(U\) and \((p)_2\) if of type \(V\). (These are intended to denote the first and second element of the pair \(p\).)

\item {} 
\sphinxAtStartPar
If \(x\) is a variable of type \(U\), and \(v\) is any expression of type \(V\), then \(\lambda x \; v\) is of type \(U \to V\).

\item {} 
\sphinxAtStartPar
If \(f\) is of type \(U \to V\) and \(u\) is of type \(U\), \(f(u)\) is of type \(V\).

\end{itemize}

\sphinxAtStartPar
In addition, simple type theory provides all the means we have in first\sphinxhyphen{}order logic—boolean connectives, quantifiers, and equality—to build propositions.

\sphinxAtStartPar
A function \(f(x, y)\) which takes elements of \(X\) and \(Y\) to a type \(Z\) is viewed as an object of type \(X \times Y \to Z\). Similarly, a binary relation \(R(x,y)\) on \(X\) and \(Y\) is viewed as an object of type \(X \times Y \to \mathrm{Prop}\). What makes higher\sphinxhyphen{}order logic “higher order” is that we can iterate the function type operation indefinitely. For example, if \(\mathbb{N}\) is the type of natural numbers, \(\mathbb{N} \to \mathbb{N}\) denotes the type of functions from the natural numbers to the natural numbers, and \((\mathbb{N} \to \mathbb{N}) \to \mathbb{N}\) denotes the type of functions \(F(f)\) which take a function as argument, and return a natural number.

\sphinxAtStartPar
We have not specified the syntax and rules of higher\sphinxhyphen{}order logic very carefully. This is done in a number of more advanced logic textbooks. The fragment of higher\sphinxhyphen{}order logic which allows only functions and relations on the basic types (without iterating these constructions) is known as second\sphinxhyphen{}order logic.

\sphinxAtStartPar
These notions should seem familiar; we have been using these constructions, with similar notation, in Lean. Indeed, Lean’s logic is an even more elaborate and expressive system of logic, which fully subsumes all the notions of higher\sphinxhyphen{}order logic we have discussed here.


\section{Functions in Lean}
\label{\detokenize{functions_in_lean:id1}}
\sphinxAtStartPar
The fact that the notions we have been discussing have such a straightforward logical form means that it is easy to define them in Lean. The main difference between the formal representation in Lean and the informal representation above is that, in Lean, we distinguish between a type \sphinxcode{\sphinxupquote{X}} and a subset
\sphinxcode{\sphinxupquote{A : Set X}} of that type.

\sphinxAtStartPar
In Lean’s library, composition and identity are defined as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{X} \PYG{n}{Y} \PYG{n}{Z} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{def} \PYG{n}{comp} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{Z}\PYG{o}{)} \PYG{o}{(}\PYG{n}{g} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Z} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦} \PYG{n}{f} \PYG{o}{(}\PYG{n}{g} \PYG{n}{x}\PYG{o}{)}

\PYG{k+kd}{infixr}\PYG{o}{:}\PYG{l+m+mi}{50} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ ∘ }\PYG{l+s+s2}{\PYGZdq{}} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{comp}

\PYG{k+kd}{def} \PYG{n}{id} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{:} \PYG{n}{X} \PYG{o}{:=}
\PYG{n}{x}
\end{sphinxVerbatim}

\sphinxAtStartPar
Ordinarily, we use \sphinxcode{\sphinxupquote{funext}} (for “function extensionality”) to prove that two functions are equal.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{f} \PYG{n}{g} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{o}{:=}
\PYG{n}{funext} \PYG{n}{h}
\end{sphinxVerbatim}

\sphinxAtStartPar
But Lean can prove some basic identities by simply unfolding definitions and simplifying expressions, using reflexivity.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{lemma} \PYG{n}{left\PYGZus{}id} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{id} \PYG{n+nb+bp}{∘} \PYG{n}{f} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{rfl}

\PYG{k+kd}{lemma} \PYG{n}{right\PYGZus{}id} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{∘} \PYG{n}{id} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{rfl}

\PYG{k+kd}{theorem} \PYG{n}{comp.assoc} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{Z} \PYG{n+nb+bp}{→} \PYG{n}{W}\PYG{o}{)} \PYG{o}{(}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{Z}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:}
  \PYG{o}{(}\PYG{n}{f} \PYG{n+nb+bp}{∘} \PYG{n}{g}\PYG{o}{)} \PYG{n+nb+bp}{∘} \PYG{n}{h} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n+nb+bp}{∘} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{h}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{rfl}

\PYG{k+kd}{theorem} \PYG{n}{comp.left\PYGZus{}id} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{id} \PYG{n+nb+bp}{∘} \PYG{n}{f} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{rfl}

\PYG{k+kd}{theorem} \PYG{n}{comp.right\PYGZus{}id} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{∘} \PYG{n}{id} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{rfl}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can define what it means for \(f\) to be injective, surjective, or bijective:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{Injective} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{o}{⦃}\PYG{n}{x₁} \PYG{n}{x₂}\PYG{o}{⦄}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x₂} \PYG{n+nb+bp}{→} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{x₂}

\PYG{k+kd}{def} \PYG{n}{Surjective} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{y}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y}

\PYG{k+kd}{def} \PYG{n}{Bijective} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{Injective} \PYG{n}{f} \PYG{n+nb+bp}{∧} \PYG{n}{Surjective} \PYG{n}{f}
\end{sphinxVerbatim}

\sphinxAtStartPar
Marking the variables \sphinxcode{\sphinxupquote{x₁}} and \sphinxcode{\sphinxupquote{x₂}} implicit in the definition of \sphinxcode{\sphinxupquote{Injective}} means that we do not have to write them as often. Specifically, given \sphinxcode{\sphinxupquote{h : Injective f}}, and \sphinxcode{\sphinxupquote{h₁ : f x₁ = f x₂}}, we write \sphinxcode{\sphinxupquote{h h₁}} rather than \sphinxcode{\sphinxupquote{h x₁ x₂ h₁}} to show \sphinxcode{\sphinxupquote{x₁ = x₂}}.

\sphinxAtStartPar
We can then prove that the identity function is bijective:

\sphinxAtStartPar
More interestingly, we can prove that the composition of injective functions is injective, and so on.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{Injective.comp} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{Z}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}}
    \PYG{o}{(}\PYG{n}{Hg} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{g}\PYG{o}{)} \PYG{o}{(}\PYG{n}{Hf} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{Injective} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{x₁} \PYG{n}{x₂} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{x₂}\PYG{o}{)}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x₂} \PYG{o}{:=} \PYG{n}{Hg} \PYG{n}{h}
  \PYG{k}{show} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{x₂}
  \PYG{n}{exact} \PYG{n}{Hf} \PYG{n}{this}

\PYG{k+kd}{theorem} \PYG{n}{Surjective.comp} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{Z}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}}
    \PYG{o}{(}\PYG{n}{hg} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{g}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hf} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{Surjective} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{z}
  \PYG{n}{cases} \PYG{n}{hg} \PYG{n}{z} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{y} \PYG{n}{hy} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{n}{cases} \PYG{n}{hf} \PYG{n}{y} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{a}\PYG{o}{,} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{z}
      \PYG{n}{rw} \PYG{o}{[}\PYG{n+nb+bp}{←} \PYG{n}{hy}\PYG{o}{,} \PYG{n+nb+bp}{←} \PYG{n}{hx}\PYG{o}{]}
      \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{a}\PYG{o}{,} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{a} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)}
      \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{rfl}\PYG{o}{⟩}

\PYG{k+kd}{theorem} \PYG{n}{Bijective.comp} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{Z}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}}
    \PYG{o}{(}\PYG{n}{hg} \PYG{o}{:} \PYG{n}{Bijective} \PYG{n}{g}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hf} \PYG{o}{:} \PYG{n}{Bijective} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{Bijective} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{gInj} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{g} \PYG{o}{:=} \PYG{n}{hg.left}
\PYG{k}{have} \PYG{n}{gSurj} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{g} \PYG{o}{:=} \PYG{n}{hg.right}
\PYG{k}{have} \PYG{n}{fInj} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{hf.left}
\PYG{k}{have} \PYG{n}{fSurj} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{f} \PYG{o}{:=} \PYG{n}{hf.right}
\PYG{n}{And.intro} \PYG{o}{(}\PYG{n}{Injective.comp} \PYG{n}{gInj} \PYG{n}{fInj}\PYG{o}{)}
  \PYG{o}{(}\PYG{n}{Surjective.comp} \PYG{n}{gSurj} \PYG{n}{fSurj}\PYG{o}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The notions of left and right inverse are defined in the expected way.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZhy{}\PYGZhy{} g is a left inverse to f}
\PYG{k+kd}{def} \PYG{n}{LeftInverse} \PYG{o}{(}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} g is a right inverse to f}
\PYG{k+kd}{def} \PYG{n}{RightInverse} \PYG{o}{(}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:} \PYG{k+kt}{Prop} \PYG{o}{:=}
\PYG{n}{LeftInverse} \PYG{n}{f} \PYG{n}{g}
\end{sphinxVerbatim}

\sphinxAtStartPar
In particular, composing with a left or right inverse yields the identity.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{LeftInverse.comp\PYGZus{}eq\PYGZus{}id} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
  \PYG{n}{LeftInverse} \PYG{n}{g} \PYG{n}{f} \PYG{n+nb+bp}{→} \PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f} \PYG{n+nb+bp}{=} \PYG{n}{id} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{H} \PYG{n+nb+bp}{↦} \PYG{n}{funext} \PYG{n}{H}

\PYG{k+kd}{def} \PYG{n}{RightInverse.comp\PYGZus{}eq\PYGZus{}id} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
  \PYG{n}{RightInverse} \PYG{n}{g} \PYG{n}{f} \PYG{n+nb+bp}{→} \PYG{n}{f} \PYG{n+nb+bp}{∘} \PYG{n}{g} \PYG{n+nb+bp}{=} \PYG{n}{id} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{H} \PYG{n+nb+bp}{↦} \PYG{n}{funext} \PYG{n}{H}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that we need to use \sphinxcode{\sphinxupquote{funext}} to show the equality of functions.

\sphinxAtStartPar
The following shows that if a function has a left inverse, then it is injective, and if it has a right inverse, then it is surjective.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{LeftInverse.injective} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
  \PYG{n}{LeftInverse} \PYG{n}{g} \PYG{n}{f} \PYG{n+nb+bp}{→} \PYG{n}{Injective} \PYG{n}{f} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{n}{h} \PYG{n}{x₁} \PYG{n}{x₂} \PYG{n}{feq}
  \PYG{k}{calc} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x₁}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}
        \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x₂}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{feq}\PYG{o}{]}
        \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{x₂}       \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{RightInverse.surjective} \PYG{o}{\PYGZob{}}\PYG{n}{g} \PYG{o}{:} \PYG{n}{Y}  \PYG{n+nb+bp}{→} \PYG{n}{X}\PYG{o}{\PYGZcb{}} \PYG{o}{\PYGZob{}}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{\PYGZcb{}} \PYG{o}{:}
  \PYG{n}{RightInverse} \PYG{n}{g} \PYG{n}{f} \PYG{n+nb+bp}{→} \PYG{n}{Surjective} \PYG{n}{f} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{h} \PYG{n}{y} \PYG{n+nb+bp}{↦}
  \PYG{k}{let} \PYG{n}{x} \PYG{o}{:} \PYG{n}{X} \PYG{o}{:=} \PYG{n}{g} \PYG{n}{y}
  \PYG{k}{have} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=}
    \PYG{k}{calc}
      \PYG{n}{f} \PYG{n}{x}  \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{f} \PYG{o}{(}\PYG{n}{g} \PYG{n}{y}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rfl}
         \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{y}         \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h} \PYG{n}{y}\PYG{o}{]}
  \PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{k}{from} \PYG{n}{Exists.intro} \PYG{n}{x} \PYG{n}{this}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that like \sphinxcode{\sphinxupquote{have}},
we used the command \sphinxcode{\sphinxupquote{let}} to define an intermediate term.
The difference is that \sphinxcode{\sphinxupquote{have}} is used for proof terms only (of type \sphinxcode{\sphinxupquote{Prop}}),
but \sphinxcode{\sphinxupquote{let}} can be used for any term.


\section{Defining the Inverse Classically}
\label{\detokenize{functions_in_lean:defining-the-inverse-classically}}
\sphinxAtStartPar
All the theorems listed in the previous section are found in the Lean
library, and are available to you when you
import \sphinxcode{\sphinxupquote{Mathlib}} and open the function namespace
with \sphinxcode{\sphinxupquote{open Function}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib}
\PYG{k+kn}{open} \PYG{n}{Function}

\PYG{k}{\PYGZsh{}check} \PYG{n}{comp}
\PYG{k}{\PYGZsh{}check} \PYG{n}{LeftInverse}
\PYG{k}{\PYGZsh{}check} \PYG{n}{HasRightInverse}
\end{sphinxVerbatim}

\sphinxAtStartPar
Defining inverse functions, however, requires classical reasoning, which
we get by opening the classical namespace:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib}
\PYG{k+kn}{open} \PYG{n}{Classical}

\PYG{k+kn}{section}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}
  \PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{R} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

  \PYG{k+kd}{example} \PYG{o}{:} \PYG{o}{(}\PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n+nb+bp}{∃} \PYG{n}{y}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{→} \PYG{n+nb+bp}{∃} \PYG{n}{f} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{,} \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{R} \PYG{n}{x} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:=}
  \PYG{n}{axiomOfChoice}

  \PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}\PYG{o}{)} \PYG{o}{:} \PYG{n}{P} \PYG{o}{(}\PYG{n}{choose} \PYG{n}{h}\PYG{o}{)} \PYG{o}{:=}
  \PYG{n}{choose\PYGZus{}spec} \PYG{n}{h}
\PYG{k+kd}{end}
\end{sphinxVerbatim}

\sphinxAtStartPar
The axiom of choice tells us that if, for every \sphinxcode{\sphinxupquote{x : X}},
there is a \sphinxcode{\sphinxupquote{y : Y}} satisfying \sphinxcode{\sphinxupquote{R x y}},
then there is a function \sphinxcode{\sphinxupquote{f : X → Y}} which,
for every \sphinxcode{\sphinxupquote{x}} chooses such a \sphinxcode{\sphinxupquote{y}}.
In Lean, this “axiom” is proved using a classical construction,
the \sphinxcode{\sphinxupquote{choose}} function
(sometimes called “the indefinite description operator”) which,
given that there is some choice \sphinxcode{\sphinxupquote{x}} satisfying \sphinxcode{\sphinxupquote{P x}},
returns such an \sphinxcode{\sphinxupquote{x}}.
With these constructions, the inverse function is defined as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib}
\PYG{k+kn}{open} \PYG{n}{Classical} \PYG{n}{Function}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{X} \PYG{n}{Y} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}

\PYG{k+kd}{noncomputable} \PYG{k+kd}{def} \PYG{n}{inverse} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{default} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Y} \PYG{n+nb+bp}{→} \PYG{n}{X} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦} \PYG{k}{if} \PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{k}{then} \PYG{n}{choose} \PYG{n}{h} \PYG{k}{else} \PYG{n}{default}
\end{sphinxVerbatim}

\sphinxAtStartPar
Lean requires us to acknowledge that the definition is not computational, since, first, it may not be algorithmically possible to decide whether or not condition \sphinxcode{\sphinxupquote{h}} holds, and even if it does, it may not be algorithmically possible to find a suitable value of \sphinxcode{\sphinxupquote{x}}.

\sphinxAtStartPar
Below, the proposition \sphinxcode{\sphinxupquote{inverse\_of\_exists}} asserts that \sphinxcode{\sphinxupquote{inverse}} meets its specification, and the subsequent theorem shows that if \sphinxcode{\sphinxupquote{f}} is injective, then the \sphinxcode{\sphinxupquote{inverse}} function really is a left inverse.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{inverse\PYGZus{}of\PYGZus{}exists} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{default} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{y} \PYG{o}{:} \PYG{n}{Y}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{f} \PYG{o}{(}\PYG{n}{inverse} \PYG{n}{f} \PYG{n}{default} \PYG{n}{y}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{inverse} \PYG{n}{f} \PYG{n}{default} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{choose} \PYG{n}{h} \PYG{o}{:=} \PYG{n}{dif\PYGZus{}pos} \PYG{n}{h}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{f} \PYG{o}{(}\PYG{n}{choose} \PYG{n}{h}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{choose\PYGZus{}spec} \PYG{n}{h}
  \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h1}\PYG{o}{,} \PYG{n}{h2}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{is\PYGZus{}left\PYGZus{}inverse\PYGZus{}of\PYGZus{}injective} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{default} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)}
  \PYG{o}{(}\PYG{n}{injf} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{f}\PYG{o}{)} \PYG{o}{:}
\PYG{n}{LeftInverse} \PYG{o}{(}\PYG{n}{inverse} \PYG{n}{f} \PYG{n}{default}\PYG{o}{)} \PYG{n}{f} \PYG{o}{:=}
  \PYG{k}{let} \PYG{n}{finv} \PYG{o}{:=} \PYG{o}{(}\PYG{n}{inverse} \PYG{n}{f} \PYG{n}{default}\PYG{o}{)}
  \PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n+nb+bp}{∃} \PYG{n}{x\PYGZsq{}}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x\PYGZsq{}} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{Exists.intro} \PYG{n}{x} \PYG{n}{rfl}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{f} \PYG{o}{(}\PYG{n}{finv} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{inverse\PYGZus{}of\PYGZus{}exists} \PYG{n}{f} \PYG{n}{default} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{n}{h1}
  \PYG{k}{show} \PYG{n}{finv} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{k}{from} \PYG{n}{injf} \PYG{n}{h2}
\end{sphinxVerbatim}


\section{Functions and Sets in Lean}
\label{\detokenize{functions_in_lean:functions-and-sets-in-lean}}
\sphinxAtStartPar
In \hyperref[\detokenize{first_order_logic:relativization-and-sorts}]{Section \ref{\detokenize{first_order_logic:relativization-and-sorts}}} we saw how to represent relativized universal and existential quantifiers when formalizing phrases like “every prime number greater than two is odd” and “some prime number is even.” In a similar way, we can relativize statements to sets. In symbolic logic, the expression \(\exists x \in A \; P (x)\) abbreviates \(\exists x \; (x \in A \wedge P(x))\), and \(\forall x \in A \; P (x)\) abbreviates \(\forall x \; (x \in A \to P(x))\).

\sphinxAtStartPar
Lean also defines notation for relativized quantifiers:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{X} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{P} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{k+kt}{Prop}\PYG{o}{)}

\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{∃} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here is an example of how to use the bounded universal quantifier:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{,} \PYG{n}{P} \PYG{n}{x}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{P} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{h} \PYG{n}{x} \PYG{n}{h1}
\end{sphinxVerbatim}

\sphinxAtStartPar
Using bounded quantifiers, we can talk about the behavior of functions on particular sets:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Basic}
\PYG{k+kn}{open} \PYG{n}{Set} \PYG{n}{Function}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{X} \PYG{n}{Y} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A}  \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{Y}\PYG{o}{)}

\PYG{k+kd}{def} \PYG{n}{MapsTo} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:=}
  \PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{x}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B}

\PYG{k+kd}{def} \PYG{n}{InjOn} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{:=}
  \PYG{n+nb+bp}{∀} \PYG{o}{\PYGZob{}}\PYG{n}{x₁} \PYG{n}{x₂}\PYG{o}{\PYGZcb{}}\PYG{o}{,} \PYG{n}{x₁} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{x₂} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{f} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x₂} \PYG{n+nb+bp}{→} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{x₂}

\PYG{k+kd}{def} \PYG{n}{SurjOn} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{B} \PYG{n+nb+bp}{⊆} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A}
\end{sphinxVerbatim}

\sphinxAtStartPar
The expression \sphinxcode{\sphinxupquote{MapsTo f A B}} asserts that \sphinxcode{\sphinxupquote{f}} maps elements of the set \sphinxcode{\sphinxupquote{A}} to the set \sphinxcode{\sphinxupquote{B}}, and the expression \sphinxcode{\sphinxupquote{InjOn f A}} asserts that \sphinxcode{\sphinxupquote{f}} is injective on \sphinxcode{\sphinxupquote{A}}. The expression \sphinxcode{\sphinxupquote{SurjOn f A B}} asserts that, viewed as a function defined on elements of \sphinxcode{\sphinxupquote{A}}, the function \sphinxcode{\sphinxupquote{f}} is surjective onto the set \sphinxcode{\sphinxupquote{B}}. Here are examples of how they can be used:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)} \PYG{o}{(}\PYG{n}{A} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{B} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{Y}\PYG{o}{)}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{MapsTo} \PYG{n}{f} \PYG{n}{A} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{h} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{InjOn} \PYG{n}{f} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{x₁} \PYG{n}{x₂} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x₁} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{x₂} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)}
    \PYG{o}{(}\PYG{n}{h3} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x₂}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x₁} \PYG{n+nb+bp}{=} \PYG{n}{x₂} \PYG{o}{:=}
\PYG{n}{h} \PYG{n}{h1} \PYG{n}{h2} \PYG{n}{h3}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the examples below, we’ll use the versions with implicit arguments. The expression \sphinxcode{\sphinxupquote{SurjOn f A B}} asserts that, viewed as a function defined on elements of \sphinxcode{\sphinxupquote{A}}, the function \sphinxcode{\sphinxupquote{f}} is surjective onto the set \sphinxcode{\sphinxupquote{B}}.

\sphinxAtStartPar
With these notions in hand, we can prove that the composition of injective functions is injective. The proof is similar to the one above, though now we have to be more careful to relativize claims to \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{B}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{InjOn.comp} \PYG{o}{(}\PYG{n}{fAB} \PYG{o}{:} \PYG{n}{MapsTo} \PYG{n}{f} \PYG{n}{A} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hg} \PYG{o}{:} \PYG{n}{InjOn} \PYG{n}{g} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hf}\PYG{o}{:} \PYG{n}{InjOn} \PYG{n}{f} \PYG{n}{A}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{InjOn} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{A} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{x1} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{x1A} \PYG{o}{:} \PYG{n}{x1} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{x2} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{x2A} \PYG{o}{:} \PYG{n}{x2} \PYG{n+nb+bp}{∈} \PYG{n}{A}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{fx1B} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x1} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{fAB} \PYG{n}{x1A}
  \PYG{k}{have} \PYG{n}{fx2B} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x2} \PYG{n+nb+bp}{∈} \PYG{n}{B} \PYG{o}{:=} \PYG{n}{fAB} \PYG{n}{x2A}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x1}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x2}\PYG{o}{)}\PYG{o}{)}
  \PYG{k}{have} \PYG{n}{h2} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x1} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n}{x2} \PYG{o}{:=} \PYG{n}{hg} \PYG{n}{fx1B} \PYG{n}{fx2B} \PYG{n}{h1}
  \PYG{k}{show} \PYG{n}{x1} \PYG{n+nb+bp}{=} \PYG{n}{x2}
  \PYG{n}{exact} \PYG{n}{hf} \PYG{n}{x1A} \PYG{n}{x2A} \PYG{n}{h2}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can similarly prove that the composition of surjective functions is surjective:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{SurjOn.comp} \PYG{o}{(}\PYG{n}{hg} \PYG{o}{:} \PYG{n}{SurjOn} \PYG{n}{g} \PYG{n}{B} \PYG{n}{C}\PYG{o}{)} \PYG{o}{(}\PYG{n}{hf}\PYG{o}{:} \PYG{n}{SurjOn} \PYG{n}{f} \PYG{n}{A} \PYG{n}{B}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{SurjOn} \PYG{o}{(}\PYG{n}{g} \PYG{n+nb+bp}{∘} \PYG{n}{f}\PYG{o}{)} \PYG{n}{A} \PYG{n}{C} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{n}{z}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{zc} \PYG{o}{:} \PYG{n}{z} \PYG{n+nb+bp}{∈} \PYG{n}{C}\PYG{o}{)}
\PYG{n}{cases} \PYG{n}{hg} \PYG{n}{zc} \PYG{k}{with}
\PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{y} \PYG{n}{h1} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{cases} \PYG{n}{hf} \PYG{o}{(}\PYG{n}{h1.left}\PYG{o}{)} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{h2} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n+nb+bp}{∃}\PYG{n}{x}\PYG{o}{,} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A} \PYG{n+nb+bp}{∧} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{z}
    \PYG{n}{apply} \PYG{n}{Exists.intro} \PYG{n}{x}
    \PYG{n}{apply} \PYG{n}{And.intro} \PYG{n}{h2.left}
    \PYG{k}{show} \PYG{n}{g} \PYG{o}{(}\PYG{n}{f} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{z}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{h2.right}\PYG{o}{]}
    \PYG{k}{show} \PYG{n}{g} \PYG{n}{y} \PYG{n+nb+bp}{=} \PYG{n}{z}
    \PYG{n}{exact} \PYG{n}{h1.right}
\end{sphinxVerbatim}

\sphinxAtStartPar
The following shows that the image of a union is the union of images:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Function}
\PYG{k+kn}{open} \PYG{n}{Set} \PYG{n}{Function}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{X} \PYG{n}{Y} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A₁} \PYG{n}{A₂} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} BEGIN}
\PYG{k+kd}{theorem} \PYG{n}{image\PYGZus{}union} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₂} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{y}
  \PYG{n}{constructor}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{image} \PYG{n}{f} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂}\PYG{o}{)}\PYG{o}{)}
    \PYG{n}{cases} \PYG{n}{h} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{have} \PYG{n}{xA₁A₂} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂} \PYG{o}{:=} \PYG{n}{hx.left}
      \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
      \PYG{n}{cases} \PYG{n}{xA₁A₂} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{xA₁} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inl} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{xA₁}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
      \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{xA₂} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inr} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{xA₂}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{image} \PYG{n}{f} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{image} \PYG{n}{f} \PYG{n}{A₂}\PYG{o}{)}
    \PYG{n}{cases} \PYG{n}{h} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{yifA₁} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{n}{cases} \PYG{n}{yifA₁} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
        \PYG{k}{have} \PYG{n}{xA₁} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{o}{:=} \PYG{n}{hx.left}
        \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
        \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{Or.inl} \PYG{n}{xA₁}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{yifA₂} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{cases} \PYG{n}{yifA₂} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
        \PYG{k}{have} \PYG{n}{xA₂} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₂} \PYG{o}{:=} \PYG{n}{hx.left}
        \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
        \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{Or.inr} \PYG{n}{xA₂}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that the expression \sphinxcode{\sphinxupquote{y ∈ image f A₁}} expands to
\sphinxcode{\sphinxupquote{∃ x, x ∈ A₁ ∧ f x = y}}.
We therefore need to provide three pieces of information: a value of \sphinxcode{\sphinxupquote{x}},
a proof that \sphinxcode{\sphinxupquote{x ∈ A₁}}, and a proof that \sphinxcode{\sphinxupquote{f x = y}}.
Note also that \sphinxcode{\sphinxupquote{f '' A}} is notation for \sphinxcode{\sphinxupquote{image f A}}.


\section{Exercises}
\label{\detokenize{functions_in_lean:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}}’s in the last three proofs below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Tactic.Basic}
\PYG{k+kn}{import} \PYG{n}{Mathlib.Algebra.Ring.Divisibility.Lemmas}
\PYG{k+kn}{open} \PYG{n}{Function} \PYG{n}{Int}

\PYG{k+kd}{def} \PYG{n}{f} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{ℤ} \PYG{o}{:=} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{3}
\PYG{k+kd}{def} \PYG{n}{g} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{ℤ} \PYG{o}{:=} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x}
\PYG{k+kd}{def} \PYG{n}{h} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{ℤ} \PYG{o}{:=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{3}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{f} \PYG{o}{:=}
\PYG{k}{fun} \PYG{n}{x1} \PYG{n}{x2} \PYG{n+nb+bp}{↦}
\PYG{k}{fun} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{x1} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{3} \PYG{n+nb+bp}{=} \PYG{n}{x2} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{3} \PYG{n+nb+bp}{↦}   \PYG{c+c1}{\PYGZhy{}\PYGZhy{} Lean knows this is the same as f x1 = f x2}
\PYG{k}{show} \PYG{n}{x1} \PYG{n+nb+bp}{=} \PYG{n}{x2} \PYG{k}{from} \PYG{n}{add\PYGZus{}right\PYGZus{}cancel} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{f} \PYG{o}{:=}
  \PYG{k}{fun} \PYG{n}{y} \PYG{n+nb+bp}{↦}
  \PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{n}{f} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{l+m+mi}{3}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=}
    \PYG{k}{calc}
      \PYG{n}{f} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{l+m+mi}{3}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{l+m+mi}{3}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{3} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rfl}
              \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{y}           \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{sub\PYGZus{}add\PYGZus{}cancel}\PYG{o}{]}
\PYG{k}{show} \PYG{n+nb+bp}{∃} \PYG{n}{x}\PYG{o}{,} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{k}{from} \PYG{n}{Exists.intro} \PYG{o}{(}\PYG{n}{y} \PYG{n+nb+bp}{\PYGZhy{}} \PYG{l+m+mi}{3}\PYG{o}{)} \PYG{n}{h1}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{n}{y} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{y}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=}
\PYG{k}{have} \PYG{n}{h1} \PYG{o}{:} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{≠} \PYG{o}{(}\PYG{l+m+mi}{0} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{decide}  \PYG{c+c1}{\PYGZhy{}\PYGZhy{} this tells Lean to figure it out itself}
\PYG{k}{show} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{k}{from} \PYG{n}{mul\PYGZus{}left\PYGZus{}cancel₀} \PYG{n}{h1} \PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{ℤ}\PYG{o}{)} \PYG{o}{:} \PYG{n+nb+bp}{\PYGZhy{}}\PYG{o}{(}\PYG{n+nb+bp}{\PYGZhy{}}\PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=} \PYG{n}{neg\PYGZus{}neg} \PYG{n}{x}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{u} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{v} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{LeftInverse} \PYG{n}{u} \PYG{n}{v}\PYG{o}{)} \PYG{o}{:}
  \PYG{n+nb+bp}{∀} \PYG{n}{x}\PYG{o}{,} \PYG{n}{u} \PYG{o}{(}\PYG{n}{v} \PYG{n}{x}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{x} \PYG{o}{:=}
\PYG{n}{h}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{u} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{v} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{LeftInverse} \PYG{n}{u} \PYG{n}{v}\PYG{o}{)} \PYG{o}{:}
  \PYG{n}{RightInverse} \PYG{n}{v} \PYG{n}{u} \PYG{o}{:=}
\PYG{n}{h}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} fill in the sorry\PYGZsq{}s in the following proofs}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Injective} \PYG{n}{h} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{Surjective} \PYG{n}{g} \PYG{o}{:=}
\PYG{g+gr}{sorry}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{A} \PYG{n}{B} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{)} \PYG{o}{(}\PYG{n}{u} \PYG{o}{:} \PYG{n}{A} \PYG{n+nb+bp}{→} \PYG{n}{B}\PYG{o}{)} \PYG{o}{(}\PYG{n}{v1} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)} \PYG{o}{(}\PYG{n}{v2} \PYG{o}{:} \PYG{n}{B} \PYG{n+nb+bp}{→} \PYG{n}{A}\PYG{o}{)}
  \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{LeftInverse} \PYG{n}{v1} \PYG{n}{u}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{RightInverse} \PYG{n}{v2} \PYG{n}{u}\PYG{o}{)} \PYG{o}{:} \PYG{n}{v1} \PYG{n+nb+bp}{=} \PYG{n}{v2} \PYG{o}{:=}
\PYG{n}{funext}
  \PYG{o}{(}\PYG{k}{fun} \PYG{n}{x} \PYG{n+nb+bp}{↦}
    \PYG{k}{calc}
      \PYG{n}{v1} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{v1} \PYG{o}{(}\PYG{n}{u} \PYG{o}{(}\PYG{n}{v2} \PYG{n}{x}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}
         \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{v2} \PYG{n}{x}          \PYG{o}{:=} \PYG{k+kd}{by} \PYG{g+gr}{sorry}\PYG{o}{)}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Fill in the \sphinxcode{\sphinxupquote{sorry}} in the proof below.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Set.Function}
\PYG{k+kn}{open} \PYG{n}{Set} \PYG{n}{Function}

\PYG{k+kd}{variable} \PYG{o}{\PYGZob{}}\PYG{n}{X} \PYG{n}{Y} \PYG{o}{:} \PYG{k+kt}{Type}\PYG{o}{\PYGZcb{}}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{A₁} \PYG{n}{A₂} \PYG{o}{:} \PYG{n}{Set} \PYG{n}{X}\PYG{o}{)}
\PYG{k+kd}{variable} \PYG{o}{(}\PYG{n}{f} \PYG{o}{:} \PYG{n}{X} \PYG{n+nb+bp}{→} \PYG{n}{Y}\PYG{o}{)}

\PYG{k+kd}{theorem} \PYG{n}{image\PYGZus{}union} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₂} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{ext} \PYG{n}{y}
  \PYG{n}{constructor}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{image} \PYG{n}{f} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂}\PYG{o}{)}\PYG{o}{)}
    \PYG{n}{cases} \PYG{n}{h} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{k}{have} \PYG{n}{xA₁A₂} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{A₂} \PYG{o}{:=} \PYG{n}{hx.left}
      \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
      \PYG{n}{cases} \PYG{n}{xA₁A₂} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{xA₁} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inl} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{xA₁}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
      \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{xA₂} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{Or.inr} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{xA₂}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
  \PYG{n+nb+bp}{.} \PYG{n}{intro} \PYG{o}{(}\PYG{n}{h} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{image} \PYG{n}{f} \PYG{n}{A₁} \PYG{n+nb+bp}{∪} \PYG{n}{image} \PYG{n}{f} \PYG{n}{A₂}\PYG{o}{)}
    \PYG{n}{cases} \PYG{n}{h} \PYG{k}{with}
    \PYG{n+nb+bp}{|} \PYG{n}{inl} \PYG{n}{yifA₁} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
      \PYG{n}{cases} \PYG{n}{yifA₁} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
        \PYG{k}{have} \PYG{n}{xA₁} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{o}{:=} \PYG{n}{hx.left}
        \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
        \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{Or.inl} \PYG{n}{xA₁}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}
    \PYG{n+nb+bp}{|} \PYG{n}{inr} \PYG{n}{yifA₂} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{cases} \PYG{n}{yifA₂} \PYG{k}{with}
      \PYG{n+nb+bp}{|} \PYG{n}{intro} \PYG{n}{x} \PYG{n}{hx} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
        \PYG{k}{have} \PYG{n}{xA₂} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₂} \PYG{o}{:=} \PYG{n}{hx.left}
        \PYG{k}{have} \PYG{n}{fxy} \PYG{o}{:} \PYG{n}{f} \PYG{n}{x} \PYG{n+nb+bp}{=} \PYG{n}{y} \PYG{o}{:=} \PYG{n}{hx.right}
        \PYG{n}{exact} \PYG{o}{⟨}\PYG{n}{x}\PYG{o}{,} \PYG{n}{Or.inr} \PYG{n}{xA₂}\PYG{o}{,} \PYG{n}{fxy}\PYG{o}{⟩}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} remember, x ∈ A ∩ B is the same as x ∈ A ∧ x ∈ B}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h2} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₂}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{A₂} \PYG{o}{:=}
\PYG{n}{And.intro} \PYG{n}{h1} \PYG{n}{h2}

\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{x} \PYG{o}{:} \PYG{n}{X}\PYG{o}{)} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{A₂}\PYG{o}{)} \PYG{o}{:} \PYG{n}{x} \PYG{n+nb+bp}{∈} \PYG{n}{A₁} \PYG{o}{:=}
\PYG{n}{And.left} \PYG{n}{h1}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} Fill in the proof below.}

\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{A₂}\PYG{o}{)} \PYG{n+nb+bp}{⊆} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₂} \PYG{o}{:=} \PYG{k+kd}{by}
\PYG{n}{intro} \PYG{n}{y}
\PYG{n}{intro} \PYG{o}{(}\PYG{n}{h1} \PYG{o}{:} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{o}{(}\PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{A₂}\PYG{o}{)}\PYG{o}{)}
\PYG{k}{show} \PYG{n}{y} \PYG{n+nb+bp}{∈} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₁} \PYG{n+nb+bp}{∩} \PYG{n}{f} \PYG{n+nb+bp}{\PYGZsq{}}\PYG{n+nb+bp}{\PYGZsq{}} \PYG{n}{A₂}
\PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\end{enumerate}


\chapter{The Natural Numbers and Induction}
\label{\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}}\label{\detokenize{the_natural_numbers_and_induction:id1}}\label{\detokenize{the_natural_numbers_and_induction::doc}}
\sphinxAtStartPar
This chapter marks a transition from the abstract to the concrete. Viewing the mathematical universe in terms of sets, relations, and functions gives us useful ways of thinking about mathematical objects and structures and the relationships between them. At some point, however, we need to start thinking about \sphinxstyleemphasis{particular} mathematical objects and structures, and the natural numbers are a good place to start. The nineteenth century mathematician Leopold Kronecker once proclaimed “God created the whole numbers; everything else is the work of man.” By this he meant that the natural numbers (and the integers, which we will also discuss below) are a fundamental component of the mathematical universe, and that many other objects and structures of interest can be constructed from these.

\sphinxAtStartPar
In this chapter, we will consider the natural numbers and the basic principles that govern them. In \hyperref[\detokenize{the_natural_numbers_and_induction_in_lean:the-natural-numbers-and-induction-in-lean}]{Chapter \ref{\detokenize{the_natural_numbers_and_induction_in_lean:the-natural-numbers-and-induction-in-lean}}} we will see that even basic operations like addition and multiplication can be defined using means described here, and their properties derived from these basic principles. Our presentation in this chapter will remain informal, however. In Chapter 19, we will see how these principles play out in number theory, one of the oldest and most venerable branches of mathematics.


\section{The Principle of Induction}
\label{\detokenize{the_natural_numbers_and_induction:the-principle-of-induction}}
\sphinxAtStartPar
The set of natural numbers is the set
\begin{equation*}
\begin{split}\mathbb{N} = \{ 0, 1, 2, 3, \ldots \}.\end{split}
\end{equation*}
\sphinxAtStartPar
In the past, opinions have differed as to whether the set of natural numbers should start with 0 or 1, but these days most mathematicians take them to start with 0. Logicians often call the function \(s(n) = n + 1\) the \sphinxstyleemphasis{successor} function, since it maps each natural number, \(n\), to the one that follows it. What makes the natural numbers special is that they are \sphinxstyleemphasis{generated} by the number zero and the successor function, which is to say, the only way to construct a natural number is to start with \(0\) and apply the successor function finitely many times. From a foundational standpoint, we are in danger of running into a circularity here, because it is not clear how we can explain what it means to apply a function “finitely many times” without talking about the natural numbers themselves. But the following principle, known as the \sphinxstyleemphasis{principle of induction}, describes this essential property of the natural numbers in a non\sphinxhyphen{}circular way.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Principle of Induction.} Let \(P\) be any property of natural numbers. Suppose \(P\) holds of zero, and whenever \(P\) holds of a natural number \(n\), then it holds of its successor, \(n + 1\). Then \(P\) holds of every natural number.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This reflects the image of the natural numbers as being generated by zero and the successor operation: by covering the zero and successor cases, we take care of all the natural numbers.

\sphinxAtStartPar
The principle of induction provides a recipe for proving that every natural number has a certain property: to show that \(P\) holds of every natural number, show that it holds of \(0\), and show that whenever it holds of some number \(n\), it holds of \(n + 1\). This form of proof is called a \sphinxstyleemphasis{proof by induction}. The first required task is called the \sphinxstyleemphasis{base case}, and the second required task is called the \sphinxstyleemphasis{induction step}. The induction step requires temporarily fixing a natural number \(n\), assuming that \(P\) holds of \(n\), and then showing that \(P\) holds of \(n + 1\). In this context, the assumption that \(P\) holds of \(n\) is called the \sphinxstyleemphasis{inductive hypothesis}.

\sphinxAtStartPar
You can visualize proof by induction as a method of knocking down an infinite stream of dominoes, all at once. We set the mechanism in place and knock down domino 0 (the base case), and every domino knocks down the next domino (the induction step). So domino 0 knocks down domino 1; that knocks down domino 2, and so on.

\sphinxAtStartPar
Here is an example of a proof by induction.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every natural number \(n\),
\begin{equation*}
\begin{split}1 + 2 + \ldots + 2^n = 2^{n+1} - 1.\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Proof.} We prove this by induction on \(n\). In the base case, when \(n = 0\), we have \(1 = 2^{0+1} - 1\), as required.

\sphinxAtStartPar
For the induction step, fix \(n\), and assume the \sphinxstyleemphasis{inductive hypothesis}
\begin{equation*}
\begin{split}1 + 2 + \ldots + 2^n = 2^{n+1} - 1.\end{split}
\end{equation*}
\sphinxAtStartPar
We need to show that this same claim holds with \(n\) replaced by \(n + 1\). But this is just a calculation:
\begin{equation*}
\begin{split}1 + 2 + \ldots + 2^{n+1} & = (1 + 2 + \ldots + 2^n) + 2^{n+1} \\
& = 2^{n+1} - 1 + 2^{n+1} \\
& = 2 \cdot 2^{n+1} - 1 \\
& = 2^{n+2} - 1.\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
In the notation of first\sphinxhyphen{}order logic, if we write \(P(n)\) to mean that \(P\) holds of \(n\), we could express the principle of induction as follows:
\begin{equation*}
\begin{split}P(0) \wedge \forall n \; (P(n) \to P(n + 1)) \to \forall n \; P(n).\end{split}
\end{equation*}
\sphinxAtStartPar
But notice that the principle of induction says that the axiom holds \sphinxstyleemphasis{for every property} \(P\), which means that we should properly use a universal quantifier for that, too:
\begin{equation*}
\begin{split}\forall P \; (P(0) \wedge \forall n \; (P(n) \to P(n + 1)) \to \forall n \; P(n)).\end{split}
\end{equation*}
\sphinxAtStartPar
Quantifying over properties takes us out of the realm of first\sphinxhyphen{}order logic; induction is therefore a second\sphinxhyphen{}order principle.

\sphinxAtStartPar
The pattern for a proof by induction is expressed even more naturally by the following natural deduction rule:



\begin{prooftree}
  \AXM{P(0)}
  \AXM{}
  \RLM{1}
  \UIM{P(n)}
  \noLine
  \UIM{\vdots}
  \noLine
  \UIM{P(n+1)}
  \BIM{\forall n \; P(n)}
\end{prooftree}

\sphinxAtStartPar
You should think about how some of the proofs in this chapter could be represented formally using natural deduction.

\sphinxAtStartPar
For another example of a proof by induction, let us derive a formula that, given any finite set \(S\), determines the number of subsets of \(S\). For example, there are four subsets of the two\sphinxhyphen{}element set \(\{1, 2\}\), namely \(\emptyset\), \(\{1\}\), \(\{2\}\), and \(\{1, 2\}\). You should convince yourself that there are eight subsets of the set \(\{1, 2, 3\}\). The following theorem establishes the general pattern.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For any finite set \(S\), if \(S\) has \(n\) elements, then there are \(2^n\) subsets of \(S\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We use induction on \(n\). In the base case, there is only one set with \(0\) elements, the empty set, and there is exactly one subset of the empty set, as required.

\sphinxAtStartPar
In the inductive case, suppose \(S\) has \(n + 1\) elements. Let \(a\) be any element of \(S\), and let \(S'\) be the set containing the remaining \(n\) elements. In order to count the subsets of \(S\), we divide them into two groups.

\sphinxAtStartPar
First, we consider the subsets of \(S\) that don’t contain \(a\). These are exactly the subsets of \(S'\), and by the inductive hypothesis, there are \(2^n\) of those.

\sphinxAtStartPar
Next we consider the subsets of \(S\) that \sphinxstyleemphasis{do} contain \(a\). Each of these is obtained by choosing a subset of \(S'\) and adding \(a\). Since there are \(2^n\) subsets of \(S'\), there are \(2^n\) subsets of \(S\) that contain \(a\).

\sphinxAtStartPar
Taken together, then, there are \(2^n + 2^n = 2^{n+1}\) subsets of \(S\), as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We have seen that there is a correspondence between properties of a domain and subsets of a domain. For every property \(P\) of natural numbers, we can consider the set \(S\) of natural numbers with that property, and for every set of natural numbers, we can consider the property of being in that set. For example, we can talk about the property of being even, or talk about the set of even numbers. Under this correspondence, the principle of induction can be cast as follows:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Principle of Induction.} Let \(S\) be any set of natural numbers that contains \(0\) and is closed under the successor operation. Then \(S = \mathbb{N}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here, saying that \(S\) is “closed under the successor operation” means that whenever a number \(n\) is in \(S\), so is \(n + 1\).


\section{Variants of Induction}
\label{\detokenize{the_natural_numbers_and_induction:variants-of-induction}}
\sphinxAtStartPar
In this section, we will consider variations on the principle of induction that are often useful. It is important to recognize that each of these can be justified using the principle of induction as stated in the last section, so they need not be taken as fundamental.

\sphinxAtStartPar
The first one is no great shakes: instead of starting from \(0\), we can start from any natural number, \(m\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Principle of Induction from a Starting Point.} Let \(P\) be any property of natural numbers, and let \(m\) be any natural number. Suppose \(P\) holds of \(m\), and whenever \(P\) holds of a natural number \(n\) greater than or equal to \(m\), then it holds of its successor, \(n + 1\). Then \(P\) holds of every natural number greater than or equal to \(m\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Assuming the hypotheses of this last principle, if we let \(P'(n)\) be the property “\(P\) holds of \(m + n\),” we can prove that \(P'\) holds of every \(n\) by the ordinary principle of induction. But this means that \(P\) holds of every number greater than or equal to \(m\).

\sphinxAtStartPar
Here is one example of a proof using this variant of induction.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every natural number \(n \geq 5\), \(2^n > n^2\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(n\). When \(n = 5\), we have \(2^n = 32 > 25 = n^2\), as required.

\sphinxAtStartPar
For the induction step, suppose \(n \ge 5\) and \(2^n > n^2\). Since \(n\) is greater than or equal to \(5\), we have \(2n + 1 \leq 3 n \leq n^2\), and so
\begin{equation*}
\begin{split}(n+1)^2 &= n^2 + 2n + 1 \\
 & \leq n^2 + n^2 \\
 & < 2^n + 2^n \\
 & = 2^{n+1}.\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
For another example, let us derive a formula for the sum total of the angles in a convex polygon. A polygon is said to be \sphinxstyleemphasis{convex} if every line between two vertices stays inside the polygon. We will accept without proof the visually obvious fact that one can subdivide any convex polygon with more than three sides into a triangle and a convex polygon with one fewer side, namely, by closing off any two consecutive sides to form a triangle. We will also accept, without proof, the basic geometric fact that the sum of the angles of any triangle is 180 degrees.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For any \(n \geq 3\), the sum of the angles of any convex \(n\)\sphinxhyphen{}gon is \(180(n - 2)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} In the base case, when \(n = 3\), this reduces to the statement that the sum of the angles in any triangle is 180 degrees.

\sphinxAtStartPar
For the induction step, suppose \(n \geq 3\), and let \(P\) be a convex \((n+1)\)\sphinxhyphen{}gon. Divide \(P\) into a triangle and an \(n\)\sphinxhyphen{}gon. By the inductive hypotheses, the sum of the angles of the \(n\)\sphinxhyphen{}gon is \(180(n-2)\) degrees, and the sum of the angles of the triangle is \(180\) degrees. The measures of these angles taken together make up the sum of the measures of the angles of \(P\), for a total of \(180(n-2) + 180 = 180(n-1)\) degrees.


\bigskip\hrule\bigskip


\sphinxAtStartPar
For our second example, we will consider the principle of \sphinxstyleemphasis{complete induction}, also sometimes known as \sphinxstyleemphasis{total induction}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Principle of Complete Induction.} Let \(P\) be any property that satisfies the following: for any natural number \(n\), whenever \(P\) holds of every number less than \(n\), it also holds of \(n\). Then \(P\) holds of every natural number.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that there is no need to break out a special case for zero: for any property \(P\), \(P\) holds of all the natural numbers less than zero, for the trivial reason that there aren’t any! So, in particular, any such property automatically holds of zero.

\sphinxAtStartPar
Notice also that if such a property \(P\) holds of every number less than \(n\), then it also holds of every number less than \(n + 1\) (why?). So, for such a \(P\), the ordinary principle of induction implies that for every natural number \(n\), \(P\) holds of every natural number less than \(n\). But this is just a roundabout way of saying that \(P\) holds of every natural number. In other words, we have justified the principle of complete induction using ordinary induction.

\sphinxAtStartPar
To use the principle of complete induction we merely have to let \(n\) be any natural number and show that \(P\) holds of \(n\), assuming that it holds of every smaller number. Compare this to the ordinary principle of induction, which requires us to show \(P (n + 1)\) assuming only \(P(n)\). The following example of the use of this principle is taken verbatim from the introduction to this book:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every natural number greater than or equal to 2 can be written as a product of primes.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We proceed by induction on \(n\). Let \(n\) be any natural number greater than 2. If \(n\) is prime, we are done; we can consider \(n\) itself as a product with one factor. Otherwise, \(n\) is composite, and we can write \(n = m \cdot k\) where \(m\) and \(k\) are smaller than \(n\) and greater than 1. By the inductive hypothesis, each of \(m\) and \(k\) can be written as a product of primes:
\begin{equation*}
\begin{split}m = p_1 \cdot p_2 \cdot \ldots \cdot p_u \\
k = q_1 \cdot q_2 \cdot \ldots \cdot q_v.\end{split}
\end{equation*}
\sphinxAtStartPar
But then we have
\begin{equation*}
\begin{split}n = m \cdot k = p_1 \cdot p_2 \cdot \ldots \cdot p_u \cdot q_1 \cdot
q_2 \cdot \ldots \cdot q_v.\end{split}
\end{equation*}
\sphinxAtStartPar
We see that \(n\) is a product of primes, as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Finally, we will consider another formulation of induction, known as the least element principle.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{The Least Element Principle.} Suppose \(P\) is some property of natural numbers, and suppose \(P\) holds of some \(n\). Then there is a smallest value of \(n\) for which \(P\) holds.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In fact, using classical reasoning, this is equivalent to the principle of complete induction. To see this, consider the contrapositive of the statement above: “if there is no smallest value for which \(P\) holds, then \(P\) doesn’t hold of any natural number.” Let \(Q(n)\) be the property “\(P\) does \sphinxstyleemphasis{not} hold of \(n\).” Saying that there is no smallest value for which \(P\) holds means that, for every \(n\), if \(P\) holds at \(n\), then it holds of some number smaller than \(n\); and this is equivalent to saying that, for every \(n\), if \(Q\) doesn’t hold at \(n\), then there is a smaller value for which \(Q\) doesn’t hold. And \sphinxstyleemphasis{that} is equivalent to saying that if \(Q\) holds for every number less than \(n\), it holds for \(n\) as well. Similarly, saying that \(P\) doesn’t hold of any natural number is equivalent to saying that \(Q\) holds of every natural number. In other words, replacing the least element principle by its contrapositive, and replacing \(P\) by “not \(Q\),” we have the principle of complete induction. Since every statement is equivalent to its contrapositive, and every predicate has its negated version, the two principles are the same.

\sphinxAtStartPar
It is not surprising, then, that the least element principle can be used in much the same way as the principle of complete induction. Here, for example, is a formulation of the previous proof in these terms. Notice that it is phrased as a proof by contradiction.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every natural number greater than equal to 2 can be written as a product of primes.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose, to the contrary, some natural number greater than or equal to 2 cannot be written as a product of primes. By the least element principle, there is a smallest such element; call it \(n\). Then \(n\) is not prime, and since it is greater than or equal to 2, it must be composite. Hence we can write \(n = m \cdot k\) where \(m\) and \(k\) are smaller than \(n\) and greater than 1. By the assumption on \(n\), each of \(m\) and \(k\) can be written as a product of primes:
\begin{equation*}
\begin{split}m = p_1 \cdot p_2 \cdot \ldots \cdot p_u \\
k = q_1 \cdot q_2 \cdot \ldots \cdot q_v.\end{split}
\end{equation*}
\sphinxAtStartPar
But then we have
\begin{equation*}
\begin{split}n = m \cdot k = p_1 \cdot p_2 \cdot \ldots \cdot p_u \cdot q_1 \cdot
q_2 \cdot \ldots \cdot q_v.\end{split}
\end{equation*}
\sphinxAtStartPar
We see that \(n\) is a product of primes, contradicting the fact that \(n\) cannot be
written as a product of primes.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here is another example:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every natural number is interesting.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose, to the contrary, some natural number is uninteresting. Then there is a smallest one, \(n\). In other words, \(n\) is the smallest uninteresting number. But that is really interesting! Contradiction.


\bigskip\hrule\bigskip



\section{Recursive Definitions}
\label{\detokenize{the_natural_numbers_and_induction:recursive-definitions}}\label{\detokenize{the_natural_numbers_and_induction:id2}}
\sphinxAtStartPar
Suppose I tell you that I have a function \(f : \mathbb{N} \to \mathbb{N}\) in
mind, satisfying the following properties:
\begin{equation*}
\begin{split}f(0) & = 1 \\
f(n + 1) & = 2 \cdot f(n)\end{split}
\end{equation*}
\sphinxAtStartPar
What can you infer about \(f\)? Try calculating a few values:
\begin{equation*}
\begin{split}f(1) & = f(0 + 1) = 2 \cdot f(0) = 2 \\
f(2) & = f(1 + 1) = 2 \cdot f(1) = 4 \\
f(3) & = f(2 + 1) = 2 \cdot f(2) = 8\end{split}
\end{equation*}
\sphinxAtStartPar
It soon becomes apparent that for every \(n\), \(f(n) = 2^n\).

\sphinxAtStartPar
What is more interesting is that the two conditions above specify \sphinxstyleemphasis{all} the values of \(f\), which is to say, there is exactly one function meeting the specification above. In fact, it does not matter that \(f\) takes values in the natural numbers; it could take values in any other domain. All that is needed is a value of \(f(0)\) and a way to compute the value of \(f(n+1)\) in terms of \(n\) and \(f(n)\). This is what the principle of definition by recursion asserts:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Principle of Definition by Recursion}. Let \(A\) be any set, and suppose \(a\) is in \(A\), and \(g : \mathbb{N} \times A \to A\). Then there is a unique function \(f\) satisfying the following two clauses:
\begin{equation*}
\begin{split}f(0) & = a \\
f(n + 1) & = g(n, f(n)).\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
The principle of recursive definition makes two claims at once: first, that there is a function \(f\) satisfying the clauses above, and, second, that any two functions \(f_1\) and \(f_2\) satisfying those clauses are equal, which is to say, they have the same values for every input. In the example with which we began this section, \(A\) is just \(\mathbb{N}\) and \(g(n, f(n)) = 2 \cdot f(n)\).

\sphinxAtStartPar
In some axiomatic frameworks, the principle of recursive definition can be justified using the principle of induction. In others, the principle of induction can be viewed as a special case of the principle of recursive definition. For now, we will simply take both to be fundamental properties of the natural numbers.

\sphinxAtStartPar
As another example of a recursive definition, consider the function \(g : \mathbb{N} \to \mathbb{N}\) defined recursively by the following clauses:
\begin{equation*}
\begin{split}g(0) & = 1 \\
g(n+1) & = (n + 1) \cdot g(n)\end{split}
\end{equation*}
\sphinxAtStartPar
Try calculating the first few values. Unwrapping the definition, we see that \(g(n) = 1 \cdot 2 \cdot 3 \cdot \ldots \cdot (n-1) \cdot n\) for every \(n\); indeed, definition by recursion is usually the proper way to make expressions using “…” precise. The value \(g(n)\) is read “\(n\) factorial,” and written \(n!\).

\sphinxAtStartPar
Indeed, summation notation
\begin{equation*}
\begin{split}\sum_{i < n} f (i) = f(0) + f(1) + \ldots + f(n-1)\end{split}
\end{equation*}
\sphinxAtStartPar
and product notation
\begin{equation*}
\begin{split}\prod_{i < n} f (i) = f(0) \cdot f(1) \cdot \cdots \cdot f(n-1)\end{split}
\end{equation*}
\sphinxAtStartPar
can also be made precise using recursive definitions. For example, the function \(k(n) = \sum_{i < n} f (i)\) can be defined recursively as follows:
\begin{equation*}
\begin{split}k(0) &= 0 \\
k(n+1) &= k(n) + f(n)\end{split}
\end{equation*}
\sphinxAtStartPar
Induction and recursion are complementary principles, and typically the way to prove something about a recursively defined function is to use the principle of induction. For example, the following theorem provides a formulas for the sum \(1 + 2 + \ldots + n\), in terms of \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every \(n\), \(\sum_{i < n + 1} i = n (n + 1) / 2\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} In the base case, when \(n = 0\), both sides are equal to \(0\).

\sphinxAtStartPar
In the inductive step, we have
\begin{equation*}
\begin{split}\sum_{i < n + 2} i & = \left(\sum_{i < n + 1} i\right) + (n + 1) \\
& = n (n + 1) / 2 + n + 1 \\
& = \frac{n^2 +n}{2} + \frac{2n + 2}{2} \\
& = \frac{n^2 + 3n + 2}{2} \\
& = \frac{(n+1)(n+2)}{2}.\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
There are just as many variations on the principle of recursive definition as there are on the principle of induction. For example, in analogy to the principle of complete induction, we can specify a value of \(f(n)\) in terms of the values that \(f\) takes at all inputs smaller than \(n\). When \(n \geq 2\), for example, the following definition specifies the value of a function \(\mathrm{fib}(n)\) in terms of its two predecessors:
\begin{equation*}
\begin{split}\mathrm{fib}(0) & = 0 \\
\mathrm{fib}(1) & = 1 \\
\mathrm{fib}(n+2) & = \mathrm{fib}(n + 1) + \mathrm{fib}(n)\end{split}
\end{equation*}
\sphinxAtStartPar
Calculating the values of \(\mathrm{fib}\) on \(0, 1, 2, \ldots\) we obtain
\begin{equation*}
\begin{split}0, 1, 1, 2, 3, 5, 8, 13, 21, \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
Here, after the second number, each successive number is the sum of the two values preceding it. This is known as the \sphinxstyleemphasis{Fibonacci sequence}, and the corresponding numbers are known as the \sphinxstyleemphasis{Fibonacci numbers}. An ordinary mathematical presentation would write \(F_n\) instead of \(\mathrm{fib}(n)\) and specify the sequence with the following equations:
\begin{equation*}
\begin{split}F_0 = 0, \quad F_1 = 1, \quad F_{n+2} = F_{n+1} + F_n\end{split}
\end{equation*}
\sphinxAtStartPar
But you can now recognize such a specification as an implicit appeal to the principle of definition by recursion. We ask you to prove some facts about the Fibonacci sequence in the exercises below.


\section{Defining Arithmetic Operations}
\label{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}\label{\detokenize{the_natural_numbers_and_induction:id3}}
\sphinxAtStartPar
In fact, we can even use the principle of recursive definition to define the most basic operations on the natural numbers and show that they have the properties we expect them to have. From a foundational standpoint, we can characterize the natural numbers as a set, \(\mathbb{N}\), with a distinguished element \(0\) and a function, \(\mathrm{succ}(m)\), which, for every natural number \(m\), returns its \sphinxstyleemphasis{successor}. These satisfy the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(0 \neq \mathrm{succ}(m)\) for any \(m\) in \(\mathbb{N}\).

\item {} 
\sphinxAtStartPar
For every \(m\) and \(n\) in \(\mathbb{N}\), if \(m \neq n\), then \(\mathrm{succ}(m) \neq \mathrm{succ}(n)\). In other words, \(\mathrm{succ}\) is \sphinxstyleemphasis{injective}.

\item {} 
\sphinxAtStartPar
If \(A\) is any subset of \(\mathbb{N}\) with the property that \(0\) is in \(A\) and whenever \(n\) is in \(A\) then \(\mathrm{succ}(n)\) is in \(A\), then \(A = \mathbb{N}\).

\end{itemize}

\sphinxAtStartPar
The last clause can be reformulated as the principle of induction:
\begin{quote}

\sphinxAtStartPar
Suppose \(P(n)\) is any property of natural numbers, such that \(P\) holds of \(0\), and for every \(n\), \(P(n)\) implies \(P(\mathrm{succ}(n))\). Then every \(P\) holds of every natural number.
\end{quote}

\sphinxAtStartPar
Remember that this principle can be used to justify the principle of definition by recursion:
\begin{quote}

\sphinxAtStartPar
Let \(A\) be any set, \(a\) be any element of \(A\), and let \(g(n,m)\) be any function from \(\mathbb{N} \times A\) to \(A\). Then there is a unique function \(f: \mathbb{N} \to A\) satisfying the following two clauses:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(0) = a\)

\item {} 
\sphinxAtStartPar
\(f(\mathrm{succ}(n)) = g(n,f(n))\) for every \(n\) in \(N\)

\end{itemize}
\end{quote}

\sphinxAtStartPar
We can use the principle of recursive definition to define addition with the following two clauses:
\begin{equation*}
\begin{split}m + 0 & = m \\
m + \mathrm{succ}(n) & = \mathrm{succ}(m + n)\end{split}
\end{equation*}
\sphinxAtStartPar
Note that we are fixing \(m\), and viewing this as a function of \(n\). If we write \(1 = \mathrm{succ}(0)\), \(2 = \mathrm{succ}(1)\), and so on, it is easy to prove \(n + 1 = \mathrm{succ}(n)\) from the definition of addition.

\sphinxAtStartPar
We can proceed to define multiplication using the following two clauses:
\begin{equation*}
\begin{split}m \cdot 0 & = 0 \\
m \cdot \mathrm{succ}(n) & = m \cdot n + m\end{split}
\end{equation*}
\sphinxAtStartPar
We can also define a predecessor function by
\begin{equation*}
\begin{split}\mathrm{pred}(0) & = 0 \\
\mathrm{pred}(\mathrm{succ}(n)) & = n\end{split}
\end{equation*}
\sphinxAtStartPar
We can define \sphinxstyleemphasis{truncated subtraction} by
\begin{equation*}
\begin{split}m \dot - 0 & = m \\
m \dot - (\mathrm{succ}(n)) & = \mathrm{pred}(m \dot - n)\end{split}
\end{equation*}
\sphinxAtStartPar
With these definitions and the induction principle, one can prove all the following identities:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n \neq 0\) implies \(\mathrm{succ}(\mathrm{pred}(n)) = n\)

\item {} 
\sphinxAtStartPar
\(0 + n = n\)

\item {} 
\sphinxAtStartPar
\(\mathrm{succ}(m) + n = \mathrm{succ}(m + n)\)

\item {} 
\sphinxAtStartPar
\((m + n) + k = m + (n + k)\)

\item {} 
\sphinxAtStartPar
\(m + n = n + m\)

\item {} 
\sphinxAtStartPar
\(m(n + k) = mn + mk\)

\item {} 
\sphinxAtStartPar
\(0 \cdot n = 0\)

\item {} 
\sphinxAtStartPar
\(1 \cdot n = n\)

\item {} 
\sphinxAtStartPar
\((mn)k = m(nk)\)

\item {} 
\sphinxAtStartPar
\(mn = nm\)

\end{itemize}

\sphinxAtStartPar
We will do the first five here, and leave the remaining ones as exercises.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every natural number \(n\), if \(n \neq 0\) then \(\mathrm{succ}(\mathrm{pred}(n)) = n\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(n\). We have ruled out the case where \(n\) is \(0\), so we only need to show that the claim holds for \(\mathrm{succ}(n)\). But in that case, we have \(\mathrm{succ}(\mathrm{pred}(\mathrm{succ}(n)) = \mathrm{succ}(n)\) by the second defining clause of the predecessor function.

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every \(n\), \(0 + n = n\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(n\). We have \(0 + 0 = 0\) by the first defining clause for addition. And assuming \(0 + n = n\), we have \(0 + \mathrm{succ}(n) = \mathrm{succ}(0 + n) = n\), using the second defining clause for addition.

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every \(m\) and \(n\), \(\mathrm{succ}(m) + n = \mathrm{succ}(m + n)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Fix \(m\) and use induction on \(n\). Then \(n = 0\), we have \(\mathrm{succ}(m) + 0 = \mathrm{succ}(m) = \mathrm{succ}(m + 0)\), using the first defining clause for addition. Assuming the claim holds for \(n\), we have
\begin{equation*}
\begin{split}\mathrm{succ}(m) + \mathrm{succ}(n) & = \mathrm{succ}(\mathrm{succ}(m) + n) \\
& = \mathrm{succ} (\mathrm{succ} (m + n)) \\
& = \mathrm{succ} (m + \mathrm{succ}(n))\end{split}
\end{equation*}
\sphinxAtStartPar
using the inductive hypothesis and the second defining clause for addition.

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every \(m\), \(n\), and \(k\), \((m + n) + k = m + (n + k)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(k\). The case where \(k = 0\) is easy, and in the induction step we have
\begin{equation*}
\begin{split}(m + n) + \mathrm{succ}(k) & = \mathrm{succ} ((m + n) + k) \\
& = \mathrm{succ} (m + (n + k)) \\
& = m + \mathrm{succ} (n + k) \\
& = m + (n + \mathrm{succ} (k)))\end{split}
\end{equation*}
\sphinxAtStartPar
using the inductive hypothesis and the definition of addition.

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every pair of natural numbers \(m\) and \(n\), \(m + n = n + m\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(n\). The base case is easy using the second proposition above. In the inductive step, we have
\begin{equation*}
\begin{split}m + \mathrm{succ}(n) & = \mathrm{succ}(m + n) \\
& = \mathrm{succ} (n + m) \\
& = \mathrm{succ}(n) + m\end{split}
\end{equation*}
\sphinxAtStartPar
using the third proposition above.


\bigskip\hrule\bigskip



\section{Arithmetic on the Natural Numbers}
\label{\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}}\label{\detokenize{the_natural_numbers_and_induction:id4}}
\sphinxAtStartPar
Continuing as in the last section, we can establish all the basic properties of the natural numbers that play a role in day\sphinxhyphen{}to\sphinxhyphen{}day mathematics. We summarize the main ones here:
\begin{equation*}
\begin{split}m + n &= n + m \quad \text{(commutativity of addition)}\\
m + (n + k) &= (m + n) + k \quad \text{(associativity of addition)}\\
n + 0 &= n \quad \text{($0$ is a neutral element for addition)}\\
n \cdot m &= m \cdot n \quad \text{(commutativity of multiplication)}\\
m \cdot (n \cdot k) &= (m \cdot n) \cdot k \quad \text{(associativity of multiplication)}\\
n \cdot 1 &= n \quad \text{($1$ is an neutral element for multiplication)}\\
n \cdot (m + k) &= n \cdot m + n \cdot k \quad \text{(distributivity)}\\
n \cdot 0 &= 0 \quad \text{($0$ is an absorbing element for multiplication)}\end{split}
\end{equation*}
\sphinxAtStartPar
In an ordinary mathematical argument or calculation, they can be used without explicit justification. We also have the following properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n + 1 \neq 0\)

\item {} 
\sphinxAtStartPar
if \(n + k = m + k\) then \(n = m\)

\item {} 
\sphinxAtStartPar
if \(n \cdot k = m \cdot k\) and \(k \neq 0\) then \(n = m\)

\end{itemize}

\sphinxAtStartPar
We can define \(m \le n\), “\(m\) is less than or equal to \(n\),” to mean that there exists a \(k\) such that \(m + k = n\). If we do that, it is not hard to show that the less\sphinxhyphen{}than\sphinxhyphen{}or\sphinxhyphen{}equal\sphinxhyphen{}to relation satisfies all the following properties, for every \(n\), \(m\), and \(k\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n \le n\) (\sphinxstyleemphasis{reflexivity})

\item {} 
\sphinxAtStartPar
if \(n \le m\) and \(m \le k\) then \(n \le k\) (\sphinxstyleemphasis{transitivity})

\item {} 
\sphinxAtStartPar
if \(n \le m\) and \(m \le n\) then \(n = m\) (\sphinxstyleemphasis{antisymmetry})

\item {} 
\sphinxAtStartPar
for all \(n\) and \(m\), either \(n \le m\) or \(m \le n\) is true (\sphinxstyleemphasis{totality})

\item {} 
\sphinxAtStartPar
if \(n \le m\) then \(n + k \le m + k\)

\item {} 
\sphinxAtStartPar
if \(n + k \le m + k\) then \(n \le m\)

\item {} 
\sphinxAtStartPar
if \(n \le m\) then \(nk \le mk\)

\item {} 
\sphinxAtStartPar
if \(m \ge n\) then \(m = n\) or \(m \ge n + 1\)

\item {} 
\sphinxAtStartPar
\(0 \le n\)

\end{itemize}

\sphinxAtStartPar
Remember from \hyperref[\detokenize{relations:relations}]{Chapter \ref{\detokenize{relations:relations}}} that the first four items assert that \(\le\) is a linear order. Note that when we write \(m \ge n\), we mean \(n \le m\).

\sphinxAtStartPar
As usual, then, we can define \(m < n\) to mean that \(m \le n\) and \(m \ne n\). In that case, we have that \(m \le n\) holds if and only if \(m < n\) or \(m = n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every \(m\), \(m + 1 \not\le 0\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Otherwise, we would have \((m + 1) + k = (m + k) + 1 = 0\) for some \(k\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
In particular, taking \(m = 0\), we have \(1 \not\le 0\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} We have \(m < n\) if and only if \(m + 1 \le n\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(m < n\). Then \(m \le n\) and \(m \ne n\). So there is a \(k\) such that \(m + k = n\), and since \(m \ne n\), we have \(k \ne 0\). Then \(k = u + 1\) for some \(u\), which means we have \(m + (u + 1) = m + 1 + u = n\), so \(m \le n\), as required.

\sphinxAtStartPar
In the other direction, suppose \(m + 1 \le n\). Then \(m \le n\). We also have \(m \ne n\), since if \(m = n\), we would have \(m + 1 \le m + 0\) and hence \(1 \le 0\), a contradiction.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In a similar way, we can show that \(m < n\) if and only if \(m \le n\) and \(m \ne n\). In fact, we can demonstrate all of the following from these properties and the properties of \(\le\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n < n\) is never true (\sphinxstyleemphasis{irreflexivity})

\item {} 
\sphinxAtStartPar
if \(n < m\) and \(m < k\) then \(n < k\) (\sphinxstyleemphasis{transitivity})

\item {} 
\sphinxAtStartPar
for all \(n\) and \(m\), either \(n < m\), \(n = m\) or \(m < n\) is true (\sphinxstyleemphasis{trichotomy})

\item {} 
\sphinxAtStartPar
if \(n < m\) then \(n + k < m + k\)

\item {} 
\sphinxAtStartPar
if \(k > 0\) and \(n < m\) then \(nk < mk\)

\item {} 
\sphinxAtStartPar
if \(m > n\) then \(m = n + 1\) or \(m > n + 1\)

\item {} 
\sphinxAtStartPar
for all \(n\), \(n = 0\) or \(n > 0\)

\end{itemize}

\sphinxAtStartPar
The first three items mean that \(<\) is a strict linear order, and the properties above means that \(\le\) is the associated linear order, in the sense described in \hyperref[\detokenize{relations:order-relations}]{Section \ref{\detokenize{relations:order-relations}}}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proof}. We will prove some of these properties using the previous characterization of the less\sphinxhyphen{}than relation.

\sphinxAtStartPar
The first property is straightforward: we know \(n \le n + 1\), and if we had \(n + 1 \le n\), we should have \(n = n + 1\), a contradiction.

\sphinxAtStartPar
For the second property, assume \(n < m\) and \(m < k\). Then \(n + 1 \le m \le m + 1 \le k\), which implies \(n < k\).

\sphinxAtStartPar
For the third, we know that either \(n \le m\) or \(m \le n\). If \(m = n\), we are done, and otherwise we have either \(n < m\) or \(m < n\).

\sphinxAtStartPar
For the fourth, if \(n + 1 \le m\), we have \(n + 1 + k = (n + k) + 1 \le m + k\), as required.

\sphinxAtStartPar
For the fifth, suppose \(k > 0\), which is to say, \(k \ge 1\). If \(n < m\), then \(n + 1 \le m\), and so \(nk + 1 \le n k + k \le mk\). But this implies \(n k < m k\), as required.

\sphinxAtStartPar
The rest of the remaining proofs are left as an exercise to the reader.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here are some additional properties of \(<\) and \(\le\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n < m\) and \(m < n\) cannot both hold (\sphinxstyleemphasis{asymmetry})

\item {} 
\sphinxAtStartPar
\(n + 1 > n\)

\item {} 
\sphinxAtStartPar
if \(n < m\) and \(m \le k\) then \(n < k\)

\item {} 
\sphinxAtStartPar
if \(n \le m\) and \(m < k\) then \(n < k\)

\item {} 
\sphinxAtStartPar
if \(m > n\) then \(m \ge n + 1\)

\item {} 
\sphinxAtStartPar
if \(m \ge n\) then \(m + 1 > n\)

\item {} 
\sphinxAtStartPar
if \(n + k < m + k\) then \(n < m\)

\item {} 
\sphinxAtStartPar
if \(nk < mk\) then \(k > 0\) and \(n < m\)

\end{itemize}

\sphinxAtStartPar
These can be proved from the ones above. Moreover, the collection of principles we have just seen can be used to justify basic facts about the natural numbers, which are again typically taken for granted in informal mathematical arguments.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} If \(m\) and \(n\) are natural numbers such that \(m + n = 0\), then \(m = n = 0\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} If \(m + n = 0\), then \(m \le 0\), so \(m = 0\) and \(n = 0 + n = m + n = 0\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} If \(n\) is a natural number such that \(n < 3\), then \(n = 0\), \(n = 1\) or \(n = 2\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} In this proof we repeatedly use the property that if \(m > n\) then \(m = n + 1\) or \(m > n + 1\). Since \(2 + 1 = 3 > n\), we conclude that either \(2 + 1 = n + 1\) or \(2 + 1 > n + 1\). In the first case we conclude \(n = 2\), and we are done. In the second case we conclude \(2 > n\), which implies that either \(2 = n + 1\), or \(2 > n + 1\). In the first case, we conclude \(n = 1\), and we are done. In the second case, we conclude \(1 > n\), and appeal one last time to the general principle presented above to conclude that either \(1 = n + 1\) or \(1 > n + 1\). In the first case, we conclude \(n = 0\), and we are once again done. In the second case, we conclude that \(0 > n\). This leads to a contradiction, since now \(0 > n \ge 0\), hence \(0 > 0\), which contradicts the irreflexivity of \(>\).


\bigskip\hrule\bigskip



\section{The Integers}
\label{\detokenize{the_natural_numbers_and_induction:the-integers}}\label{\detokenize{the_natural_numbers_and_induction:id5}}
\sphinxAtStartPar
The natural numbers are designed for counting discrete quantities, but they suffer an annoying drawback: it is possible to subtract \(n\) from \(m\) if \(n\) is less than or equal to \(m\), but not if \(m\) is greater than \(n\). The set of \sphinxstyleemphasis{integers}, \(\mathbb{Z}\), extends the natural numbers with negative values, to make it possible to carry out subtraction in full:
\begin{equation*}
\begin{split}\mathbb{Z} = \{ \ldots, -3, -2, -1, 0, 1, 2, 3, \ldots \}.\end{split}
\end{equation*}
\sphinxAtStartPar
We will see in a later chapter that the integers can be extended to the \sphinxstyleemphasis{rational numbers}, the \sphinxstyleemphasis{real numbers}, and the \sphinxstyleemphasis{complex numbers}, each of which serves useful purposes. For dealing with discrete quantities, however, the integers will get us pretty far.

\sphinxAtStartPar
You can think of the integers as consisting of two copies of the natural numbers, a positive one and a negative one, sharing a common zero. Conversely, once we have the integers, you can think of the natural numbers as consisting of the nonnegative integers, that is, the integers that are greater than or equal to \(0\). Most mathematicians blur the distinction between the two, though we will see that in Lean, for example, the natural numbers and the integers represent two different data types.

\sphinxAtStartPar
Most of the properties of the natural numbers that were enumerated in the last section hold of the integers as well, but not all. For example, it is no longer the case that \(n + 1 \neq 0\) for every \(n\), since the claim is false for \(n = -1\). For another example, it is not the case that every integer is either equal to \(0\) or greater than \(0\), since this fails to hold of the negative integers.

\sphinxAtStartPar
The key property that the integers enjoy, which sets them apart from the natural numbers, is that for every integer \(n\) there is a value \(-n\) with the property that \(n + (-n) = 0\). The value \(-n\) is called the \sphinxstyleemphasis{negation} of \(n\). We define subtraction \(n - m\) to be \(n + (-m)\). For any integer \(n\), we also define the \sphinxstyleemphasis{absolute value} of \(n\), written \(|n|\), to be \(n\) if \(n \geq 0\), and \(-n\) otherwise.

\sphinxAtStartPar
We can no longer use proof by induction on the integers, because induction does not cover the negative numbers. But we can use induction to show that a property holds of every nonnegative integer, for example. Moreover, we know that every negative integer is the negation of a positive one. As a result, proofs involving the integers often break down into two cases, where one case covers the nonnegative integers, and the other case covers the negative ones.


\section{Exercises}
\label{\detokenize{the_natural_numbers_and_induction:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Write the principle of complete induction using the notation of symbolic logic. Also write the least element principle this way, and use logical manipulations to show that the two are equivalent.

\item {} 
\sphinxAtStartPar
Show that for every \(n\), \(0^2 + 1^2 + 2^2 + \ldots n^2= \frac{1}{6}n(1+n)(1+2n)\).

\item {} 
\sphinxAtStartPar
Show that for every \(n\), \(0^3 + 1^3 + \ldots + n^3 = \frac{1}{4} n^2 (n+1)^2\).

\item {} 
\sphinxAtStartPar
Show that for every \(n\), \(\sum_{i \le n} \frac{i}{(i + 1)!} = \frac{n! - 1}{n}\).

\item {} 
\sphinxAtStartPar
Given the definition of the Fibonacci numbers in \hyperref[\detokenize{the_natural_numbers_and_induction:recursive-definitions}]{Section \ref{\detokenize{the_natural_numbers_and_induction:recursive-definitions}}}, prove Cassini’s identity: for every \(n\), \(F^2_{n+1} - F_{n+2} F_n = (-1)^n\). Hint: in the induction step, write \(F_{n+2}^2\) as \(F_{n+2}(F_{n+1} + F_n)\).

\item {} 
\sphinxAtStartPar
Prove \(\sum_{i < n} F_{2i+1} = F_{2n}\).

\item {} 
\sphinxAtStartPar
Prove the following two identities:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(F_{2n+1} = F^2_{n+1} + F^2_n\)

\item {} 
\sphinxAtStartPar
\(F_{2n+2} = F^2_{n+2} - F^2_n\)

\end{itemize}

\sphinxAtStartPar
Hint: use induction on \(n\), and prove them both at once. In the induction step, expand \(F_{2n+3} = F_{2n+2} + F_{2n+1}\), and similarly for \(F_{2n+4}\). Proving the second equation is especially tricky. Use the inductive hypothesis and the first identity to simplify the left\sphinxhyphen{}hand side, and repeatedly unfold the Fibonacci number with the highest index and simplify the equation you need to prove. (When you have worked out a solution, write a clear equational proof, calculating in the ``forward’’ direction.)

\item {} 
\sphinxAtStartPar
Prove that every natural number can be written as a sum of \sphinxstyleemphasis{distinct} powers of 2. For this problem, \(1 = 2^0\) is counted as power of 2.

\item {} 
\sphinxAtStartPar
Let \(V\) be a non\sphinxhyphen{}empty set of integers such that the following two properties hold:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(x, y \in V\), then \(x - y \in V\).

\item {} 
\sphinxAtStartPar
If \(x \in V\), then every multiple of \(x\) is an element of \(V\).

\end{itemize}

\sphinxAtStartPar
Prove that there is some \(d \in V\), such that \(V\) is equal to the set of multiples of \(d\). Hint: use the least element principle.

\item {} 
\sphinxAtStartPar
Give an informal but detailed proof that for every natural number \(n\), \(1 \cdot n = n\), using a proof by induction, the definition of multiplication, and the theorems proved in \hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}}.

\item {} 
\sphinxAtStartPar
Show that multiplication distributes over addition. In other words, prove that for natural numbers \(m\), \(n\), and \(k\), \(m (n + k) = m n + m k\). You should use the definitions of addition and multiplication and facts proved in \hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}} (but nothing more).

\item {} 
\sphinxAtStartPar
Prove the multiplication is associative, in the same way. You can use any of the facts proved in \hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}} and the previous exercise.

\item {} 
\sphinxAtStartPar
Prove that multiplication is commutative.

\item {} 
\sphinxAtStartPar
Prove \((m^n)^k = m^{nk}\).

\item {} 
\sphinxAtStartPar
Following the example in \hyperref[\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}}}, prove that if \(n\) is a natural number and \(n < 5\), then \(n\) is one of the values \(0, 1, 2, 3\), or \(4\).

\item {} 
\sphinxAtStartPar
Prove that if \(n\) and \(m\) are natural numbers and \(n m = 1\), then \(n = m = 1\), using only properties listed in \hyperref[\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}}}.

\sphinxAtStartPar
This is tricky. First show that \(n\) and \(m\) are greater than \(0\), and hence greater than or equal to \(1\). Then show that if either one of them is greater than \(1\), then \(n m > 1\).

\item {} 
\sphinxAtStartPar
Prove any of the other claims in \hyperref[\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}}} that were stated without proof.

\item {} 
\sphinxAtStartPar
Prove the following properties of negation and subtraction on the integers, using only the properties of negation and subtraction given in \hyperref[\detokenize{the_natural_numbers_and_induction:the-integers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:the-integers}}}.
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(n + m = 0\) then \(m = -n\).

\item {} 
\sphinxAtStartPar
\(-0 = 0\).

\item {} 
\sphinxAtStartPar
If \(-n = -m\) then \(n = m\).

\item {} 
\sphinxAtStartPar
\(m + (n - m) = n\).

\item {} 
\sphinxAtStartPar
\(-(n + m) = -n - m\).

\item {} 
\sphinxAtStartPar
If \(m < n\) then \(n - m > 0\).

\item {} 
\sphinxAtStartPar
If \(m < n\) then \(-m > -n\).

\item {} 
\sphinxAtStartPar
\(n \cdot (-m) = -nm\).

\item {} 
\sphinxAtStartPar
\(n(m - k) = nm - nk\).

\item {} 
\sphinxAtStartPar
If \(n < m\) then \(n - k < m - k\).

\end{itemize}

\item {} 
\sphinxAtStartPar
Suppose you have an infinite chessboard with a natural number written in each square. The value in each square is the average of the values of the four neighboring squares. Prove that all the values on the chessboard are equal.

\item {} 
\sphinxAtStartPar
Prove that every natural number can be written as a sum of \sphinxstyleemphasis{distinct non\sphinxhyphen{}consecutive} Fibonacci numbers. For example, \(22 = 1 + 3 + 5 + 13\) is not allowed, since 3 and 5 are consecutive Fibonacci numbers, but \(22 = 1 + 21\) is allowed.

\end{enumerate}


\chapter{The Natural Numbers and Induction in Lean}
\label{\detokenize{the_natural_numbers_and_induction_in_lean:the-natural-numbers-and-induction-in-lean}}\label{\detokenize{the_natural_numbers_and_induction_in_lean:id1}}\label{\detokenize{the_natural_numbers_and_induction_in_lean::doc}}

\section{Induction and Recursion in Lean}
\label{\detokenize{the_natural_numbers_and_induction_in_lean:induction-and-recursion-in-lean}}
\sphinxAtStartPar
Internally, in Lean, the natural numbers are defined as a type generated inductively from an axiomatically declared \sphinxcode{\sphinxupquote{zero}} and \sphinxcode{\sphinxupquote{succ}} operation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{inductive} \PYG{n}{Nat} \PYG{o}{:} \PYG{k+kt}{Type}
\PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{o}{:} \PYG{n}{Nat}
\PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{o}{:} \PYG{n}{Nat} \PYG{n+nb+bp}{→} \PYG{n}{Nat}
\end{sphinxVerbatim}

\sphinxAtStartPar
If you click the button that copies this text into the editor in the online version of this textbook, you will see that we wrap it with the phrases \sphinxcode{\sphinxupquote{namespace hidden}} and \sphinxcode{\sphinxupquote{end hidden}}. This puts the definition into a new “namespace,” so that the identifiers that are defined are \sphinxcode{\sphinxupquote{hidden.Nat}}, \sphinxcode{\sphinxupquote{hidden.Nat.zero}} and \sphinxcode{\sphinxupquote{hidden.Nat.succ}}, to avoid conflicting with the one that is in the Lean library. Below, we will do that in a number of places where our examples duplicate objects defined in the library. The unicode symbol \sphinxcode{\sphinxupquote{ℕ}}, entered with \sphinxcode{\sphinxupquote{\textbackslash{}N}} or \sphinxcode{\sphinxupquote{\textbackslash{}nat}}, is a synonym for \sphinxcode{\sphinxupquote{Nat}}.

\sphinxAtStartPar
Declaring \sphinxcode{\sphinxupquote{Nat}} as an inductively defined type means that we can define functions by recursion, and prove theorems by induction. For example, these are the first two recursive definitions presented in the last chapter:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{k+kd}{def} \PYG{n}{two\PYGZus{}pow} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}        \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{two\PYGZus{}pow} \PYG{n}{n}

\PYG{k+kd}{def} \PYG{n}{fact} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}        \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{fact} \PYG{n}{n}
\end{sphinxVerbatim}

\sphinxAtStartPar
Addition and numerals are defined in such a way that Lean recognizes \sphinxcode{\sphinxupquote{succ n}} and \sphinxcode{\sphinxupquote{n + 1}} as essentially the same, so we could instead write these definitions as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{two\PYGZus{}pow} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}       \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{2} \PYG{n+nb+bp}{*} \PYG{n}{two\PYGZus{}pow} \PYG{n}{n}

\PYG{k+kd}{def} \PYG{n}{fact} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}       \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{fact} \PYG{n}{n}
\end{sphinxVerbatim}

\sphinxAtStartPar
If we wanted to define the function \sphinxcode{\sphinxupquote{m\textasciicircum{}n}}, we would do that by fixing \sphinxcode{\sphinxupquote{m}}, and writing doing the recursion on the second argument:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{def} \PYG{n}{pow} \PYG{o}{(}\PYG{n}{m} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}        \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)}  \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{o}{(}\PYG{n}{pow} \PYG{n}{m} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}
\end{sphinxVerbatim}

\sphinxAtStartPar
In fact, this is how the power function on the natural numbers,
\sphinxcode{\sphinxupquote{Nat.pow}}, is defined in Lean’s library.

\sphinxAtStartPar
Lean is also smart enough to interpret more complicated forms of recursion, like this one:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{} BEGIN}
\PYG{k+kd}{def} \PYG{n}{fib} \PYG{o}{:} \PYG{n}{ℕ} \PYG{n+nb+bp}{→} \PYG{n}{ℕ}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{0}        \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{0}
\PYG{n+nb+bp}{|} \PYG{l+m+mi}{1}        \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{l+m+mi}{1}
\PYG{n+nb+bp}{|} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{2}\PYG{o}{)}  \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{fib} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{+} \PYG{n}{fib} \PYG{n}{n}
\end{sphinxVerbatim}

\sphinxAtStartPar
In addition to defining functions by recursion, we can prove theorems by induction. In Lean, each clause of a recursive definition results in a new identity. For example, the two clauses in the definition of \sphinxcode{\sphinxupquote{pow}} above give rise to the following two theorems:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Nat.pow} \PYG{n}{n} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{n}{rfl}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{Nat.pow} \PYG{n}{m} \PYG{o}{(}\PYG{n}{n}\PYG{n+nb+bp}{+}\PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{Nat.pow} \PYG{n}{m} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m} \PYG{o}{:=} \PYG{n}{rfl}
\end{sphinxVerbatim}

\sphinxAtStartPar
Lean defines the usual notation for exponentiation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{n}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{n}{rfl}
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{n}\PYG{n+nb+bp}{+}\PYG{l+m+mi}{1}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m} \PYG{o}{:=} \PYG{n}{rfl}

\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.pow\PYGZus{}zero}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.pow\PYGZus{}succ}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice that we could alternatively have used \sphinxcode{\sphinxupquote{m * Nat.pow m n}}
in the second clause of the definition of \sphinxcode{\sphinxupquote{Nat.pow}}.
Of course, we can prove that the two definitions are equivalent using the
commutativity of multiplication, but,
using a proof by induction,
we can also prove it using only the associativity of multiplication,
and the properties \sphinxcode{\sphinxupquote{1 * m = m}} and \sphinxcode{\sphinxupquote{m * 1 = m}}.
This is useful, because the power function is also often used in situations
where multiplication is not commutative,
such as with matrix multiplication.
The theorem can be proved in Lean as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{induction} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0}
    \PYG{k}{calc}
        \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{*} \PYG{n}{m} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{*} \PYG{n}{m}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}zero}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m}       \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.one\PYGZus{}mul}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{l+m+mi}{1}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.mul\PYGZus{}one}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}zero}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n}{ih} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}
    \PYG{k}{calc}
      \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{]}
                      \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}    \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{ih}\PYG{o}{]}
                      \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{o}{)}    \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.mul\PYGZus{}assoc}\PYG{o}{]}
                      \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}    \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
This is a typical proof by induction in Lean.
It begins with the tactic \sphinxcode{\sphinxupquote{induction n with}},
which is like \sphinxcode{\sphinxupquote{cases n with}},
but also supplies the induction hypothesis \sphinxcode{\sphinxupquote{ih}}
in the successor case.
Here is a shorter proof:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{induction} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}zero}\PYG{o}{,} \PYG{n}{Nat.one\PYGZus{}mul}\PYG{o}{,} \PYG{n}{Nat.mul\PYGZus{}one}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n}{ih} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{,} \PYG{n+nb+bp}{←} \PYG{n}{Nat.mul\PYGZus{}assoc}\PYG{o}{,} \PYG{n+nb+bp}{←} \PYG{n}{ih}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}succ}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Remember that you can write a \sphinxcode{\sphinxupquote{rewrite}} proof incrementally, checking the error messages to make sure things are working so far, and to see how far Lean got.

\sphinxAtStartPar
As another example of a proof by induction, here is a proof of the identity \sphinxcode{\sphinxupquote{m\textasciicircum{}(n + k) = m\textasciicircum{}n * m\textasciicircum{}k}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{induction} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}
    \PYG{k}{calc} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}       \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.zero\PYGZus{}add}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.one\PYGZus{}mul}\PYG{o}{]}
                 \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}zero}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n}{ih} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}
    \PYG{k}{calc}
      \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.succ\PYGZus{}add}\PYG{o}{]}
                  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)}    \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ\PYGZsq{}}\PYG{o}{]}
                  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}\PYG{o}{)}    \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{ih}\PYG{o}{]}
                  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}  \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.mul\PYGZus{}assoc}\PYG{o}{]}
                  \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pow\PYGZus{}succ\PYGZsq{}}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Notice the same pattern.
We do induction on \sphinxcode{\sphinxupquote{n}},
and the base case and inductive step are routine.
The theorem is called \sphinxcode{\sphinxupquote{pow\_add}} in the library,
and once again, with a bit of cleverness,
we can shorten the proof with \sphinxcode{\sphinxupquote{rewrite}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{induction} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.zero\PYGZus{}add}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}zero}\PYG{o}{,} \PYG{n}{Nat.one\PYGZus{}mul}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n}{ih} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{o}{(}\PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{m}\PYG{n+nb+bp}{\PYGZca{}}\PYG{n}{k}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.succ\PYGZus{}add}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}succ\PYGZsq{}}\PYG{o}{,} \PYG{n}{ih}\PYG{o}{,} \PYG{n+nb+bp}{←} \PYG{n}{Nat.mul\PYGZus{}assoc}\PYG{o}{,} \PYG{n}{Nat.pow\PYGZus{}succ\PYGZsq{}}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
You should not hesitate to use \sphinxcode{\sphinxupquote{calc}},
however, to make the proofs more explicit.
Remember that you can also use \sphinxcode{\sphinxupquote{calc}} and \sphinxcode{\sphinxupquote{rewrite}} together,
using \sphinxcode{\sphinxupquote{calc}} to structure the calculational proof,
and using \sphinxcode{\sphinxupquote{rewrite}} to fill in each justification step.


\section{Defining the Arithmetic Operations in Lean}
\label{\detokenize{the_natural_numbers_and_induction_in_lean:defining-the-arithmetic-operations-in-lean}}
\sphinxAtStartPar
In fact, addition and multiplication are defined in Lean essentially as described in \hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}}. The defining equations for addition hold by reflexivity, but they are also named \sphinxcode{\sphinxupquote{add\_zero}} and \sphinxcode{\sphinxupquote{add\_succ}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{o}{:=} \PYG{n}{Nat.add\PYGZus{}zero} \PYG{n}{m}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=} \PYG{n}{Nat.add\PYGZus{}succ} \PYG{n}{m} \PYG{n}{n}
\end{sphinxVerbatim}

\sphinxAtStartPar
Similarly, we have the defining equations for the predecessor function
and multiplication:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.pred\PYGZus{}zero}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.pred\PYGZus{}succ}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.mul\PYGZus{}zero}
\PYG{k}{\PYGZsh{}check} \PYG{n+nb+bp}{@}\PYG{n}{Nat.mul\PYGZus{}succ}
\end{sphinxVerbatim}

\sphinxAtStartPar
Here are the five propositions proved in \hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{succ\PYGZus{}pred} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{ℕ}\PYG{o}{)} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{≠} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{→} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{pred} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{o}{:=} \PYG{k+kd}{by}
  \PYG{n}{intro} \PYG{o}{(}\PYG{n}{hn} \PYG{o}{:} \PYG{n}{n} \PYG{n+nb+bp}{≠} \PYG{l+m+mi}{0}\PYG{o}{)}
  \PYG{n}{cases} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{exact} \PYG{n}{absurd} \PYG{n}{rfl} \PYG{o}{(}\PYG{n}{hn} \PYG{o}{:} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{≠} \PYG{l+m+mi}{0}\PYG{o}{)}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.pred\PYGZus{}succ}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that we don’t need to use \sphinxcode{\sphinxupquote{induction}} here, only \sphinxcode{\sphinxupquote{cases}}.
We prove the next one in term mode instead:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{zero\PYGZus{}add} \PYG{o}{(}\PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{)} \PYG{o}{:} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{o}{:=}
  \PYG{k}{match} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{n}{zero} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{k}{from} \PYG{n}{rfl}
  \PYG{n+nb+bp}{|} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{n}{n} \PYG{k}{from} \PYG{k}{calc}
      \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rfl}
               \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{n}{n} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{zero\PYGZus{}add} \PYG{n}{n}\PYG{o}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{match}} notation is very similar to \sphinxcode{\sphinxupquote{induction}},
except it does not let us provide a name like \sphinxcode{\sphinxupquote{ih}}
for the induction hypothesis.
Instead, we call \sphinxcode{\sphinxupquote{zero\_add n : 0 + n = n}},
which is the induction hypothesis.
Note that calling \sphinxcode{\sphinxupquote{zero\_add (succ n)}} in the same place would be circular,
and if we did so Lean would throw an error.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{succ\PYGZus{}add} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{)} \PYG{o}{:} \PYG{n}{succ} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=}
  \PYG{k}{match} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{n}{succ} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{k}{from} \PYG{n}{rfl}
  \PYG{n+nb+bp}{|} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}}
    \PYG{k}{show} \PYG{n}{succ} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{k}{from} \PYG{k}{calc}
         \PYG{n}{succ} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rfl}
                       \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{succ\PYGZus{}add} \PYG{n}{m} \PYG{n}{n}\PYG{o}{]}
                       \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rfl}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note that this time we used \sphinxcode{\sphinxupquote{0}} and \sphinxcode{\sphinxupquote{n + 1}} in the \sphinxcode{\sphinxupquote{match}} cases.
Here are the final two:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kd}{theorem} \PYG{n}{add\PYGZus{}assoc} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{o}{:=}
  \PYG{k}{match} \PYG{n}{k} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0}\PYG{o}{)} \PYG{k}{from} \PYG{k+kd}{by}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.add\PYGZus{}zero}\PYG{o}{,} \PYG{n}{Nat.add\PYGZus{}zero}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{k} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{k} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{o}{(}\PYG{n}{succ} \PYG{n}{k}\PYG{o}{)}\PYG{o}{)} \PYG{k}{from} \PYG{k+kd}{by}
    \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}succ}\PYG{o}{,} \PYG{n}{add\PYGZus{}assoc} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k}\PYG{o}{,} \PYG{n}{add\PYGZus{}succ}\PYG{o}{,} \PYG{n}{add\PYGZus{}succ}\PYG{o}{]}

\PYG{k+kd}{theorem} \PYG{n}{add\PYGZus{}comm} \PYG{o}{(}\PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{)} \PYG{o}{:} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{m} \PYG{o}{:=}
  \PYG{k}{match} \PYG{n}{n} \PYG{k}{with}
  \PYG{n+nb+bp}{|} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{+} \PYG{n}{m} \PYG{k}{from} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{Nat.add\PYGZus{}zero}\PYG{o}{,} \PYG{n}{Nat.zero\PYGZus{}add}\PYG{o}{]}
  \PYG{n+nb+bp}{|} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{=}\PYG{n+nb+bp}{\PYGZgt{}} \PYG{k}{show} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{m} \PYG{k}{from} \PYG{k}{calc}
      \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{n}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}succ}\PYG{o}{]}
               \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{m}\PYG{o}{)} \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{add\PYGZus{}comm} \PYG{n}{m} \PYG{n}{n}\PYG{o}{]}
               \PYG{n}{\PYGZus{}} \PYG{n+nb+bp}{=} \PYG{n}{succ} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{m}   \PYG{o}{:=} \PYG{k+kd}{by} \PYG{n}{rw} \PYG{o}{[}\PYG{n}{succ\PYGZus{}add}\PYG{o}{]}
\end{sphinxVerbatim}


\section{Exercises}
\label{\detokenize{the_natural_numbers_and_induction_in_lean:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Formalize as many of the identities from
\hyperref[\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}]{Section \ref{\detokenize{the_natural_numbers_and_induction:defining-arithmetic-operations}}}
as you can by replacing each \sphinxtitleref{sorry} with a proof.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}1.a.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k}\PYG{o}{)} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{k} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}1.b.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{*} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{l+m+mi}{0} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}1.c.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{l+m+mi}{1} \PYG{n+nb+bp}{*} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}1.d.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{o}{(}\PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{n}\PYG{o}{)} \PYG{n+nb+bp}{*} \PYG{n}{k} \PYG{n+nb+bp}{=} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{o}{(}\PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{k}\PYG{o}{)} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}1.e.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{n} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{m} \PYG{o}{:=} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\item {} 
\sphinxAtStartPar
Formalize as many of the identities from \hyperref[\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:arithmetic-on-the-natural-numbers}}} as you can by replacing each \sphinxtitleref{sorry} with a proof.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n}{Mathlib.Data.Nat.Defs}

\PYG{k+kn}{open} \PYG{n}{Nat}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}2.a.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{n} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{n+nb+bp}{→} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{k} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}2.b.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{n} \PYG{n+nb+bp}{+} \PYG{n}{k} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{n+nb+bp}{+} \PYG{n}{k} \PYG{n+nb+bp}{→} \PYG{n}{n} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}2.c.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{n}{k} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{n} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{n+nb+bp}{→} \PYG{n}{n} \PYG{n+nb+bp}{*} \PYG{n}{k} \PYG{n+nb+bp}{≤} \PYG{n}{m} \PYG{n+nb+bp}{*} \PYG{n}{k} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}2.d.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{m} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{n}{m} \PYG{n+nb+bp}{≥} \PYG{n}{n} \PYG{n+nb+bp}{→} \PYG{n}{m} \PYG{n+nb+bp}{=} \PYG{n}{n} \PYG{n+nb+bp}{∨} \PYG{n}{m} \PYG{n+nb+bp}{≥} \PYG{n}{n}\PYG{n+nb+bp}{+}\PYG{l+m+mi}{1} \PYG{o}{:=} \PYG{g+gr}{sorry}

\PYG{c+c1}{\PYGZhy{}\PYGZhy{}2.e.}
\PYG{k+kd}{example} \PYG{o}{:} \PYG{n+nb+bp}{∀} \PYG{n}{n} \PYG{o}{:} \PYG{n}{Nat}\PYG{o}{,} \PYG{l+m+mi}{0} \PYG{n+nb+bp}{≤} \PYG{n}{n} \PYG{o}{:=} \PYG{g+gr}{sorry}
\end{sphinxVerbatim}

\end{enumerate}


\chapter{Elementary Number Theory}
\label{\detokenize{elementary_number_theory:elementary-number-theory}}\label{\detokenize{elementary_number_theory:id1}}\label{\detokenize{elementary_number_theory::doc}}
\sphinxAtStartPar
In the last two chapters, we saw that the natural numbers are characterized by the fact that they support \sphinxstyleemphasis{proof by induction} and \sphinxstyleemphasis{definition by recursion}. Moreover, with these components, we can actually define \(+\), \(\times\), and \(<\) in a suitable axiomatic foundation, and prove that they have the relevant properties. In \hyperref[\detokenize{the_natural_numbers_and_induction:the-integers}]{Section \ref{\detokenize{the_natural_numbers_and_induction:the-integers}}} we also discussed the integers, which include negative numbers and support the operation of subtraction.

\sphinxAtStartPar
The natural numbers and the integers are the central components of \sphinxstyleemphasis{number theory}, a branch of mathematics dating back to the ancients. In this chapter, we will discuss some of the rudiments of this subject.


\section{The Quotient\sphinxhyphen{}Remainder Theorem}
\label{\detokenize{elementary_number_theory:the-quotient-remainder-theorem}}
\sphinxAtStartPar
A key property of the integers that we will use here is the quotient\sphinxhyphen{}remainder theorem:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(n\) and \(m\) be integers with \(m > 0\). Then there are integers \(q\) and \(r\) satisfying \(n = m q + r\) and \(0 \le r < m\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} First we prove this in the case where \(n\) is a natural number, in which case use complete induction on \(n\). Let \(n\) be any natural number. If \(n < m\), then we can take \(q = 0\) and \(r = n\), and we indeed have \(n = m q + r\) and \(0 \le r < m\). Otherwise, we have \(n \geq m\). In this case \(n - m\) is a natural number smaller than \(n\). By induction hypothesis, we know that we can find \(q'\) and \(r'\) such that \(n - m = m q' + r'\) and \(0 \le r' < m\). Then we can choose \(q = q' + 1\) and \(r = r'\), and we obtain \(n = m q + r\) and \(0 \le r < m\), as desired.

\sphinxAtStartPar
If \(n\) is negative, then \(-(n+1)\) is a natural number, hence we can use the previous part for \(-(n+1)\) to obtain \(q'\) and \(r'\) such that \(-(n+1) = m q' + r'\) and \(0 \le r' < m\). Now let \(q = -(q' + 1)\) and \(r = m - r' - 1\). Then we can compute
\begin{equation*}
\begin{split}m q + r &= -m (q' + 1) + m - r' - 1\\
&=  -(m q' + r') - m + m - 1\\
&= -(-(n+1)) - 1\\
&= n + 1 - 1\\
&= n.\end{split}
\end{equation*}
\sphinxAtStartPar
Also, since \(r' \geq 0\) we have \(r < m\) and since \(r' < m\) we have \(r \geq 0\). This completes the proof.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Intuitively, \(q\) is the integer \sphinxstyleemphasis{quotient} when you divide \(n\) by \(m\) and \(r\) is the \sphinxstyleemphasis{remainder}. Remember that using the word “the” presupposes that there are unique values meeting that description. That is, in fact, the case:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} If \(n\) and \(m\) are as above, \(n = m q + r\) and \(n = m q' + r'\) with both \(r\) and \(r'\) less than \(m\), then \(q = q'\) and \(r = r'\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By assumption, we have \(mq + r = m q' + r'\). It suffices to show that \(q = q'\), because then \(m q = m q'\), and hence \(r = r'\).

\sphinxAtStartPar
Suppose \(q \ne q'\). Then either \(q < q'\) or \(q' < q\). Suppose without loss of generality that \(q < q'\). (The other case is symmetric.) Then \(m q < m q'\), so we can subtract \(mq\) from both sides of the equality \(mq + r = m q' + r'\) to obtain
\begin{equation*}
\begin{split}r = m q' + r' - m q = m (q - q') + r'.\end{split}
\end{equation*}
\sphinxAtStartPar
But since \(q' < q\), we have \(q - q' \ge 1\), which means
\begin{equation*}
\begin{split}m (q - q') + r' \ge m + r' \ge m,\end{split}
\end{equation*}
\sphinxAtStartPar
which contradicts the fact that \(r < m\).


\bigskip\hrule\bigskip



\section{Divisibility}
\label{\detokenize{elementary_number_theory:divisibility}}
\sphinxAtStartPar
We can define divisibility on the integers as follows.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Given two integers \(m\) and \(n\), we say that \(m\) \sphinxstyleemphasis{is a divisor of} \(n\), written \(m \mid n\), if there exists some integer \(k\) such that \(m \cdot k = n\). We also say that \(n\) \sphinxstyleemphasis{is divisible by} \(m\) or that \(m\) \sphinxstyleemphasis{divides} \(n\). We write \(m \nmid n\) to say that \(m\) is not a divisor of \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can now prove the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} The relation \(\mid\) is reflexive and transitive. Also, if \(n \mid m\) and \(m \mid n\), then \(m = \pm n\). This means that restricted to the natural numbers, this relation is a partial order.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Reflexivity is immediate, because \(n \cdot 1 = n\), hence \(n\mid n\).

\sphinxAtStartPar
For transitivity, suppose \(m \mid n\) and \(n \mid r\). Then there are \(k,\ell\) such that \(m \cdot k = n\) and \(n \cdot \ell = r\). Now we compute
\begin{equation*}
\begin{split}m \cdot (k \cdot \ell) &= (m \cdot k) \cdot \ell \\
& = n \cdot \ell  \\
& = r.\end{split}
\end{equation*}
\sphinxAtStartPar
Suppose that \(n\) and \(m\) are integers such that \(n\mid m\) and \(m \mid n\). Then there exist \(k\) and \(\ell\) such that \(n\cdot k = m\) and \(m \cdot \ell = n\). We distinguish two cases. If \(n = 0\), then we have \(m = n\cdot k = 0 = n\), so we are done. If \(n \neq 0\), then we use the the equations to get \(n \cdot k \cdot \ell = m \cdot \ell = n\), and we can cancel \(n\) on both sides to get \(k \cdot \ell = 1\). We conclude that \(k = \ell = \pm 1\), hence we get \(m = n \cdot k = \pm n\).

\sphinxAtStartPar
Note that this means that if \(n\) and \(m\) are both natural numbers, then \(n = m\), which means that \(\mid\) is antisymmetric, and hence a partial order, on the natural numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
See Exercise 1 for some basic properties of divisibility. For example, we have that for every \(a\), \(b\), and \(c\), if \(a \mid b\) and \(a \mid c\) then \(a \mid b + c\), and for every \(a\), \(b\), and \(c\), if \(a \mid b\) then \(a \mid bc\). Also, if \(a \mid b\) and \(b \ne 0\), then \sphinxtitleref{|a| le |b|}. We will use properties like these repeatedly.

\sphinxAtStartPar
An integer is \sphinxstyleemphasis{even} if it is divisible by \(2\), in other words, \(n\) is even if \(2 \mid n\). An integer is \sphinxstyleemphasis{odd} if it is not even. Of course, odd numbers are of the form \(2k+1\) for some \(k\), and we can prove this now.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If \(n\) is an odd integer, then \(n=2k+1\) for some integer \(k\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By the quotient\sphinxhyphen{}remainder theorem, we can write \(n = 2k+r\) for some integers \(k\) and \(r\) with \(0\le r < 2\). The last condition means that \(r = 0\) or \(r = 1\). In the first case, we have \(n = 2k\), hence \(2 \mid n\), contradicting that \(n\) is odd. So we have \(r = 1\), which means that \(n = 2k+1\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every sequence of \(k\) consecutive numbers contains a number divisible by \(k\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Denote the largest element of the sequence by \(n\). This means that the sequence is \(n - (k - 1), \ldots, n - 1, n\). By the quotient\sphinxhyphen{}remainder theorem, we have \(n = q k + r\) for some integers \(q\) and \(r\) with \(0\leq r < k\). From these inequalities we conclude that \(n - r\) is in our sequence, and \(n - r = q k\), hence divisible by \(k\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Given two integers \(m\) and \(n\) such that either \(m \neq 0\) or \(n \neq 0\), we define the \sphinxstyleemphasis{greatest common divisor} \(\gcd(m,n)\) of \(m\) and \(n\) to be the largest integer \(d\) which is both a divisor of \(m\) and \(n\), that is, \(d \mid m\) and \(d \mid n\).

\sphinxAtStartPar
This largest integer exists, because there is at least one common divisor, but only finitely many. There is at least one, since 1 is a common divisor of any two integers, and there are finitely many, since a nonzero number has only finitely many divisors.

\sphinxAtStartPar
If \(n = m = 0\), then we define \(\gcd(0,0) = 0\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
The greatest common divisor of two numbers is always a natural number, since 1 is always a common divisor of two numbers. As an example, let us compute the greatest common divisor of 6 and 28. The positive divisors of 6 are \(\{1, 2, 3, 6\}\) and the positive divisors of 28 are \(\{1, 2, 4, 7, 14, 28\}\). The largest number in both these sets is 2, which is the greatest common divisor of 6 and 28.

\sphinxAtStartPar
However, computing the greatest common divisor of two numbers by listing all the divisors of both numbers is a lot of work, so we will now consider a method to compute the greatest common divisor more efficiently.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Lemma.} For all integers \(m\), \(n\) and \(k\) we have \(\gcd(m,n)=\gcd(n,m-kn)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(d = \gcd(m,n)\) and \(r = m-kn\). If \(m = n = 0\), then \(d = 0 = \gcd(n,r)\), and we’re done.

\sphinxAtStartPar
In the other case we first show that the set of common divisors of \(m\) and \(n\) is the same as the set of the common divisors of \(n\) and \(r\). To see this, let \(d' \mid m\) and \(d' \mid n\). Then also \(d' \mid m - kn\) by Exercise 1. Hence \(d'\) is a common divisor of \(n\) and \(r\). On the other hand, if \(d'\) is a divisor of \(n\) and \(r\), then \(d' \mid r + kn\), hence \(d' \mid m\), hence \(d'\) is a common divisor of \(m\) and \(n\).

\sphinxAtStartPar
Since the sets of common divisors are the same, the largest element in each set is also the same, hence \(\gcd(m,n)=\gcd(n,m-kn)\).

\sphinxAtStartPar
\sphinxstylestrong{Lemma.} For all integers \(n\) we have \(\gcd(n,0)=|n|\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Every number is a divisor of 0, hence the greatest common divisor of \(n\) and 0 is just the greatest divisor of \(n\), which is the absolute value of \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
These two lemmas give us a quick way to compute the greatest common divisor of two numbers. This is called the \sphinxstyleemphasis{Euclidean Algorithm}. Suppose we want to compute \(\gcd(m, n)\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
We let \(r_0 = m\) and \(r_1 = n\).

\item {} 
\sphinxAtStartPar
Given \(r_i\) and \(r_{i+1}\) we compute \(r_{i+2}\) as the remainder of of \(r_i\) when divided by \(r_{i+1}\).

\item {} 
\sphinxAtStartPar
Once \(r_i = 0\), we stop, and \(\gcd(m, n) = |r_{i-1}|\).

\end{itemize}

\sphinxAtStartPar
This works, because by the lemmas above, we have \(\gcd(r_k,r_{k+1}) = \gcd(r_{k+1}, r_{k+2})\), since \(r_{k+2} = r_k - qr_{k+1}\) for some \(q\). Hence if \(r_i=0\) we have
\begin{equation*}
\begin{split}\gcd(m,n)=\gcd(r_0,r_1)=\gcd(r_{i-1},r_i)=\gcd(r_{i-1},0)=|r_{i-1}|.\end{split}
\end{equation*}
\sphinxAtStartPar
For example, suppose we want to compute the greatest common divisor of 1311 and 5757. We compute the following remainders:
\begin{equation*}
\begin{split}5757 &= 4\times1311 + 513\\
1311 &= 2\times513 + 285\\
513 &= 1\times285 + 228\\
285 &= 1\times228 + 57\\
228 &= 4\times57 + 0.\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(\gcd(1311,5757) = 57\). This is much quicker than computing all the divisors of both 1311 and 5757.

\sphinxAtStartPar
Here is an important result about greatest common divisors. It is only called a “lemma” for historical reasons.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem} (B‎ézout’s Lemma). Let \(m\) and \(n\) be integers. Then there are integers \(a\) and \(b\) such that \(am+bn=\gcd(m,n)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We compute \(\gcd(m,n)\) by the Euclidean Algorithm given above, and during the algorithm we get the intermediate values \(r_0, r_1, \ldots, r_k\) where \(r_k = 0\). Now by induction on \(i\) we prove that we can write \(r_i = a_i m+b_i n\) for some integers \(a_i\) and \(b_i\). Indeed: \(r_0 = 1\cdot m + 0\cdot n\) and \(r_1 = 0\cdot m + 1\cdot n\). Now if we assume that \(r_i = a_i m+b_i n\) and \(r_{i+1} = a_{i+1}m+b_{i+1}n\), we know that \(r_{i+2} = r_i - q\cdot r_{i+1}\), where \(q\) is the quotient of \(r_i\) when divided by \(r_{i+1}\). These equations together give
\begin{equation*}
\begin{split}r_{i+2} = (a_i-qa_{i+1})m + (b_i-qb_{i+1})n.\end{split}
\end{equation*}
\sphinxAtStartPar
This completes the induction. In particular, \(r_{k-1} = a_{k-1}m+b_{k-1}n\), and since \(\gcd(m,n)=\pm r_{k-1}\) we can write \(\gcd(m,n)\) as \(am+bn\) for some \(a\) and \(b\).

\sphinxAtStartPar
\sphinxstylestrong{Alternative proof.} We can assume \(m\) and \(n\) are positive, since \(\gcd(m, n) = \gcd(|m|, |n|)\). Let \(d\) be the least positive number of the form \(a m + b n\), that is, the smallest element of the set \(\{ a m + b n \mid a, b\in \mathbb N \}\). We claim \(d = \gcd(m, n)\).

\sphinxAtStartPar
Let \(a\) and \(b\) be such that \(d = a m + b n\). Clearly, if \(c \mid m\) and \(c \mid n\), then \(c \mid d\). So it suffices to show \(d \mid m\) and \(d \mid n\). We’ll show that \(d \mid m\), since the other case is symmetric. Write \(m = d q + r\), with \(0 \le r < d\). We need to show \(r = 0\).

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}r = m - dq = m - q (a m + b n) = (1 - aq)m + (- q b) n,\end{split}
\end{equation*}
\sphinxAtStartPar
with \(r \ge 0\) and \(r < d\).  Since \(d\) is the smallest positive number that can be written in that form, we have \(r = 0\). Hence \(m = dq\), so \(d \mid m\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Corollary.} If \(c\) is any common divisor of \(m\) and \(n\), then \(c \mid \gcd(m, n)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By B‎ézout’s Lemma, there are \(a\) and \(b\) such that \(\gcd(m,n)=am+bn\). Since \(c\) divides both \(m\) and \(n\), \(c\) divides \(am+bn\) by Exercise 1 below, and hence also \(\gcd(m,n)\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Of special interest are pairs of integers which have no divisors in common, except 1 and \(-1\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Two integers \(m\) and \(n\) are \sphinxstyleemphasis{coprime} if \(\gcd(m,n) = 1\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(m\), \(n\) and \(k\) be integers such that \(m\) and \(k\) are coprime. If \(k \mid mn\) then \(k \mid n\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By B‎ézout’s Lemma, there are \(a\) and \(b\) such that \(am+bk = 1\). Multiplying by \(n\) gives \(amn + bkn = n\) Since \(k\) divides \(mn\), \(k\) divides the left\sphinxhyphen{}hand side of the equation, hence \(k \mid n\).


\bigskip\hrule\bigskip



\section{Prime Numbers}
\label{\detokenize{elementary_number_theory:prime-numbers}}
\sphinxAtStartPar
In this section we consider properties of prime numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} An integer \(p\geq 2\) is called \sphinxstyleemphasis{prime} if the only positive divisors of \(p\) are 1 and \(p\). An integer \(n \geq 2\) which is not prime is called \sphinxstyleemphasis{composite}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
An equivalent definition of a prime number is a positive number with exactly 2 positive divisors.

\sphinxAtStartPar
Recall from \hyperref[\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}]{Chapter \ref{\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}}} that every natural number greater than 1 can be written as the product of primes. In particular, ever natural number greater than 1 is divisible by some prime number.

\sphinxAtStartPar
We now prove some other properties about prime numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} There are infinitely many primes.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose for the sake of contradiction that there are only finitely many primes \(p_1, p_2, \ldots, p_k\). Let \(n = p_1 \times p_2 \times \cdots \times p_k\). Since \(n\) is divisible by \(p_i\) for all \(i\leq k\) we know that \(n+1\) is not divisible by \(p_i\) for any \(i\). However, we assumed that these are all primes, contradicting the fact that every number is divisible by a prime number.

\sphinxAtStartPar
\sphinxstylestrong{Lemma.} If \(n\) is an integer and \(p\) is a prime number, then either \(n\) and \(p\) are coprime or \(p \mid n\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(d = \gcd(n, p)\). Since \(d\) is a positive divisor of \(p\), either \(d = 1\) or \(d = p\). In the first case, \(n\) and \(p\) are coprime by definition, and in the second case we have \(p \mid n\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} If \(n\) and \(m\) are integers and \(p\) is a prime number such that \(p \mid nm\) then either \(p \mid n\) or \(p \mid m\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose that \(p \nmid n\). By the previous lemma, this means that \(p\) and \(n\) are coprime. From this we can conclude that \(p \mid m\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
The last result in this section captures that the primes are the “building blocks” of the positive integers for multiplication: all other integers can be written as a product of primes in an essentially unique way.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem} (Fundamental Theorem of Arithmetic). Let \(n > 0\) be an integer. Then there are primes \(p_1, \ldots, p_k\) such that \(n = p_1\times \cdots \times p_k\). Moreover, these primes are unique up to reordering. That means that if there are prime numbers \(q_1, \ldots, q_\ell\) such that \(q_1\times \cdots \times q_\ell = n\), then the \(q_i\) are a reordering of the \(p_i\). To be completely precise, this means that there is a bijection \(\sigma : \{1, \ldots, k\} \to \{1, \ldots, k\}\) such that \(q_i = p_{\sigma(i)}\).

\sphinxAtStartPar
\sphinxstylestrong{Remark.} 1 can be written as the product of zero prime numbers. The \sphinxstyleemphasis{empty product} is defined to be 1.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We have already seen that every number can be written as the product of primes, so we only need to prove the uniqueness up to reordering. Suppose this is not true, and by the least element principle, let \(n\) be the smallest positive integers such that \(n\) can be written as the product of primes in two ways: \(n = p_1\times \cdots \times p_k = q_1 \times \cdots \times q_\ell\).

\sphinxAtStartPar
Since 1 can be written as product of primes only as an empty product, we have \(n > 1\), hence \(k \geq 1\). Since \(p_k\) is prime, we must have \(p_k \mid q_j\) for some \(j \leq \ell\). By swapping \(q_j\) and \(q_\ell\), we may assume that \(j = \ell\). Since \(q_\ell\) is also prime, we have \(p_k = q_\ell\).

\sphinxAtStartPar
Now we have \(p_1\times \cdots \times p_{k-1} = q_1 \times \cdots \times q_{\ell-1}\). This product is smaller than \(n\), but can be written as product of primes in two different ways. But we assumed \(n\) was the smallest such number. Contradiction!


\bigskip\hrule\bigskip



\section{Modular Arithmetic}
\label{\detokenize{elementary_number_theory:modular-arithmetic}}\label{\detokenize{elementary_number_theory:id2}}
\sphinxAtStartPar
In the discussion of equivalence relations in \hyperref[\detokenize{relations:equivalence-relations-and-equality}]{Section \ref{\detokenize{relations:equivalence-relations-and-equality}}} we considered the example of the relation of modular equivalence on the integers. This is sometimes thought of as “clock arithmetic.” Suppose you have a 12\sphinxhyphen{}hour clock without a minute hand, so it only has an hour hand which can point to the hours 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 and then it wraps to 12 again. We can do arithmetic with this clock.
\begin{itemize}
\item {} 
\sphinxAtStartPar
If the hand currently points to 10, then 5 hours later it will point to 3.

\item {} 
\sphinxAtStartPar
If the hand points to 7, then 23 hours before that, it pointed to 8.

\item {} 
\sphinxAtStartPar
If the hand points to 9, and we work for a 8 hours, then when we are done the hand will point to 5. If we worked twice as long, starting at 9, the hand will point to 1.

\end{itemize}

\sphinxAtStartPar
We want to write these statements using mathematical notation, so that we can reason about them more easily. We cannot write \(10 + 5 = 3\) for the first expression, because that would be false, so instead we use the notation \(10 + 5 \equiv 3 \pmod{12}\). The notation \(\pmod{12}\) indicates that we forget about multiples of 12, and we use the “congruence” symbol with three horizontal lines to remind us that these values are not exactly equal, but only equal up to multiples of 12. The other two lines can be formulated as \(7 - 23 \equiv 8 \pmod{12}\) and \(9 + 2 \cdot 8 \equiv 1 \pmod{12}\).

\sphinxAtStartPar
Here are some more examples:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(6 + 7 \equiv 1 \pmod{12}\)

\item {} 
\sphinxAtStartPar
\(6 \cdot 7 \equiv 42 \equiv 6 \pmod{12}\)

\item {} 
\sphinxAtStartPar
\(7 \cdot 5 \equiv 35 \equiv -1 \pmod{12}\)

\end{itemize}

\sphinxAtStartPar
The last example shows that we can use negative numbers as well.

\sphinxAtStartPar
We now give a precise definition.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} For integers \(a\), \(b\) and \(n\) we say that \(a\) and \(b\) are \sphinxstyleemphasis{congruent modulo} \(n\) if \(n \mid a - b\). This is written \(a \equiv b \pmod{n}\). The number \(n\) is called the \sphinxstyleemphasis{modulus}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Typically we only use this definition when the modulus \(n\) is positive.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Congruence modulo \(n\) is an equivalence relation.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We have to show that congruence modulo \(n\) is reflexive, symmetric and transitive.

\sphinxAtStartPar
It is reflexive, because \(a - a = 0\), so \(n \mid a - a\), and hence \(a\equiv a \pmod{n}\).

\sphinxAtStartPar
To show that it is symmetric, suppose that \(a \equiv b \pmod{n}\). Then by definition, \(n \mid a - b\). So \(n \mid (-1) \cdot (a - b)\), which means that \(n \mid b - a\). This means by definition that \(b \equiv a \pmod{n}\).

\sphinxAtStartPar
To show that it is transitive, suppose that \(a \equiv b \pmod{n}\) and \(b \equiv c \pmod{n}\). Then we have \(n \mid a - b\) and \(n \mid b - c\). Hence we have \(n \mid (a - b) + (b - c)\) which means that \(n \mid a - c\). So \(a \equiv c \pmod{n}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
This theorem justifies the “chaining” notation we used above when we wrote \(7 \cdot 5 \equiv 35 \equiv -1 \pmod{12}\). Since congruence modulo 12 is transitive, we can now actually conclude that \(7\cdot 5\equiv -1 \pmod{12}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Suppose that \(a\equiv b \pmod{n}\) and \(c\equiv d\pmod{n}\). Then \(a+c\equiv b+d \pmod{n}\) and \(a\cdot c\equiv b\cdot d\pmod{n}\).

\sphinxAtStartPar
Moreover, if \(a\equiv b \pmod{n}\) then \(a^k\equiv b^k \pmod{n}\) for all natural numbers \(k\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We know that \(n \mid a - b\) and \(n \mid c - d\). For the first statement, we can calculate that \((a + c) - (b + d) = (a - b) + (c - d)\), so we can conclude that \(n \mid (a + c) - (b + d)\) hence that \(a+c\equiv b+d\pmod{n}\).

\sphinxAtStartPar
For the second statement, we want to show that \(n \mid a\cdot c - b\cdot d\). We can factor \(a\cdot c - b\cdot d = (a - b)\cdot c + b\cdot(c-d)\). Now \(n\) divides both summands on the right, hence \(n\) divides \(a\cdot c - b\cdot d\), which means that \(a\cdot c\equiv b\cdot d\pmod{n}\).

\sphinxAtStartPar
The last statement follows by induction on \(k\). If \(k = 0\), then \(1\equiv 1 \pmod{n}\), and for the induction step, suppose that \(a^k\equiv b^k\pmod{n}\), then we have \(a^{k+1}= a\cdot a^k \equiv b \cdot b^k = b^{k+1} \pmod{n}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
This theorem is useful for carrying out computations modulo \(n\). Here are some examples.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Suppose we want to compute \(77 \cdot 123\) modulo 12. We know that \(77 \equiv 5 \pmod{12}\) and \(123 \equiv 3 \pmod{12}\), so \(77 \cdot 123 \equiv 5 \cdot 3 \equiv 15 \equiv 3 \pmod{12}\)

\item {} 
\sphinxAtStartPar
Suppose we want to compute \(99 \cdot 998\) modulo 10. We know that \(99 \equiv -1\pmod{10}\) and \(998 \equiv -2 \pmod{10}\), hence \(99 \cdot 998 \equiv (-1) \cdot (-2) \equiv 2 \pmod{10}\).

\item {} 
\sphinxAtStartPar
Suppose we want to know the last digit of \(101^{101}\). Notice that the last digit of a number \(n\) is congruent to \(n\) modulo 10, so we can just compute \(101^{101} \equiv 1^{101} \equiv 1 \pmod{10}\). So the last digit of \(101^{101}\) is 1.

\end{itemize}

\sphinxAtStartPar
\sphinxstyleemphasis{Warning.} You cannot do all computations you might expect with modular arithmetic:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Modular arithmetic does not respect division. For example \(12 \equiv 16 \pmod{4}\), but we cannot divide both sides of the equation by 2, because \(6 \not\equiv 8 \pmod{4}\).

\item {} 
\sphinxAtStartPar
Exponents also do not respect modular arithmetic. For example \(8 \equiv 3 \pmod{5}\), but \(2^8 \not\equiv 2^3 \pmod{5}\). To see this: \(2^8 = 256 \equiv 1 \pmod{5}\), but \(2^3 = 8 \equiv 3 \pmod{5}\).

\end{itemize}

\sphinxAtStartPar
Recall the quotient\sphinxhyphen{}remainder theorem: if \(n > 0\), then any integer \(a\) can be expressed as \(a = n q + r\), where \(0 \le r < n\). In the language of modular arithmetic this means that \(a \equiv r \pmod{n}\). So if \(n > 0\), then every integer is congruent to a number between 0 and \(n-1\) (inclusive). So there “are only \(n\) different numbers” when working modulo \(n\). This can be used to prove many statements about the natural numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For every integer \(k\), \(k^2+1\) is not divisible by 3.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Translating this problem to modular arithmetic, we have to show that \(k^2+1 \not\equiv 0 \pmod{3}\) or in other words that \(k^2\not\equiv 2 \pmod{3}\) for all \(k\). By the quotient\sphinxhyphen{}remainder theorem, we know that \(k\) is either congruent to 0, 1 or 2, modulo 3. In the first case, \(k^2\equiv 0^2\equiv 0\pmod{3}\). In the second case, \(k^{2}\equiv 1^2 \equiv 1 \pmod{3}\), and in the last case we have \(k^{2}\equiv2^2\equiv4\equiv1\pmod{3}\). In all of those cases, \(k^2\not\equiv2\pmod{3}\). So \(k^2+1\) is never divisible by 3.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} For all integers \(a\) and \(b\), \(a^2+b^2-3\) is not divisible by 4.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We first compute the squares modulo 4. We compute
\begin{equation*}
\begin{split}0^2&\equiv 0\pmod{4}\\
1^2&\equiv 1\pmod{4}\\
2^2&\equiv 0\pmod{4}\\
3^2&\equiv 1\pmod{4}.\end{split}
\end{equation*}
\sphinxAtStartPar
Since every number is congruent to 0, 1, 2 or 3 modulo 4, we know that every square is congruent to 0 or 1 modulo 4. This means that there are only four possibilities for \(a^2+b^2\pmod{4}\). It can be congruent to \(0+0\), \(1+0\), \(0+1\) or \(1+1\). In all those cases, \(a^2+b^2\not\equiv 3\pmod{4}\) Hence \(4\nmid a^2+b^2-3\), proving the proposition.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Recall that we warned you about dividing in modular arithmetic. This doesn’t always work, but often it does. For example, suppose we want to solve \(2n \equiv 1 \pmod{5}\). We cannot solve this by saying that \(n \equiv \frac12 \pmod{5}\), because we cannot work with fractions in modular arithmetic. However, we can still solve it by multiplying both sides with 3. Then we get \(6n \equiv 3 \pmod{5}\), and since \(6\equiv 1 \pmod{5}\) we get \(n \equiv 3 \pmod{5}\). So instead of dividing by 2 we could multiply by 3 to get the answer. The reason this worked is because \(2\times 3\equiv 1\pmod{5}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Let \(n\) and \(a\) be integers. A \sphinxstyleemphasis{multiplicative inverse of} \(a\) \sphinxstyleemphasis{modulo} \(n\) is an integer \(b\) such that \(ab \equiv 1\pmod{n}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
For example, 3 is a multiplicative inverse of 5 modulo 7, since \(3\times 5\equiv1\pmod{7}\). But \(2\) has no multiplicative inverse modulo 6. Indeed, suppose that \(2b\equiv 1 \pmod{6}\), then \(6 \mid 2b-1\). However, \(2b-1\) is odd, and cannot be divisible by an even number. We can use multiplicative inverses to solve equations. If we want to solve \(ax\equiv c \pmod{n}\) for \(x\) and we know that \(b\) is a multiplicative inverse of \(a\), the solution is \(x\equiv bc \pmod{n}\) which we can see by multiplying both sides by \(b\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Lemma} Let \(n\) and \(a\) be integers. \(a\) has at most one multiplicative inverse modulo \(n\). That is, if \(b\) and \(b'\) are both multiplicative inverses of \(a\) modulo \(n\), then \(b\equiv b'\pmod{n}\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose that \(ab\equiv 1 \equiv ab' \pmod{n}\). Then we can compute \(bab'\) in two ways: \(b \equiv b(ab') = (ba)b' \equiv b' \pmod{n}\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} Let \(n\) and \(a\) be integers. \(a\) has a multiplicative inverse modulo \(n\) if and only if \(n\) and \(a\) are coprime.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(b\) is a multiplicative inverse of \(a\) modulo \(n\). Then \(n \mid ab - 1\). Let \(d = \gcd(a, n)\). Since \(d \mid n\) we have \(d \mid ab-1\). But since \(d\) is a divisor of \(ab\), we have \(d \mid ab - (ab-1) = 1\). Since \(d\geq0\) we have \(d=1\). Hence \(n\) and \(a\) are coprime.

\sphinxAtStartPar
On the other hand, suppose that \(n\) and \(a\) are coprime. By B‎ézout’s Lemma we know that there are integers \(b\) and \(c\) such that \(cn+ba=\gcd(n,a)=1\). We can rewrite this to \(ab - 1 = (-c)n\), hence \(n \mid ab - 1\), which means by definition \(ab \equiv 1 \pmod{n}\). This means that \(b\) is a multiplicative inverse of \(a\) modulo \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Note that if \(p\) is a prime number and \(a\) is a integer not divisible by \(p\), then \(a\) and \(p\) are coprime, hence \(a\) has a multiplicative inverse.


\section{Properties of Squares}
\label{\detokenize{elementary_number_theory:properties-of-squares}}
\sphinxAtStartPar
Mathematicians from ancient times have been interested in the question as to which integers can be written as a sum of two squares. For example, we can write \(2 = 1^1 + 1^1\), \(5 = 2^2 + 1^2\), \(13 = 3^2 + 2^2\). If we make a sufficiently long list of these, an interesting pattern emerges: if two numbers can be written as a sum of two squares, then so can their product. For example, \(10 = 5 \cdot 2\), and we can write \(10 = 3^2 + 1^2\). Or \(65 = 13 \cdot 5\), and we can write \(65 = 8^2 + 1^2\).

\sphinxAtStartPar
At first, one might wonder whether this is just a coincidence. The following provides a proof of the fact that it is not.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(x\) and \(y\) be any two integers. If \(x\) and \(y\) are both sums of two squares, then so is \(x y\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(x = a^2 + b^2\), and suppose \(y = c^2 + d^2\). I claim that
\begin{equation*}
\begin{split}xy = (ac - bd)^2 + (ad + bc)^2.\end{split}
\end{equation*}
\sphinxAtStartPar
To show this, notice that on the one hand we have
\begin{equation*}
\begin{split}xy = (a^2 + b^2) (c^2 + d^2) = a^2 c^2 + a^2 d^2 + b^2 c^2 + b^2 d^2.\end{split}
\end{equation*}
\sphinxAtStartPar
On the other hand, we have
\begin{equation*}
\begin{split}(ac - bd)^2 + (ad + bc)^2 & = (a^2c^2 - 2abcd + b^2 d^2) + (a^2 d^2 + 2 a b c d + b^2 c^2) \\
 & = a^2 c^2 + b^2 d^2 + a^2 d^2 + b^2 c^2.\end{split}
\end{equation*}
\sphinxAtStartPar
Up to the order of summands, the two right\sphinxhyphen{}hand sides are the same.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Consider the prime numbers, \(2, 3, 5, 7, 11, 13, \ldots\). Which ones can be written as sums of two squares? We have \(2 = 1^2 + 1^2\), \(5 = 2^2 + 1^2\), and \(13 + 3^2 + 2^2\). Trying all possibilities shows that 3, 7, and 11 cannot be written as sums of two squares. Notice that any odd prime is congruent to either 1 or 3 modulo 4. A lovely theorem by Fermat, which we will not prove here, shows that an odd prime can be written as a sum of squares if and only if it is congruent to 1 modulo 4.

\sphinxAtStartPar
We will now prove that \(\sqrt{2}\) is not a fraction of two integers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} There are no integers \(a\) and \(b\) such that \(\frac ab=\sqrt{2}\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose that \(\frac ab=\sqrt{2}\) for some integers \(a\) and \(b\). By canceling common factors, we may assume that \(a\) and \(b\) are coprime. By squaring both sides, we get \(\frac{a^2}{b^2}=2\), and multiplying both sides by \(b^2\) gives \(a^2=2b^2\). Since \(2b^2\) is even, we know that \(a^2\) is even, and since odd squares are odd, we conclude that \(a\) is even. Hence we can write \(a = 2c\) for some integer \(c\). This means that \((2c)^2=2b^2\), hence \(2c^2=b^2\). The same reasoning shows that \(b\) is even. But we assumed that \(a\) and \(b\) are coprime, which contradicts the fact that they are both even.

\sphinxAtStartPar
Hence there are no integers \(a\) and \(b\) such that \(\frac ab=\sqrt{2}\).


\bigskip\hrule\bigskip



\section{Exercises}
\label{\detokenize{elementary_number_theory:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Prove the following properties about divisibility (for any integers \(a\), \(b\) and \(c\)):
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(a \mid b\) and \(a \mid c\) then \(a \mid b + c\) and \(a \mid b - c\).

\item {} 
\sphinxAtStartPar
If \(a \mid b\) then \(a \mid bc\).

\item {} 
\sphinxAtStartPar
\(a \mid 0\);

\item {} 
\sphinxAtStartPar
If \(0 \mid a\) then \(a = 0\).

\item {} 
\sphinxAtStartPar
If \(a \neq 0\) then the statements \(b \mid c\) and \(ab \mid ac\) are equivalent.

\item {} 
\sphinxAtStartPar
If \(a \mid b\) and \(b \neq 0\) then \(|a| \leq |b|\).

\end{itemize}

\item {} 
\sphinxAtStartPar
Prove that if \(k \ne 0\), \(k \mid m\), and \(k \mid n\), then \(\gcd(m / k, n / k) = \gcd(m, n) / k\). (Hint: it helps to show that whenever \(a \ne 0\), \(a \mid b\), and \(b \mid c\), then \(b / a \mid c / a\).)

\item {} 
\sphinxAtStartPar
Prove that for any integer \(n\), \(n^2\) leaves a remainder of 0 or 1 when you divide it by 4. Conclude that \(n^2 + 2\) is never divisible by 4.

\item {} 
\sphinxAtStartPar
Prove that if \(n\) is odd, \(n^2 - 1\) is divisible by 8.

\item {} 
\sphinxAtStartPar
Prove that if \(m\) and \(n\) are odd, then \(m^2 + n^2\) is even but not divisible by 4.

\item {} 
\sphinxAtStartPar
Say that two integers “have the same parity” if they are both even or both odd. Prove that if \(m\) and \(n\) are any two integers, then \(m + n\) and \(m - n\) have the same parity.

\item {} 
\sphinxAtStartPar
Write 11160 as a product of primes.

\item {} 
\sphinxAtStartPar
List all the divisors of 42 and 198, and find the greatest common divisor by looking at the largest number in both lists. Also compute the greatest common divisor of the numbers by the Euclidean Algorithm.

\item {} 
\sphinxAtStartPar
Compute \(\gcd(15, 55)\), \(\gcd(12345, 54321)\) and \(\gcd(-77, 110)\)

\item {} 
\sphinxAtStartPar
Show by induction on \(n\) that for every pair of integers \(x\) and \(y\), \(x - y\) divides \(x^n - y^n\). (Hint: in the induction step, write \(x^{n+1} - y^{n+1}\) as \(x^n (x - y) + x^n y - y^{n+1}\).)

\item {} 
\sphinxAtStartPar
Compute \(2^{12} \pmod{13}\). Use this to compute \(2^{1212004} \pmod{13}\).

\item {} 
\sphinxAtStartPar
Find the last digit of \(99^{99}\). Can you also find the last two digits of this number?

\item {} 
\sphinxAtStartPar
Prove that \(50^{22} - 22^{50}\) is divisible by 7.

\item {} 
\sphinxAtStartPar
Check whether the following multiplicative inverses exist, and if so, find them.
\begin{itemize}
\item {} 
\sphinxAtStartPar
the multiplicative inverse of 5 modulo 7

\item {} 
\sphinxAtStartPar
the multiplicative inverse of 17 modulo 21

\item {} 
\sphinxAtStartPar
the multiplicative inverse of 4 modulo 14

\item {} 
\sphinxAtStartPar
the multiplicative inverse of \(-2\) modulo 9

\end{itemize}

\item {} 
\sphinxAtStartPar
Find all integers \(x\) such that \(75x \equiv 45 \pmod{8}\).

\item {} 
\sphinxAtStartPar
Show that for every integer \(n\) the number \(n^4\) is congruent to 0 or 1 modulo 5. Hint: to simplify the computation, use that \(4^4\equiv(-1)^4\pmod{5}\).

\item {} 
\sphinxAtStartPar
Prove that the equation \(n^4+m^4=k^4+3\) has no solutions in the integers. (Hint: use the previous exercise.)

\item {} 
\sphinxAtStartPar
Suppose \(p\) is a prime number such that \(p \nmid k\). Show that if \(kn\equiv km \pmod{p}\) then \(n \equiv m \pmod{p}\).

\item {} 
\sphinxAtStartPar
Let \(n\), \(m\) and \(c\) be given integers. Use B‎ézout’s Lemma to prove that the equation \(an+bm=c\) has a solution for integers \(a\) and \(b\) if and only if \(\gcd(n, m) \mid c\).

\item {} 
\sphinxAtStartPar
Suppose that \(a \mid n\) and \(a \mid m\) and let \(d = \gcd(n,m)\). Prove that \(\gcd(\frac na, \frac ma) =\frac da\). Conclude that for any two integers \(n\) and \(m\) with greatest common divisor \(d\) the numbers \(\frac nd\) and \(\frac md\) are coprime.

\end{enumerate}


\chapter{Combinatorics}
\label{\detokenize{combinatorics:combinatorics}}\label{\detokenize{combinatorics:id1}}\label{\detokenize{combinatorics::doc}}
\sphinxAtStartPar
Combinatorics is the art of counting without counting. It is a fundamental mathematical task to determine how many things there are in a given collection, and when the collection is large, it can be tedious or infeasible to count the elements individually. Moreover, when the collection is described in terms of a changing parameter (say, a natural number, \(n\)), we would like a formula that tells us how the number of objects depends on that parameter. In this chapter we will set up a foundation for achieving this goal, and learn some of the tricks of the
trade.


\section{Finite Sets and Cardinality}
\label{\detokenize{combinatorics:finite-sets-and-cardinality}}
\sphinxAtStartPar
It will be helpful, for every natural number \(n\), to have a canonical set of elements of size \(n\). To that end, we will choose the set
\begin{equation*}
\begin{split}[n] = \{ m \mid m < n \} = \{ 0, 1, \ldots, n-1 \}.\end{split}
\end{equation*}
\sphinxAtStartPar
We used the same notation, \([n]\), to describe equivalence classes with respect to an equivalence relation, but hopefully our intended meaning will always be clear from the context.

\sphinxAtStartPar
A set \(A\) of elements is said to be \sphinxstyleemphasis{finite} if there is a bijection from \([n]\) to \(A\) for some \(n\). In that case, we would like to say that \(A\) \sphinxstyleemphasis{has} \(n\) \sphinxstyleemphasis{elements}, or that the set \(A\) \sphinxstyleemphasis{has cardinality} \(n\), and write \(|A| = n\). But to do so, we need to know that when \(A\) is finite, there is a unique \(n\) with the property above.

\sphinxAtStartPar
Suppose there are bijections from both \([m]\) and \([n]\) to \(A\). Composing the first bijection with the inverse of the second, we get a bijection from \([m]\) to \([n]\). It seems intuitively clear that this implies \(m = n\), but our goal is to prove this from the fundamental properties of sets, functions, and the natural numbers.

\sphinxAtStartPar
So suppose, for the sake of contradiction, \(m \neq n\). Without loss of generality, we can assume \(m > n\) (why?). In particular, there is an injective function \(f\) from \([m]\) to \([n]\). Since \(m > n\), \(m \geq n+1\), and so we can restrict \(f\) to get an injective function from \([n+1]\) to \([n]\). The next theorem shows that this cannot happen.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For any natural number \(n\), there is no injective function from \([n+1]\) to \([n]\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(n\). The theorem is clear when \(n = 0\), because \([1] = \{ 0 \}\) and \([0] = \emptyset\). If \(f\) were an injective function from \([1]\) to \([0]\), we would have \(f(0) \in \emptyset\), which is impossible.

\sphinxAtStartPar
So suppose the claim is true for \(n\), and suppose \(f\) is an injective function from \([n+2]\) to \([n+1]\). We consider two cases.

\sphinxAtStartPar
In the first case, suppose \(n\) is not in the image of \(f\). Then \(f\) maps \([n+2]\) to \([n]\), and restricting the domain, we have an injective function from \([n+1]\) to \([n]\), contradicting the inductive hypothesis.

\sphinxAtStartPar
In the second case, there is some \(m < n + 2\) such that \(f(m) = n\). The idea is to alter \(f\) slightly to get an injective function from \([n+1]\) to \([n]\), again contradicting the inductive hypothesis. If \(m = n + 1\), which is to say it is the last element of \([n+2]\) that is mapped to the last element of \([n+1]\), we can just restrict \(f\) to \([n+1]\). The fact that \(f\) was injective implies that all the elements in \([n+1]\) are mapped to \(n\).

\sphinxAtStartPar
Otherwise, define \(f' : [n+1] \to [n]\) by
\begin{equation*}
\begin{split}f'(i) =
  \begin{cases}
    f(i) & \mbox{if $i \neq m$} \\
    f(n+1) & \mbox{if $i = m$.}
  \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, we map \(m\) to the value that \(n+1\) was mapped to. Since \(f\) is injective, \(f(n+1) \neq f(m)\), and so \(f(n+1) < n\), as required. It is not hard to check that \(f'\) is injective, so we have the contradiction we were after.


\bigskip\hrule\bigskip


\sphinxAtStartPar
This theorem is known as the “pigeonhole principle.” It implies that if \(n + 1\) pigeons inhabit \(n\) holes, then at least one hole has more than one pigeon. The principle implies that for every finite set \(A\), there is a unique \(n\) such that there is a bijection from \([n]\) to \(A\), and we can define the cardinality of \(A\) to be that \(n\).

\sphinxAtStartPar
We now introduce the notation \(\sum_{i \in A} f(i)\) and \(\prod_{i \in A} f(i)\) for sums and products over finite sets. If \(A = \{ a_0, \ldots, a_{n-1} \}\), then \(\sum_{i \in A} f(i)\) is defined to be \(f(a_0) + \cdots + f(a_{n-1})\), and similarly for products. Formally, what we are doing is choosing a bijection \(g : [n] \to A\) and defining \(\sum_{i \in A} f(i)\) to be \(\sum_{j < n} f(g(j))\). It takes some work to show that this makes sense, which is to say, the answer we get doesn’t depend on which bijection we choose. We will just take this fact for granted here.


\section{Counting Principles}
\label{\detokenize{combinatorics:counting-principles}}\label{\detokenize{combinatorics:id2}}
\sphinxAtStartPar
Here is a basic counting principle.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) and \(B\) be disjoint finite sets. Then \(| A \cup B | = | A | + | B |\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(f : [m] \to A\) and \(g : [n] \to B\) are bijections. Define \(h : [m + n] \to A \cup B\) by
\begin{equation*}
\begin{split}h(i) =
  \begin{cases}
    f(i) & \mbox{if $i < m$} \\
    g(i - m) & \mbox{if $m \leq i < m + n$.}
  \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
To see that \(h\) is surjective, note that every \(k\) in \(A \cup B\) can be written as either \(k = f(i)\) for some \(i \in [m]\) or \(k = g(j)\) for some \(j \in [n]\). In the first case, \(k = f(i) = h(i)\), and in the second case, \(k = g(j) = h(m + j)\).

\sphinxAtStartPar
It is not hard to show that \(h\) is also injective. Suppose \(h(i) = h(j)\). If \(h(i)\) is in \(A\), then it is not in the range of \(g\), and so we must have \(h(i) = f(i)\) and \(h(j) = f(j)\). Then \(f(i) = f(j)\), the injectivity of \(f\) implies that \(i = j\). If \(h(i)\) is instead in \(B\), the argument it similar.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The proof only spells out our basic intuitions: if you want to list all of the elements of \(A \cup B\), you can list all the elements of \(A\) and then all the elements of \(B\). And if \(A\) and \(B\) have no elements in common, then to count the elements of \(A \cup B\), you can count the elements of \(A\) and then continue counting the elements of \(B\). Once you are comfortable translating the intuitive argument into a precise mathematical proof (and mathematicians generally are), you can use the more intuitive descriptions (and mathematicians generally do).

\sphinxAtStartPar
Here is another basic counting principle:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) and \(B\) be finite sets. Then \(| A \times B | = | A | \cdot | B |\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that this time we are counting the number of ordered pairs \((a, b)\) with \(a \in A\) and \(b \in B\). The exercises ask you to give a detailed proof of this theorem. There are at least two ways to go about it. The first is to start with bijections \(f : [m] \to A\) and \(g : [n] \to B\) and describe an explicit bijection \(h : [m \cdot n] \to A \times B\). The second is to fix \(m\), say, and use induction on \(n\) and the previous counting principle. Notice that if \(U\) and \(V\) are any sets and \(w\) is not in \(V\), we have
\begin{equation*}
\begin{split}U \times (V \cup \{ w \}) = (U \times V) \cup (U \times \{w\}),\end{split}
\end{equation*}
\sphinxAtStartPar
and the two sets in this union are disjoint.

\sphinxAtStartPar
Just as we have notions of union \(\bigcup_{i\in I} A_i\) and intersection \(\bigcap_{i \in I} A_i\) for indexed families of sets, it is useful to have a notion of a product \(\prod_{i \in I} A_i\). We can think of an element \(a\) of this product as a function which, for each element \(i \in I\), returns an element \(a_i \in A_i\). For example, when \(I = \{1, 2, 3\}\), an element of \(\prod_{i \in I} A_i\) is just a triple \(a_1, a_2, a_3\) with \(a_1 \in A_1\), \(a_2 \in A_2\), and \(a_3 \in A_3\). This is essentially the same as \(A_1 \times A_2 \times A_3\), up to the fiddly details as to whether we represent a triple as a function or with iterated pairing \((a_1, (a_2, a_3))\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(I\) be a finite index set, and let \((A_i)_{i \in I}\) be a family of finite sets. Then:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If each pair of sets \(A_i\), \(A_j\) are disjoint, then \(|\bigcup_{i \in I} A_i| = \sum_{i \in I} | A_i |\).

\item {} 
\sphinxAtStartPar
\(| \prod_{i \in I} A_i | = \prod_{i \in I} | A_i |\).

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on \(|I|\), using the previous counting principles.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can already use these principles to carry out basic calculations.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Example.} The dessert menu at a restaurant has four flavors of ice cream, two kinds of cake, and three kinds of pie. How many dessert choices are there?

\sphinxAtStartPar
\sphinxstylestrong{Solution.} \(4 + 2 + 3 = 9\), the cardinality of the union of the three disjoint sets.

\sphinxAtStartPar
\sphinxstylestrong{Example.} The menu at a diner has 6 choices of appetizers, 7 choices of entrée, and 5 choices of dessert. How many choices of three\sphinxhyphen{}course dinners are there?

\sphinxAtStartPar
\sphinxstylestrong{Solution.} A three\sphinxhyphen{}course dinner is a triple consisting of an appetizer, an entrée, and a dessert. There are therefore \(6 \cdot 7 \cdot 5 = 210\) options.


\bigskip\hrule\bigskip


\sphinxAtStartPar
A special case of the previous counting principles arises when all the sets have the same size. If \(I\) has cardinality \(k\) and each \(A_i\) has cardinality \(n\), then the cardinality of \(\bigcup_{i \in I} A_i\) is \(k \cdot n\) if the sets are pairwise disjoint, and the cardinality of \(\prod_{i \in I} A_i\) is \(n^k\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Example.} A deck of playing cards has four suits (diamonds, hearts, spades, and clubs) and 13 cards in each suit, for a total of \(4 \cdot 13 = 52\).

\sphinxAtStartPar
\sphinxstylestrong{Example.} A binary string of length \(n\) is a sequence of \(n\) many 0’s and 1’s. We can think of this as an element of
\begin{equation*}
\begin{split}\{0, 1\}^n = \prod_{i < n} \{0, 1\},\end{split}
\end{equation*}
\sphinxAtStartPar
so there are \(2^n\) many binary strings of length \(n\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
There is another counting principle that is almost too obvious to mention: if \(A\) is a finite set and there is a bijection between \(A\) and \(B\), then \(B\) is also finite, and \(|A| = |B|\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Example.} Consider the power set of \([n]\), that is, the collection of all subsets of \(\{0, 1, 2, \ldots, n-1\}\). There is a one\sphinxhyphen{}to\sphinxhyphen{}one correspondence between subsets and binary strings of length \(n\), where element \(i\) of the string is \(1\) if \(i\) is in the set and \(0\) otherwise. As a result, we have \(| \mathcal P ([n]) | = 2^n\).


\bigskip\hrule\bigskip



\section{Ordered Selections}
\label{\detokenize{combinatorics:ordered-selections}}
\sphinxAtStartPar
Let \(S\) be a finite set, which we will think of as being a set of options, such as items on a menu or books that can be selected from a shelf. We now turn to a family of problems in combinatorics that involves making repeated selections from that set of options. In each case, there are finitely many selections, and the order counts: there is a first choice, a second one, a third one, and so on.

\sphinxAtStartPar
In the first variant of the problem, you are allowed to repeat a choice. For example, if you are choosing 3 flavors from a list of 31 ice cream flavors, you can choose “chocolate, vanilla, chocolate.” This is known as \sphinxstyleemphasis{ordered selection with repetition}. If you are making \(k\) choices from among \(n\) options in \(S\), such a selection is essentially a tuple \((a_0, a_1, \ldots, a_{k-1})\), where each \(a_i\) is one of the \(n\) elements in \(S\). In other words, the set of ways of making \(k\) selections from \(S\) with repetition is the set \(S^k\), and we have seen in the last section that if \(S\) has cardinality \(n\), the set \(S^k\) has cardinality \(n^k\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(S\) be a set of \(n\) elements. Then the number of ways of making \(k\) selections from \(S\) with repetition allowed is \(n^k\).

\sphinxAtStartPar
\sphinxstylestrong{Example.} How many three\sphinxhyphen{}letter strings (like “xyz,” “qqa,” …) can be formed using the twenty\sphinxhyphen{}six letters of the alphabet?

\sphinxAtStartPar
\sphinxstylestrong{Solution.} We have to make three selections from a set of 26 elements, for a total of \(26^3 = 17,576\) possibilities.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Suppose instead we wish to make \(k\) ordered selections, but we are not allowed to repeat ourselves. This would arise, from example, if a museum had 26 paintings in its storeroom, and has to select three of them to put on display, ordered from left to right along a wall. There are 26 choices for the first position. Once we have made that choice, 25 remain for the second position, and then 24 remain for the third. So it seems clear that there are \(26 \cdot 25 \cdot 24\) arrangements overall.

\sphinxAtStartPar
Let us try to frame the problem in mathematical terms. We can think of an ordered selection of \(k\) elements from a set \(S\) without repetition as being an \sphinxstyleemphasis{injective function} \(f\) from \([k]\) to \(S\). The element \(f(0)\) is the first choice; \(f(1)\) is the second choice, which has to be distinct from \(f(0)\); \(f(2)\) is the third choice, which has to be distinct from \(f(0)\) and \(f(1)\); and so on.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) and \(B\) be finite sets, with \(|A| = k\) and \(|B| = n\), and \(k \le n\). The number of injective functions from \(A\) to \(B\) is \(n \cdot (n - 1) \cdot \ldots \cdot (n - k + 1)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Using induction on \(k\), we will show that for every \(A\), \(B\), and \(n \geq k\), the claim holds. When \(k = 0\) there is only one injective function, namely the function with empty domain. Suppose \(A\) has cardinality \(k + 1\), let \(a_0\) be any element of \(A\). Then any injective function from \(A\) to \(B\) can be obtained by choosing an element \(b_0\) for the image of \(a_0\), and then choosing an injective function from \(A \setminus \{ a_0 \}\) to \(B \setminus \{ b_0 \}\). There are \(n\) choices of \(b_0\), and since \(| A \setminus \{ a_0 \} | = n - 1\) and \(|B \setminus \{ b_0 \} | = k - 1\), there are \((n - 1) \cdot \ldots \cdot (n - k + 1)\) choices of the injective function, by the inductive hypothesis.

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(S\) be a finite set, with \(|S| = n\). Then the number of ways of making \(k\) selections from \(S\) without repetition allowed is \(n \cdot (n - 1) \cdot \ldots \cdot (n - k + 1)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} This is just a restatement of the previous theorem, where \(A = [k]\) and \(B = S\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
If \(A\) is a finite set, a bijection \(f\) from \(A\) to \(A\) is also called a \sphinxstyleemphasis{permutation} of \(A\). The previous theorem shows that if \(|A| = n\) then the number of permutations of \(A\) is \(n \cdot (n - 1) \cdot \ldots \cdot 1\). This quantity comes up so often that it has a name, \(n\) \sphinxstyleemphasis{factorial}, and a special notation, \(n!\). If we think of the elements of \(A\) listed in some order, a permutation of \(A\) is essentially an ordered selection of \(n\) elements from \(A\) without repetition: we choose where to map the first element, then the second element, and so on. It is a useful convention to take \(0!\) to be equal to \(1\).

\sphinxAtStartPar
The more general case where we are choosing only \(k\) elements from a set \(A\) is called a \(k\)\sphinxhyphen{}permutation of \(A\). The theorem above says that the number of \(k\)\sphinxhyphen{}permutations of an \(n\)\sphinxhyphen{}element set is equal to \(n! / (n - k)!\), because if you expand the numerator and denominator into products and cancel, you get exactly the \(n \cdot (n - 1) \cdot \ldots \cdot (n - k + 1)\). This number is often denoted \(P(n, k)\) or \(P^n_k\), or some similar variant. So we have \(P(n, k) = n! / (n - k)!\). Notice that the expression on the right side of the equality provides an efficient way of writing the value of \(P(n, k)\), but an inefficient way of calculating it.


\section{Combinations and Binomial Coefficients}
\label{\detokenize{combinatorics:combinations-and-binomial-coefficients}}\label{\detokenize{combinatorics:id3}}
\sphinxAtStartPar
In the last section, we calculated the number of ways in which a museum could arrange three paintings along a wall, chosen from among 26 paintings in its storeroom. By the final observation in the previous section, we can write this number as \(26! / 23!\).

\sphinxAtStartPar
Suppose now we want to calculate the number of ways that a museum can choose three paintings from its storeroom to put on display, where we do not care about the order. In other words, if \(a\), \(b\), and \(c\) are paintings, we do not want to distinguish between choosing \(a\) then \(b\) then \(c\) and choosing \(c\) then \(b\) then \(a\). When we were arranging paintings along all wall, it made sense to consider these two different arrangements, but if we only care about the \sphinxstyleemphasis{set} of elements we end up with at the end, the order that we choose them does not matter.

\sphinxAtStartPar
The problem is that each set of three paintings will be counted multiple times. In fact, each one will be counted six times: there are \(3! = 6\) permutations of the set \(\{a, b, c\}\), for example. So to count the number of outcomes we simply need to divide by 6. In other words, the number we want is \(\frac{26!}{3! \cdot 23!}\).

\sphinxAtStartPar
There is nothing special about the numbers \(26\) and \(3\). The same formula holds for what we will call \sphinxstyleemphasis{unordered selections of} \(k\) \sphinxstyleemphasis{elements from a set of} \(n\) \sphinxstyleemphasis{elements}, or \(k\)\sphinxhyphen{}\sphinxstyleemphasis{combinations from an} \(n\)\sphinxhyphen{}\sphinxstyleemphasis{element set}. Our goal is once again to describe the situation in precise mathematical terms, at which point we will be able to state the formula as a theorem.

\sphinxAtStartPar
In fact, describing the situation in more mathematical terms is quite easy to do. If \(S\) is a set of \(n\) elements, an unordered selection of \(k\) elements from \(S\) is just a subset of \(S\) that has cardinality \(k\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(S\) be any set with cardinality \(n\), and let \(k \leq n\). Then the number of subsets of \(S\) of cardinality \(k\) is \(\frac{n!}{k!(n-k)!}\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(U\) be the set of unordered selections of \(k\) elements from \(S\), let \(V\) be the set of permutations of \([k]\), and let \(W\) be the set of \sphinxstyleemphasis{ordered} selections of \(k\) elements from \(S\). There is a bijection between \(U \times V\) and \(W\), as follows. Suppose we assign to every \(k\)\sphinxhyphen{}element subset \(\{ a_0, \ldots, a_{k-1} \}\) of \(S\) some way of listing the elements, as shown. Then given any such set and any permutation \(f\) of \([k]\), we get an ordered the ordered selection \((a_{f(0)}, a_{f(1)}, \ldots, a_{f(k-1)})\). Any ordered selection arises from such a subset and a suitable permutation, so the mapping is surjective. And a different set or a different permutation results in a different ordered selection, so the mapping is injective.

\sphinxAtStartPar
By the counting principles, we have
\begin{equation*}
\begin{split}P(n, k) = |W| = |U \times V| = |U| \cdot |V| = |U| \cdot k!,\end{split}
\end{equation*}
\sphinxAtStartPar
so we have \(|U| = P(n,k) / k! = \frac{n!}{k!(n-k)!}\).

\sphinxAtStartPar
\sphinxstylestrong{Example.} Someone is going on vacation and wants to choose three outfits from ten in their closet to pack in their suitcase. How many choices do they have?

\sphinxAtStartPar
\sphinxstylestrong{Solution.} \(\frac{10!}{3! 7!} = \frac{10 \cdot 9 \cdot 8}{3 \cdot 2 \cdot 1} = 120\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
The number of unordered selections of \(k\) elements from a set of size \(n\), or, equivalently, the number of \(k\)\sphinxhyphen{}combinations from an \(n\)\sphinxhyphen{}element set, is typically denoted by \(\binom{n}{k}\), \(C(n, k)\), \(C^n_k\), or something similar. We will use the first notation, because it is most common. Notice that \(\binom{n}0 = 1\) for every \(n\); this makes sense, because there is exactly one subset of any \(n\)\sphinxhyphen{}element set of cardinality \(0\).

\sphinxAtStartPar
Here is one important property of this function.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every \(n\) and \(k \leq n\), we have \(\binom{n}{k} = \binom{n}{n - k}\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} This is an easy calculation:
\begin{equation*}
\begin{split}\frac{n!}{(n - k)! (n - (n - k))!} = \frac{n!}{(n - k)! k!}.\end{split}
\end{equation*}
\sphinxAtStartPar
But it is also easy to see from the combinatorial interpretation: choosing \(k\) outfits from \(n\) to take on vacation is the same task as choosing \(n - k\) outfits to leave home.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Here is another important property.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every \(n\) and \(k\), if \(k + 1 \leq n\),
then
\begin{equation*}
\begin{split}\binom{n+1}{k+1} = \binom{n}{k+1} + \binom{n}{k}.\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Proof.} One way to understand this theorem is in terms of the combinatorial interpretation. Suppose you want to choose \(k+1\) outfits out of \(n + 1\). Set aside one outfit, say, the blue one. Then you have two choices: you can either choose \(k+1\) outfits from the remaining ones, with \(\binom{n}{k+1}\) possibilities; or you can take the blue one, and choose \(k\) outfits from the remaining ones.

\sphinxAtStartPar
The theorem can also be proved by direct calculation. We can express the left\sphinxhyphen{}hand side of the equation as follows:
\begin{equation*}
\begin{split}\binom{n+1}{k+1} & = \frac{(n + 1)!}{(k+1)!((n+1)-(k+1))!} \\ & = \frac{(n + 1)!}{(k+1)!(n - k)!}.\end{split}
\end{equation*}
\sphinxAtStartPar
Similarly, we can simplify the right\sphinxhyphen{}hand side:
\begin{equation*}
\begin{split}\binom{n}{k+1} + \binom{n}{k} & = \frac{n!}{(k+1)!(n-(k+1))!} + \frac{n!}{k!(n-k)!} \\
& = \frac{n!(n-k)}{(k+1)!(n-k-1)!(n-k)} + \frac{(k+1)n!}{(k+1)k!(n-k)!} \\
& = \frac{n!(n-k)}{(k+1)!(n-k)!} + \frac{(k+1)n!}{(k+1)!(n-k)!} \\
& = \frac{n!(n-k + k + 1)}{(k+1)!(n-k)!} \\
& = \frac{n!(n + 1)}{(k+1)!(n-k)!} \\
& = \frac{(n + 1)!}{(k+1)!(n-k)!}.\end{split}
\end{equation*}
\sphinxAtStartPar
Thus the left\sphinxhyphen{}hand side and the right\sphinxhyphen{}hand side are equal.


\bigskip\hrule\bigskip


\sphinxAtStartPar
For every \(n\), we know \(\binom{n}{0} = \binom{n}{n} = 1\). The previous theorem then gives a recipe to compute all the binomial coefficients: once we have determine \(\binom{n}{k}\) for some \(n\) and every \(k \leq n\), we can determine the values of \(\binom{n+1}{k}\) for every \(k \leq n + 1\) using the recipe above. The results can be displayed graphically in what is known as \sphinxstyleemphasis{Pascal’s triangle}:



\begin{center}
\begin{tabular}{rccccccccc}
    &    &    &    &  1 \\\noalign{\smallskip\smallskip}
    &    &    &  1 &    &  1 \\\noalign{\smallskip\smallskip}
    &    &  1 &    &  2 &    &  1 \\\noalign{\smallskip\smallskip}
    &  1 &    &  3 &    &  3 &    &  1 \\\noalign{\smallskip\smallskip}
  1 &    &  4 &    &  6 &    &  4 &    &  1 \\\noalign{\smallskip\smallskip}
\end{tabular}
\end{center}

\sphinxAtStartPar
Specifically, if we start counting at \(0\), the \(k\)th element of the \(n\)th row is equal to \(\binom{n}{k}\).

\sphinxAtStartPar
There is also a connection between \(\binom{n}{k}\) and the polynomials \((a + b)^n\), namely, that the \(k\)th coefficient of \((a + b)^n\) is exactly \(\binom{n}{k}\). For example, we have
\begin{equation*}
\begin{split}(a + b)^4 = a^4 + 4 a^3 b + 6 a^2 b^2 + 4 a b^3 + b^4.\end{split}
\end{equation*}
\sphinxAtStartPar
For that reason, the values \(\binom{n}{k}\) are often called \sphinxstyleemphasis{binomial coefficients}, and the statement that
\begin{equation*}
\begin{split}(a + b)^n = \sum_{k \le n} \binom{n}{k} a^{n-k} b^k\end{split}
\end{equation*}
\sphinxAtStartPar
is known as the \sphinxstyleemphasis{binomial theorem}.

\sphinxAtStartPar
There are a couple of ways of seeing why this theorem holds. One is to expand the polynomial,
\begin{equation*}
\begin{split}(a + b)^n = (a + b) (a + b) \cdots (a + b)\end{split}
\end{equation*}
\sphinxAtStartPar
and notice that the coefficient of the term \(a^{n-k} b^k\) is equal to the number of ways of taking the summand \(b\) in exactly \(k\) positions, and \(a\) in the remaining \(n - k\) positions. Another way to prove the result is to use induction on \(n\), and use the identity \(\binom{n+1}{k+1} = \binom{n}{k+1} + \binom{n}{k}\). The details are left as an exercise.

\sphinxAtStartPar
Finally, we have considered ordered selections with and without repetitions, and unordered selections without repetitions. What about unordered selections with repetitions? In other words, given a set \(S\) with \(n\) elements, we would like to know how many ways there are of making \(k\) choices, where we can choose elements of \(S\) repeatedly, but we only care about the number of times each element was chosen, and not the order. We have the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
The number of unordered selections of \(k\) elements from an \(n\)\sphinxhyphen{}element set, with repetition, is \(\binom{n + k - 1}{k}\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
A proof of this is outlined in the exercises.


\section{The Inclusion\sphinxhyphen{}Exclusion Principle}
\label{\detokenize{combinatorics:the-inclusion-exclusion-principle}}
\sphinxAtStartPar
Let \(A\) and \(B\) be any two subsets of some domain, \(U\). Then \(A = A \setminus B \cup (A \cap B)\), and the two sets in the union are disjoint, so we have \(|A| = |A \setminus B| + |A \cap B|\). This means \(|A \setminus B| = |A| - |A \cap B|\). Intuitively, this makes sense: we can count the elements of \(A \setminus B\) by counting the elements in \(A\), and then subtracting the number of elements that are in both \(A\) and \(B\).

\sphinxAtStartPar
Similarly, we have \(A \cup B = A \cup (B \setminus A)\), and the two sets on the right\sphinxhyphen{}hand side of this equation are disjoint, so we
have
\begin{equation*}
\begin{split}|A \cup B| = |A| + |B \setminus A| = |A| + |B| - |A \cap B|.\end{split}
\end{equation*}
\sphinxAtStartPar
If we draw a Venn diagram, this makes sense: to count the elements in \(A \cup B\), we can add the number of elements in \(A\) to the number of elements in \(B\), but then we have to subtract the number of elements of both.

\sphinxAtStartPar
What happen when there are three sets? To compute \(|A \cup B \cup C|\), we can start by adding the number of elements in each, and then subtracting the number of elements of \(| A \cap B |\), \(|A \cap C|\), and \(|B \cap C|\), each of which have been double\sphinxhyphen{}counted. But thinking about the Venn diagram should help us realize that then we have over\sphinxhyphen{}corrected: each element of \(A \cap B \cap C\) was counted three times in the original sum, and the subtracted three times. So we need to add them back in:
\begin{equation*}
\begin{split}| A \cup B \cup C | = | A | + | B | + | C | - | A \cap B | - | A \cap C | - | B \cap C | + | A \cap B \cap C |.\end{split}
\end{equation*}
\sphinxAtStartPar
This generalizes to any number of sets. To state the general result, suppose the sets are numbered \(A_0, \ldots, A_{n-1}\). For each nonempty subset \(I\) of \(\{0, \ldots, n-1 \}\), consider \(\bigcap_{i \in I} A_i\). If \(|I|\) is odd (that is, equal to 1, 3, 5, …) we want to add the cardinality of the intersection; if it is even we want to subtract it. This recipe is expressed compactly by the following formula:
\begin{equation*}
\begin{split}\left| \bigcup_{i < n} A_i \right| = \sum_{\emptyset \ne I \subseteq [n]} (-1)^{|I|+1} \left| \bigcap_{i \in I} A_i \right| .\end{split}
\end{equation*}
\sphinxAtStartPar
You are invited to try proving this as an exercise, if you are ambitious. The following example illustrates its use:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Example.} Among a group of college Freshmen, 30 are taking Logic, 25 are taking History, and 20 are taking French. Moreover, 11 are taking Logic and History, 10 are taking Logic and French, 7 are taking History and French, and 3 are taking all three. How many students are taking at least one of the three classes?

\sphinxAtStartPar
\sphinxstylestrong{Solution.} Letting \(L\), \(H\), and \(F\) denote the sets of students taking Logic, History, and French, respectively, we have
\begin{equation*}
\begin{split}| L \cup H \cup F | = 30 + 25 + 20 - 11 - 10 - 7 + 3 = 50.\end{split}
\end{equation*}

\bigskip\hrule\bigskip



\section{Exercises}
\label{\detokenize{combinatorics:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Suppose that, at a party, every two people either know each other or don’t. In other words, “\(x\) knows \(y\)” is symmetric. Also, let us ignore the complex question of whether we always know ourselves by restricting attention to the relation between distinct people; in other words, for this problem, take “\(x\) knows \(y\)” to be irreflexive as well.

\sphinxAtStartPar
Use the pigeonhole principle (and an additional insight) to show that there must be two people who know exactly the same number of people.

\item {} 
\sphinxAtStartPar
Show that in any set of \(n + 1\) integers, two of them are equivalent modulo \(n\).

\item {} 
\sphinxAtStartPar
Spell out in detail a proof of the second counting principle in \hyperref[\detokenize{combinatorics:counting-principles}]{Section \ref{\detokenize{combinatorics:counting-principles}}}.

\item {} 
\sphinxAtStartPar
An ice cream parlor has 31 flavors of ice cream.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
Determine how many three\sphinxhyphen{}flavor ice\sphinxhyphen{}cream cones are possible, if we care about the order and repetitions are allowed. (So choosing chocolate\sphinxhyphen{}chocolate\sphinxhyphen{}vanilla scoops, from bottom to top, is different from choosing chocolate\sphinxhyphen{}vanilla\sphinxhyphen{}chocolate.)

\item {} 
\sphinxAtStartPar
Determine how many three flavor ice\sphinxhyphen{}cream cones are possible, if we care about the order, but repetitions are not allowed.

\item {} 
\sphinxAtStartPar
Determine how many three flavor ice\sphinxhyphen{}cream cones are possible, if we don’t care about the order, but repetitions are not allowed.

\end{enumerate}

\item {} 
\sphinxAtStartPar
A club of 10 people has to elect a president, vice president, and secretary. How many possibilities are there:
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
if no person can hold more than one office?

\item {} 
\sphinxAtStartPar
if anyone can hold any number of those offices?

\item {} 
\sphinxAtStartPar
if anyone can hold up to two offices?

\item {} 
\sphinxAtStartPar
if the president cannot hold another office, but the vice president and secretary may or may not be the same person?

\end{enumerate}

\item {} 
\sphinxAtStartPar
How many 7 digit phone numbers are there, if any 7 digits can be used? How many are there if the first digit cannot be 0?

\item {} 
\sphinxAtStartPar
In a class of 20 kindergarten students, two are twins. How many ways are there of lining up the students, so that the twins are standing together?

\item {} 
\sphinxAtStartPar
A woman has 8 murder mysteries sitting on her shelf, and wants to take three of them on a vacation. How many ways can she do this?

\item {} 
\sphinxAtStartPar
In poker, a “full house” is a hand with three of one rank and two of another (for example, three kings and two fives). Determine the number of full houses that can be formed from an ordinary deck of 52 cards.

\item {} 
\sphinxAtStartPar
We saw in \hyperref[\detokenize{combinatorics:combinations-and-binomial-coefficients}]{Section \ref{\detokenize{combinatorics:combinations-and-binomial-coefficients}}} that
\begin{equation*}
\begin{split}\binom{n+1}{k+1} = \binom{n}{k+1} + \binom{n}{k}.\end{split}
\end{equation*}
\sphinxAtStartPar
Replacing \(k + 1\) by \(k\), whenever \(1 \leq k \leq n\), we have
\begin{equation*}
\begin{split}\binom{n+1}{k} = \binom{n}{k} + \binom{n}{k-1}.\end{split}
\end{equation*}
\sphinxAtStartPar
Use this to show, by induction on \(n\), that for every \(k \leq n\), that if \(S\) is any set of \(n\) elements, \(\binom{n}{k}\) is the number of subsets of \(S\) with \(k\) elements.

\item {} 
\sphinxAtStartPar
How many distinct arrangements are there of the letters in the word MISSISSIPPI?

\sphinxAtStartPar
(Hint: this is tricky. First, suppose all the S’s, I’s, and P’s were painted different colors. Then determine how many distinct arrangements of the letters there would be. In the absence of distinguishing colors, determine how many times each configuration appeared in the first count, and divide by that number.)

\item {} 
\sphinxAtStartPar
Prove the inclusion\sphinxhyphen{}exclusion principle.

\item {} 
\sphinxAtStartPar
Use the inclusion\sphinxhyphen{}exclusion principle to determine the number of integers less than 100 that are divisible by 2, 3, or 5.

\item {} 
\sphinxAtStartPar
Show that the number of \sphinxstyleemphasis{unordered} selections of \(k\) elements from an \(n\)\sphinxhyphen{}element set is \(\binom{n + k - 1}{k}\).

\sphinxAtStartPar
Hint: consider \([n]\). We need to choose some number \(i_0\) of 0’s, some number \(i_1\) of 1’s, and so on, so that \(i_0 + i_1 + \ldots + i_{n-1} = k\). Suppose we assign to each such tuple a the following binary sequence: we write down \(i_0\) 0’s, then a 1, then \(i_1\) 0’s, then a 1, then \(i_2\) 0’s, and so on. The result is a binary sequence of length \(n + k - 1\) with exactly \(k\) 1’s, and such binary sequence arises from a unique tuple in this way.

\end{enumerate}


\chapter{The Real Numbers}
\label{\detokenize{the_real_numbers:the-real-numbers}}\label{\detokenize{the_real_numbers:id1}}\label{\detokenize{the_real_numbers::doc}}

\section{The Number Systems}
\label{\detokenize{the_real_numbers:the-number-systems}}
\sphinxAtStartPar
We have already come across some of the fundamental number systems: the natural numbers, \(\mathbb{N}\), the integers, \(\mathbb{Z}\), and the rationals, \(\mathbb{Q}\). In a sense, each subsequent element of the list was designed to remedy defects in the previous system. We can subtract any integer from any other integer and end up with another integer, and we can divide any rational number by a nonzero rational number and end up with a rational number.

\sphinxAtStartPar
The integers satisfy all of the following properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Addition is associative and commutative.

\item {} 
\sphinxAtStartPar
There is an additive identity, \(0\), and every element \(x\) has an additive inverse, \(-x\).

\item {} 
\sphinxAtStartPar
Multiplication is associative and commutative.

\item {} 
\sphinxAtStartPar
There is a multiplicative identity, \(1\).

\item {} 
\sphinxAtStartPar
Multiplication distributes over addition: for every \(x\), \(y\), and \(z\), we have \(x (y + z) = x y + x z\).

\item {} 
\sphinxAtStartPar
The ordering \(\leq\) is a total order.

\item {} 
\sphinxAtStartPar
For any elements \(x\), \(y\), and \(z\), if \(x \leq y\) then \(x + z \leq y + z\).

\item {} 
\sphinxAtStartPar
For any elements \(x\) and \(y\), if \(0 \leq x\) and \(0 \leq y\) then \(0 \leq x y\).

\end{itemize}

\sphinxAtStartPar
The first five clauses say that with \(\times\), \(+\), \(0\), and \(1\), the integers form a \sphinxstyleemphasis{commutative ring}, and the last three say that together with \(\leq\), the structure is an \sphinxstyleemphasis{ordered ring}. The natural numbers lack additive inverses, so they satisfy a slightly weaker set of axioms that make them an \sphinxstyleemphasis{ordered semiring}. On the other hand, the rational numbers also form an ordered ring, satisfying the following additional property:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Every nonzero element has a multiplicative inverse, \(x^{-1}\).

\end{itemize}

\sphinxAtStartPar
This makes them an instance of an \sphinxstyleemphasis{ordered field}.

\sphinxAtStartPar
It is worth knowing that once we have the natural numbers, it is possible to \sphinxstyleemphasis{construct} the integers and rational numbers, using set\sphinxhyphen{}theoretic constructions you have already seen. For example, we can take an integer to be a pair \((i, n)\) of natural numbers where \(i\) is either 0 or 1, with the intention that \((0, n)\) represents the positive integer \(n\), and \((1, n)\) represents the negative integer \(-(n+1)\). (We use \(-(n+1)\) instead of \(-n\) to avoid having two representations of \(0\).) With this definition, the integers are simply \(\{0, 1\} \times \mathbb{N}\). We can then go on to define the operations of addition and multiplication, the additive inverse, and the order relation, and prove they have the desired properties.

\sphinxAtStartPar
This construction has the side effect that the natural numbers themselves are not integers; for example, we have to distinguish between the natural number \(2\) and the integer \(2\). This is the case in Lean. In ordinary mathematics, it is common to think of the natural numbers as a subset of the integers. Once we construct the integers, however, we can throw away the old version of the natural numbers, and afterwards identify the natural numbers as nonnegative integers.

\sphinxAtStartPar
We can do the same for the rationals, defining them to be the set of pairs \((a, b)\) in \(\mathbb{Z} \times \mathbb{N}\), where either \(a = 0\) and \(b = 1\), or \(b > 0\) and \(a\) and \(b\) have no common divisor (other than \(1\) and \(-1\)). The idea is that \((a, b)\) represents \(a / b\). With this definition, the rationals are really a subset of \(\mathbb{Z} \times \mathbb{N}\), and we can then define all the operations accordingly.

\sphinxAtStartPar
In the next section, we will define a more sophisticated approach, one which will scale to a definition of the real numbers. And in a later chapter, we will show how to construct the natural numbers from the axioms of set theory. This shows that we can construct all the number systems from the bottom up.

\sphinxAtStartPar
But first, let us pause for a moment to consider why the real numbers are needed. We have seen that \(2\) has no rational square root. This means, in a sense, that there is a “gap” in the rationals: the are rationals whose squares are arbitrarily close to 2, but there is no rational \(x\) with the property that \(x^2 = 2\). But it seems intuitively clear that there should be some \sphinxstyleemphasis{number} with that property: \(\sqrt{2}\) is the length of the diagonal of a square with side length \(1\). Similarly, \(\pi\), the area of a circle with radius 1, is missing from the rationals. These are the kinds of defects that the real numbers are designed to repair.

\sphinxAtStartPar
You may be used to thinking of real numbers as (potentially) infinite decimals: for example, \(\sqrt{2} = 1.41421356\ldots\) and \(\pi = 3.14159265\ldots\). A central goal of this chapter is to make the “…” precise. The idea is that we can take an infinite decimal to represent a sequence of rational approximations. For example, we can approximate the square root of 2 with the sequence \(1, 1.4, 1.41, 1.414, \ldots\). We would like to define \(\sqrt{2}\) to be the “limit” of that sequence, but we have seen that the sequence does not have a limit in the rationals. So we have to construct new objects, the real numbers, to serve that purpose.

\sphinxAtStartPar
In fact, we will define the real numbers, more or less, to \sphinxstyleemphasis{be} such sequences of rational approximations. But we will have to deal with the fact that, for example, there are \sphinxstyleemphasis{lots} of ways of approximating the square root of two. For example, we can just as well approach it from above, \(2, 1.5, 1.42, \ldots\), or by oscillating above and below. The next section will show us how to “glue” all these sequences together and treat them as a single object.


\section{Quotient Constructions}
\label{\detokenize{the_real_numbers:quotient-constructions}}\label{\detokenize{the_real_numbers:id2}}
\sphinxAtStartPar
Let \(A\) be any set, and let \(\equiv\) be any equivalence relation on \(A\). Recall from \hyperref[\detokenize{relations:equivalence-relations-and-equality}]{Section \ref{\detokenize{relations:equivalence-relations-and-equality}}} that we can assign to every element \(a\) of \(A\) the equivalence class \([a]\), where \(b \in [a]\) means \(b \equiv a\). This assignment has the property that for every \(a\) and \(b\), \(a \equiv b\) if and only if \([a] = [b]\).

\sphinxAtStartPar
Given any set \(A\) and equivalence relation \(\equiv\), define \(A / \mathord{\equiv}\) to be the set \(\{ [ a ] \mid a \in A \}\) of \sphinxstyleemphasis{equivalence classes} of \(A\) modulo \(\equiv\). This set is called “\(A\) modulo \(\mathord{\equiv}\),” or the \sphinxstyleemphasis{quotient} of \(A\) by \(\equiv\). You can think of this as the set \(A\) where equivalent elements are “glued together” to make a coarser set.

\sphinxAtStartPar
For example, if we consider the integers \(\mathbb{Z}\) with \(\equiv\) denoting equivalence modulo 5 (as in \hyperref[\detokenize{elementary_number_theory:modular-arithmetic}]{Section \ref{\detokenize{elementary_number_theory:modular-arithmetic}}}), then \(\mathbb{Z} / \mathord{\equiv}\) is just \(\{ [0], [1], [2], [3], [4] \}\). We can define addition on \(\mathbb{Z} / \mathord{\equiv}\) by \([a] + [b] = [a + b]\). For this definition to make sense, it is important to know that the right\sphinxhyphen{}hand side does not depend on which representatives of \([a]\) and \([b]\) we choose. In other words, we need to know that whenever \([a] = [a']\) and \([b] = [b']\), then \([a + b] = [a' + b']\). This, in turn, is equivalent to saying that if \(a \equiv a'\) and \(b \equiv b'\), then \(a + b \equiv a' + b'\). In other words, we require that the operation of addition \sphinxstyleemphasis{respects} the equivalence relation, and we saw in \hyperref[\detokenize{elementary_number_theory:modular-arithmetic}]{Section \ref{\detokenize{elementary_number_theory:modular-arithmetic}}} that this is in fact the case.

\sphinxAtStartPar
This general strategy for transferring a function defined on a set to a function defined on a quotient of that set is given by the following theorem.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(A\) and \(B\) be any sets, let \(\equiv\) be any equivalence relation defined on \(A\), and let \(f : A \to B\). Suppose \(f\) respects the equivalence relation, which is to say, for every \(a\) and \(a'\) in \(A\), if \(a \equiv a'\), then \(f(a) = f(a')\). Then there is a unique function \(\bar f : A / \mathord{\equiv} \to B\), defined by \(\bar f ([a]) = f(a)\) for every \(a\) in \(A\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We have defined the value of \(\bar f\) on an equivalence class \(x\) by writing \(x = [a]\), and setting \(\bar f(x) = f(a)\). In other words, we say that \(\bar f(x) = y\) if and only if there is an \(a\) such that \(x = [a]\), and \(f(a) = y\). What is dubious about the definition is that, a priori, it might depend on how we express \(x\) in that form; in other words, we need to show that there is a \sphinxstyleemphasis{unique} \(y\) meeting this description. Specifically, we need to know that if \(x = [a] = [a']\), then \(f(a) = f(a')\). But since \([a] = [a']\) is equivalent to \(a \equiv a'\), this amounts to saying that \(f\) respects the equivalence relation, which is exactly what we have assumed.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Mathematicians often “define” \(\bar f\) by the equation \(\bar f ([a])= f(a)\), and then express the proof above as a proof that “\(\bar f\) is well defined.” This is confusing. What they really mean is what the theorem says, namely, that there is a unique function meeting that description.

\sphinxAtStartPar
To construct the integers, start with \(\mathbb{N} \times \mathbb{N}\). Think of the pair of natural numbers \((m, n)\) as representing \(m - n\), where the subtraction takes place in the integers (which we haven’t constructed yet!). For example, both \((2, 5)\) and \((6, 9)\) represent the integer \(-3\). Intuitively, the pairs \((m, n)\) and \((m', n')\) will represent the same integer when \(m - n = m' - n'\), but we cannot say this yet, because we have not yet defined the appropriate notion of subtraction. But the equation is equivalent to \(m + n' = m' + n\), and \sphinxstyleemphasis{this} makes sense with addition on the natural numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Define the relation \(\equiv\) on \(\mathbb{N} \times \mathbb{N}\) by \((m, n) \equiv (m', n')\) if and only if \(m + n' = m' + n\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} \(\equiv\) is an equivalence relation.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} For reflexivity, it is clear that \((m, n) \equiv (m, n)\), since \(m + n = m + n\).

\sphinxAtStartPar
For symmetry, suppose \((m, n) \equiv (m', n')\). This means \(m + n' = m' + n\). But the symmetry of equality implies \((m', n') \equiv (m, n)\), as required.

\sphinxAtStartPar
For transitivity, suppose \((m, n) \equiv (m', n')\), and \((m', n') = (m'', n'')\). Then we have \(m + n' = m' + n\) and \(m' + n'' = n' + m''\). Adding these equations, we get
\begin{equation*}
\begin{split}m + n' + m' + n'' = m' + n + n' + m''.\end{split}
\end{equation*}
\sphinxAtStartPar
Subtracting \(m' + n'\) from both sides, we get \(m + n'' = n + m''\), which is equivalent to \((m, n) = (m'', n'')\), as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can now define the integers to be \(\mathbb{N} \times \mathbb{N} / \mathord{\equiv}\). How should we define addition? If \([(m, n)]\) represents \(m - n\), and \([(u, v)]\) represents \(u - v\), then \([(m, n)] + [(u, v)]\) should represent \((m + u) - (n + v)\). Thus, it makes sense to define \([(m, n)] + [(u, v)]\) to be \([(m + u) - (n + v)]\). For this to work, we need to know that the operation which sends \((m, n)\) and \((u, v)\) to \((m + u, n + v)\) respects the equivalence relation.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition.} If \((m, n) \equiv (m', n')\) and \((u, v) \equiv (u', v')\), then \((m + u, n + v) \equiv (m' + u', n' + v')\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} The first equivalence means \(m + n' = m' + n\), and the second means \(u + v' = u' + v\). Adding the two equations, we get \((m + u) + (n' + v') \equiv (m' + u') + (n + v)\), which is exactly the same as saying \((m + u, n + v) \equiv (m' + u', n' + v')\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Every natural number \(n\) can be represented by the integer \([(n, 0)]\), and, in particular, \(0\) is represented by \([(0, 0)]\). Moreover, if \([(m, n)]\) is any integer, we can define its negation to be \([(n, m)]\), since \([(m, n)] + [(n, m)] = [(m + n, n + m)] = [(0, 0)]\), since \((m + n, n + m) \equiv (0, 0)\). In short, we have “invented” the negative numbers!

\sphinxAtStartPar
We could go on this way to define multiplication and the ordering on the integers, and prove that they have the desired properties. We could also carry out a similar construction for the rational numbers. Here, we would start with the set \(\mathbb{Z} \times \mathbb{Z}^{>0}\), where \(\mathbb{Z}^{>0}\) denotes the strictly positive integers. The idea, of course, is that \((a, b)\) represents \((a / b)\). With that in mind, it makes sense to define \((a, b) \equiv (c, d)\) if \(a d = b c\). We could go on to define addition, multiplication, and the ordering there, too. The details are tedious, however, and not very illuminating. So we turn, instead, to a construction of the real numbers.


\section{Constructing the Real Numbers}
\label{\detokenize{the_real_numbers:constructing-the-real-numbers}}
\sphinxAtStartPar
The problem we face is that the sequence \(1, 1.4, 1.41, 1.414, 1.4142, \ldots\) of rational numbers seems to approach a value that \sphinxstyleemphasis{would} be the square root of 2, but there is no rational number that can play that role. The next definition captures the notion that this sequence of numbers “seems to approach a value,” without referring to a value that it is approaching.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A sequence of rational numbers \((q_i)_{i \in \mathbb{N}}\) is \sphinxstyleemphasis{Cauchy} if for every rational number \(\varepsilon > 0\), there is some natural number \(N \in \mathbb{N}\) such that for all \(i, j \geq N\), we have that \(|q_i - q_j| < \varepsilon\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
Roughly speaking, a Cauchy sequence is one where the elements become arbitrarily close, not just to their successors but to all following elements. It is common in mathematics to use \(\varepsilon\) to represent a quantity that is intended to denote something small; you should read the phrase “for every \(\varepsilon > 0\)” as saying “no matter how small \(\varepsilon\) is.” So a sequence is Cauchy if, for any \(\varepsilon > 0\), no matter how small, there is some point \(N\), beyond which the elements stay within a distance of \(\varepsilon\) of one another.

\sphinxAtStartPar
Cauchy sequences can be used to describe these gaps in the rationals, but, as noted above, many Cauchy sequences can be used to describe the same gap. At this stage, it is slightly misleading to say that they “approach the same point,” since there is no rational point that they approach; a more precise statement is that the sequences eventually become arbitrarily close.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Two Cauchy sequences \(p = (p_i)_{i \in \mathbb{N}}\) and \(q = (q_i)_{i \in \mathbb{N}}\) are \sphinxstyleemphasis{equivalent} if for every rational number \(\varepsilon > 0\), there is some natural number \(N \in \mathbb{N}\) such that for all \(i \geq N\), we have that \(|p_i - q_i| < \varepsilon\). We will write \(p \equiv q\) to express that \(p\) is equivalent to \(q\).

\sphinxAtStartPar
\sphinxstylestrong{Proposition.} \(\equiv\) is an equivalence relation on Cauchy sequences.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Reflexivity and symmetry are easy, so let us prove transitivity. Suppose \((p_i) \equiv (q_i)\) and \((q_i) \equiv (r_i)\). We want to show that the sequence \((p_i)\) is equivalent to \((r_i)\). So, given any \(\varepsilon > 0\), choose \(N_0\) large enough such that for every \(i \ge N_0\), \(|p_i - q_i| < \varepsilon / 2\). Choose another number, \(N_1\), so that for every \(i \geq N_1\), \(|q_i - r_i| < \varepsilon / 2\). Let \(N = \max(N_0, N_1)\). Then for every \(i \geq N\), we have
\begin{equation*}
\begin{split}|p_i - r_i | = |(p_i - q_i) + (q_i - r_i)| \leq |p_i - q_i| + |q_i - r_i| < \varepsilon / 2 + \varepsilon / 2 = \varepsilon,\end{split}
\end{equation*}
\sphinxAtStartPar
as required.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that the proof uses the \sphinxstyleemphasis{triangle inequality}, which states for any rational numbers \(a\) and \(b\), \(|a + b| \leq |a| + |b|\). If we define \(|a|\) to be the maximum of \(a\) and \(-a\), the triangle inequality in fact holds for any ordered ring:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(a\) and \(b\) be elements of any ordered ring. Then \(|a + b| \leq |a| + |b|\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By the definition of absolute value, it suffices to show that \(a + b \leq |a| + |b|\) and \(-(a + b) \leq |a| + |b|\). The first claim follows from the fact that \(a \leq |a|\) and \(b \leq |b|\). For the second claim, we similarly have \(-a \leq |a|\) and \(-b \leq |b|\), so \(-(a + b) = -a + - b \leq |a| + |b|\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
In the theorem above, if we let \(a = x - y\) and \(b = y - z\), we get \(|x - z| \leq |x - y| + |y - z|\). The fact that \(|x - y|\) represents the distance between \(x\) and \(y\) on the number line explains the name: for any three “points” \(x\), \(y\), and \(z\), the distance from \(x\) to \(z\) can’t be any greater than the distance from \(x\) to \(y\) plus the distance from \(y\) to \(z\).

\sphinxAtStartPar
We now let \(A\) be the set of Cauchy sequences of rationals, and define the real numbers, \(\mathbb{R}\), to be \(A / \mathord{\equiv}\). In other words, the real numbers are the set of Cauchy sequence of rationals, modulo the equivalence relation we just defined.

\sphinxAtStartPar
Having the set \(\mathbb{R}\) by itself is not enough: we also would like to know how to add, subtract, multiply, and divide real numbers. As with the integers, we need to define operations on the underlying set, and then show that they respect the equivalence relation. For example, we will say how to add Cauchy sequences of rationals, and then show that if \(p_1 \equiv p_2\) and \(q_1 \equiv q_2\), then \(p_1 + q_1 \equiv p_2 + q_2\). We can then lift this definition to \(\mathbb{R}\) by defining \([p] + [q]\) to be \([p + q]\).

\sphinxAtStartPar
Luckily, it is easy to define addition, subtraction, and multiplication on Cauchy sequences. If \(p = (p_i)_{i \in \mathbb{N}}\) and \(q = (q_i)_{i \in \mathbb{N}}\) are Cauchy sequences, let \(p + q = (p_i + q_i)_{i \in \mathbb{N}}\), and similarly for subtraction and multiplication. It is trickier to show that these sequences are Cauchy themselves, and to show that the operations have the appropriate algebraic properties. We ask you to prove some of these properties in the exercises.

\sphinxAtStartPar
We can identify each rational number \(q\) with the constant Cauchy sequence \(q, q, q, \ldots\), so the real numbers include all the rationals. The next step is to abstract away the details of the particular construction we have chosen, so that henceforth we can work with the real numbers abstractly, and no longer think of them as given by equivalence classes of Cauchy sequences of rationals.


\section{The Completeness of the Real Numbers}
\label{\detokenize{the_real_numbers:the-completeness-of-the-real-numbers}}
\sphinxAtStartPar
We constructed the real numbers to fill in the gaps in the rationals. How do we know that we have got them all? Perhaps we need to construct even more numbers, using Cauchy sequences of reals? The next theorem tells us that, on the contrary, there is no need to extend the reals any further in this way.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Let \(r\) be a real number. A sequence \((r_i)_{i \in \mathbb{N}}\) of real numbers \sphinxstyleemphasis{converges} to \(r\) if, for every \(\varepsilon > 0\), there is an \(N\) such that for every \(i \geq N\), \(|r_i - r| < \varepsilon\).

\sphinxAtStartPar
\sphinxstylestrong{Definition.} A sequence \((r_i)_{i \in \mathbb{N}}\) \sphinxstyleemphasis{converges} if it converges to some \(r\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Every Cauchy sequence of real numbers converges.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The statement of the theorem is often expressed by saying that the real numbers are \sphinxstyleemphasis{complete}. Roughly, it says that everywhere you look for a real number, you are bound to find one. Here is a similar principle.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} An element \(u \in \mathbb{R}\) is said to be an \sphinxstyleemphasis{upper bound} to a subset \(S \subseteq \mathbb{R}\) if everything in \(S\) is less than or equal to \(u\). \(S\) is said to be \sphinxstyleemphasis{bounded} if there is an upper bound to \(S\). An element \(u\) is said to be a \sphinxstyleemphasis{least upper bound} to \(S\) if it is an upper bound to \(S\), and nothing smaller than \(u\) is an upper bound to \(S\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \(S\) be a bounded, nonempty subset of \(\mathbb{R}\). Then \(S\) has a least upper bound.


\bigskip\hrule\bigskip


\sphinxAtStartPar
The rational numbers do not have this property: if we set \(S = \{x \in \mathbb{Q} \mid x^2 < 2\}\), then the rational number 2 is an upper bound for \(S\), but \(S\) has no least upper bound in \(\mathbb{Q}\).

\sphinxAtStartPar
It is a fundamental theorem that the real numbers are characterized exactly by the property that they are a complete ordered field, such that every real number \(r\) is less than or equal to some natural number \(N\). Any two models that meet these requirements must behave in exactly the same way, at least insofar as the constants \(0\) and \(1\), the operations \(+\) and \(*\), and the relation \(\leq\) are concerned. This fact is extremely powerful because it allows us to avoid thinking about the Cauchy sequence construction in normal mathematics. Once we have shown that our construction meets these requirements, we can take \(\mathbb{R}\) to be “the” unique complete totally ordered field and ignore any implementation details. We are also free to implement \(\mathbb{R}\) in any way we choose, and as long as it meets this interface, and as long as they do not refer to the underlying representations, any theorems we prove about the reals will hold equally well for all constructions.


\section{An Alternative Construction}
\label{\detokenize{the_real_numbers:an-alternative-construction}}
\sphinxAtStartPar
Many sources use an alternative construction of the reals, taking them instead to be \sphinxstyleemphasis{Dedekind cuts}. A Dedekind cut is an ordered pair \((A, B)\) of sets of rational numbers with the following properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Every rational number \(q\) is in either \(A\) or \(B\).

\item {} 
\sphinxAtStartPar
Each \(a \in A\) is less than every \(b \in B\).

\item {} 
\sphinxAtStartPar
There is no greatest element of \(A\).

\item {} 
\sphinxAtStartPar
\(A\) and \(B\) are both nonempty.

\end{itemize}

\sphinxAtStartPar
The first two properties show why we call this pair a “cut.” The set \(A\) contains all of the rational numbers to the left of some mark on the number line, and \(B\) all of the points to the right. The third property tells us something about what happens exactly at that mark. But there are two possibilities: either \(B\) has a least element, or it doesn’t. Picturing the situation where \(A\) has no greatest element and \(B\) has no least element may be tricky, but consider the example \(A = \{x \in \mathbb{Q} \mid x^2 < 2\}\) and \(B = \{x \in \mathbb{Q} \mid x^2 > 2\}\). There is no rational number \(q\) such that \(q^2 = 2\), but there are rational numbers on either side that are arbitrarily close; thus neither \(A\) nor \(B\) contains an endpoint.

\sphinxAtStartPar
We can define \(\mathbb{R}\) to be the set of Dedekind cuts. A Dedekind cut \((A, B)\) corresponds to a rational number \(q\) if \(q\) is the least element of \(B\), and to an irrational number if \(B\) has no least element. It is straightforward to define addition on \(\mathbb{R}\):
\begin{equation*}
\begin{split}(A_1, B_1) + (A_2, B_2) = ( \{a_1 + a_2 \mid a_1 \in A_1, a_2 \in A_2 \}, \{b_1 + b_2 \mid b_1 \in B_1, b_2 \in B_2 \} ).\end{split}
\end{equation*}
\sphinxAtStartPar
Some authors prefer this construction to the Cauchy sequence construction because it avoids taking the quotient of a set, and thus removes the complication of showing that arithmetic operations respect equivalence. Others prefer Cauchy sequences since they provide a clearer notion of approximation: if a real number \(r\) is given by a Cauchy sequence \((q_i)_{i \in \mathbb{N}}\), then an arbitrarily close rational approximation of \(r\) is given by \(q_N\) for a sufficiently large \(N\).

\sphinxAtStartPar
For most mathematicians most of the time, though, the difference is immaterial. Both constructions create complete linear ordered fields, and in a certain sense, they create the \sphinxstyleemphasis{same} complete linear ordered field. Strictly speaking, the set of Cauchy reals is not equal to the set of Dedekind reals, since one consists of equivalence classes of rational Cauchy sequences and one consists of pairs of sets of rationals. But there is a bijection between the two sets that preserves the field properties. That is, there is a bijection \(f\) from the Cauchy reals to the Dedekind reals such that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(0)=0\)

\item {} 
\sphinxAtStartPar
\(f(1)=1\)

\item {} 
\sphinxAtStartPar
\(f(x+y)=f(x)+f(y)\)

\item {} 
\sphinxAtStartPar
\(f(x \cdot y)=f(x) \cdot f(y)\)

\item {} 
\sphinxAtStartPar
\(f(-x)=-f(x)\)

\item {} 
\sphinxAtStartPar
\(f(x^{-1})=f(x)^{-1}\)

\item {} 
\sphinxAtStartPar
\(f(x) \leq f(y) \iff x \leq y\)

\end{itemize}

\sphinxAtStartPar
We say that the two constructions are \sphinxstyleemphasis{isomorphic}, and that the function \(f\) is an \sphinxstyleemphasis{isomorphism}. Since we often only care about the real numbers in regard to their status as a complete ordered field, and the two constructions are indistinguishable as ordered fields, it makes no difference which construction is used.


\section{Exercises}
\label{\detokenize{the_real_numbers:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Show that addition for the integers, as defined in \hyperref[\detokenize{the_real_numbers:quotient-constructions}]{Section \ref{\detokenize{the_real_numbers:quotient-constructions}}}, is commutative and associative.

\item {} 
\sphinxAtStartPar
Show from the construction of the integers in \hyperref[\detokenize{the_real_numbers:quotient-constructions}]{Section \ref{\detokenize{the_real_numbers:quotient-constructions}}} that \(a + 0 = a\) for every integer \(a\).

\item {} 
\sphinxAtStartPar
Define subtraction for the integers by \(a - b = a + (-b)\), and show that \(a - b + b = a\) for every pair of integers \(a\) and \(b\).

\item {} 
\sphinxAtStartPar
Define multiplication for the integers, by first defining it on the underlying representation and then showing that the operation respects the equivalence relation.

\item {} 
\sphinxAtStartPar
Show that every Cauchy sequence is bounded: that is, if \((q_i)_{i \in \mathbb{N}}\) is Cauchy, there is some rational \(M\) such that \(|q_i| \leq M\) for all \(i\). Hint: try letting \(\varepsilon = 1\).

\item {} 
\sphinxAtStartPar
Let \(p = (p_i)_{i \in \mathbb{N}}\) and \(q = (q_i)_{i \in \mathbb{N}}\) be Cauchy sequences. Define \(p + q = (p_i + q_i)_{i \in \mathbb{N}}\) and \(p q = (p_i  q_i)_{i \in \mathbb{N}}\).
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
Show that \(p + q\) is Cauchy. That is, for arbitrary \(\varepsilon > 0\), show that there exists an \(N\) such that for all \(i, j \geq N\), \(|(p_i + q_i) - (p_j + q_j)| < \varepsilon\).

\item {} 
\sphinxAtStartPar
Show that \(p q\) is Cauchy. In addition to the triangle inequality, you will find the previous exercise useful.

\end{enumerate}

\item {} 
\sphinxAtStartPar
These two parts show that addition of Cauchy sequences respects equivalence.
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
Show that if \(p, p', q\) are Cauchy sequences and \(p \equiv p'\), then \(p + q \equiv p' + q\).

\item {} 
\sphinxAtStartPar
Using the first part of this problem, show that if \(p, p', q, q'\) are Cauchy sequences, \(p \equiv p'\), and \(q \equiv q'\), then \(p + q \equiv p' + q'\). You can use the fact that addition on the real numbers is commutative.

\end{enumerate}

\item {} 
\sphinxAtStartPar
Show that if \((A_1, B_1)\) and \((A_2, B_2)\) are Dedekind cuts, then \((A_1, B_1) + (A_2, B_2)\) is also a Dedekind cut.

\end{enumerate}


\chapter{The Infinite}
\label{\detokenize{the_infinite:the-infinite}}\label{\detokenize{the_infinite::doc}}

\section{Equinumerosity}
\label{\detokenize{the_infinite:equinumerosity}}
\sphinxAtStartPar
Remember that in \hyperref[\detokenize{combinatorics:combinatorics}]{Chapter \ref{\detokenize{combinatorics:combinatorics}}} we defined, for each natural number \(n\), the set \([n] = \{0, 1, \ldots, n-1\}\).  We then said that a set \(A\) is \sphinxstyleemphasis{finite} if there is a bijection between \(A\) and \([n]\) for some \(n\). A set is said to be \sphinxstyleemphasis{infinite} if it is not finite.

\sphinxAtStartPar
If \(A\) and \(B\) are two finite sets, then they have the same cardinality if and only if there is a bijection between them. It turns out that the same notion of “having the same cardinality” makes sense even if \(A\) and \(B\) are not finite.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} Two sets \(A\) and \(B\) are said to be \sphinxstyleemphasis{equinumerous}, written \(A \approx B\), if there is a bijection between them. Equivalently, we say that \(A\) and \(B\) \sphinxstyleemphasis{have the same cardinality}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
At this stage, saying that \(A\) and \(B\) have the same cardinality may sound strange, because it is not clear that there is any object, “the cardinality of \(A\),” that they both “have.” It turns out that, in set\sphinxhyphen{}theoretic foundations, there are certain objects—generalizations of the natural numbers—that one can use to measure the size of an infinite set. There are known as the “cardinal numbers” or “cardinals.” But they are irrelevant to our purposes here. For the rest of this chapter, when we say that \(A\) and \(B\) have the same cardinality, we mean neither more nor less than the fact that there is a bijection between them.

\sphinxAtStartPar
The following theorem says, essentially, that equinumerosity is an equivalence relation. (The caveat is that so far we have spoke only of relations between sets, and the collection of all sets is not itself a set.)


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Proposition}. Let \(A\), \(B\), and \(C\) be any sets.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A \approx A\).

\item {} 
\sphinxAtStartPar
If \(A \approx B\), then \(B \approx A\).

\item {} 
\sphinxAtStartPar
If \(A \approx B\) and \(B \approx C\) then \(A \approx C\).

\end{itemize}


\bigskip\hrule\bigskip


\sphinxAtStartPar
The proof is left as an exercise.


\section{Countably Infinite Sets}
\label{\detokenize{the_infinite:countably-infinite-sets}}
\sphinxAtStartPar
The set of natural numbers, \(\mathbb{N}\), is a prototypical example of an infinite set. To see that it is infinite, suppose, on the other hand, that it is finite. This means that there is a bijection \(f\) between \(\mathbb{N}\) and \([n]\) for some natural number \(n\). We can restrict to the subset \([n+1]\) of \(\mathbb{N}\), and thereby obtain an injective map from \([n+1]\) to \([n]\). But this violates the pigeonhole principle, proved in \hyperref[\detokenize{combinatorics:combinatorics}]{Chapter \ref{\detokenize{combinatorics:combinatorics}}}.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A set is said to be \sphinxstyleemphasis{countably infinite} if it is equinumerous with \(\mathbb{N}\). A set is said to be \sphinxstyleemphasis{countable} if it is finite or countably infinite.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Since the identity map \(id(x) = x\) is a bijection on any set, every set is equinumerous with itself, and thus \(\mathbb{N}\) itself is countably infinite.

\sphinxAtStartPar
The term “countably infinite” is meant to be evocative. Suppose \(A\) is a countable set. By definition, there is a bijection \(f : \mathbb{N} \to A\). So \(A\) has a “first” element \(f(0)\), a “second” element \(f(1)\), a “third” element \(f(2)\), and so on. Since \(f\) is a bijection, for every element \(a\) of \(A\), \(a\) is the \(n\)th element enumerated in this way, for a unique value of \(n\). That is, each element of \(A\) is “counted” at some finite stage.

\sphinxAtStartPar
With this definition in hand, it is natural to wonder which of our favorite sets are countable. Is the set of integers \(\mathbb{Z}\) countable? How about the set of rationals \(\mathbb{Q}\), or the set of reals \(\mathbb{R}\)? At this point, you should reflect on the logical form of the statement “\(A\) is countable,” and think about what is required to show that a set \(A\) does or does not have this property.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} The set of integers, \(\mathbb{Z}\), is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} We need to show that there exists a bijection between \(\mathbb{N}\) and \(\mathbb{Z}\). Define \(f : \mathbb{N} \to \mathbb{Z}\) as follows:
\begin{equation*}
\begin{split}f(n) = \begin{cases}
         n / 2 & \mbox{if $n$ is even} \\
         -(n + 1) / 2 & \mbox{if $n$ is odd.}
       \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
We claim that \(f\) is a bijection. To see that it is injective, suppose \(f(m) = f(n)\). If \(f(m)\) (and hence also \(f(n)\)) is nonnegative, then \(m\) and \(n\) are even, in which case \(m / 2 = n / 2\) implies \(m = n\). Otherwise, \(m\) and \(n\) are odd, and again \(-(m+1) / 2 = -(n+1)/ 2\) implies \(m = n\).

\sphinxAtStartPar
To see that \(f\) is surjective, suppose \(a\) is any integer. If \(a\) is nonnegative, then \(a = f(2 a)\). If \(a\) is strictly negative, then \(2 a - 1\) is also strictly negative, and hence \(-(2 a - 1)\) is an odd natural number. In that case, it is not hard to check that \(a = f(-(2a - 1))\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
We will now build up an arsenal of theorems that we can use to show that various sets are countable.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} A set \(A\) is countable if and only if \(A\) is empty or there is a surjective function \(f : \mathbb{N} \to A\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} For the forward direction, suppose \(A\) is countable. Then it is either finite or countably infinite. If \(A\) is countably infinite, there is a bijection from \(\mathbb{N}\) to \(A\), and we are done. Suppose, then, that \(A\) is finite. If \(A\) is empty, we are done. Otherwise, for some \(n\), there is a bijection \(f : [n] \to A\), with \(n \geq 1\). Define a function \(g : \mathbb{N} \to A\) as follows:
\begin{equation*}
\begin{split}g(i) = \begin{cases}
         f(i) & \mbox{if $i < n$} \\
         f(0) & \mbox{otherwise.}
       \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, \(g\) enumerates the elements of \(A\) by using \(f\) first, and then repeating the element \(f(0)\). Clearly \(f\) is surjective, as required.

\sphinxAtStartPar
In the other direction, if \(A\) is finite, then it is countable, and we are done. So suppose \(A\) is not finite. Then it is not empty, and so there is a surjective function \(f : \mathbb{N} \to A\). We need to turn \(f\) into a \sphinxstyleemphasis{bijective} function. The problem is that \(f\) may not be injective, which is to say, elements in \(A\) may be enumerated more than once. The solution is to define a function, \(g\), which eliminates all the duplicates. The idea is that \(g\) should enumerate the elements \(f(0), f(1), f(2), \ldots\), but skip over the ones that have already been enumerated.

\sphinxAtStartPar
To be precise, the function \(g\) is defined recursively as follows: \(g(0) = f(0)\), and for every \(i\), \(g(i+1) = f(j)\), where \(j\) is the least natural number such that \(f(j)\) is not among \(\{g(0), g(1), g(2), \ldots, g(i) \}\). The assumption that \(A\) is infinite and \(f\) is surjective guarantees that some such \(j\) always exists.

\sphinxAtStartPar
We only need to check that \(g\) is a bijection. By definition, for every \(i\), \(g(i+1)\) is different from \(g(0), \ldots, g(i)\). This implies that \(g\) is injective. But we can also show by induction that for every \(i\), \(\{g(0), \ldots, g(i)\} \supseteq \{ f(0), \ldots, f(i)\}\). Since \(f\) is surjective, \(g\) is too.


\bigskip\hrule\bigskip


\sphinxAtStartPar
In a manner similar to the way we proved that the integers are countable, we can prove the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If \(A\) and \(B\) are countably infinite, then so is \(A \cup B\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(f : \mathbb{N} \to A\) and \(g : \mathbb{N} \to B\) are surjective. Then we can define a function \(h : \mathbb{N} \to A \cup B\):
\begin{equation*}
\begin{split}h(n) = \begin{cases}
         f(n/2) & \mbox{if $n$ is even} \\
         g((n-1)/2) & \mbox{if $n$ is odd.}
       \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
It is not hard to show that \(h\) is surjective.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Intuitively, if \(A = \{ f(0), f(1), f(2), \ldots \}\) and \(B = \{ g(0), g(1), g(2), \ldots\}\), then we can enumerate \(A \cup B\) as \(\{ f(0), g(0), f(1), g(1), f(2), g(2), \ldots \}\).

\sphinxAtStartPar
The next two theorems are also helpful. The first says that to show that a set \(B\) is countable, it is enough to “cover” it with a surjective function from a countable set. The second says that to show that a set \(A\) is countable, then it is enough to embed it in a countable set.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If \(A\) is countable and \(f : A \to B\) is surjective, then \(B\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} If \(A\) is countable, then there is a surjective function \(g : \mathbb{N} \to A\), and \(f \circ g\) is a surjective function from \(\mathbb{N} \to B\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If \(B\) is countable and \(f : A \to B\) is injective, then \(A\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Assuming \(f : A \to B\) is injective, it has a left inverse, \(g : B \to A\). Since \(g\) has a right inverse, \(f\), we know that \(g\) is surjective, and we can apply the previous theorem.

\sphinxAtStartPar
\sphinxstylestrong{Corollary.} If \(B\) is countable and \(A \subseteq B\), then \(A\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} The function \(f : A \to B\) defined by \(f(x) = x\) is injective.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Remember that \(\mathbb{N} \times \mathbb{N}\) is the set of ordered pairs \((i, j)\) where \(i\) and \(j\) are natural numbers.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} \(\mathbb{N} \times \mathbb{N}\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Enumerate the elements as follows:
\begin{equation*}
\begin{split}(0, 0), (1, 0), (0, 1), (2, 0), (1, 1), (1, 2), (3, 0), (2, 1), (1, 2), (0, 3), \ldots\end{split}
\end{equation*}

\bigskip\hrule\bigskip


\sphinxAtStartPar
If you think of the pairs as coordinates in the \(x\)\sphinxhyphen{}\(y\) plane, the pairs are enumerated along diagonals: first the diagonal with pairs whose elements sum to \(0\), then the diagonal with pairs whose elements sum to \(1\), and so on. This is often called a “dovetailing” argument, because if you imagine drawing a line that weaves back and forth through the pairs enumerated this ways, it will be analogous to the a carpenter’s practice of using a dovetail to join two pieces of wood. (And that term, in turn, comes from the similarity to a dove’s tail.)

\sphinxAtStartPar
As far as proofs go, the informal description above and the associated diagram are perfectly compelling. It is possible to describe a bijection between \(\mathbb{N} \times \mathbb{N}\) explicitly, however, in algebraic terms. You are asked to do this in the exercises.

\sphinxAtStartPar
The previous theorem has a number of interesting consequences.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} If \(A\) and \(B\) are countable, then so is \(A \times B\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} If \(p\) is any element of \(\mathbb{N} \times \mathbb{N}\), write \(p_0\) and \(p_1\) to denote the two components. Let \(f : \mathbb{N} \to \mathbb{N} \times \mathbb{N}\) be a surjection, as guaranteed by the previous theorem. Suppose \(g : \mathbb{N} \to A\) and \(h : \mathbb{N} \to B\) be surjective. Then the function \(k(i) = ( g(f(i)_0), h(f(i)_1) )\) is a surjective function from \(\mathbb{N}\) to \(A \times B\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} The set of rational numbers, \(\mathbb{Q}\), is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By the previous theorem, we know that \(\mathbb{Z} \times \mathbb{Z}\) is countable. Define \(f : \mathbb{Z} \times \mathbb{Z} \to \mathbb{Q}\) by
\begin{equation*}
\begin{split}f(i,j) = \begin{cases}
           i / j & \mbox{if $j \neq 0$} \\
           0 & \mbox{otherwise.}
         \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
Since every element of \(\mathbb{Q}\) can be written as \(i / j\) for some \(i\) and \(j\) in \(\mathbb{Z}\), \(f\) is surjective.

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Suppose that \(A\) is countable. For each \(n\), the set \(A^n\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Remember that we can identify the set of \(n\)\sphinxhyphen{}tuples of elements from \(A\) with \(A \times \ldots \times A\), where there are \(n\) copies of \(A\) in the product. The result follows using induction on \(n\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Let \((A_i)_{i \in \mathbb{N}}\) be a family of sets indexed by the natural numbers, and suppose that each \(A_i\) is countable. Then \(\bigcup_i A_i\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose for each \(i\), \(f_i\) is a surjective function from \(\mathbb{N}\) to \(A_i\). Then the function \(g(i, j) = f_i(j)\) is a surjective function from \(\mathbb{N} \times \mathbb{N}\) to \(\bigcup_i A_i\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} Suppose that \(A\) is countable. Then the set of finite sequences of elements of \(A\) is countable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} The set of finite sequences of elements of \(A\) is equal to \(\bigcup_i A^i\), and we can apply the previous two theorems.


\bigskip\hrule\bigskip


\sphinxAtStartPar
Notice that the set of all alphanumeric characters and punctuation (say, represented as the set of all ASCII characters) is finite. Together with the last theorem, this implies that there are only countably many sentences in the English language (and, indeed, any language in which sentences are represented by finite sequences of symbols, chosen from any countable stock).

\sphinxAtStartPar
At this stage, it might seem as though everything is countable. In the next section, we will see that this is not the case: the set of real numbers, \(\mathbb{R}\), is not countable, and if \(A\) is any set (finite or infinite), the powerset of \(A\), \({\mathcal P}(A)\), is not equinumerous with \(A\).


\section{Cantor’s Theorem}
\label{\detokenize{the_infinite:cantor-s-theorem}}
\sphinxAtStartPar
A set \(A\) is \sphinxstyleemphasis{uncountable} if it is not countable. Our goal is to prove the following theorem, due to Georg Cantor.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} The set of real numbers is uncountable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Remember that \([0,1]\) denotes the closed interval \(\{ r \in \mathbb{R} \mid 0 \leq r \leq 1\}\). It suffices to show that there is no surjective function \(f : \mathbb{N} \to [0,1]\), since if \(\mathbb{R}\) were countable, \([0,1]\) would be countable too.

\sphinxAtStartPar
Recall that every real number \(r \in [0,1]\) has a decimal expansion of the form \(r = 0.r_0 r_1 r_2 r_3 r_4 \ldots\), where each \(r_i\) is a digit in \(\{0, 1, \ldots, 9\}\). More formally, we can write \(r = \sum_{i = 0}^\infty \frac{r_i}{10^{i}}\) for each \(r \in \mathbb{R}\) with \(0 \leq r \leq 1\).

\sphinxAtStartPar
(Notice that \(1\) can be written \(0.9999\ldots\). In general every other rational number in \([0,1]\) will have two representations of this form; for example, \(0.5 = 0.5000\ldots = 0.49999\ldots\). For concreteness, for these numbers we can choose the representation that ends with zeros.)

\sphinxAtStartPar
As a result, we can write
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(0) = 0.r^0_0 r^0_1 r^0_2 r^0_3 r^0_4 \ldots\)

\item {} 
\sphinxAtStartPar
\(f(1) = 0.r^1_0 r^1_1 r^1_2 r^1_3 r^1_4 \ldots\)

\item {} 
\sphinxAtStartPar
\(f(2) = 0.r^2_0 r^2_1 r^2_2 r^2_3 r^2_4 \ldots\)

\item {} 
\sphinxAtStartPar
\(f(3) = 0.r^3_0 r^3_1 r^3_2 r^3_3 r^3_4 \ldots\)

\item {} 
\sphinxAtStartPar
\(f(4) = 0.r^4_0 r^4_1 r^4_2 r^4_3 r^4_4 \ldots\)

\item {} 
\sphinxAtStartPar
…

\end{itemize}

\sphinxAtStartPar
(We use superscripts, \(r^i\), to denote the digits of \(f(i)\). The superscripts do not mean the “\(i\)th power.”)

\sphinxAtStartPar
Our goal is to show that \(f\) is not surjective. To that end, define a new sequence of digits \((r_i)_{i \in \mathbb{N}}\) by
\begin{equation*}
\begin{split}r_i = \begin{cases}
        7 & \mbox{if $r^i_i \neq 7$} \\
        3 & \mbox{otherwise.}
      \end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
The define the real number \(r = 0.r_0 r_1 r_2 r_3 \ldots\). Then, for each \(i\), \(r\) differs from \(f(i)\) in the \(i\)th digit. But this means that for every \(i\), \(f(i) \neq r\). Since \(r\) is not in the range of \(f\), we see that \(f\) is not surjective. Since \(f\) was arbitrary, there is no surjective function from \(\mathbb{N}\) to \([0,1]\).

\sphinxAtStartPar
(We chose the digits \(3\) and \(7\) only to avoid \(0\) and \(9\), to avoid the case where, for example, \(f(0) = 0.5000\ldots\) and \(r = 0.4999\ldots\). Since there are no zeros or nines in \(r\), since the \(i\)th digit of \(r\) differs from \(f(i)\), it really is a different real number.)


\bigskip\hrule\bigskip


\sphinxAtStartPar
This remarkable proof is known as a “diagonalization argument.” We are trying to construct a real number with a certain property, namely, that it is not in the range of \(f\). We make a table of digits, in which the rows represent infinitely many constraints we have to satisfy (namely, that for each \(i\), \(f(i) \neq r\)), and the columns represent opportunities to satisfy that constraint (namely, by choosing the \(i\)th digit of \(r\) appropriately). Then we complete the construction by stepping along the diagonal, using the \(i\)th opportunity to satisfy the \(i\)th constraint. This technique is used often in logic and computability theory.

\sphinxAtStartPar
The following provides another example of an uncountable set.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} The power set of the natural numbers, \({\mathcal P}(\mathbb{N})\), is uncountable.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Let \(f : \mathbb{N} \to {\mathcal P}(\mathbb{N})\) be any function. Once again, our goal is to show that \(f\) is not surjective. Let \(S\) be the set of natural numbers, defined as follows:
\begin{equation*}
\begin{split}S = \{ n \in \mathbb{N} \mid n \notin f(n) \}.\end{split}
\end{equation*}
\sphinxAtStartPar
In words, for every natural number, \(n\), \(n\) is in \(S\) if and only if it is not in \(f(n)\). Then clearly for every \(n\), \(f(n) \neq S\). So \(f\) is not surjective.


\bigskip\hrule\bigskip


\sphinxAtStartPar
We can also view this as a diagonalization argument: draw a table with rows and columns indexed by the natural numbers, where the entry in the \(i\)th row and \(j\)th column is “yes” if \(j\) is an element of \(f(i)\), and “no” otherwise. The set \(S\) is constructed by switching “yes” and “no” entries along the diagonal.

\sphinxAtStartPar
In fact, exactly the same argument yields the following:


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For every set \(A\), there is no surjective function from \(A\) to \({\mathcal P}(A)\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} As above, if \(f\) is any function from \(A\) to \({\mathcal P}(A)\), the set \(S = \{ a \in A \mid a \notin f(a) \}\) is not in the range of \(f\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
This shows that there is an endless hierarchy of infinities. For example, in the sequence \(\mathbb{N}, {\mathcal P}(\mathbb{N}), {\mathcal P}({\mathcal P}(\mathbb{N})), \ldots\), there is an injective function mapping each set into the next, but no surjective function. The union of all those sets is even larger still, and then we can take the power set of \sphinxstyleemphasis{that}, and so on. Set theorists are still today investigating the structure within this hierarchy.


\section{An Alternative Definition of Finiteness}
\label{\detokenize{the_infinite:an-alternative-definition-of-finiteness}}
\sphinxAtStartPar
One thing that distinguishes the infinite from the finite is that an infinite set can have the same size as a proper subset of itself. For example, the natural numbers, the set of even numbers, and the set of perfect squares are all equinumerous, even though the latter two are strictly contained among the natural numbers.

\sphinxAtStartPar
In the nineteenth century, the mathematician Richard Dedekind used this curious property to \sphinxstyleemphasis{define} what it means to be finite. We can show that his definition is equivalent to ours, but the proof requires the axiom of choice.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} A set is \(A\) \sphinxstyleemphasis{Dedekind infinite} if \(A\) is equinumerous with a proper subset of itself, and \sphinxstyleemphasis{Dedekind finite} otherwise.

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} A set is Dedekind infinite if and only it is infinite.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(A\) is Dedekind infinite. We need to show it is not finite; suppose, to the contrary, it is bijective with \([n]\) for some \(n\). Composing bijections, we have that \([n]\) is bijective with a proper subset of itself. This means that there is an injective function \(f\) from \([n]\) to a proper subset of \(n\). Modifying \(f\), we can get an injective function from \([n]\) into \([n-1]\), contradicting the pigeonhole principle.

\sphinxAtStartPar
Suppose, on the other hand, that \(A\) is infinite. We need to show that there is an injective function \(f\) from \(A\) to a proper subset of itself (because then \(f\) is a bijection between \(A\) and the range of \(f\)). Choose a sequence of distinct element \(a_0, a_1, a_2, \ldots\) of \(A\). Let \(f\) map each \(a_i\) to \(a_{i+1}\), but leave every other element of \(A\) fixed. Then \(f\) is injective, but \(a_0\) is not in the range of \(f\), as required.


\bigskip\hrule\bigskip



\section{The Cantor\sphinxhyphen{}Bernstein Theorem}
\label{\detokenize{the_infinite:the-cantor-bernstein-theorem}}\label{\detokenize{the_infinite:id1}}
\sphinxAtStartPar
Saying that \(A\) and \(B\) are equinumerous means, intuitively, that \(A\) and \(B\) have the same size. There is also a natural way of saying that \(A\) is not larger than \(B\):


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Definition.} For two sets \(A\) and \(B\), we say the cardinality of \(A\) is less than or equal to the cardinality of \(B\), written \(A \preceq B\), when there is an injection \(f : A \to B\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
As an exercise, we ask you to show that \(\preceq\) is a \sphinxstyleemphasis{preorder}, which is to say, it is reflexive and transitive. Here is a natural question: does \(A \preceq B\) and \(B \preceq A\) imply \(A \approx B\)? In other words, assuming there are injective functions \(f : A \to B\) and \(g : B \to A\), is there necessarily a bijection from \(A\) to \(B\)?

\sphinxAtStartPar
The answer is “yes,” but the proof is tricky. The result is known as the \sphinxstyleemphasis{Cantor\sphinxhyphen{}Bernstein Theorem}, and we state it without proof.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Theorem.} For any sets \(A\) and \(B\), if \(A \preceq B\) and \(B \preceq A\), then \(A \approx B\).


\bigskip\hrule\bigskip



\section{Exercises}
\label{\detokenize{the_infinite:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Show that equinumerosity is reflexive, symmetric, and transitive.

\item {} 
\sphinxAtStartPar
Show that the function \(f(x) = x / (1 - x)\) is a bijection between the interval \([0,1)\) and \(\mathbb{R}^{\geq 0}\).

\item {} 
\sphinxAtStartPar
Show that the \(g(x) = x / (1 - |x|)\) gives a bijection between \((-1, 1)\) and \(\mathbb{R}\).

\item {} 
\sphinxAtStartPar
Define a function \(J : \mathbb{N} \times \mathbb{N} \to \mathbb{N}\) by \(J(i,j) = \frac{(i + j)(i + j + 1)}{2} + i\). This goal of this problem is to show that \(J\) is a bijection from \(\mathbb{N} \times \mathbb{N}\) to \(\mathbb{N}\).
\begin{enumerate}
\sphinxsetlistlabels{\alph}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
Draw a picture indicating which pairs are sent to \(0, 1, 2, \ldots\).

\item {} 
\sphinxAtStartPar
Let \(n = i + j\). Show that \(J(i,j)\) is equal the number of pairs \((u, v)\) such that either \(u + v < n\), or \(u + v = n\) and \(u < i\). (Use the fact that \(1 + 2 + \ldots + n = n(n+1)/2\).)

\item {} 
\sphinxAtStartPar
Conclude that \(J\) is surjective: to find \(i\) and \(j\) such that \(J(i,j) = k\), it suffices to find the largest \(n\) such that \(n(n+1)/2 \leq k\), let \(i = k - n(n+1)/2\), and let \(j = n - i\).

\item {} 
\sphinxAtStartPar
Conclude that \(J\) is injective: if \(J(i,j) = J(i',j')\), let \(n = i + j\) and \(n' = i' + j'\). Argue that \(n = n'\), and so \(i = i'\) and \(j = j'\).

\end{enumerate}

\item {} 
\sphinxAtStartPar
Let \(S\) be the set of functions from \(\mathbb{N}\) to \(\{ 0, 1\}\). Use a diagonal argument to show that \(S\) is uncountable. (Notice that you can think of a function \(f: \mathbb{N} \to \{0, 1\}\) as an infinite sequence of 0’s and 1’s, given by \(f(0), f(1), f(2), \ldots\). So, given a function \(F(n)\) which, for each natural number \(n\), returns an infinite sequence of 0’s and 1’s, you need to find a sequence that is not in the image of \(F\).)

\item {} 
\sphinxAtStartPar
If \(f\) and \(g\) are functions from \(\mathbb{N}\) to \(\mathbb{N}\), say that \(g\) \sphinxstyleemphasis{eventually dominates} \(f\) if there is some \(n\) such that for every \(m \geq n\), \(g(m) > f(m)\). In other words, from some point on, \(g\) is bigger than \(f\).

\sphinxAtStartPar
Show that if \(f_0, f_1, f_2, \ldots\) is any sequence of functions from \(\mathbb{N}\) to \(\mathbb{N}\), indexed by the natural numbers, then there is a function \(g\) that eventually dominates each \(f_i\). (Hint: construct \(g\) so that for each \(i\), \(g(n) > f_i(n)\) for every \(n \geq i\).)

\item {} 
\sphinxAtStartPar
Show that the relation \(\preceq\) defined in \hyperref[\detokenize{the_infinite:the-cantor-bernstein-theorem}]{Section \ref{\detokenize{the_infinite:the-cantor-bernstein-theorem}}} is reflexive and transitive.

\end{enumerate}


\chapter{Axiomatic Foundations}
\label{\detokenize{axiomatic_foundations:axiomatic-foundations}}\label{\detokenize{axiomatic_foundations:id1}}\label{\detokenize{axiomatic_foundations::doc}}
\sphinxAtStartPar
In this final chapter, our story comes full circle. We started our journey with symbolic logic, using the propositional connectives to model logical terms like “and,” “or,” “not,” and “implies.” To that we added the quantifiers and function and relation symbols of first\sphinxhyphen{}order logic. From there, we moved to sets, functions, and relations, which are ubiquitous in modern mathematics; the natural numbers and induction; and then topics such as number theory, combinatorics, the real numbers, and the infinite. Here we return to symbolic logic, and see how it can be used to provide a formal foundation for all of mathematics.

\sphinxAtStartPar
Specifically, we will consider an axiomatic framework known as \sphinxstyleemphasis{Zermelo\sphinxhyphen{}Fraenkel set theory}, which was introduced early in the twentieth century. In the set\sphinxhyphen{}theoretic view of mathematics, every mathematical object is a set. The axioms assert the existence of sets with various properties. From the collection of all sets, we carve out the usual inhabitants of the mathematical universe, not just the various number systems we have considered, but also pairs, finite sequences, relations, functions, and so on. This provides us with an idealized foundation for everything we have done since \hyperref[\detokenize{sets:sets}]{Chapter \ref{\detokenize{sets:sets}}}.

\sphinxAtStartPar
At the end of this chapter, we will briefly describe another axiomatic framework, \sphinxstyleemphasis{dependent type theory}, which is the one used by Lean. We will see that it provides an alternative perspective on mathematical objects and constructions, but one which is nonetheless inter\sphinxhyphen{}interpretable with the set\sphinxhyphen{}theoretic point of view.


\section{Basic Axioms for Sets}
\label{\detokenize{axiomatic_foundations:basic-axioms-for-sets}}\label{\detokenize{axiomatic_foundations:id2}}
\sphinxAtStartPar
The axioms of set theory are expressed in first\sphinxhyphen{}order logic, for a language with a single binary relation symbol, \(\mathord{\in}\). We think of the entire mathematical universe as consisting of nothing but sets; if \(x\) and \(y\) are sets, we can express that \(x\) is an element of \(y\) by writing \(x \in y\). The first axiom says that two sets are equal if and only if they have the same elements.
\begin{equation*}
\begin{split}\text{Extensionality:} \;\; \forall x, y \; (x = y \leftrightarrow \forall z (z \in x \leftrightarrow z \in y))\end{split}
\end{equation*}
\sphinxAtStartPar
The next axiom tells us that there is at least one interesting set in the universe, namely, the set with no element.
\begin{equation*}
\begin{split}\text{Empty set:} \;\; \exists x \; \forall y \; y \notin x\end{split}
\end{equation*}
\sphinxAtStartPar
Here, of course, \(x \notin y\) abbreviates \(\neg (x \in y)\). By the axiom of extensionality, the set asserted to exist by this axiom is unique: in other words, if \(x_1\) and \(x_2\) each have no elements, then, vacuously, any element is in one if and only if it is in the other, so \(x_1 = x_2\). This justifies using the word \sphinxstyleemphasis{the} in the phrase \sphinxstyleemphasis{the empty set}. Given this fact, it should seem harmless to introduce a new symbol, \(\emptyset\), to denote the set matching that description. Indeed, one can show that this is case: in a precise sense, such expansions to a first\sphinxhyphen{}order language can be viewed as nothing more than a convenient manner of expression, and statements in the bigger language can be translated to the original language in a way that justifies all the expected inferences. We will not go into the details here, and, rather, take this fact for granted. Using the new symbol, the empty set axiom tells us the empty set satisfies the property \(\forall y \; y \notin \emptyset\).

\sphinxAtStartPar
The third axiom tells us that given two sets \(x\) and \(y\), we can form a new set \(z\) whose elements are exactly \(x\) and \(y\).
\begin{equation*}
\begin{split}\text{Pairing:} \;\; \forall x, y \; \exists z \; \forall w \; (w \in z \leftrightarrow w = x \vee w = y)\end{split}
\end{equation*}
\sphinxAtStartPar
There is a stealth usage of this axiom lurking nearby. The axiom does not require that \(x\) and \(y\) are different, so, for example, we can take them both to be the empty set. This tells us that the set \(\{ \emptyset \}\), whose only element is the empty set, exists. More generally, the axiom tells us that for any \(x\), we have the set \(\{ x \}\) whose only element is \(x\), and for any \(x\) and \(y\), we have \(\{x, y\}\), as described above. Once again, the axiom of extensionality tells us that the sets meeting these descriptions are unique, so it is fair to use the corresponding notation. We are now off and running! We now have all of the following sets, and more:
\begin{equation*}
\begin{split}\emptyset, \;\; \{ \emptyset \}, \; \; \{ \{ \emptyset \} \}, \;\; \{ \emptyset, \{ \emptyset \} \}, \;\; \{ \{ \{ \emptyset \} \} \}, \;\; \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
Still, we can never form a set with more than two elements in this way. To that end, it would be reasonable to add an axiom that asserts for every \(x\) and \(y\), the set \(x \cup y\) exists. But we can do better. Remember that if \(x\) is any set, \(\bigcup x\) denotes the union of all the sets in \(x\). In other words, for any set \(z\), \(z\) is an element of \(\bigcup x\) if and only if \(z\) is in \(w\) for some set \(w\) in \(x\). The following axiom asserts that this set exists.
\begin{equation*}
\begin{split}\text{Union:} \;\; \forall x \; \exists y \; \forall z \; (z \in y \leftrightarrow \exists w \; (w \in x \wedge z \in w))\end{split}
\end{equation*}
\sphinxAtStartPar
Once again, this justifies the use of the \(\bigcup\) notation. We get the ordinary binary union using this axiom together with pairing, since we have \(x \cup y = \bigcup \{ x, y \}\).

\sphinxAtStartPar
At this stage, it will be useful to invoke some additional notation that was first introduced in our informal presentation of sets. If \(A\) is any first\sphinxhyphen{}order formula in the language of set theory, \(\forall x \in y \; A\) abbreviates \(\forall x \; (x \in y \rightarrow A)\) and \(\exists x \in y \; A\) abbreviates \(\exists x \; (x \in y \wedge A)\), relativizing the quantifiers as described in \hyperref[\detokenize{first_order_logic:relativization-and-sorts}]{Section \ref{\detokenize{first_order_logic:relativization-and-sorts}}}. The expression \(x \subseteq y\) abbreviates \(\forall z \in x \; (z \in y)\), as you would expect.

\sphinxAtStartPar
The next axiom asserts that for every set \(x\), the power set, \(\mathcal{P}(x)\) exists.
\begin{equation*}
\begin{split}\text{Power Set:} \;\; \forall x \; \exists y \; \forall z \; (z \in y \leftrightarrow z \subseteq x)\end{split}
\end{equation*}
\sphinxAtStartPar
We have begun to populate the universe with basic set constructions. It is the next axiom, however, that gives set theory its remarkable flexibility. Properly speaking, it is not a single axiom, but a \sphinxstyleemphasis{schema}, an infinite family of axioms given by a single template. The schema is meant to justify set\sphinxhyphen{}builder notation \(\{ w \mid \ldots \}\) that was ubiquitous in \hyperref[\detokenize{sets:sets}]{Chapter \ref{\detokenize{sets:sets}}}. The first question we need to address is what we are allowed to write in place of the ellipsis. In our informal presentation of set theory, we said that one can define a set using any property, but that only prompts the question here as to what counts as a “property.” Axiomatic set theory provides a simple but powerful answer: we can use any first\sphinxhyphen{}order formula in the language of set theory.

\sphinxAtStartPar
Another concern centers around Russell’s paradox, as discussed in \hyperref[\detokenize{sets:elementary-set-theory}]{Section \ref{\detokenize{sets:elementary-set-theory}}}. Any theory that allows us to define the set \(\{ w \mid w \notin w \}\) is inconsistent, since if we call this set \(z\), we can show \(z \in z\) if and only if \(z \notin z\), which is a contradiction. Once again, set theory offers a simple and elegant solution: for any formula \(A(z)\) and set \(y\), we can instead form the set \(\{ w \in y \mid A(w) \}\), consisting of the elements of \(y\) that satisfy \(A\). In other words, we have to first use the other axioms of set theory to form a set \(y\) that is big enough to include all the elements that we want to consider, and then use the formula \(A\) to pick out the ones we want.

\sphinxAtStartPar
The axiom schema we want is called \sphinxstyleemphasis{separation}, because we use it to separate the elements we want from those in a bigger collection.
\begin{equation*}
\begin{split}\text{Separation:} \;\; \forall x_1, x_2, \ldots, x_n, y \; \exists z \; \forall w \; (w \in z \leftrightarrow w \in y \wedge A(w,x_1, x_2, \ldots, x_n))\end{split}
\end{equation*}
\sphinxAtStartPar
Here, \(A\) can be any formula, and the list of variables \(x_1, \ldots, x_n\) that are shown indicate that the formula \(A\) can have some parameters, in which case the set we form depends on these values. For example, in ordinary mathematics, given a number \(m\) we can form the set \(\{ n \in \mathbb{N} \mid \mathit{prime}(n) \wedge n > m\}\). In this example, the description involves \(m\) and \(n\), and the set so defined depends on \(m\).

\sphinxAtStartPar
We could use the separation axiom to simplify the previous axioms. For example, as long as we know that \sphinxstyleemphasis{any} set \(x\) exists, we can define the empty set as \(\{ y \in x \mid \bot \}\). Similarly, in the pairing axiom, it is enough to assert that there is a set that contains \(x\) and \(y\) as elements, because then we can use separation to carve out the set whose elements are exactly \(x\) and \(y\).

\sphinxAtStartPar
These are only the first six axioms of set theory; we have four more to go. But these axioms alone provide a foundation for reasoning about sets, relations, and functions, as we did in \hyperref[\detokenize{sets:sets}]{Chapter \ref{\detokenize{sets:sets}}}, \hyperref[\detokenize{relations:relations}]{Chapter \ref{\detokenize{relations:relations}}}, and \hyperref[\detokenize{functions:functions}]{Chapter \ref{\detokenize{functions:functions}}}. For example, we have already defined the union operation, and we can define set intersection \(x \cap y\) as \(\{ z \in x \cup y \mid z \in x \wedge z \in y \}\).  We cannot define arbitrary set complements; for example, the exercises ask you to show that in set theory we can prove that there is no set that contains all sets, and so the complement of the empty set does not exist. But given any two sets \(x\) and \(y\), we can define their difference \(x \setminus y\) as \(\{ z \in x \mid z \notin y \}\). The exercises below ask you to show that we can also define indexed unions and intersections, once we have developed the notion of a function.

\sphinxAtStartPar
We would like to define a binary relation between two sets \(x\) and \(y\) to be a subset of \(x \times y\), but we first have to define the cartesian product \(x \times y\). Remember that in \hyperref[\detokenize{sets:cartesian-product-and-power-set}]{Section \ref{\detokenize{sets:cartesian-product-and-power-set}}} we defined the ordered pair \((u, v)\) to be the set \(\{ \{ u \}, \{ u, v \} \}\). As a result, we can use the separation axiom to define
\begin{equation*}
\begin{split}x \times y = \{ z \in \ldots \mid \exists u \in x \; \exists v \in y \; (z = (u, v)) \}\end{split}
\end{equation*}
\sphinxAtStartPar
provided we can prove the existence of a set big enough to fill the “….” In the exercises below, we ask you to show that the set \(\mathcal P (\mathcal P (x \cup y))\) contains all the relevant ordered pairs. A binary relation \(r\) on \(x\) and \(y\) is then just a subset of \(x \times y\), where we interpret \(r(u, v)\) as \((u, v) \in r\). We can think of ordered triples from the sets \(x\), \(y\), \(z\) as elements of \(x \times (y \times z)\) and so on. This gives us ternary relations, four\sphinxhyphen{}place relations, and so on.

\sphinxAtStartPar
Now we can say that a function \(f : x \to y\) is really a binary relation satisfying \(\forall u \in x \; \exists! v \in y \; f(u, v)\), and we write \(f(u) = v\) when \(v\) is the unique element satisfying \(f(u, v)\). A function \(f\) taking arguments from sets \(x\), \(y\), and \(z\) and returning an element of \sphinxtitleref{w} can be interpreted as a function \(f : x \times y \times z \to w\), and so on.

\sphinxAtStartPar
With sets, relations, and functions, we have the basic infrastructure we need to do mathematics. All we are missing at this point are some interesting sets and structures to work with. For example, it would be nice to have a set of natural numbers, \(\mathbb{N}\), with all the properties we expect it to have. So let us turn to that next.


\section{The Axiom of Infinity}
\label{\detokenize{axiomatic_foundations:the-axiom-of-infinity}}
\sphinxAtStartPar
With the axioms we have so far, we can form lots of finite sets, starting with \(\emptyset\) and iterating pairing, union, powerset, and separation constructions. This will give us sets like
\begin{equation*}
\begin{split}\emptyset, \{ \emptyset \}, \{ \{ \emptyset \} \}, \{ \emptyset, \{ \emptyset \} \}, \{ \{ \{ \emptyset \} \} \}, \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
But the axioms so far do not allow us to define sets that are more interesting than these. In particular, none of the axioms gives us an infinite set. So we need a further axiom to tell us that such a set exists.

\sphinxAtStartPar
Remember that in \hyperref[\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}]{Chapter \ref{\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}}} we characterized the natural numbers as a set with a distinguished element, \(0\), and an injective operation \(\mathit{succ}\), satisfying the principles of induction and recursive definition. In set theory, everything is a set, so if we want to represent the natural numbers in that framework, we need to identify them with particular sets. There is a natural choice for \(0\), namely, the empty set, \(\emptyset\). For a successor operation, we will use the function \(\mathit{succ}\) defined by \(\mathit{succ}(x) = x \cup \{ x \}\). The choice is a bit of a hack; the best justification for the definition is that it works. With this definition, the first few natural numbers are as follows:
\begin{equation*}
\begin{split}0 = \emptyset, \;\; 1 = \{ \emptyset \}, \;\; 2 = \{ \emptyset, \{ \emptyset \} \}, \;\; 3 = \{ \emptyset, \{ \emptyset \}, \{ \emptyset, \{ \emptyset \} \} \}, \;\; \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
It is more perspicuous to write them as follows:
\begin{equation*}
\begin{split}0 = \emptyset, \;\; 1 = \{ 0 \}, \;\; 2 = \{ 0, 1 \}, \;\; 3 = \{ 0, 1, 2 \}, \;\; 4 = \{ 0, 1, 2, 3 \}, \;\; \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
In general, \(n+1\) is represented by the set \(\{ 0, 1, \ldots, n \}\), in which case, \(m \in n\) is the same as \(m < n\). This is just an incidental property of our encoding, but it is a rather charming one.

\sphinxAtStartPar
Recall from \hyperref[\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}]{Chapter \ref{\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}}} that we can characterize the set of natural numbers as follows:
\begin{itemize}
\item {} 
\sphinxAtStartPar
There is an element \(0 \in \mathbb{N}\) and there is an injective function \(\mathit{succ} : \mathbb{N} \to \mathbb{N}\), with the additional property that \(\mathit{succ}(x) \ne 0\) for any \(x\) in \(\mathbb{N}\).

\item {} 
\sphinxAtStartPar
The set \(\mathbb{N}\) satisfies the principle of induction: if \(x\) is a subset of \(\mathbb{N}\) that contains \(0\) and is closed under \(\mathit{succ}\) (that is, whenever \(z\) is in \(\mathbb{N}\), so is \(\mathit{succ}\)), then \(x = \mathbb{N}\).

\end{itemize}

\sphinxAtStartPar
We have already settled on the definitions of \(0\) and \(\mathit{succ}\), but we don’t yet have any set that contains the first and is closed under applying the second. The axiom of infinity asserts precisely that there exists such a set.
\begin{equation*}
\begin{split}\text{Infinity:} \;\; \exists x \; (\emptyset \in x \wedge \forall y \; (y \in x \rightarrow y \cup \{ y \} \in x))\end{split}
\end{equation*}
\sphinxAtStartPar
Say a set \(x\) is \sphinxstyleemphasis{inductive} if it satisfies the property after the existential quantifier, namely, that it contains the empty set and is closed under our successor operation. Notice that the set of natural numbers, which we are still trying to define formally, has this property. The axiom of infinity asserts the existence of \sphinxstyleemphasis{some} inductive set, but not necessarily the natural numbers themselves; an inductive set can have other things in it as well. In a sense, the principle of induction says that the natural numbers is the \sphinxstyleemphasis{smallest} inductive set. So we need a way to separate that set from the one asserted to exist by the axiom of infinity.

\sphinxAtStartPar
Let \(x\) be any inductive set, as asserted to exist by the axiom of infinity. Let
\begin{equation*}
\begin{split}y = \bigcap \{ z \subseteq x \mid \mbox{$z$ is inductive} \}.\end{split}
\end{equation*}
\sphinxAtStartPar
Here \(z \subseteq x\) can also be written \(z \in \mathcal P(x)\), so the inside set exists by the separation axiom. According to this definition, \(y\) is the intersection of every inductive subset of \(x\), so an element \(w\) is in \(y\) if and only if \(w\) is in every inductive subset of \(x\). We claim that \(y\) itself is inductive. First, we have \(\emptyset \in y\), since the empty set is an element of every inductive set. Next, suppose \(w\) is in \(y\). Then \(w\) is in every inductive subset of \(x\). But since every inductive set is closed under successor, \(\mathit{succ}(w)\) is in every inductive subset of \(x\). So \(\mathit{succ}(w)\) is in the intersection of all inductive subsets of \(x\)—which is \(y\)!

\sphinxAtStartPar
It quickly follows that \(y\) is a subset of \sphinxstyleemphasis{every} inductive set. To see this, suppose that \(z\) is inductive. You can check that \(z \cap x\) is inductive, and thus \(y \subseteq z \cap x \subseteq z\).

\sphinxAtStartPar
The more interesting point is that \(y\) also satisfies the principle of induction. To see this, suppose \(u \subseteq y\) contains the empty set and is closed under \(\mathit{succ}\). Then \(u\) is inductive, and since \(y\) is a subset of every inductive set, we have \(y \subseteq u\). Since we assumed \(u \subseteq y\), we have \(u = y\), which is what we want.

\sphinxAtStartPar
To summarize, then, we have proved the existence of a set that contains \(0\) and is closed under a successor operation and satisfies the induction axiom. Moreover, there is only one such set: if \(y_1\) and \(y_2\) both have this property, then so does \(y_1 \cap y_2\), and by the induction principle, this intersection has to be equal to both \(y_1\) and \(y_2\), in which case \(y_1\) and \(y_2\) are equal. It then makes sense to call the unique set with these properties the \sphinxstyleemphasis{natural numbers}, and denote it by the symbol \(\mathbb{N}\).

\sphinxAtStartPar
There is only one piece of the puzzle missing. It is clear from the definition that \(0\) is not the successor of any number, but it is not clear that the successor function is injective. We can prove that by first noticing that the natural numbers, as we have defined them, have a peculiar property: if \(z\) is a natural number, \(y\) is an element of \(z\), and \(x\) is an element of \(y\), then \(x\) is an element of \(z\). This says exactly that the \(\in\) relation is transitive on natural numbers, which is not surprising, since we have noted that \(\in\) on the natural numbers, under our representation, coincides with \(<\). To prove this claim formally, say that a set \(z\) is \sphinxstyleemphasis{transitive} if it has the property just mentioned, namely, that every element of an element of \(z\) is an element of \sphinxtitleref{z}. This is equivalent to saying that for every \(y \in z\), we have \(y \subseteq z\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Lemma.} Every natural number is transitive.

\sphinxAtStartPar
\sphinxstylestrong{Proof.} By induction on the natural numbers. Clearly, \(\emptyset\) is transitive. Suppose \(x\) is transitive, and suppose \(y \in \mathit{succ}(x)\) and \(z \in y\). Since \(\mathit{succ}(x) = x \cup \{ x \}\), we have \(y \in x\) or \(y \in \{x\}\). If \(y \in x\), then by the inductive hypothesis, we have \(z \in x\), and hence \(z \in \mathit{succ}(x)\). Otherwise, we have \(y \in \{ x \}\), and so \(y = x\). In that case, again we have \(z \in x\), and hence \(z \in \mathit{succ}(x)\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
The next lemma shows that, on transitive sets, union acts like the predecessor operation.


\bigskip\hrule\bigskip


\sphinxAtStartPar
\sphinxstylestrong{Lemma.} If \(x\) is transitive, then \(\bigcup \mathit{succ}(x) = x\).

\sphinxAtStartPar
\sphinxstylestrong{Proof}. Suppose \(y\) is in \(\bigcup \mathit{succ}(x) = \bigcup (x \cup \{ x \})\). Then either \(y \in z\) for some \(z \in x\), or \(y \in x\). In the first case, also have \(y \in x\), since \(x\) is transitive.

\sphinxAtStartPar
Conversely, suppose \(y\) is in \(x\). Then \(y\) is in \(\bigcup \mathit{succ}(x)\), since we have \(x \in \mathit{succ}(x)\).

\sphinxAtStartPar
\sphinxstylestrong{Theorem.} \(\mathit{succ}\) is injective on \(\mathbb{N}\).

\sphinxAtStartPar
\sphinxstylestrong{Proof.} Suppose \(x\) and \(y\) are in \(\mathbb{N}\), and \(\mathit{succ}(x) = \mathit{succ}(y)\). Then \(x\) and \(y\) are both transitive, and we have \(x = \bigcup \mathit{succ}(x) = \bigcup \mathit{succ}(y) = y\).


\bigskip\hrule\bigskip


\sphinxAtStartPar
With that, we are off and running. Although we will not present the details here, using the principle of induction we can justify the principle of recursive definition. We can then go on to define the basic operations of arithmetic and derive their properties, as done in \hyperref[\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}]{Chapter \ref{\detokenize{the_natural_numbers_and_induction:the-natural-numbers-and-induction}}}. We can go on to define the integers, the rational numbers, and the real numbers, as described in Chapter \hyperref[\detokenize{the_real_numbers:the-real-numbers}]{Chapter \ref{\detokenize{the_real_numbers:the-real-numbers}}}, and to develop subjects like number theory and combinatorics, as described in Chapters \hyperref[\detokenize{elementary_number_theory:elementary-number-theory}]{Chapter \ref{\detokenize{elementary_number_theory:elementary-number-theory}}} and \hyperref[\detokenize{combinatorics:combinatorics}]{Chapter \ref{\detokenize{combinatorics:combinatorics}}}. In fact, it seems that any reasonable branch of mathematics can be developed formally on the basis of axiomatic set theory. There are pitfalls, for example, having to do with large collections: for example, just as it is inconsistent to postulate the existence of a set of all sets, in the same way, there is no collection of all partial orders, or all groups. So when interpreting some mathematical claims, care has to be taken in some cases to restrict to sufficiently large collections of such objects. But this rarely amounts to more than careful bookkeeping, and it is a remarkable fact that, for the most part, the axioms of set theory are flexible and powerful enough to justify most ordinary mathematical constructions.


\section{The Remaining Axioms}
\label{\detokenize{axiomatic_foundations:the-remaining-axioms}}\label{\detokenize{axiomatic_foundations:id3}}
\sphinxAtStartPar
The seven axioms we have seen are quite powerful, and suffice to represent large portions of mathematics. We discuss the remaining axioms of Zermelo\sphinxhyphen{}Fraenkel set theory here.

\sphinxAtStartPar
So far, none of the axioms we have seen rule out the possibility that a set \(x\) can be an element of itself, that is, that we can have \(x \in x\). The following axiom precludes that.
\begin{equation*}
\begin{split}\text{Foundation} \;\; \forall x \; (\exists y \; y \in x \to \exists y \in x \; \forall z \in x \; z \notin y)))\end{split}
\end{equation*}
\sphinxAtStartPar
The axiom says that if \(x\) is a nonempty set, there is an element \(y\) of \(x\) with the property that no element of \(y\) is again an element of \(x\). This implies we cannot have a descending chain of sets, each one an element of the one before:
\begin{equation*}
\begin{split}x_1 \ni x_2 \ni x_3 \ni \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
If we apply the axiom of foundation to the set \(\{x_1, x_2, x_3, \ldots\}\), we find that some element \(x_i\) does not contain any others, which is only possible if the sequence has terminated with \(x_i\). In other words, the axiom implies (and is in fact equivalent to) the statement that the elementhood relation is \sphinxstyleemphasis{well founded}, which explains the name.

\sphinxAtStartPar
The axioms listed in the previous section tell a story of how sets come to be: we start with the empty set, and keep applying constructions like power set, union, and separation, to build more sets. Set theorists often imagine the hierarchy of sets as forming a big V, with the empty set at the bottom and a set at any higher level comprising, as its elements, sets that appear in levels below. In a precise sense (which we will not spell out here), the axiom of foundation says that every set arises in such a way.

\sphinxAtStartPar
Now consider the following sequence of sets:
\begin{equation*}
\begin{split}\mathbb{N}, \;\; \mathcal P(\mathbb{N}), \;\; \mathcal P(\mathcal P(\mathbb{N}), \;\; \mathcal P (\mathcal P (\mathcal P (\mathbb{N}))), \;\; \ldots\end{split}
\end{equation*}
\sphinxAtStartPar
It is consistent with all the axioms we have seen so far that every set in the mathematical universe is an element of one of these. That still gives us a lot of sets, but, since we have described that sequence, we can just as well imagine a set that contains all of them:
\begin{equation*}
\begin{split}\{ \mathbb{N}, \;\; \mathcal P(\mathbb{N}), \;\; \mathcal P(\mathcal P(\mathbb{N}), \;\; \mathcal P (\mathcal P (\mathcal P (\mathbb{N}))), \;\; \ldots \}.\end{split}
\end{equation*}
\sphinxAtStartPar
The following axiom implies the existence of such a set.
\begin{equation*}
\begin{split}\text{Replacement:} \;\; \forall x, y_1, \ldots, y_n \;\; (\forall z \in x \; \exists ! w \; A(z, w, y_1, \ldots, y_n) \rightarrow \\
\exists u \; \forall w \; (w \in u \leftrightarrow \exists z \in x \; A(z, w, y_1, \ldots, y_n)))\end{split}
\end{equation*}
\sphinxAtStartPar
Like the axiom of separation, this axiom is really a schema, which is to say, a separate axiom for each formula \(A\). Here, too, the variables \(y_1, y_2, \ldots, y_n\) are free variables that can occur in \(A\). To understand the axiom, it is easiest to think of them as parameters that are fixed in the background, and then ignore them. The axioms says that if, for every \(z\) in \(x\) there is a unique \(w\) satisfying \(A(z,w)\), then there is a single set, \(u\), that consists of the \(w\) values corresponding to every such \(z\). In other words, if you think of \(A\) as a function whose domain is \(x\), the axiom asserts that the range of that function exists. In the example above, \(x\) is the natural numbers, and \(A(z, w)\) says that \(w\) is the \(z\)\sphinxhyphen{}fold iterate of the power set of the natural numbers.

\sphinxAtStartPar
The nine axioms we have listed so far comprise what is known as \sphinxstyleemphasis{Zermelo\sphinxhyphen{}Fraenkel Set Theory}. There is on additional axiom, the axiom of choice, which is usually listed separately for historical reasons: it was once considered controversial, and in the early days, mathematicians considered it important to keep track of whether the axiom was actually used in a proof. There are many equivalent formulations, but this one is one of the most straightforward.
\begin{equation*}
\begin{split}\text{Choice:} \;\; \forall x \; (\emptyset \notin x \rightarrow \exists f : x \to \bigcup x \; \forall y \in x \; f(y) \in y)\end{split}
\end{equation*}
\sphinxAtStartPar
The axiom says that for any collection \(x\) of nonempty sets, there is a function \(f\) that selects an element from each one. We used this axiom, informally, in \hyperref[\detokenize{functions:injective-surjective-and-bijective-functions}]{Section \ref{\detokenize{functions:injective-surjective-and-bijective-functions}}} to show that every surjective function has a right inverse. In fact, this last statement can be shown to be equivalent to the axiom of choice on the basis of the other axioms.

\sphinxAtStartPar
To summarize, then, the axioms of Zermelo\sphinxhyphen{}Fraenkel Set Theory with the axiom of choice are as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Extensionality:
\begin{quote}
\begin{equation*}
\begin{split}\forall x, y \; (x = y \leftrightarrow \forall z (z \in x \leftrightarrow z \in y))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Empty set:
\begin{quote}
\begin{equation*}
\begin{split}\exists x \; \forall y \; y \notin x\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Pairing:
\begin{quote}
\begin{equation*}
\begin{split}\forall x, y \; \exists z \; \forall w \; (w \in z \leftrightarrow w = x \vee w = y)\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Union:
\begin{quote}
\begin{equation*}
\begin{split}\forall x \; \exists y \; \forall z \; (z \in y \leftrightarrow \exists w \; (w \in x \wedge z \in w))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Power set:
\begin{quote}
\begin{equation*}
\begin{split}\forall x \; \exists y \; \forall z \; (z \in y \leftrightarrow z \subseteq y)\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Separation:
\begin{quote}
\begin{equation*}
\begin{split}\forall x_1, x_2, \ldots, x_n, y \; \exists z \; \forall w \; (w \in z \leftrightarrow w \in y \wedge A(w,x_1, x_2, \ldots, x_n))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Infinity:
\begin{quote}
\begin{equation*}
\begin{split}\exists x \; (\emptyset \in x \wedge \forall y \; (y \in x \rightarrow y \cup \{ y \} \in x))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Foundation:
\begin{quote}
\begin{equation*}
\begin{split}\forall x \; (\exists y \; y \in x \to \exists y \in x \; \forall z \in x \; z \notin y)))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Replacement:
\begin{quote}
\begin{equation*}
\begin{split}\forall x, y_1, \ldots, y_n \;\; (\forall z \in x \; \exists ! w \; A(z, w, y_1, \ldots, y_n) \rightarrow \\
\exists u \; \forall w \; (w \in u \leftrightarrow \exists z \in x \; A(z, w, y_1, \ldots, y_n)))\end{split}
\end{equation*}\end{quote}

\item {} 
\sphinxAtStartPar
Choice:
\begin{quote}
\begin{equation*}
\begin{split}\forall x \; (\emptyset \notin x \rightarrow \exists f : x \to \bigcup x \; \forall y \in x \; f(y) \in y)\end{split}
\end{equation*}\end{quote}

\end{enumerate}


\section{Type Theory}
\label{\detokenize{axiomatic_foundations:type-theory}}
\sphinxAtStartPar
As a foundation for mathematics, Zermelo\sphinxhyphen{}Fraenkel set theory is appealing. The underlying logic, first\sphinxhyphen{}order logic, provides the basic logical framework for quantifiers and the logical connectives. On top of that, the theory describes a single, intuitively natural concept, that of a set of elements. The axioms are plausible eminently reasonable. It is remarkable that virtually all of modern mathematics can be reduced to such simple terms.

\sphinxAtStartPar
There are other foundations on offer, however. These tend to be largely inter\sphinxhyphen{}interpretable with set theory. After all, set\sphinxhyphen{}theoretic language is now ubiquitous in everyday mathematics, so any reasonable foundation should be able to make sense of such language. On the other hand, we have already noted that set theory is remarkably expressive and robust, and so it should not be surprising that other foundational approaches can often be understood in set\sphinxhyphen{}theoretic terms.

\sphinxAtStartPar
This is, in particular, true of \sphinxstyleemphasis{dependent type theory}, which is the basis of the Lean theorem prover. The syntax of type theory is more complicated than that of set theory. In set theory, there is only one kind of object; officially, everything is a set. In contrast, in type theory, every well\sphinxhyphen{}formed expression in Lean has a \sphinxstyleemphasis{type}, and there is a rich vocabulary of defining types.

\sphinxAtStartPar
In fact, Lean is based on a version of an axiomatic framework known as the \sphinxstyleemphasis{Calculus of Inductive Constructions}, which provides all of the following:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A hierarchy of \sphinxstyleemphasis{type universes}, \sphinxcode{\sphinxupquote{Type 0}}, \sphinxcode{\sphinxupquote{Type 1}}, \sphinxcode{\sphinxupquote{Type 2}}, … and a special type \sphinxcode{\sphinxupquote{Prop}}. The expression \sphinxcode{\sphinxupquote{Type}} abbreviates \sphinxcode{\sphinxupquote{Type 0}}, and saying \sphinxcode{\sphinxupquote{T : Type}} can be interpreted as saying that \sphinxcode{\sphinxupquote{T}} is a datatype. The type \sphinxcode{\sphinxupquote{Prop}} is the type of propositions.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Dependent function types} \sphinxcode{\sphinxupquote{Π x : A, B x}}. An element \sphinxcode{\sphinxupquote{f}} of this type is a function which maps any element \sphinxcode{\sphinxupquote{a}} of type \sphinxcode{\sphinxupquote{A}} to an element \sphinxcode{\sphinxupquote{f a}} of type \sphinxcode{\sphinxupquote{B a}}. The fact that the type of the output depends on the type of the input is what makes the function “dependent.” In the case where the output type does not depend on the input, we have the simple function type \sphinxcode{\sphinxupquote{A → B}}.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Inductive types}, like the natural numbers, specified by \sphinxstyleemphasis{constructors}, like zero and successor. Each such type comes with principles of induction and recursion.

\end{itemize}

\sphinxAtStartPar
These constructions account for both the underlying logic of assertions (that is, the propositions) as well as the objects of the universe, which are elements of the ordinary types.

\sphinxAtStartPar
It is straightforward to interpret type theory in set theory, since we can view each type as a set. The type universes are simply large collections of sets, and dependent function types and inductive types can be explained in terms of set\sphinxhyphen{}theoretic constructions. We can view \sphinxcode{\sphinxupquote{Prop}} as the set \(\{ \top, \bot \}\) of truth values, just as we did when we described truth\sphinxhyphen{}table semantics for propositional logic.

\sphinxAtStartPar
Given this last fact, why not just use set theory instead of type theory for interactive theorem proving? Some interactive theorem provers do just that. But type theory has some advantages:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The fact that the rules for forming expressions are so rigid makes it easier for the system to recognize typographical errors and provide useful feedback. In type theory, if \sphinxcode{\sphinxupquote{f}} has type \sphinxcode{\sphinxupquote{ℕ → ℕ}} it can be applied only to a natural number, and a theorem prover can flag an error if the argument has the wrong type. In set theory, anything can be applied to anything, whether or not doing so really makes sense.

\item {} 
\sphinxAtStartPar
Again, because the rules for forming expressions are so rigid, the system can infer useful information from the components of an expression, whereas set theory would require us to make such information explicit. For example, with \sphinxcode{\sphinxupquote{f}} as above, a theorem prover can infer that a variable \sphinxcode{\sphinxupquote{x}} in \sphinxcode{\sphinxupquote{f x}} should have type \sphinxcode{\sphinxupquote{ℕ}}, and that the resulting expression again has type \sphinxcode{\sphinxupquote{ℕ}}. In set theory, \(x \in \mathbb{N}\) has to be stated as an explicit hypothesis, and \(f(x) \in \mathbb{N}\) is then a theorem.

\item {} 
\sphinxAtStartPar
By encoding propositions as certain kinds of types, we can use the same language for defining mathematical objects and writing mathematical proofs. For example, we can apply a function to an argument in the same way we apply a theorem to some hypotheses.

\item {} 
\sphinxAtStartPar
Expressions in a sufficiently pure part of dependent type theory have a computational interpretation, so, for example, the logical framework tells us how to evaluate the factorial function, given its definition. In set theory, the computational interpretation is specified independently, after the fact.

\end{itemize}

\sphinxAtStartPar
These facts hark back to the separation of concerns that we raised in \hyperref[\detokenize{introduction:introduction}]{Chapter \ref{\detokenize{introduction:introduction}}}: different axiomatic foundations provide different idealized descriptions of mathematical activity, and can be designed to serve different purposes. If you want a clean, simple theory that accounts for the vast majority of mathematical proof, set theory is hard to beat. If you are looking for a foundation that makes computation central or takes the notion of a function rather than a set as basic, various flavors of type theory have their charms. For interactive theorem proving, pragmatic issues regarding implementation and usability come into play. What is important to recognize is that what all these idealized descriptions have in common is that they are all designed to model important aspects of mathematical language and proof. Our goal here has been to help you reflect on those features of mathematical language and proof that give mathematics its special character, and to help you better understand how they work.


\section{Exercises}
\label{\detokenize{axiomatic_foundations:exercises}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Use an argument similar Russell’s paradox to show that there is no “set of all sets,” that is, there is no set that contains every other set as an element.

\item {} 
\sphinxAtStartPar
Suppose \(x\) is a nonempty set, say, containing an element \(y\). Use the axiom of separation to show that the set \(\bigcap x\) exists. (Remember that something is an element of \(\bigcap x\) if it is an element of every element of \(x\).)

\item {} 
\sphinxAtStartPar
Justify the claim in \hyperref[\detokenize{axiomatic_foundations:basic-axioms-for-sets}]{Section \ref{\detokenize{axiomatic_foundations:basic-axioms-for-sets}}} that every element of \(x \times y\) is an element of \(\mathcal P (\mathcal P (x \cup y))\).

\item {} 
\sphinxAtStartPar
Given a set \(x\) and a function \(A : x \to y\), use the axioms of set theory to prove the existence of \(\bigcup_{i \in x} A(i)\).

\end{enumerate}


\chapter{Appendix: Natural Deduction Rules}
\label{\detokenize{nd_quickref:appendix-natural-deduction-rules}}\label{\detokenize{nd_quickref::doc}}
\sphinxAtStartPar
\sphinxstyleemphasis{Implication:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1 \;\; \mathord{\to}\mathrm{I}}
\UIM{A \to B}
\DP
\quad\quad
\AXM{A \to B}
\AXM{A}
\RLM{\mathord{\to}\mathrm{E}}
\BIM{B}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Conjunction:}



\begin{quote}
\AXM{A}
\AXM{B}
\RLM{\mathord{\wedge}\mathrm{I}}
\BIM{A \wedge B}
\DP
\quad\quad
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_l}}
\UIM{A}
\DP
\quad\quad
\AXM{A \wedge B}
\RLM{\mathord{\wedge}\mathrm{E_r}}
\UIM{B}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Negation:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1 \;\; \neg \mathrm{I}}
\UIM{\neg A}
\DP
\quad\quad
\AXM{\neg A}
\AXM{A}
\RLM{\neg \mathrm{E}}
\BIM{\bot}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Disjunction:}



\begin{quote}
\AXM{A}
\RLM{\mathord{\vee}\mathrm{I_l}}
\UIM{A \vee B}
\DP
\quad\quad
\AXM{B}
\RLM{\mathord{\vee}\mathrm{I_r}}
\UIM{A \vee B}
\DP
\quad\quad
\AXM{A \vee B}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{C}
\RLM{1 \;\; \mathord{\vee}\mathrm{E}}
\TIM{C}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Truth and falsity:}



\begin{quote}
\AXM{\bot}
\RLM{\bot \mathrm{E}}
\UIM{A}
\DP
\quad\quad
\AXM{}
\RLM{\top \mathrm{I}}
\UIM{\top}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Bi\sphinxhyphen{}implication:}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{A}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\AXM{}
\RLM{1}
\UIM{B}
\noLine
\UIM{\vdots}
\noLine
\UIM{A}
\RLM{1 \;\; \mathord{\leftrightarrow}\mathrm{I}}
\BIM{A \leftrightarrow B}
\DP
\AXM{A \leftrightarrow B}
\AXM{A}
\RLM{\mathord{\leftrightarrow}\mathrm{E}_l}
\BIM{B}
\DP
\quad\quad
\AXM{A \leftrightarrow B}
\AXM{B}
\RLM{\mathord{\leftrightarrow}\mathrm{E}_r}
\BIM{A}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{Reductio ad absurdum (proof by contradiction):}



\begin{quote}
\AXM{}
\RLM{1}
\UIM{\neg A}
\noLine
\UIM{\vdots}
\noLine
\UIM{\bot}
\RLM{1 \;\; \mathrm{RAA}}
\UIM{A}
\DP
\end{quote}

\sphinxAtStartPar
\sphinxstyleemphasis{The universal quantifier:}



\begin{quote}
\AXM{A(x)}
\RLM{\mathord{\forall}\mathrm{I}}
\UIM{\fa y A(y)}
\DP
\quad\quad
\AXM{\fa x A(x)}
\RLM{\mathord{\forall}\mathrm{E}}
\UIM{A(t)}
\DP
\end{quote}

\sphinxAtStartPar
In the introduction rule, \(x\) should not be free in any uncanceled hypothesis. In the elimination rule, \(t\) can be any term that does not clash with any of the bound variables in \(A\).

\sphinxAtStartPar
\sphinxstyleemphasis{The existential quantifier:}



\begin{quote}
\AXM{A(t)}
\RLM{\mathord{\exists}\mathrm{I}}
\UIM{\exists  x A(x)}
\DP
\quad\quad
\AXM{\exists  x A(x)}
\AXM{}
\RLM{1}
\UIM{A(y)}
\noLine
\UIM{\vdots}
\noLine
\UIM{B}
\RLM{1 \;\; \mathord{\exists}\mathrm{E}}
\BIM{B}
\DP
\end{quote}

\sphinxAtStartPar
In the introduction rule, \(t\) can be any term that does not clash with any of the bound variables in \(A\). In the elimination rule, \(y\) should not be free in \(B\) or any uncanceled hypothesis.

\sphinxAtStartPar
\sphinxstyleemphasis{Equality:}



\begin{center}
\AXM{}
\RLM{\mathrm{refl}}
\UIM{t = t}
\DP
\quad
\AXM{s = t}
\RLM{\mathrm{symm}}
\UIM{t = s}
\DP
\quad
\AXM{r = s}
\AXM{s = t}
\RLM{\mathrm{trans}}
\BIM{r = t}
\DP
\\
\ \\
\AXM{s = t}
\RLM{\mathrm{subst}}
\UIM{r(s) = r(t)}
\DP
\quad
\AXM{s = t}
\RLM{\mathrm{subst}}
\AXM{P(s)}
\BIM{P(t)}
\DP
\end{center}

\sphinxAtStartPar
Strictly speaking, only \(\mathrm{refl}\) and the second substitution rule are necessary. The others can be derived from them.



\renewcommand{\indexname}{Index}
\printindex
\end{document}